{"namespace": "mistune.toc.add_toc_hook", "type": "function", "project_path": "Text-Processing/mistune", "completion_path": "Text-Processing/mistune/src/mistune/toc.py", "signature_position": [4, 4], "body_position": [23, 44], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function adds a hook to save table of contents (TOC) items into the state.env. It is usually helpful for doc generator.", "Arguments": ":param md: Markdown instance. The instance of the Markdown class.\n:param min_level: Integer. The minimum heading level to include in the TOC.\n:param max_level: Integer. The maximum heading level to include in the TOC.\n:param heading_id: Function. A function to generate heading_id.\n:return: No return values."}, "tests": ["tests/test_hooks.py::TestTocHook::test_customize_heading_id_func"], "indent": 4}
{"namespace": "falcon.inspect.inspect_compiled_router", "type": "function", "project_path": "Internet/falcon", "completion_path": "Internet/falcon/falcon/inspect.py", "signature_position": [204, 204], "body_position": [216, 245], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function inspects a compiled router to return a list of defined routes. It walks through the compiled router and extracts information about the defined routes.", "Arguments": ":param router: CompiledRouter. The router to inspect.\n:return: List[RouteInfo]. A list of RouteInfo objects representing the defined routes."}, "tests": ["tests/test_inspect.py::TestRouter::test_compiled_partial", "tests/test_inspect.py::TestRouter::test_compiled_no_method_map"], "indent": 4}
{"namespace": "authlib.oauth2.rfc6749.util.scope_to_list", "type": "function", "project_path": "Internet/Authlib", "completion_path": "Internet/Authlib/authlib/oauth2/rfc6749/util.py", "signature_position": [15, 15], "body_position": [17, 21], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Convert a space separated string to a list of scopes. It checks if the input is a tuple, list, or set and converts each element to a unicode string. If the input is None, it returns None. Otherwise, it splits the input string by space and returns the list of scopes.", "Arguments": ":param scope: The space separated string of scopes or a tuple, list, or set of scopes or None.\n:return: list[str] or None. The list of scopes. If the input is None, it returns None."}, "tests": ["tests/core/test_oauth2/test_rfc6749_misc.py::OAuth2UtilTest::test_scope_to_list"], "indent": 4}
{"namespace": "datasette.filters.where_filters", "type": "function", "project_path": "Database/datasette", "completion_path": "Database/datasette/datasette/filters.py", "signature_position": [10, 11], "body_position": [12, 40], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "The function is used to handle the \"_where=\" parameter in a request. If the \"_where\" parameter is present in the request parameters, it checks if the user has permission to execute SQL. If no permission is granted, it raises a 403 error. If permission is granted, it adds the values of the \"_where\" parameter to the where_clauses list and generates a separate UI element for each value, which is added to the extra_wheres_for_ui list. Finally, it passes the where_clauses and extra_wheres_for_ui as arguments to the FilterArguments class and returns an inner function.", "Arguments": ":param request: The request object.\n:param database: The database object.\n:param datasette: The datasette object.\n:return: A nested function that processes the \"_where\" query parameter and returns the filter arguments."}, "tests": ["tests/test_filters.py::test_where_filters_from_request"], "indent": 4}
{"namespace": "datasette.utils.initial_path_for_datasette", "type": "function", "project_path": "Database/datasette", "completion_path": "Database/datasette/datasette/utils/__init__.py", "signature_position": [1076, 1076], "body_position": [1078, 1089], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function returns the suggested path for opening the given Datasette instance based on the number of databases and tables it contains. It first checks the number of databases and if there is only one database, it returns the path to that database. If the database contains only one table, it returns the path to that table. If there are multiple databases, it returns the path to the instance.", "Arguments": ":param datasette: Datasette. The Datasette instance for which the path is to be suggested.\n:return: String. The suggested path for opening the Datasette instance."}, "tests": ["tests/test_utils.py::test_initial_path_for_datasette"], "indent": 4}
{"namespace": "kinto.plugins.accounts.views.on_account_created", "type": "function", "project_path": "Internet/kinto", "completion_path": "Internet/kinto/kinto/plugins/accounts/views/__init__.py", "signature_position": [176, 176], "body_position": [177, 190], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function is called when an account is created. It checks if the account validation is enabled in the settings. If it is enabled, the function proceeds to iterate through each impacted object in the event. For each impacted object, it retrieves the account information, which includes the user email, and an activation key. If the activation key is not found (i.e., it is None), the function skips to the next impacted object. Otherwise, the function sends an email to the user using the Emailer class, passing the request object and the account information as arguments to the send_activation method. The email contains a link for the user to activate their account.", "Arguments": ":param event: The event object containing the request and impacted objects.\n:return: No return values."}, "tests": ["tests/plugins/test_accounts.py::AccountValidationCreationTest::test_user_creation_listener"], "indent": 4}
{"namespace": "mongo_connector.doc_managers.formatters.DocumentFlattener.format_document", "type": "method", "project_path": "Database/mongo-doc-manager", "completion_path": "Database/mongo-doc-manager/mongo_connector/doc_managers/formatters.py", "signature_position": [150, 150], "body_position": [151, 170], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function flattens the given document and returns a dictionary with the flattened keys and values. It uses a recursive approach to flatten the document. For example, given a dictionary {\"a\": 2, \"b\": {\"c\": {\"d\": 5}}, \"e\": [6, 7, 8]}, it would output {\"a\": 2, \"b.c.d\": 5, \"e.0\": 6, \"e.1\": 7, \"e.2\": 8}.", "Arguments": ":param self: DocumentFlattener. An instance of the DocumentFlattener class.\n:param document: Dictionary. The document to be flattened.\n:return: Dictionary. The flattened document."}, "tests": ["tests/test_formatters.py::TestFormatters::test_flattener"], "indent": 8}
{"namespace": "bplustree.memory.FileMemory.read_transaction", "type": "method", "project_path": "Database/bplustree", "completion_path": "Database/bplustree/bplustree/memory.py", "signature_position": [167, 168], "body_position": [169, 177], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function creates a read transaction for the FileMemory instance. When the transaction begins ( __enter__ method), it acquires a reader lock, ensuring thread-safe read access to a shared resource. Upon completion or exit of the transaction ( __exit__ method), it releases this reader lock.", "Arguments": ":param self: FileMemory. An instance of the FileMemory class.\n:return: ReadTransaction. The created ReadTransaction instance."}, "tests": ["tests/test_memory.py::test_file_memory_write_transaction"], "indent": 8}
{"namespace": "psd_tools.api.numpy_io.get_pattern", "type": "function", "project_path": "Multimedia/psd-tools", "completion_path": "Multimedia/psd-tools/src/psd_tools/api/numpy_io.py", "signature_position": [105, 105], "body_position": [107, 112], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function gets the pattern array from the input pattern. It first extracts the height and width from the third place and fourth place of the rectangle in the pattern's \"data\" attribute and then creates a pattern array by parsing the data from the channels in the pattern's \"data\" attribute.", "Arguments": ":param pattern: Pattern. The input pattern from which the pattern array is to be extracted.\n:return: Numpy array. The pattern array extracted from the input pattern."}, "tests": ["tests/psd_tools/api/test_numpy_io.py::test_get_pattern"], "indent": 4}
{"namespace": "arctic.decorators.mongo_retry", "type": "function", "project_path": "Database/arctic-latest", "completion_path": "Database/arctic-latest/arctic/decorators.py", "signature_position": [35, 35], "body_position": [40, 66], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function is a decorator that handles AutoReconnect and OperationFailure errors from PyMongo. It catches all exceptions and logs them if the module name contains 'arctic' and finally set the global attribute _retry_count and _in_retry.", "Arguments": ":param f: The function to be decorated.\n:return: The decorated function."}, "tests": ["tests/unit/test_decorators_unit.py::test_mongo_retry_hook_changes", "tests/unit/test_decorators_unit.py::test_retry_nested", "tests/unit/test_decorators_unit.py::test_mongo_retry_fails", "tests/unit/test_decorators_unit.py::test_all_other_exceptions_logged", "tests/unit/test_decorators_unit.py::test_mongo_retry"], "indent": 4}
{"namespace": "arctic.chunkstore.date_chunker.DateChunker.filter", "type": "method", "project_path": "Database/arctic-latest", "completion_path": "Database/arctic-latest/arctic/chunkstore/date_chunker.py", "signature_position": [101, 101], "body_position": [114, 133], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function ensures that the data is properly subset to the range in range_obj. It checks the type of range_obj and converts it to DateRange if it is a tuple or pd.DatetimeIndex. Then, it filters the data based on the Pandas DateRange.", "Arguments": ":param self: DateChunker. An instance of the DateChunker class.\n:param data: DataFrame. The data to be filtered.\n:param range_obj: DateRange or tuple. The range to filter the data.\n:return: DataFrame. The data filtered by range_obj."}, "tests": ["tests/unit/chunkstore/test_date_chunker.py::test_with_tuples", "tests/unit/chunkstore/test_date_chunker.py::test_date_filter_with_pd_date_range", "tests/unit/chunkstore/test_date_chunker.py::test_date_filter", "tests/unit/chunkstore/test_date_chunker.py::test_date_filter_no_index"], "indent": 8}
{"namespace": "mopidy.config.schemas._did_you_mean", "type": "function", "project_path": "Multimedia/Mopidy", "completion_path": "Multimedia/Mopidy/mopidy/config/schemas.py", "signature_position": [6, 6], "body_position": [8, 17], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function suggests the most likely setting based on the Levenshtein distance. It calculates the Levenshtein distance between the input name and each choice, sorts the results, and returns the most likely setting if the distance is less than or equal to 3.", "Arguments": ":param name: String. The input name for which the most likely setting is to be suggested.\n:param choices: List of strings. The list of choices to compare with the input name.\n:return: String. The most likely setting based on the Levenshtein distance, or None if no choices are provided or the distance is greater than 3."}, "tests": ["tests/config/test_schemas.py::DidYouMeanTest::test_suggestions"], "indent": 4}
{"namespace": "fs.wildcard.match_any", "type": "function", "project_path": "System/fs", "completion_path": "System/fs/fs/wildcard.py", "signature_position": [61, 62], "body_position": [76, 78], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function tests if a name matches any of a list of patterns. It returns True if the patterns list is empty.", "Arguments": ":param patterns: Iterable of Text. A list of wildcard patterns, e.g., [\"*.py\", \"*.pyc\"].\n:param name: Text. A filename.\n:return: bool. True if the name matches at least one of the patterns."}, "tests": ["tests/test_wildcard.py::TestFNMatch::test_match_any"], "indent": 4}
{"namespace": "fs.wildcard.imatch_any", "type": "function", "project_path": "System/fs", "completion_path": "System/fs/fs/wildcard.py", "signature_position": [81, 82], "body_position": [96, 98], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function tests if a name matches any of a list of patterns in a case-insensitive manner. It returns True if the patterns list is empty.", "Arguments": ":param patterns: Iterable of Text. A list of wildcard patterns, e.g., [\"*.py\", \"*.pyc\"].\n:param name: Text. A filename.\n:return: bool. True if the name matches at least one of the patterns."}, "tests": ["tests/test_wildcard.py::TestFNMatch::test_match_any"], "indent": 4}
{"namespace": "trailscraper.cloudtrail.parse_records", "type": "function", "project_path": "Security/trailscraper", "completion_path": "Security/trailscraper/trailscraper/cloudtrail.py", "signature_position": [240, 240], "body_position": [242, 243], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function takes a list of JSON records and converts them into Record objects. It uses the _parse_record function to parse each JSON record and then filters out any None values from the parsed records.", "Arguments": ":param json_records: List. A list of JSON records to be parsed.\n:return: List. A list of Record objects parsed from the JSON records."}, "tests": ["tests/cloudtrail/cloudtrail_test.py::test_parse_records_should_ignore_records_that_cant_be_parsed"], "indent": 4}
{"namespace": "trailscraper.s3_download._s3_key_prefixes", "type": "function", "project_path": "Security/trailscraper", "completion_path": "Security/trailscraper/trailscraper/s3_download.py", "signature_position": [22, 22], "body_position": [23, 36], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function generates a list of S3 key prefixes based on the given parameters. It first calculates the delta between the two dates, then generates a list of dates based on the delta. It then creates a list of S3 key prefixes based on the organization IDs, account IDs, regions, and dates.", "Arguments": ":param prefix: String. The prefix for the S3 key.\n:param org_ids: List of Strings. The organization IDs.\n:param account_ids: List of Strings. The account IDs.\n:param regions: List of Strings. The regions.\n:param from_date: Datetime. The start date.\n:param to_date: Datetime. The end date.\n:return: List of Strings. The list of S3 key prefixes."}, "tests": ["tests/s3/key_prefixes_test.py::test_should_generate_prefixes_for_multiple_days", "tests/s3/key_prefixes_test.py::test_should_generate_prefixes_for_one_day", "tests/s3/key_prefixes_test.py::test_should_generate_prefixes_for_multiple_accounts_on_one_day", "tests/s3/key_prefixes_test.py::test_should_generate_prefixes_for_regions", "tests/s3/key_prefixes_test.py::test_should_generate_prefixes_for_one_day_when_datetime_contains_time"], "indent": 4}
{"namespace": "pycoin.crack.ecdsa.crack_secret_exponent_from_k", "type": "function", "project_path": "Security/pycoin", "completion_path": "Security/pycoin/pycoin/crack/ecdsa.py", "signature_position": [2, 2], "body_position": [6, 7], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Given a signature of a signed value and a known k, this function returns the secret exponent for RSA.", "Arguments": ":param generator: The generator.\n:param signed_value: The signed value.\n:param sig: The signature.\n:param k: The known k value.\n:return: The secret exponent."}, "tests": ["tests/crack_sig_test.py::CrackSigTest::test_crack_secret_exponent_from_k"], "indent": 4}
{"namespace": "pycoin.crack.ecdsa.crack_k_from_sigs", "type": "function", "project_path": "Security/pycoin", "completion_path": "Security/pycoin/pycoin/crack/ecdsa.py", "signature_position": [10, 10], "body_position": [29, 34], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function calculates the value of k from the given signatures and values in RSA domain.", "Arguments": ":param generator: The generator value.\n:param sig1: The first signature.\n:param val1: The first value.\n:param sig2: The second signature.\n:param val2: The second value.\n:return: The value of k."}, "tests": ["tests/crack_sig_test.py::CrackSigTest::test_crack_k_from_sigs"], "indent": 4}
{"namespace": "pycoin.message.make_parser_and_packer.standard_streamer", "type": "function", "project_path": "Security/pycoin", "completion_path": "Security/pycoin/pycoin/message/make_parser_and_packer.py", "signature_position": [209, 209], "body_position": [214, 217], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Create a satoshi_streamer, which parses and packs using the bitcoin protocol (mostly the custom way arrays and integers are parsed and packed) through register array length parsing function and register other parsing functions.", "Arguments": ":param parsing_functions: The parsing functions to be registered with the streamer.\n:param parse_satoshi_int: The function to parse satoshi integers. Defaults to parse_satoshi_int.\n:return: Streamer. The created streamer instance."}, "tests": ["tests/message_test.py::MessageTest::test_make_parser_and_packer"], "indent": 4}
{"namespace": "tools.cgrep.get_nets", "type": "function", "project_path": "Security/capirca", "completion_path": "Security/capirca/tools/cgrep.py", "signature_position": [380, 380], "body_position": [390, 394], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function retrieves a list of all networks that are inside a network object. It iterates through the input network objects, retrieves the networks inside each object from the network and service definitions, and returns the results.", "Arguments": ":param objects: network objects. List of network objects for which the networks need to be retrieved.\n:param db: network and service definitions. The database containing network and service definitions.\n:return: List. List of tuples containing the network object and the corresponding network inside it."}, "tests": ["tests/lib/cgrep_test.py::CgrepTest::test_token_to_ips", "tests/lib/cgrep_test.py::CgrepTest::test_token_to_ip_fail"], "indent": 2}
{"namespace": "tools.cgrep.get_ports", "type": "function", "project_path": "Security/capirca", "completion_path": "Security/capirca/tools/cgrep.py", "signature_position": [447, 447], "body_position": [458, 462], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function gets the ports and protocols defined in a service group. It iterates through each service in the service group and retrieves the corresponding port and protocol from the network and service definitions.", "Arguments": ":param svc_group: List of strings. A list of strings for each service group.\n:param db: Network and service definitions.\n:return: List of tuples. A list of tuples for each service defined, in the format: (service name, \"<port>/<protocol>\")."}, "tests": ["tests/lib/cgrep_test.py::CgrepTest::test_svc_to_port_fail", "tests/lib/cgrep_test.py::CgrepTest::test_svc_to_port"], "indent": 2}
{"namespace": "tools.cgrep.compare_ip_token", "type": "function", "project_path": "Security/capirca", "completion_path": "Security/capirca/tools/cgrep.py", "signature_position": [426, 426], "body_position": [436, 444], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function checks if a network IP is contained in a network object. It iterates through the list of IPs and checks if each IP is in the network object. It then returns a string stating the results.", "Arguments": ":param options: The options sent to the script.\n:param db: Network and service definitions.\n:return: String. The end-user string stating the results."}, "tests": ["tests/lib/cgrep_test.py::CgrepTest::test_ip_in_token", "tests/lib/cgrep_test.py::CgrepTest::test_ipv6_in_token", "tests/lib/cgrep_test.py::CgrepTest::test_ipv6_in_token_fail", "tests/lib/cgrep_test.py::CgrepTest::test_ip_in_token_fail"], "indent": 2}
{"namespace": "tools.cgrep.get_services", "type": "function", "project_path": "Security/capirca", "completion_path": "Security/capirca/tools/cgrep.py", "signature_position": [465, 465], "body_position": [476, 482], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function finds any services that include a specific port/protocol pair. It retrieves the port and protocol from the options and then searches the network and service definitions to find services containing this pair.", "Arguments": ":param options: The options sent to the script.\n:param db: Network and service definitions.\n:return: Tuple. The port, protocol, and a list of services containing this pair."}, "tests": ["tests/lib/cgrep_test.py::CgrepTest::test_get_port_parents_range_udp", "tests/lib/cgrep_test.py::CgrepTest::test_get_port_parents", "tests/lib/cgrep_test.py::CgrepTest::test_get_port_parents_fail", "tests/lib/cgrep_test.py::CgrepTest::test_get_port_parents_range_tcp"], "indent": 2}
{"namespace": "faker.utils.decorators.slugify", "type": "function", "project_path": "Software-Development/Faker", "completion_path": "Software-Development/Faker/faker/utils/decorators.py", "signature_position": [9, 10], "body_position": [11, 14], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function is a decorator that takes a function and returns a new function. The new function calls the original function and then slugifies the result.", "Arguments": ":param fn: Callable. The original function to be decorated.\n:return: Callable. The decorated function."}, "tests": ["tests/test_factory.py::FactoryTestCase::test_slugify"], "indent": 4}
{"namespace": "faker.utils.decorators.slugify_domain", "type": "function", "project_path": "Software-Development/Faker", "completion_path": "Software-Development/Faker/faker/utils/decorators.py", "signature_position": [17, 18], "body_position": [19, 22], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function is a decorator that takes a function and returns a new function. The new function calls the original function and then slugifies the result using the `text.slugify` function with the `allow_dots` parameter set to True.", "Arguments": ":param fn: Callable. The original function to be decorated.\n:return: Callable. The decorated function."}, "tests": ["tests/test_factory.py::FactoryTestCase::test_slugify"], "indent": 4}
{"namespace": "faker.utils.decorators.slugify_unicode", "type": "function", "project_path": "Software-Development/Faker", "completion_path": "Software-Development/Faker/faker/utils/decorators.py", "signature_position": [25, 26], "body_position": [27, 30], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function is a decorator that wraps the input function and returns a new function. The new function slugifies the output of the input function and returns the slugified string.", "Arguments": ":param fn: Callable. The input function to be wrapped and modified.\n:return: Callable. The wrapper function that slugifies the output of the input function."}, "tests": ["tests/test_factory.py::FactoryTestCase::test_slugify"], "indent": 4}
{"namespace": "faker.providers.python.Provider.pystr", "type": "method", "project_path": "Software-Development/Faker", "completion_path": "Software-Development/Faker/faker/providers/python/__init__.py", "signature_position": [105, 111], "body_position": [121, 131], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function generates a random string of upper and lowercase letters. It can generate a random string of a specific length between the minimum and maximum length. It can also add a prefix and suffix to the random string.", "Arguments": ":param self: Provider. An instance of the Provider class.\n:param min_chars: Optional integer. The minimum length of the random part. Defaults to None.\n:param max_chars: Integer. The maximum length of the random part. Defaults to 20.\n:param prefix: String. An optional prefix to prepend to the random string. Defaults to an empty string.\n:param suffix: String. An optional suffix to append to the random string. Defaults to an empty string.\n:return: String. Random of random length between min and max characters."}, "tests": ["tests/test_factory.py::FactoryTestCase::test_random_pystr_characters"], "indent": 8}
{"namespace": "albumentations.core.keypoints_utils.convert_keypoints_to_albumentations", "type": "function", "project_path": "Software-Development/albumentations", "completion_path": "Software-Development/albumentations/albumentations/core/keypoints_utils.py", "signature_position": [261, 268], "body_position": [269, 272], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Convert a list of keypoints to the format used by the Albumentations library. It iterates through each keypoint and converts it to the required format.", "Arguments": ":param keypoints: Sequence of Sequence. A list of keypoints to be converted.\n:param source_format: String. The format of the input keypoints.\n:param rows: Int. The number of rows in the image.\n:param cols: Int. The number of columns in the image.\n:param check_validity: Bool. Whether to check the validity of the keypoints. Defaults to False.\n:param angle_in_degrees: Bool. Whether the angle is in degrees. Defaults to True.\n:return: List of Tuple. The converted keypoints in the format used by the Albumentations library."}, "tests": ["tests/test_keypoint.py::test_convert_keypoints_to_albumentations"], "indent": 4}
{"namespace": "albumentations.core.keypoints_utils.convert_keypoints_from_albumentations", "type": "function", "project_path": "Software-Development/albumentations", "completion_path": "Software-Development/albumentations/albumentations/core/keypoints_utils.py", "signature_position": [275, 282], "body_position": [283, 286], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Convert the keypoints from the albumentations format to the target format. It iterates through each keypoint and converts it to the target format.", "Arguments": ":param keypoints: Sequence of Sequence. The keypoints to be converted.\n:param target_format: String. The format to which the keypoints are to be converted.\n:param rows: Int. The number of rows in the image.\n:param cols: Int. The number of columns in the image.\n:param check_validity: Bool. Whether to check the validity of the keypoints. Defaults to False.\n:param angle_in_degrees: Bool. Whether the angle is in degrees. Defaults to True.\n:return: List of Tuple. The converted keypoints.\n```"}, "tests": ["tests/test_keypoint.py::test_convert_keypoints_from_albumentations"], "indent": 4}
{"namespace": "albumentations.core.composition.ReplayCompose.replay", "type": "method", "project_path": "Software-Development/albumentations", "completion_path": "Software-Development/albumentations/albumentations/core/composition.py", "signature_position": [462, 462], "body_position": [463, 464], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function replays the saved augmentations on the input data and returns the augmented data.", "Arguments": ":param saved_augmentations: Dict. A dictionary containing the saved augmentations.\n:param **kwargs: Any. Additional keyword arguments to be passed to the augmentations.\n:return: Dict. The augmented data after replaying the saved augmentations."}, "tests": ["tests/test_bbox.py::test_crop_boxes_replay_compose", "tests/test_core.py::test_deterministic_oneof", "tests/test_core.py::test_deterministic_sequential", "tests/test_core.py::test_deterministic_one_or_other"], "indent": 8}
{"namespace": "wandb.sdk.internal.system.assets.ipu.IPUStats.sample", "type": "method", "project_path": "Scientific-Engineering/wandb", "completion_path": "Scientific-Engineering/wandb/wandb/sdk/internal/system/assets/ipu.py", "signature_position": [81, 81], "body_position": [82, 111], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function samples the IPU stats and logs the metrics for the devices. It first gets the devices and their metrics. Then, it filters the metrics based on the user process id and logs the metrics for the devices that have not been called before or have variable metric keys. An exception will be thrown if any errors occur.", "Arguments": ":param self: IPUStats. An instance of the IPUStats class.\n:return: None. No return value."}, "tests": ["tests/pytest_tests/unit_tests/test_system_metrics/test_ipu.py::test_profiler"], "indent": 8}
{"namespace": "pytube.cli._download", "type": "function", "project_path": "Utilities/pytube", "completion_path": "Utilities/pytube/pytube/cli.py", "signature_position": [251, 255], "body_position": [256, 264], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Download a file from the given stream to the target location. It calculates the file size in megabytes, prints the filename and file size, and then downloads the file to the target location.", "Arguments": ":param stream: Stream. The stream from which the file is to be downloaded.\n:param target: String. The target location where the file is to be downloaded. Defaults to None.\n:param filename: String. The name of the file to be downloaded. Defaults to None.\n:return: No return value."}, "tests": ["tests/test_cli.py::test_download_stream_file_exists"], "indent": 4}
{"namespace": "pytube.cli.display_streams", "type": "function", "project_path": "Utilities/pytube", "completion_path": "Utilities/pytube/pytube/cli.py", "signature_position": [484, 484], "body_position": [491, 492], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function probes a YouTube video and lists its available formats.", "Arguments": ":param youtube: YouTube. A valid YouTube watch URL.\n:return: No return value."}, "tests": ["tests/test_cli.py::test_display_stream"], "indent": 4}
{"namespace": "pymc.sampling.forward.observed_dependent_deterministics", "type": "function", "project_path": "Scientific-Engineering/pymc", "completion_path": "Scientific-Engineering/pymc/pymc/sampling/forward.py", "signature_position": [335, 335], "body_position": [337, 344], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function finds the deterministics that depend directly on observed variables in the given model. It first retrieves the deterministics, observed random variables, and basic random variables from the model. Then, it returns a list of deterministics that depend directly on observed variables.", "Arguments": ":param model: Model. The input model.\n:return: List. A list of deterministics that depend directly on observed variables."}, "tests": ["tests/sampling/test_forward.py::test_observed_dependent_deterministics"], "indent": 4}
{"namespace": "boltons.funcutils.format_invocation", "type": "function", "project_path": "Utilities/boltons", "completion_path": "Utilities/boltons/boltons/funcutils.py", "signature_position": [338, 338], "body_position": [350, 366], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function formats a basic Python-style function call based on the given name, positional arguments, and keyword arguments. It returns the formatted function call.\nExample:\n>>> print(format_invocation('func', args=(1, 2), kwargs={'c': 3}))\nfunc(1, 2, c=3)\n>>> print(format_invocation('a_func', args=(1,)))\na_func(1)\n>>> print(format_invocation('kw_func', kwargs=[('a', 1), ('b', 2)]))\nkw_func(a=1, b=2)", "Arguments": ":param name: String. The name of the function.\n:param args: Tuple. The positional arguments of the function.\n:param kwargs: Dictionary. The keyword arguments of the function.\n:param kw: Dictionary. Additional keyword arguments.\n:return: String. The formatted function call."}, "tests": ["tests/test_funcutils.py::test_format_invocation"], "indent": 4}
{"namespace": "boltons.formatutils.get_format_args", "type": "function", "project_path": "Utilities/boltons", "completion_path": "Utilities/boltons/boltons/formatutils.py", "signature_position": [156, 156], "body_position": [172, 200], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function takes a format string and returns two lists of arguments referenced by the format string. One list contains positional arguments, and the other contains named arguments. Each element of the list includes the name and the nominal type of the field.", "Arguments": ":param fstr: String. The format string to be processed.\n:return: Tuple. Two lists of arguments referenced by the format string. The first list contains positional arguments, and the second list contains named arguments."}, "tests": ["tests/test_formatutils.py::test_get_fstr_args"], "indent": 4}
{"namespace": "boltons.dictutils.OneToOne.update", "type": "method", "project_path": "Utilities/boltons", "completion_path": "Utilities/boltons/boltons/dictutils.py", "signature_position": [874, 874], "body_position": [875, 888], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Update the OneToOne instance with the given dictionary or iterable and keyword arguments. It first checks if the input is a dictionary or an iterable and then updates the instance with the input values.", "Arguments": ":param self: OneToOne. An instance of the OneToOne class.\n:param dict_or_iterable: Dictionary or Iterable. The dictionary or iterable to update the instance with.\n:param kw: Keyword arguments. Additional keyword arguments to update the instance with.\n:return: No return values."}, "tests": ["tests/test_dictutils.py::test_one_to_one"], "indent": 8}
{"namespace": "boltons.dictutils.subdict", "type": "function", "project_path": "Utilities/boltons", "completion_path": "Utilities/boltons/boltons/dictutils.py", "signature_position": [1020, 1020], "body_position": [1042, 1049], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function computes the \"subdictionary\" of a dictionary. It returns a new dictionary with any keys in *drop* removed, and any keys in *keep* still present, provided they were in the original dictionary.", "Arguments": ":param d: Dictionary. The original dictionary.\n:param keep: List. The list of keys to keep in the original dictionary. Defaults to all keys.\n:param drop: List. The list of keys to remove from the original dictionary. Defaults to empty.\n:return: Dictionary. The subdictionary of the original dictionary."}, "tests": ["tests/test_dictutils.py::test_subdict_keep_type", "tests/test_dictutils.py::test_subdict"], "indent": 4}
{"namespace": "gunicorn.config.validate_callable", "type": "function", "project_path": "Utilities/gunicorn", "completion_path": "Utilities/gunicorn/gunicorn/config.py", "signature_position": [420, 420], "body_position": [421, 441], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function validates the input value to ensure it is a callable object with the specified arity. It first checks if the input value is a string, then tries to import the module and get the object. If the input value is not callable or has a different arity, it raises a TypeError.", "Arguments": ":param arity: Integer. The arity of the callable object. If set to -1, it means the arity can be any value.\n:return: Callable. The validated callable object."}, "tests": ["tests/test_config.py::test_callable_validation_for_string"], "indent": 4}
{"namespace": "imapclient.imap_utf7.encode", "type": "function", "project_path": "Communications/IMAPClient", "completion_path": "Communications/IMAPClient/imapclient/imap_utf7.py", "signature_position": [14, 14], "body_position": [20, 55], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Encode a folder name using IMAP modified UTF-7 encoding. It takes a string or bytes as input and returns the encoded bytes. If the input is not a string, it returns the input unchanged.", "Arguments": ":param s: Union[str, bytes]. The input string to be encoded.\n:return: bytes. The encoded bytes of the input string."}, "tests": ["tests/test_imap_utf7.py::IMAP4UTF7TestCase::test_encode", "tests/test_imap_utf7.py::IMAP4UTF7TestCase::test_printable_singletons"], "indent": 4}
{"namespace": "zulipterminal.ui_tools.buttons.MessageLinkButton.handle_narrow_link", "type": "method", "project_path": "Communications/zulip-term", "completion_path": "Communications/zulip-term/zulipterminal/ui_tools/buttons.py", "signature_position": [608, 608], "body_position": [613, 623], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function narrows to the respective narrow if the narrow link is valid or updates the footer with an appropriate validation error message.", "Arguments": ":param self: MessageLinkButton. An instance of the MessageLinkButton class.\n:return: None. No return value."}, "tests": ["tests/ui_tools/test_buttons.py::TestMessageLinkButton::test_handle_narrow_link"], "indent": 8}
{"namespace": "chatette.cli.interactive_commands.command_strategy.CommandStrategy.execute", "type": "method", "project_path": "Communications/chatette", "completion_path": "Communications/chatette/chatette/cli/interactive_commands/command_strategy.py", "signature_position": [272, 272], "body_position": [279, 314], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function executes the whole command represented by the object. It can be overridden by subclasses if a different algorithm is required.", "Arguments": ":param self: CommandStrategy. An instance of the CommandStrategy class.\n:return: No return values."}, "tests": ["tests/unit-testing/cli/interactive_commands/test_show_command.py::test_err", "tests/unit-testing/cli/interactive_commands/test_hide_command.py::test_err", "tests/unit-testing/cli/interactive_commands/test_hide_command.py::test_execute", "tests/unit-testing/cli/interactive_commands/test_show_command.py::test_execute", "tests/unit-testing/cli/interactive_commands/test_hide_command.py::test_variations"], "indent": 8}
{"namespace": "aioxmpp.connector.XMPPOverTLSConnector._context_factory_factory", "type": "method", "project_path": "Communications/aioxmpp", "completion_path": "Communications/aioxmpp/aioxmpp/connector.py", "signature_position": [291, 291], "body_position": [292, 310], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function creates a context factory for the XMPPOverTLSConnector. It sets the ALPN protocol to \"xmpp-client\" if the ssl_context has the set_alpn_protos method. It also sets up the context with the verifier and returns the ssl_context.", "Arguments": ":param self: XMPPOverTLSConnector. An instance of the XMPPOverTLSConnector class.\n:param logger: The logger to be used for logging.\n:param metadata: The metadata to be used for creating the ssl context.\n:param verifier: The verifier to be used for setting up the context.\n:return: The context factory function."}, "tests": ["tests/test_connector.py::TestXMPPOverTLSConnector::test_context_factory_warns_if_set_alpn_protos_is_not_defined", "tests/test_connector.py::TestXMPPOverTLSConnector::test_context_factory", "tests/test_connector.py::TestXMPPOverTLSConnector::test_context_factory_warns_if_set_alpn_protos_raises"], "indent": 8}
{"namespace": "aioxmpp.callbacks.AdHocSignal.ASYNC_WITH_LOOP", "type": "method", "project_path": "Communications/aioxmpp", "completion_path": "Communications/aioxmpp/aioxmpp/callbacks.py", "signature_position": [389, 389], "body_position": [390, 400], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "The function creates a wrapper for the given function to be executed asynchronously with the given event loop. It first checks if the loop is provided, if not, it gets the default event loop. Then, it creates a wrapper for the given function to be executed asynchronously with the provided loop.", "Arguments": ":param cls: Class. The class instance.\n:param loop: Event loop. The event loop to be used for asynchronous execution. Defaults to None.\n:return: Wrapper function. The wrapper function for the given function to be executed asynchronously with the provided loop."}, "tests": ["tests/test_callbacks.py::TestAdHocSignal::test_connect_async", "tests/test_callbacks.py::TestAdHocSignal::test_ASYNC_WITH_LOOP_rejects_non_callable"], "indent": 8}
{"namespace": "aioxmpp.callbacks.AdHocSignal.SPAWN_WITH_LOOP", "type": "method", "project_path": "Communications/aioxmpp", "completion_path": "Communications/aioxmpp/aioxmpp/callbacks.py", "signature_position": [431, 431], "body_position": [432, 450], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Create a spawn function that can be used to spawn a coroutine function. It ensures that the function is a coroutine and then adds a done callback to the task to log the spawned task.", "Arguments": ":param cls: AdHocSignal. The class instance.\n:param loop: The event loop to be used. If not specified, the default event loop is used.\n:return: The spawn function."}, "tests": ["tests/test_callbacks.py::TestAdHocSignal::test_connect_spawn", "tests/test_callbacks.py::TestAdHocSignal::test_SPAWN_rejects_non_coroutine", "tests/test_callbacks.py::TestAdHocSignal::test_connect_spawn_emits_always"], "indent": 8}
{"namespace": "aioxmpp.protocol.send_and_wait_for", "type": "function", "project_path": "Communications/aioxmpp", "completion_path": "Communications/aioxmpp/aioxmpp/protocol.py", "signature_position": [872, 874], "body_position": [875, 920], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function sends a message and waits for a response. It sends a message to the xmlstream and waits for a response. If the response is not received within the specified timeout, a TimeoutError is raised.", "Arguments": ":param xmlstream: The xmlstream to send the message to and wait for a response.\n:param send: The message to be sent.\n:param wait_for: The response to wait for.\n:param timeout: The time to wait for the response. If None, it waits indefinitely.\n:param cb: The callback function to be called when a response is received.\n:return: The response received from the xmlstream."}, "tests": ["tests/test_protocol.py::Testsend_and_wait_for::test_handles_setup_issues_properly", "tests/test_protocol.py::Testsend_and_wait_for::test_handles_send_issues_properly", "tests/test_protocol.py::Testsend_and_wait_for::test_receive_handler_invokes_cb"], "indent": 4}
{"namespace": "aioxmpp.xso.model.events_to_sax", "type": "function", "project_path": "Communications/aioxmpp", "completion_path": "Communications/aioxmpp/aioxmpp/xso/model.py", "signature_position": [2801, 2801], "body_position": [2806, 2817], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function converts an iterable `events` of XSO events to SAX events by calling the matching SAX methods on `dest`. It iterates through the events and calls the corresponding SAX methods on `dest` based on the event type.", "Arguments": ":param events: Iterable. An iterable of XSO events.\n:param dest: Object. The destination object on which the matching SAX methods will be called.\n:return: No return values."}, "tests": ["tests/xso/test_model.py::Testevents_to_sax::test_start", "tests/xso/test_model.py::Testevents_to_sax::test_start_and_end", "tests/xso/test_model.py::Testevents_to_sax::test_text", "tests/xso/test_model.py::Testevents_to_sax::test_nested_stuff"], "indent": 4}
{"namespace": "aioxmpp.adhoc.service.AdHocClient.get_command_info", "type": "method", "project_path": "Communications/aioxmpp", "completion_path": "Communications/aioxmpp/aioxmpp/adhoc/service.py", "signature_position": [93, 93], "body_position": [115, 120], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function obtains information about a command from a peer. It sends a service discovery query to the service discovery node of the command and returns the service discovery information about the command.", "Arguments": ":param self: AdHocClient. An instance of the AdHocClient class.\n:param peer_jid: JID. The JID of the peer to query.\n:param command_name: String. The node name of the command.\n:return: InfoQuery. Service discovery information about the command."}, "tests": ["tests/adhoc/test_service.py::TestAdHocClient::test_get_command_info_uses_disco"], "indent": 8}
{"namespace": "aioxmpp.entitycaps.caps390._process_identities", "type": "function", "project_path": "Communications/aioxmpp", "completion_path": "Communications/aioxmpp/aioxmpp/entitycaps/caps390.py", "signature_position": [62, 62], "body_position": [75, 80], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function generates the `Identities String` from an iterable of identities. It processes each identity in the iterable and generates the `Identities String` as specified in :xep:`390`.", "Arguments": ":param identities: Iterable. The identities to generate the features string from. It is an iterable of Identity objects.\n:return: Bytes. The `Identities String` generated from the given `identities`."}, "tests": ["tests/entitycaps/test_caps390.py::Test_process_identities::test_on_large_testcase", "tests/entitycaps/test_caps390.py::Test_process_identities::test_on_small_testcase"], "indent": 4}
{"namespace": "aioxmpp.entitycaps.caps390._process_extensions", "type": "function", "project_path": "Communications/aioxmpp", "completion_path": "Communications/aioxmpp/aioxmpp/entitycaps/caps390.py", "signature_position": [103, 103], "body_position": [116, 121], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Generate the `Extensions String` from an iterable of data forms. It generates the `Extensions String` from the given `exts` as specified in :xep:`390`.", "Arguments": ":param exts: The data forms to generate the extensions string from.\n:type exts: :class:`~collections.abc.Iterable` of :class:`~.forms.xso.Data`.\n:return: The `Extensions String` as `bytes`."}, "tests": ["tests/entitycaps/test_caps390.py::Test_process_extensions::test_on_small_testcase", "tests/entitycaps/test_caps390.py::Test_process_extensions::test_on_large_testcase"], "indent": 4}
{"namespace": "aioxmpp.entitycaps.caps390._calculate_hash", "type": "function", "project_path": "Communications/aioxmpp", "completion_path": "Communications/aioxmpp/aioxmpp/entitycaps/caps390.py", "signature_position": [132, 132], "body_position": [133, 135], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Calculate the hash of the given input using the specified algorithm.", "Arguments": ":param algo: String. The algorithm to be used for hashing.\n:param hash_input: The input data to be hashed.\n:return: The hash of the input data using the specified algorithm."}, "tests": ["tests/entitycaps/test_caps390.py::TestKey::test_verify_large_input_precalculated", "tests/entitycaps/test_caps390.py::Test_calculate_hash::test_uses_and_hash_from_algo", "tests/entitycaps/test_caps390.py::TestKey::test_verify_small_input", "tests/entitycaps/test_caps390.py::TestKey::test_verify_small_input_precalculated", "tests/entitycaps/test_caps390.py::TestKey::test_verify_large_input"], "indent": 4}
{"namespace": "aioxmpp.entitycaps.caps390.Implementation.extract_keys", "type": "method", "project_path": "Communications/aioxmpp", "completion_path": "Communications/aioxmpp/aioxmpp/entitycaps/caps390.py", "signature_position": [172, 172], "body_position": [173, 180], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Extracts the keys from the presence instance if the xep0390_caps is not None. It returns the keys if the presence object contain information about the entity's capabilities, else it returns an empty generator.", "Arguments": ":param self: Implementation. An instance of the Implementation class.\n:param presence: Presence. The presence instance from which the keys are to be extracted.\n:return: The extracted keys as Tuple."}, "tests": ["tests/entitycaps/test_caps390.py::TestImplementation::test_extract_keys_returns_empty_if_caps_is_None", "tests/entitycaps/test_caps390.py::TestImplementation::test_extract_keys_creates_Key_objects_from_digests_and_checks_for_support"], "indent": 8}
{"namespace": "datasets.iterable_dataset.IterableDataset.remove_columns", "type": "method", "project_path": "Scientific-Engineering/datasets", "completion_path": "Scientific-Engineering/datasets/src/datasets/iterable_dataset.py", "signature_position": [1990, 1990], "body_position": [2015, 2028], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Remove one or several column(s) in the dataset and the features associated with them. The removal is done on-the-fly on the examples when iterating over the dataset.", "Arguments": ":param self: IterableDataset. An instance of the IterableDataset class.\n:param column_names (`Union[str, List[str]]`): Name of the column(s) to remove.\n:return: `IterableDataset`: A copy of the dataset object without the columns to remove."}, "tests": ["tests/test_iterable_dataset.py::test_concatenate_datasets_axis_1_resolves_features", "tests/test_iterable_dataset.py::test_concatenate_datasets_axis_1", "tests/test_iterable_dataset.py::test_concatenate_datasets_axis_1_with_different_lengths"], "indent": 8}
{"namespace": "datasets.dataset_dict.DatasetDict.with_format", "type": "method", "project_path": "Scientific-Engineering/datasets", "completion_path": "Scientific-Engineering/datasets/src/datasets/dataset_dict.py", "signature_position": [643, 649], "body_position": [691, 693], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Set the `__getitem__` return format (type and columns) for the dataset. The data formatting is applied on-the-fly. The format `type` (for example \"numpy\") is used to format batches when using `__getitem__`. The format is set for every dataset in the dataset dictionary.", "Arguments": ":param type: Optional string. Output type selected in `[None, 'numpy', 'torch', 'tensorflow', 'pandas', 'arrow', 'jax']`. `None` means `__getitem__` returns python objects (default).\n:param columns: Optional list of strings. Columns to format in the output. `None` means `__getitem__` returns all columns (default).\n:param output_all_columns: Bool. Keep un-formatted columns as well in the output (as python objects). Defaults to `False`.\n:param **format_kwargs: Additional keyword arguments. Keywords arguments passed to the convert function like `np.array`, `torch.tensor` or `tensorflow.ragged.constant`.\n:return: DatasetDict. A new `DatasetDict` object with new `Dataset` objects."}, "tests": ["tests/test_dataset_dict.py::DatasetDictTest::test_with_format"], "indent": 8}
{"namespace": "datasets.dataset_dict.DatasetDict.with_transform", "type": "method", "project_path": "Scientific-Engineering/datasets", "completion_path": "Scientific-Engineering/datasets/src/datasets/dataset_dict.py", "signature_position": [695, 700], "body_position": [745, 747], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Set `__getitem__` return format using this transform. The transform is applied on-the-fly on batches when `__getitem__` is called. The transform is set for every dataset in the dataset dictionary. It returns a new `DatasetDict` object with new `Dataset` objects.", "Arguments": ":param self: DatasetDict. An instance of the DatasetDict class.\n:param transform: Callable. User-defined formatting transform, replaces the format defined by [`~datasets.Dataset.set_format`].\n:param columns: List of string. Columns to format in the output. If specified, then the input batch of the transform only contains those columns.\n:param output_all_columns: Bool. Keep un-formatted columns as well in the output (as python objects). If set to `True`, then the other un-formatted columns are kept with the output of the transform.\n:return: \"DatasetDict\". The new `DatasetDict` object with new `Dataset` objects."}, "tests": ["tests/test_dataset_dict.py::DatasetDictTest::test_with_transform"], "indent": 8}
{"namespace": "datasets.dataset_dict.DatasetDict.align_labels_with_mapping", "type": "method", "project_path": "Scientific-Engineering/datasets", "completion_path": "Scientific-Engineering/datasets/src/datasets/dataset_dict.py", "signature_position": [1549, 1549], "body_position": [1550, 1556], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Align the labels with the given mapping. It aligns the labels of the dataset with the given label2id mapping based on the label_column.", "Arguments": ":param self: DatasetDict. An instance of the DatasetDict class.\n:param label2id: Dict. A dictionary that maps labels to ids.\n:param label_column: String. The name of the label column.\n:return: DatasetDict. The updated DatasetDict instance."}, "tests": ["tests/test_dataset_dict.py::DatasetDictTest::test_align_labels_with_mapping"], "indent": 8}
{"namespace": "datasets.arrow_dataset.Dataset.num_rows", "type": "method", "project_path": "Scientific-Engineering/datasets", "completion_path": "Scientific-Engineering/datasets/src/datasets/arrow_dataset.py", "signature_position": [1788, 1788], "body_position": [1800, 1802], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function returns the number of rows in the dataset. It first checks if the indices are not None and returns the number of rows from the indices. If the indices are None, it returns the number of rows from the data.", "Arguments": ":param self: Dataset. An instance of the Dataset class.\n:return: int. The number of rows in the dataset."}, "tests": ["tests/test_arrow_reader.py::BaseReaderTest::test_read_files", "tests/test_arrow_reader.py::BaseReaderTest::test_read_sharded", "tests/test_arrow_reader.py::BaseReaderTest::test_read"], "indent": 8}
{"namespace": "datasets.utils.extract.TarExtractor.extract", "type": "method", "project_path": "Scientific-Engineering/datasets", "completion_path": "Scientific-Engineering/datasets/src/datasets/utils/extract.py", "signature_position": [125, 125], "body_position": [126, 129], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function extracts the contents of a tar file to the specified output path. It first creates the output directory if it does not exist, then opens the tar file, extracts all its contents to the output path, and closes the tar file.", "Arguments": ":param input_path: Union[Path, str]. The path to the input tar file.\n:param output_path: Union[Path, str]. The path to the output directory where the contents will be extracted.\n:return: No return value."}, "tests": ["tests/test_extract.py::test_tar_extract_insecure_files"], "indent": 8}
{"namespace": "datasets.utils.extract.Extractor.infer_extractor_format", "type": "method", "project_path": "Scientific-Engineering/datasets", "completion_path": "Scientific-Engineering/datasets/src/datasets/utils/extract.py", "signature_position": [314, 314], "body_position": [315, 319], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function infers the format of the extractor based on the given path. It reads the magic number from the file and checks if the extractor is extractable for the given path and magic number.", "Arguments": ":param cls: Extractor. The class itself.\n:param path: Union[Path, str]. The path of the file to infer the extractor format.\n:return: str. The inferred extractor format."}, "tests": ["tests/test_extract.py::test_extractor"], "indent": 8}
{"namespace": "datasets.utils.metadata.MetadataConfigs.from_dataset_card_data", "type": "method", "project_path": "Scientific-Engineering/datasets", "completion_path": "Scientific-Engineering/datasets/src/datasets/utils/metadata.py", "signature_position": [173, 173], "body_position": [174, 191], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Create a MetadataConfigs instance based on the given dataset card data. It first checks if the dataset card data contains the field name. If it does, it processes the metadata configurations and creates a MetadataConfigs instance.", "Arguments": ":param cls: Class. The class itself.\n:param dataset_card_data: DatasetCardData. The dataset card data to be used to create the MetadataConfigs instance.\n:return: MetadataConfigs. The created MetadataConfigs instance."}, "tests": ["tests/test_metadata_util.py::test_metadata_configs_incorrect_yaml", "tests/test_metadata_util.py::test_metadata_configs_dataset_card_data"], "indent": 8}
{"namespace": "boltons.socketutils.NetstringSocket.setmaxsize", "type": "method", "project_path": "Utilities/boltons", "completion_path": "Utilities/boltons/boltons/socketutils.py", "signature_position": [667, 667], "body_position": [668, 669], "dependency": {"intra_class": ["boltons.socketutils.NetstringSocket._calc_msgsize_maxsize", "boltons.socketutils.NetstringSocket._msgsize_maxsize", "boltons.socketutils.NetstringSocket.maxsize"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Set the maximum size for receiving netstrings in the NetstringSocket instance. It updates the maxsize of the instance and calculates the maximum size for a netstring message based on the new maxsize value.", "Arguments": ":param self: NetstringSocket. An instance of the NetstringSocket class.\n:param maxsize: The maximum size for receiving netstrings.\n:return: No return values."}, "tests": ["tests/test_socketutils.py::test_socketutils_netstring"], "indent": 8}
{"namespace": "boto.datapipeline.connect_to_region", "type": "function", "project_path": "Internet/boto", "completion_path": "Internet/boto/boto/datapipeline/__init__.py", "signature_position": [38, 38], "body_position": [39, 42], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["boto.datapipeline.layer1.DataPipelineConnection", "boto.regioninfo.connect"]}, "requirement": {"Functionality": "Connect to a specific region in the AWS Data Pipeline service. It creates a connection to the Data Pipeline service in the specified region using the provided parameters.", "Arguments": ":param region_name: String. The name of the region to connect to.\n:param **kw_params: Additional keyword arguments that can be passed to the connection.\n:return: DataPipelineConnection. The connection object to the Data Pipeline service in the specified region."}, "tests": ["tests/unit/test_connect_to_region.py::TestDatapipelineConnection::test_connect_to_region"], "indent": 4}
{"namespace": "mongoengine.base.datastructures.BaseDict.get", "type": "method", "project_path": "Database/mongoengine", "completion_path": "Database/mongoengine/mongoengine/base/datastructures.py", "signature_position": [56, 57], "body_position": [58, 61], "dependency": {"intra_class": ["mongoengine.base.datastructures.BaseDict.__getitem__"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function retrieves the value associated with the given key in the BaseDict instance. If the key is not found, it returns the default value instead. It overrides the default behavior.", "Arguments": ":param self: BaseDict. An instance of the BaseDict class.\n:param key: The key to retrieve the value for.\n:param default: The value to return if the key is not found. Defaults to None.\n:return: The value associated with the key, or the default value if the key is not found."}, "tests": ["tests/test_datastructures.py::TestBaseDict::test_get_sublist_gets_converted_to_BaseList_just_like__getitem__", "tests/test_datastructures.py::TestBaseDict::test_get_default", "tests/test_datastructures.py::TestBaseDict::test_get_returns_the_same_as___getitem__"], "indent": 8}
{"namespace": "mopidy.http.Extension.get_config_schema", "type": "method", "project_path": "Multimedia/Mopidy", "completion_path": "Multimedia/Mopidy/mopidy/http/__init__.py", "signature_position": [20, 20], "body_position": [21, 33], "dependency": {"intra_class": ["mopidy.ext.Extension", "mopidy.ext.Extension.get_config_schema"], "intra_file": [], "cross_file": ["mopidy.config", "mopidy.config.types.Boolean", "mopidy.config.types.Deprecated", "mopidy.config.types.Hostname", "mopidy.config.types.List", "mopidy.config.types.Port", "mopidy.config.types.String"]}, "requirement": {"Functionality": "This function returns the configuration schema for the Extension class. It first calls the parent class's method to get the base schema, and then adds additional configuration options specific to the Extension class.", "Arguments": ":param self: Extension. An instance of the Extension class.\n:return: dict. The configuration schema for the Extension class, including the base schema and additional options."}, "tests": ["tests/http/test_extension.py::test_get_config_schema", "tests/http/test_extension.py::test_default_config_is_valid"], "indent": 8}
{"namespace": "pyinfra.operations.files.file", "type": "function", "project_path": "System/pyinfra", "completion_path": "System/pyinfra/pyinfra/operations/files.py", "signature_position": [1191, 1202], "body_position": [1238, 1289], "dependency": {"intra_class": [], "intra_file": ["pyinfra.operations.files._create_remote_dir", "pyinfra.operations.files._raise_or_remove_invalid_path", "pyinfra.operations.files._validate_path"], "cross_file": ["pyinfra.facts.files.File", "pyinfra.operations.util.files.chmod", "pyinfra.operations.util.files.chown", "pyinfra.operations.util.files.ensure_mode_int", "pyinfra.api.host.Host.get_fact", "pyinfra.api.host.Host.noop", "pyinfra.operations.util.files"]}, "requirement": {"Functionality": "This function is used to add, remove, or update files. It performs different actions based on the input parameters. It can create a file, remove a file, or update the properties of an existing file.", "Arguments": ":param path: String. The name or path of the remote file.\n:param present: Bool. Whether the file should exist. If set to False, the file will be removed if it exists.\n:param user: String. The user to own the files.\n:param group: String. The group to own the files.\n:param mode: Integer. The permissions of the files.\n:param touch: Bool. Whether to touch the file.\n:param create_remote_dir: Bool. Whether to create the remote directory if it doesn't exist.\n:param force: Bool. If the target exists and is not a file, move or remove it and continue.\n:param force_backup: Bool. Whether to remove any existing non-file when force=True.\n:param force_backup_dir: String. The directory to move any backup to when force=True.\n:return: No return values."}, "tests": ["tests/test_api/test_api_operations.py::TestOperationsApi::test_op"], "indent": 4}
{"namespace": "litecli.packages.parseutils.is_destructive", "type": "function", "project_path": "Database/litecli", "completion_path": "Database/litecli/litecli/packages/parseutils.py", "signature_position": [219, 219], "body_position": [221, 222], "dependency": {"intra_class": [], "intra_file": ["litecli.packages.parseutils.queries_start_with"], "cross_file": []}, "requirement": {"Functionality": "Check if any of the queries in the given list is considered destructive. It checks if any of the queries start with certain keywords that are commonly associated with destructive actions.", "Arguments": ":param queries: List of strings. The queries to be checked.\n:return: Bool. True if any of the queries is considered destructive, False otherwise."}, "tests": ["tests/test_parseutils.py::test_is_destructive"], "indent": 4}
{"namespace": "sacred.experiment.Experiment.main", "type": "method", "project_path": "Utilities/sacred", "completion_path": "Utilities/sacred/sacred/experiment.py", "signature_position": [140, 140], "body_position": [149, 151], "dependency": {"intra_class": ["sacred.experiment.Experiment.default_command"], "intra_file": [], "cross_file": ["sacred.ingredient.Ingredient.command"]}, "requirement": {"Functionality": "This function is a decorator that is used to define the main function of an experiment. The main function is the default command that is executed when no command is specified or when calling the run() method. It captures the decorated function and sets it as the default command for the experiment.", "Arguments": ":param self: Experiment. An instance of the Experiment class.\n:param function: The function to be decorated and set as the main function.\n:return: The captured function that is set as the default command."}, "tests": ["tests/test_modules.py::test_experiment_named_config_subingredient_overwrite", "tests/test_modules.py::test_experiment_run_subingredient_function", "tests/test_modules.py::test_double_nested_config", "tests/test_experiment.py::test_additional_cli_options_flag", "tests/test_ingredients.py::test_config_docs_are_preserved"], "indent": 8}
{"namespace": "fs.path.frombase", "type": "function", "project_path": "System/fs", "completion_path": "System/fs/fs/path.py", "signature_position": [522, 523], "body_position": [538, 540], "dependency": {"intra_class": [], "intra_file": ["fs.path.isparent"], "cross_file": []}, "requirement": {"Functionality": "Take two paths - `path1` and `path2` as input. Return the part of `path2` that is not present in `path1`. If `path1` is not a parent directory of `path2`, a ValueError raised. \n", "Arguments": ":param path1: String, a PyFileSystem path, e.g., ``'a/b/c'``.\n:param path2: String, a PyFileSystem path, e.g., ``'a/b/c'``.\n:return: String, the final part of path2 that is not present in path1.\n"}, "tests": ["tests/test_path.py::TestPathFunctions::test_frombase"], "indent": 4}
{"namespace": "pyramid.registry.Introspector.remove", "type": "method", "project_path": "Internet/pyramid", "completion_path": "Internet/pyramid/src/pyramid/registry.py", "signature_position": [163, 163], "body_position": [164, 173], "dependency": {"intra_class": ["pyramid.registry.Introspector._categories", "pyramid.registry.Introspector._refs", "pyramid.registry.Introspector.get"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Remove an introspection object from the Introspector instance. It first retrieves the introspection object based on the category name and discriminator. If the object is found, it removes all references to the object and deletes it from the category dictionary.", "Arguments": ":param self: Introspector. An instance of the Introspector class.\n:param category_name: str. The name of the category where the introspection object belongs.\n:param discriminator: The discriminator of the introspection object.\n:return: No return values."}, "tests": ["tests/test_registry.py::TestIntrospector::test_remove"], "indent": 8}
{"namespace": "mrjob.job.MRJob.set_status", "type": "method", "project_path": "System/mrjob", "completion_path": "System/mrjob/mrjob/job.py", "signature_position": [587, 587], "body_position": [594, 599], "dependency": {"intra_class": ["mrjob.job.MRJob.stderr"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function sets the job status in Hadoop streaming by printing a message to the standard error stream of the input MRJob instance. It is also used as a keepalive mechanism to prevent the job from timing out. The format of the message is \"reporter:status:{message}\\n\".", "Arguments": ":param self: MRJob. An instance of the MRJob class.\n:param msg: String. The message to set as the job status.\n:return: No return values."}, "tests": ["tests/test_job.py::CountersAndStatusTestCase::test_counters_and_status"], "indent": 8}
{"namespace": "pyramid.util.InstancePropertyHelper.make_property", "type": "method", "project_path": "Internet/pyramid", "completion_path": "Internet/pyramid/src/pyramid/util.py", "signature_position": [104, 104], "body_position": [110, 134], "dependency": {"intra_class": [], "intra_file": ["pyramid.util.SettableProperty", "pyramid.util.SettableProperty.__init__", "pyramid.util.get_callable_name"], "cross_file": ["pyramid.decorator.reify.__init__"]}, "requirement": {"Functionality": "This function takes a callable object and converts it into a property suitable for adding to an instance. It returns a tuple containing the computed (name, property) pair.", "Arguments": ":param cls: type. InstancePropertyHelper.\n:param callable: Callable. The callable object to be converted into a property.\n:param name: str. The name of the property. If not specified, it will be derived from the callable's __name__ attribute. Defaults to None.\n:param reify: bool. Whether to use the reify decorator on the property. Defaults to False.\n:return: Tuple. A tuple containing the computed (name, property) pair."}, "tests": ["tests/test_scripting.py::Test_prepare::test_it_with_extensions", "tests/test_util.py::Test_InstancePropertyHelper::test_apply_properties_with_iterable", "tests/test_util.py::Test_InstancePropertyHelper::test_apply_properties_with_dict", "tests/test_util.py::Test_InstancePropertyHelper::test_make_property", "tests/test_router.py::TestRouter::test_call_with_request_extensions"], "indent": 8}
{"namespace": "falcon.request.Request.client_prefers", "type": "method", "project_path": "Internet/falcon", "completion_path": "Internet/falcon/falcon/request.py", "signature_position": [1101, 1101], "body_position": [1115, 1122], "dependency": {"intra_class": ["falcon.request.Request.accept"], "intra_file": [], "cross_file": ["falcon.vendor.mimeparse", "falcon.vendor.mimeparse.best_match"]}, "requirement": {"Functionality": "This function returns the client's preferred media type from a list of choices. It uses the Accept header of the client's request to determine the preferred type.", "Arguments": ":param self: Request. An instance of the Request class.\n:param media_types: Iterable of strings. One or more Internet media types from which to choose the client's preferred type.\n:return: String. The client's preferred media type based on the Accept header. Returns None if the client does not accept any of the given types."}, "tests": ["tests/test_request_attrs.py::TestRequestAttributes::test_client_prefers"], "indent": 8}
{"namespace": "pyramid.registry.Introspectable.discriminator_hash", "type": "method", "project_path": "Internet/pyramid", "completion_path": "Internet/pyramid/src/pyramid/registry.py", "signature_position": [232, 232], "body_position": [233, 234], "dependency": {"intra_class": ["pyramid.registry.Introspectable._assert_resolved", "pyramid.registry.Introspectable.discriminator"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Calculate the hash of the discriminator of the Introspectable instance.", "Arguments": ":param self: Introspectable. An instance of the Introspectable class.\n:return: int. The hash value of the discriminator in the instance."}, "tests": ["tests/test_registry.py::TestIntrospectable::test_discriminator_hash"], "indent": 8}
{"namespace": "zulipterminal.ui_tools.boxes.WriteBox.stream_box_view", "type": "method", "project_path": "Communications/zulip-term", "completion_path": "Communications/zulip-term/zulipterminal/ui_tools/boxes.py", "signature_position": [381, 383], "body_position": [384, 399], "dependency": {"intra_class": ["zulipterminal.ui_tools.boxes.WriteBox._set_stream_write_box_style", "zulipterminal.ui_tools.boxes.WriteBox._setup_common_stream_compose", "zulipterminal.ui_tools.boxes.WriteBox._stream_box_autocomplete", "zulipterminal.ui_tools.boxes.WriteBox.model", "zulipterminal.ui_tools.boxes.WriteBox.stream_write_box"], "intra_file": [], "cross_file": ["zulipterminal.config.keys.primary_key_for_command"]}, "requirement": {"Functionality": "This function sets up the view for a stream box. It creates a stream write box with a specified caption and title, enables autocomplete functionality, and sets up the common stream compose. It also sets a callback to set the stream marker and connects a signal to update the style of the stream write box.", "Arguments": ":param self: WriteBox. An instance of the WriteBox class.\n:param stream_id: int. The ID of the stream.\n:param caption: str. The caption for the stream write box. Defaults to an empty string.\n:param title: str. The title for the stream write box. Defaults to an empty string.\n:return: No return values."}, "tests": ["tests/ui_tools/test_boxes.py::TestWriteBox::test__stream_box_autocomplete_with_spaces", "tests/ui_tools/test_boxes.py::TestWriteBox::test__set_stream_write_box_style_markers", "tests/ui_tools/test_boxes.py::TestWriteBox::test__compose_attributes_reset_for_stream_compose", "tests/ui_tools/test_boxes.py::TestWriteBox::test_write_box_header_contents", "tests/ui_tools/test_boxes.py::TestWriteBox::test_keypress_CYCLE_COMPOSE_FOCUS"], "indent": 8}
{"namespace": "boltons.funcutils.FunctionBuilder.get_arg_names", "type": "method", "project_path": "Utilities/boltons", "completion_path": "Utilities/boltons/boltons/funcutils.py", "signature_position": [962, 962], "body_position": [963, 967], "dependency": {"intra_class": ["boltons.funcutils.FunctionBuilder.get_defaults_dict", "boltons.funcutils.FunctionBuilder.args", "boltons.funcutils.FunctionBuilder.kwonlyargs"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function returns a tuple of argument names for a function. It includes both positional arguments and keyword-only arguments. If the \"only_required\" parameter is set to True, it only returns the names of required arguments, excluding those with default values.", "Arguments": ":param self: FunctionBuilder. An instance of the FunctionBuilder class.\n:param only_required: bool. Whether to only return the names of required arguments. Defaults to False.\n:return: Tuple. A tuple of argument names."}, "tests": ["tests/test_funcutils_fb.py::test_get_arg_names", "tests/test_funcutils_fb_py3.py::test_get_arg_names"], "indent": 8}
{"namespace": "mrjob.hadoop.HadoopJobRunner._stream_history_log_dirs", "type": "method", "project_path": "System/mrjob", "completion_path": "System/mrjob/mrjob/hadoop.py", "signature_position": [546, 546], "body_position": [548, 555], "dependency": {"intra_class": ["mrjob.hadoop.HadoopJobRunner._hadoop_log_dirs", "mrjob.hadoop.HadoopJobRunner.fs"], "intra_file": ["mrjob.hadoop.log"], "cross_file": ["mrjob.logs.mixin.LogInterpretationMixin._read_logs", "mrjob.logs.wrap._logs_exist", "mrjob.util.unique"]}, "requirement": {"Functionality": "This function yields lists of directories to search for the history log in. It first checks if logs should be read, and then iterates over unique log directories obtained from the hadoop log directories. If the directory exists, it logs an info message: 'Looking for history log in {directory}...'. It then yields a list containing the directory.", "Arguments": ":param self: HadoopJobRunner. An instance of the HadoopJobRunner class.\n:param output_dir: str. The output directory to search for the history log. Defaults to None.\n:return: Generator. Yields lists of directories to search for the history log in."}, "tests": ["tests/test_hadoop.py::StreamHistoryLogDirsTestCase::test_output_dir", "tests/test_hadoop.py::StreamHistoryLogDirsTestCase::test_basic", "tests/test_hadoop.py::StreamHistoryLogDirsTestCase::test_io_error_from_fs_exists", "tests/test_hadoop.py::StreamHistoryLogDirsTestCase::test_empty", "tests/test_hadoop.py::StreamHistoryLogDirsTestCase::test_no_read_logs"], "indent": 8}
{"namespace": "sslyze.plugins.session_renegotiation_plugin._SessionRenegotiationCliConnector.result_to_console_output", "type": "method", "project_path": "System/sslyze", "completion_path": "System/sslyze/sslyze/plugins/session_renegotiation_plugin.py", "signature_position": [57, 57], "body_position": [58, 76], "dependency": {"intra_class": [], "intra_file": ["sslyze.plugins.session_renegotiation_plugin.SessionRenegotiationScanResult", "sslyze.plugins.session_renegotiation_plugin.SessionRenegotiationScanResult.is_vulnerable_to_client_renegotiation_dos", "sslyze.plugins.session_renegotiation_plugin.SessionRenegotiationScanResult.supports_secure_renegotiation"], "cross_file": ["sslyze.plugins.plugin_base.ScanCommandCliConnector._format_field", "sslyze.plugins.plugin_base.ScanCommandCliConnector._format_title"]}, "requirement": {"Functionality": "This function takes a SessionRenegotiationScanResult object as input and converts the result into a list of strings that represent the output to be displayed on the console. It formats the different fields of the result and appends them to the result_txt list.", "Arguments": ":param cls: The class object of _SessionRenegotiationCliConnector.\n:param result: SessionRenegotiationScanResult. The result of a session renegotiation scan.\n:return: List of strings. The formatted output to be displayed on the console."}, "tests": ["tests/plugins_tests/test_session_renegotiation_plugin.py::TestSessionRenegotiationPlugin::test_renegotiation_is_vulnerable_to_client_renegotiation_dos"], "indent": 8}
{"namespace": "prometheus_client.mmap_dict.MmapedDict.read_value", "type": "method", "project_path": "System/prometheus-client", "completion_path": "System/prometheus-client/prometheus_client/mmap_dict.py", "signature_position": [121, 121], "body_position": [122, 125], "dependency": {"intra_class": ["prometheus_client.mmap_dict.MmapedDict._init_value", "prometheus_client.mmap_dict.MmapedDict._m", "prometheus_client.mmap_dict.MmapedDict._positions"], "intra_file": ["prometheus_client.mmap_dict._unpack_two_doubles"], "cross_file": []}, "requirement": {"Functionality": "Read the value corresponding to the given key from the MmapedDict instance. If the key is not found in the instance, it initializes the value and then returns it.", "Arguments": ":param self: MmapedDict. An instance of the MmapedDict class.\n:param key: The key to read the value from the instance.\n:return: The value corresponding to the key."}, "tests": ["tests/test_multiprocess.py::TestMmapedDict::test_process_restart"], "indent": 8}
{"namespace": "zulipterminal.server_url.near_message_url", "type": "function", "project_path": "Communications/zulip-term", "completion_path": "Communications/zulip-term/zulipterminal/server_url.py", "signature_position": [73, 73], "body_position": [79, 83], "dependency": {"intra_class": [], "intra_file": ["zulipterminal.server_url.near_pm_message_url", "zulipterminal.server_url.near_stream_message_url"], "cross_file": ["zulipterminal.api_types.Message"]}, "requirement": {"Functionality": "This function returns the correct encoded URL of a message based on its type (stream or private message). It calls the appropriate helper function to generate the URL.", "Arguments": ":param server_url: String. The base URL of the server.\n:param message: Message. The message object for which the URL needs to be generated.\n:return: String. The encoded URL of the message."}, "tests": ["tests/server_url/test_server_url.py::test_near_message_url"], "indent": 4}
{"namespace": "datasette.facets.ArrayFacet.facet_results", "type": "method", "project_path": "Database/datasette", "completion_path": "Database/datasette/datasette/facets.py", "signature_position": [370, 371], "body_position": [372, 453], "dependency": {"intra_class": ["datasette.facets.ArrayFacet.type"], "intra_file": ["datasette.facets.Facet.database", "datasette.facets.Facet.ds", "datasette.facets.Facet.get_configs", "datasette.facets.Facet.get_facet_size", "datasette.facets.Facet.get_querystring_pairs", "datasette.facets.Facet.params", "datasette.facets.Facet.request", "datasette.facets.Facet.sql"], "cross_file": ["datasette.database.QueryInterrupted", "datasette.utils.escape_sqlite", "datasette.utils.path_with_added_args", "datasette.utils.path_with_removed_args", "datasette.app.Datasette.absolute_url", "datasette.app.Datasette.execute", "datasette.app.Datasette.setting", "datasette.app.Datasette.urls", "datasette.url_builder.Urls.path"]}, "requirement": {"Functionality": "This function retrieves facet results for an ArrayFacet instance. It iterates through the configurations and generates facet SQL queries based on the column and other parameters. It then executes the queries and processes the results to create facet result objects. Finally, it returns the facet results and a list of columns that timed out during the execution.", "Arguments": ":param self: ArrayFacet. An instance of the ArrayFacet class.\n:return: Tuple. A tuple containing the facet results and a list of columns that timed out during the execution."}, "tests": ["tests/test_facets.py::test_array_facet_results"], "indent": 8}
{"namespace": "mingus.core.progressions.substitute_diminished_for_diminished", "type": "function", "project_path": "Multimedia/mingus", "completion_path": "Multimedia/mingus/mingus/core/progressions.py", "signature_position": [363, 365], "body_position": [374, 395], "dependency": {"intra_class": [], "intra_file": ["mingus.core.progressions.interval_diff", "mingus.core.progressions.parse_string", "mingus.core.progressions.skip", "mingus.core.progressions.tuple_to_string"], "cross_file": []}, "requirement": {"Functionality": "This function substitutes a diminished chord for another diminished chord in a given progression based on certain conditions.\nThe function first parses the chord at the specified index in the given progression. It then checks if the chord suffix is 'dim7', 'dim', or an empty string with a Roman numeral 'VII'. If the ignore_suffix flag is set to True, the suffix is ignored. If any of the above conditions are met, the function adds a diminished chord to the result. Iterates three times, each time skipping to the next chord based on the last chord's position and adding the appropriate accidentals. The resulting chords are appended to the result list.\n", "Arguments": ":param progression: List of strings. The chord progression.\n:param substitute_index: Int. The index of the chord to be substituted.\n:param ignore_suffix: Bool. Whether to ignore the chord suffix when substituting. Defaults to False.\n:return: List of strings. The substituted chord progression.\n"}, "tests": ["tests/unit/core/test_progressions.py::test_progressions::test_substitute_diminished_for_diminished"], "indent": 4}
{"namespace": "boto.ec2.securitygroup.SecurityGroup.add_rule", "type": "method", "project_path": "Internet/boto", "completion_path": "Internet/boto/boto/ec2/securitygroup.py", "signature_position": [97, 99], "body_position": [105, 116], "dependency": {"intra_class": ["boto.ec2.securitygroup.SecurityGroup.rules"], "intra_file": ["boto.ec2.securitygroup.IPPermissions", "boto.ec2.securitygroup.IPPermissions.__init__", "boto.ec2.securitygroup.IPPermissions.add_grant", "boto.ec2.securitygroup.IPPermissions.from_port", "boto.ec2.securitygroup.IPPermissions.ip_protocol", "boto.ec2.securitygroup.IPPermissions.to_port"], "cross_file": []}, "requirement": {"Functionality": "Add a rule to a SecurityGroup instance. Note that this method only changes the local version of the instance. No information is sent to EC2.", "Arguments": ":param self: SecurityGroup. An instance of the SecurityGroup class.\n:param ip_protocol: String. The IP protocol for the rule.\n:param from_port: Integer. The starting port range for the rule.\n:param to_port: Integer. The ending port range for the rule.\n:param src_group_name: String. The name of the source security group.\n:param src_group_owner_id: String. The ID of the owner of the source security group.\n:param cidr_ip: String. The CIDR IP range for the rule.\n:param src_group_group_id: String. The ID of the source security group.\n:param dry_run: Bool. Whether to perform a dry run. Defaults to False.\n:return: No return values."}, "tests": ["tests/unit/ec2/test_securitygroup.py::SecurityGroupTest::test_add_rule"], "indent": 8}
{"namespace": "sumy.nlp.stemmers.null_stemmer", "type": "function", "project_path": "Internet/sumy", "completion_path": "Internet/sumy/sumy/nlp/stemmers/__init__.py", "signature_position": [16, 16], "body_position": [18, 19], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["sumy._compat.to_unicode"]}, "requirement": {"Functionality": "This function takes an object as input and converts it to a lowercase Unicode string.", "Arguments": ":param object: Any data type. The object to be converted to lowercase Unicode.\n:return: String. The converted object in lowercase Unicode."}, "tests": ["tests/test_stemmers.py::test_null_stemmer"], "indent": 4}
{"namespace": "pyramid.scripts.pshell.PShellCommand.make_shell", "type": "method", "project_path": "Internet/pyramid", "completion_path": "Internet/pyramid/src/pyramid/scripts/pshell.py", "signature_position": [238, 238], "body_position": [239, 279], "dependency": {"intra_class": ["pyramid.scripts.pshell.PShellCommand.args", "pyramid.scripts.pshell.PShellCommand.default_runner", "pyramid.scripts.pshell.PShellCommand.find_all_shells", "pyramid.scripts.pshell.PShellCommand.preferred_shells"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function is used to determine which shell to use for the PShellCommand instance. If the user has specified a shell, it will use that shell if it is available, otherwise it will raise a ValueError with 'could not find a shell named \"%s\"' as the message. If the user has not specified a shell, it will use the first available preferred shell if that is specified, otherwise it will use the first available shell, with python as the least preferred shell. If no shell is available at all, it will use the default runner.", "Arguments": ":param self: PShellCommand. An instance of the PShellCommand class.\n:return: The selected shell to be used."}, "tests": ["tests/test_scripts/test_pshell.py::TestPShellCommand::test_shell_ordering", "tests/test_scripts/test_pshell.py::TestPShellCommand::test_shell_override", "tests/test_scripts/test_pshell.py::TestPShellCommand::test_shell_entry_points"], "indent": 8}
{"namespace": "mrjob.hadoop.HadoopJobRunner._find_binaries_and_jars", "type": "method", "project_path": "System/mrjob", "completion_path": "System/mrjob/mrjob/hadoop.py", "signature_position": [334, 334], "body_position": [342, 348], "dependency": {"intra_class": ["mrjob.hadoop.HadoopJobRunner.get_hadoop_streaming_jar", "mrjob.hadoop.HadoopJobRunner.get_hadoop_version"], "intra_file": [], "cross_file": ["mrjob.runner.MRJobRunner._has_hadoop_streaming_steps", "mrjob.runner.MRJobRunner._has_spark_steps", "mrjob.bin.MRJobBinRunner.get_spark_submit_bin"]}, "requirement": {"Functionality": "This function is used to find the necessary Hadoop and Spark binaries and jars before continuing with the job. It triggers the loading of the Hadoop binary and checks if there are Hadoop streaming steps or Spark steps in the job. If there are, it also loads the Hadoop streaming jar and the Spark submit binary.", "Arguments": ":param self: HadoopJobRunner. An instance of the HadoopJobRunner class.\n:return: No return values."}, "tests": ["tests/test_hadoop.py::FindBinariesAndJARsTestCase::test_always_call_get_hadoop_version"], "indent": 8}
{"namespace": "bentoml._internal.runner.container.DefaultContainer.from_batch_payloads", "type": "method", "project_path": "Scientific-Engineering/bentoml", "completion_path": "Scientific-Engineering/bentoml/src/bentoml/_internal/runner/container.py", "signature_position": [550, 554], "body_position": [555, 556], "dependency": {"intra_class": ["bentoml._internal.runner.container.DefaultContainer.batches_to_batch"], "intra_file": ["bentoml._internal.runner.container.Payload"], "cross_file": []}, "requirement": {"Functionality": "This function takes a sequence of payloads and converts them into batches. It creates a list of batches on each payload in the sequence. Then, it combines the batches into a single batch along the specified batch dimension.", "Arguments": ":param cls: DefaultContainer. The class itself.\n:param payloads: Sequence of Payload. The payloads to be converted into batches.\n:param batch_dim: int. The dimension along which the batches will be combined. Defaults to 0.\n:return: tuple[list[Any], list[int]]. A tuple containing the list of batches and a list of integers representing the batch sizes."}, "tests": ["tests/unit/_internal/runner/test_container.py::test_default_container"], "indent": 8}
{"namespace": "falcon.http_error.HTTPError.to_json", "type": "method", "project_path": "Internet/falcon", "completion_path": "Internet/falcon/falcon/http_error.py", "signature_position": [178, 178], "body_position": [191, 195], "dependency": {"intra_class": ["falcon.http_error.HTTPError.to_dict"], "intra_file": ["falcon.http_error._DEFAULT_JSON_HANDLER"], "cross_file": ["falcon.constants.MEDIA_JSON", "falcon.media.json.JSONHandler.serialize"]}, "requirement": {"Functionality": "This function converts the HTTPError instance into a JSON representation. It takes an optional handler object to customize the serialization process. If no handler is provided, a default handler using the built-in JSON library is used.", "Arguments": ":param self: HTTPError. An instance of the HTTPError class.\n:param handler: Handler object. An optional handler object that will be used to serialize the representation of this error to JSON. Defaults to None.\n:return: bytes. A JSON document representing the error."}, "tests": ["tests/test_httperror.py::TestHTTPError::test_to_json_dumps"], "indent": 8}
{"namespace": "boto.s3.connect_to_region", "type": "function", "project_path": "Internet/boto", "completion_path": "Internet/boto/boto/s3/__init__.py", "signature_position": [62, 62], "body_position": [63, 76], "dependency": {"intra_class": [], "intra_file": ["boto.s3.S3RegionInfo", "boto.s3.S3RegionInfo.connect"], "cross_file": ["boto.regioninfo.connect", "boto.s3.connection.S3Connection", "boto.regioninfo", "boto.regioninfo.RegionInfo.__init__"]}, "requirement": {"Functionality": "Connect to a specific region using the provided region name and additional parameters. It first checks if a custom host is provided in the input parameters. If so, it creates a custom region and connects to it using the provided parameters. Otherwise, it connects to the default S3 region using the region name and additional parameters.", "Arguments": ":param region_name: String. The name of the region to connect to.\n:param kw_params: Additional keyword arguments that can be passed to the connection.\n:return: The connection to the specified region."}, "tests": ["tests/unit/test_connect_to_region.py::TestS3Connection::test_connect_to_custom_host", "tests/unit/test_connect_to_region.py::TestS3Connection::test_connect_to_region"], "indent": 4}
{"namespace": "alembic.operations.ops.DropColumnOp.from_column_and_tablename", "type": "method", "project_path": "Database/alembic", "completion_path": "Database/alembic/alembic/operations/ops.py", "signature_position": [2202, 2207], "body_position": [2208, 2213], "dependency": {"intra_class": ["alembic.operations.ops.DropColumnOp.__init__"], "intra_file": ["alembic.operations.ops.AddColumnOp", "alembic.operations.ops.AddColumnOp.from_column_and_tablename"], "cross_file": []}, "requirement": {"Functionality": "This function creates an instance of the class based on the given parameters.", "Arguments": ":param cls: A class.\n:param schema: Optional string. The schema of the table.\n:param tname: String. The name of the table.\n:param col: Column. The column to be dropped.\n:return: The created instance."}, "tests": ["tests/test_autogen_render.py::AutogenRenderTest::test_render_drop_column_w_schema", "tests/test_autogen_render.py::AutogenRenderTest::test_render_drop_column", "tests/test_autogen_diffs.py::OrigObjectTest::test_drop_column"], "indent": 8}
{"namespace": "boto.dynamodb2.table.Table.count", "type": "method", "project_path": "Internet/boto", "completion_path": "Internet/boto/boto/dynamodb2/table.py", "signature_position": [1604, 1604], "body_position": [1617, 1618], "dependency": {"intra_class": ["boto.dynamodb2.table.Table.describe"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function returns an approximate count of the number of items in a table. The count may not be accurate due to lag time.", "Arguments": ":param self: Table. An instance of the Table class.\n:return: Integer. The approximate count of the number of items in the table."}, "tests": ["tests/unit/dynamodb2/test_table.py::TableTestCase::test_count"], "indent": 8}
{"namespace": "pyramid.i18n.Translations.add", "type": "method", "project_path": "Internet/pyramid", "completion_path": "Internet/pyramid/src/pyramid/i18n.py", "signature_position": [277, 277], "body_position": [293, 307], "dependency": {"intra_class": ["pyramid.i18n.Translations.DEFAULT_DOMAIN", "pyramid.i18n.Translations._domains", "pyramid.i18n.Translations.domain", "pyramid.i18n.Translations.merge", "pyramid.i18n.Translations.plural"], "intra_file": ["pyramid.i18n.DEFAULT_PLURAL"], "cross_file": []}, "requirement": {"Functionality": "This function adds the given translations to the catalog. If the domain of the translations is different from the current catalog, they are added as a separate catalog. It also provides the option to merge translations for message domains that have already been added.", "Arguments": ":param self: Translations. An instance of the Translations class.\n:param translations: Translations. The Translations instance with the messages to add.\n:param merge: Bool. Whether translations for message domains that have already been added should be merged with the existing translations. Defaults to True.\n:return: Translations. The Translations instance (self) so that merge calls can be easily chained."}, "tests": ["tests/test_i18n.py::TestTranslations::test_add_default_domain_replaces_plural_first_time", "tests/test_i18n.py::TestTranslations::test_add_different_domain_merge_true_notexisting", "tests/test_i18n.py::TestTranslations::test_add_same_domain_merge_true", "tests/test_i18n.py::TestTranslations::test_add_different_domain_merge_true_existing"], "indent": 8}
{"namespace": "twilio.twiml.voice_response.Dial.client", "type": "method", "project_path": "Communications/twilio-fatisar", "completion_path": "Communications/twilio-fatisar/twilio/twiml/voice_response.py", "signature_position": [1974, 1983], "body_position": [1997, 2007], "dependency": {"intra_class": [], "intra_file": ["twilio.twiml.voice_response.Client", "twilio.twiml.voice_response.Client.__init__"], "cross_file": ["twilio.twiml.TwiML.nest"]}, "requirement": {"Functionality": "This function creates a `<Client>` element with the given parameters and returns it. It is used to create a client element for making calls in the Dial class.", "Arguments": ":param self: Dial. An instance of the Dial class.\n:param identity: String [optional]. The identity of the client.\n:param url: String [optional]. The URL of the client.\n:param method: String [optional]. The method to be used for the client URL.\n:param status_callback_event: String [optional]. The events that trigger the status callback.\n:param status_callback: String [optional]. The URL for the status callback.\n:param status_callback_method: String [optional]. The method to be used for the status callback URL.\n:param kwargs: Additional attributes [optional].\n:return: `<Client>` element. The created client element."}, "tests": ["tests/unit/twiml/test_voice_response.py::TestDial::test_add_client", "tests/unit/twiml/test_voice_response.py::TestDial::test_add_empty_client"], "indent": 8}
{"namespace": "boto.dynamodb2.table.Table._build_filters", "type": "method", "project_path": "Internet/boto", "completion_path": "Internet/boto/boto/dynamodb2/table.py", "signature_position": [990, 990], "body_position": [995, 1052], "dependency": {"intra_class": ["boto.dynamodb2.table.Table._dynamizer"], "intra_file": [], "cross_file": ["boto.dynamodb2.exceptions.UnknownFilterTypeError", "boto.dynamodb2.types.QUERY_OPERATORS", "boto.dynamodb2.exceptions", "boto.dynamodb.types.Dynamizer.encode"]}, "requirement": {"Functionality": "This function is an internal method used to convert query/scan-style keyword arguments into the raw structure that DynamoDB expects for filtering. It creates a dictionary of filters based on the input filter_kwargs.", "Arguments": ":param self: Table. An instance of the Table class.\n:param filter_kwargs: Dictionary. The query/scan-style keyword arguments to be converted into filters.\n:param using: Dictionary. The dictionary of query operators to be used for comparison. It defaults to QUERY_OPERATORS if not specified.\n:return: None."}, "tests": ["tests/unit/dynamodb2/test_table.py::TableTestCase::test__build_filters"], "indent": 8}
{"namespace": "bplustree.memory.WAL.checkpoint", "type": "method", "project_path": "Database/bplustree", "completion_path": "Database/bplustree/bplustree/memory.py", "signature_position": [314, 314], "body_position": [316, 333], "dependency": {"intra_class": ["bplustree.memory.WAL._committed_pages", "bplustree.memory.WAL._dir_fd", "bplustree.memory.WAL._fd", "bplustree.memory.WAL._not_committed_pages", "bplustree.memory.WAL._page_size", "bplustree.memory.WAL.filename"], "intra_file": ["bplustree.memory.fsync_file_and_dir", "bplustree.memory.logger", "bplustree.memory.read_from_file"], "cross_file": []}, "requirement": {"Functionality": "This function is used to checkpoint the modified data back to the tree and close the Write-Ahead Log (WAL). It first checks if there are any uncommitted data and logs a warning message if there are. Then, it performs a file sync operation on the file descriptor and directory file descriptor. Next, it reads the committed pages from the file and yields each page along with its corresponding data. After that, it closes the file descriptor, deletes the WAL file, and performs a file sync operation on the directory file descriptor if it exists.", "Arguments": ":param self: WAL. An instance of the WAL class.\n:return: No return values."}, "tests": ["tests/test_memory.py::test_wal_checkpoint"], "indent": 8}
{"namespace": "bentoml._internal.runner.container.NdarrayContainer.batch_to_payloads", "type": "method", "project_path": "Scientific-Engineering/bentoml", "completion_path": "Scientific-Engineering/bentoml/src/bentoml/_internal/runner/container.py", "signature_position": [323, 328], "body_position": [329, 332], "dependency": {"intra_class": ["bentoml._internal.runner.container.NdarrayContainer.batch_to_batches", "bentoml._internal.runner.container.NdarrayContainer.to_payload"], "intra_file": ["bentoml._internal.runner.container.Payload"], "cross_file": ["bentoml._internal.external_typing.NpNDArray", "bentoml._internal.external_typing"]}, "requirement": {"Functionality": "This function converts a batch of ndarrays into a list of payloads. It first divides the batch into smaller batches based on the given indices and batch dimension. Then, it converts each subbatch into a payload.", "Arguments": ":param cls: NdarrayContainer. The class itself.\n:param batch: ext.NpNDArray. The input batch of ndarrays.\n:param indices: Sequence of integers. The indices used to divide the batch into smaller batches.\n:param batch_dim: Integer. The dimension along which the batch is divided. Defaults to 0.\n:return: list[Payload]. The list of payloads created from the batch."}, "tests": ["tests/unit/_internal/runner/test_container.py::test_ndarray_container"], "indent": 8}
{"namespace": "pylatex.utils.dumps_list", "type": "function", "project_path": "Text-Processing/PyLaTeX", "completion_path": "Text-Processing/PyLaTeX/pylatex/utils.py", "signature_position": [150, 150], "body_position": [189, 201], "dependency": {"intra_class": [], "intra_file": ["pylatex.utils.NoEscape.__init__", "pylatex.utils._latex_item_to_string"], "cross_file": []}, "requirement": {"Functionality": "This function takes a list of objects and generates a LaTeX string representation of the list. It converts each object in the list to a string and separates them using a specified token. It also provides options for escaping special LaTeX characters and applying additional mapping functions to the objects in the list.", "Arguments": ":param l: list. A list of objects to be converted into a single string.\n:param escape: bool. Whether to escape special LaTeX characters in converted text. Defaults to True.\n:param token: str. The token to separate objects in the list. Defaults to \"%\\n\".\n:param mapper: callable or list. A function, class, or a list of functions/classes that should be called on all entries of the list after converting them to a string.\n:param as_content: bool. Indicates whether the items in the list should be dumped using `~.LatexObject.dumps_as_content`.\n:return: NoEscape. A single LaTeX string."}, "tests": ["tests/test_utils_dumps_list.py::test_mapper"], "indent": 4}
{"namespace": "zxcvbn.scoring.uppercase_variations", "type": "function", "project_path": "Security/zxcvbn-python", "completion_path": "Security/zxcvbn-python/zxcvbn/scoring.py", "signature_position": [374, 374], "body_position": [375, 390], "dependency": {"intra_class": [], "intra_file": ["zxcvbn.scoring.ALL_LOWER", "zxcvbn.scoring.ALL_UPPER", "zxcvbn.scoring.END_UPPER", "zxcvbn.scoring.START_UPPER", "zxcvbn.scoring.nCk"], "cross_file": []}, "requirement": {"Functionality": "This function calculates the number of uppercase variations in a given word. It checks if the word is all lowercase or if it is already in lowercase, and returns 1 in those cases. Otherwise, it checks if the word starts with an uppercase letter, ends with an uppercase letter, or is all uppercase, and returns 2 in those cases. If none of the above conditions are met, it calculates the number of uppercase and lowercase letters in the word and calculates the number of variations possible by combining them. It returns the total number of variations.", "Arguments": ":param match: Dictionary. A dictionary containing the token (word) to be checked.\n:return: Integer. The number of uppercase variations in the word."}, "tests": ["tests/scoring_test.py::test_dictionary_guesses", "tests/scoring_test.py::test_uppercase_variants"], "indent": 4}
{"namespace": "mingus.core.intervals.is_consonant", "type": "function", "project_path": "Multimedia/mingus", "completion_path": "Multimedia/mingus/mingus/core/intervals.py", "signature_position": [489, 489], "body_position": [502, 504], "dependency": {"intra_class": [], "intra_file": ["mingus.core.intervals.is_imperfect_consonant", "mingus.core.intervals.is_perfect_consonant"], "cross_file": []}, "requirement": {"Functionality": "This function determines if the given interval between two notes is consonant.\n", "Arguments": ":param note1: str. The first note. \n:param note2: str. The second note.\n:param include_fourths: bool. Whether to include perfect fourths as consonant intervals. Defaults to True.\n:return: bool. True if the interval is consonant, False otherwise.\n"}, "tests": ["tests/unit/core/test_intervals.py::test_intervals::test_is_consonant"], "indent": 4}
{"namespace": "mrjob.logs.history._parse_pre_yarn_history_records", "type": "function", "project_path": "System/mrjob", "completion_path": "System/mrjob/mrjob/logs/history.py", "signature_position": [336, 336], "body_position": [360, 392], "dependency": {"intra_class": [], "intra_file": ["mrjob.logs.history._PRE_YARN_HISTORY_KEY_PAIR", "mrjob.logs.history._PRE_YARN_HISTORY_RECORD", "mrjob.logs.history._pre_yarn_history_unescape"], "cross_file": []}, "requirement": {"Functionality": "This function parses a sequence of lines and yields records based on the given format. The function extracts the fields and their values from each line. It handles unescaping values and can handle multi-line records. The format begins the line with the type, and then the fields are specified in the format 'field_name=\"field_value\"'. The fields are separated by spaces. Each record ends with a period that ends the line.", "Arguments": ":param lines: List[str]. The sequence of lines to parse.\n:return: Generator. Yields dict representing each record, with 'fields', 'num_lines', 'start_line' and 'type' as keys."}, "tests": ["tests/logs/test_history.py::ParsePreYARNHistoryRecordsTestCase::test_unescape", "tests/logs/test_history.py::ParsePreYARNHistoryRecordsTestCase::test_basic", "tests/logs/test_history.py::ParsePreYARNHistoryRecordsTestCase::test_empty", "tests/logs/test_history.py::ParsePreYARNHistoryRecordsTestCase::test_bad_records", "tests/logs/test_history.py::ParsePreYARNHistoryRecordsTestCase::test_multiline"], "indent": 4}
{"namespace": "pythonforandroid.pythonpackage.get_package_name", "type": "function", "project_path": "Utilities/python-for-android", "completion_path": "Utilities/python-for-android/pythonforandroid/pythonpackage.py", "signature_position": [587, 588], "body_position": [589, 602], "dependency": {"intra_class": [], "intra_file": ["pythonforandroid.pythonpackage._extract_info_from_package", "pythonforandroid.pythonpackage.package_name_cache"], "cross_file": []}, "requirement": {"Functionality": "This function retrieves the package name for a given dependency. It first checks if the package name is already cached and if the cache is still valid. If not, it extracts the package name and updates the cache with the new value.", "Arguments": ":param dependency: The dependency for which the package name is to be retrieved.\n:param use_cache: Bool. Whether to use the cached value if available. Defaults to True.\n:return: The package name of the dependency."}, "tests": ["tests/test_pythonpackage_basic.py::test_get_package_name"], "indent": 4}
{"namespace": "feedparser.urls.make_safe_absolute_uri", "type": "function", "project_path": "Text-Processing/feedparser", "completion_path": "Text-Processing/feedparser/feedparser/urls.py", "signature_position": [86, 87], "body_position": [88, 103], "dependency": {"intra_class": [], "intra_file": ["feedparser.urls.ACCEPTABLE_URI_SCHEMES", "feedparser.urls._urljoin"], "cross_file": []}, "requirement": {"Functionality": "This function creates a safe absolute URI by joining a base URL and a relative URL. If the base URL is empty, it returns the relative URL. If the relative URL is empty, it outputs the base URL. Finally, if the resulting URI's scheme is not acceptable, it returns an empty string. Otherwise, it returns the resulting URI.", "Arguments": ":param base: String. The base URL to join with the relative URL.\n:param rel: String. The relative URL to join with the base URL. Defaults to None.\n:return: String. The safe absolute URI created by joining the base and relative URLs."}, "tests": ["tests/runtests.py::TestMakeSafeAbsoluteURI::test_catch_ValueError"], "indent": 4}
{"namespace": "twilio.twiml.voice_response.VoiceResponse.gather", "type": "method", "project_path": "Communications/twilio-fatisar", "completion_path": "Communications/twilio-fatisar/twilio/twiml/voice_response.py", "signature_position": [152, 173], "body_position": [199, 221], "dependency": {"intra_class": [], "intra_file": ["twilio.twiml.voice_response.Gather", "twilio.twiml.voice_response.Gather.__init__"], "cross_file": ["twilio.twiml.TwiML.nest"]}, "requirement": {"Functionality": "This function creates a <Gather> element for Twilio VoiceResponse. It takes various input parameters and returns the <Gather> element with the specified attributes.", "Arguments": ":param self: VoiceResponse. An instance of the VoiceResponse class.\n:param input: String. The type of input that Twilio should accept.\n:param action: String. The URL where Twilio should send the gathered input.\n:param method: String. The HTTP method to be used when making the request to the action URL.\n:param timeout: Integer. The time in seconds that Twilio should wait for input.\n:param speech_timeout: String or Integer. The time in seconds that Twilio should wait for speech input. It can be either \"auto\" or a positive integer.\n:param max_speech_time: Integer. The maximum allowed time for speech input.\n:param profanity_filter: Boolean. Whether to enable the profanity filter on speech input.\n:param finish_on_key: String. The key that should end the gathering of input.\n:param num_digits: Integer. The number of digits to collect.\n:param partial_result_callback: String. The URL where Twilio should send partial recognition results.\n:param partial_result_callback_method: String. The HTTP method to be used when making the request to the partial result callback URL.\n:param language: String. The language to use for speech recognition.\n:param hints: List of strings. Speech recognition hints.\n:param barge_in: Boolean. Whether to stop playing media upon speech input.\n:param debug: Boolean. Whether to allow debug for the gather element.\n:param action_on_empty_result: Boolean. Whether to force the webhook to the action URL event if there is no input.\n:param speech_model: String. Specify the speech model that is best suited for your use case.\n:param enhanced: Boolean. Whether to use the enhanced speech model.\n:param kwargs: Additional attributes.\n:return: <Gather> element. The created <Gather> element with the specified attributes."}, "tests": ["tests/unit/twiml/test_voice_response.py::TestGather::test_empty", "tests/unit/twiml/test_voice_response.py::TestResponse::test_nested_verbs"], "indent": 8}
{"namespace": "boto.utils.LazyLoadMetadata.values", "type": "method", "project_path": "Internet/boto", "completion_path": "Internet/boto/boto/utils.py", "signature_position": [345, 345], "body_position": [346, 347], "dependency": {"intra_class": ["boto.utils.LazyLoadMetadata._materialize"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function returns the values of the LazyLoadMetadata instance after materializing it.", "Arguments": ":param self: LazyLoadMetadata. An instance of the LazyLoadMetadata class.\n:return: The dict values of the LazyLoadMetadata instance."}, "tests": ["tests/unit/utils/test_utils.py::TestLazyLoadMetadata::test_meta_data_with_invalid_json_format_happened_twice", "tests/unit/utils/test_utils.py::TestLazyLoadMetadata::test_meta_data_with_invalid_json_format_happened_once"], "indent": 8}
{"namespace": "falcon.inspect.inspect_error_handlers", "type": "function", "project_path": "Internet/falcon", "completion_path": "Internet/falcon/falcon/inspect.py", "signature_position": [141, 141], "body_position": [152, 157], "dependency": {"intra_class": [], "intra_file": ["falcon.inspect.ErrorHandlerInfo", "falcon.inspect.ErrorHandlerInfo.__init__", "falcon.inspect._get_source_info_and_name", "falcon.inspect._is_internal"], "cross_file": ["falcon.app.App", "falcon.app.App._error_handlers"]}, "requirement": {"Functionality": "This function inspects the error handlers of an application. It iterates through the error handlers dictionary and creates a list of `ErrorHandlerInfo` objects containing information about each error handler.", "Arguments": ":param app: falcon.App. The application to inspect. It can be an instance of either `falcon.App` or `falcon.asgi.App`.\n:return: List[ErrorHandlerInfo]. A list of `ErrorHandlerInfo` objects representing the error handlers used by the application."}, "tests": ["tests/test_inspect.py::TestStringVisitor::test_error_handler", "tests/test_inspect.py::TestInspectApp::test_error_handler", "tests/test_inspect.py::TestStringVisitor::test_error_handler_verbose"], "indent": 4}
{"namespace": "jinja2.environment.Environment.get_template", "type": "method", "project_path": "Internet/Jinja2", "completion_path": "Internet/Jinja2/src/jinja2/environment.py", "signature_position": [976, 981], "body_position": [1005, 1010], "dependency": {"intra_class": ["jinja2.environment.Environment._load_template", "jinja2.environment.Environment.join_path"], "intra_file": ["jinja2.environment.Template"], "cross_file": []}, "requirement": {"Functionality": "This function loads a template by name using the specified loader and returns a Template object. If the template does not exist, a TemplateNotFound exception is raised. It also allows for specifying a parent template and additional global variables.", "Arguments": ":param self: Environment. An instance of the Environment class.\n:param name: Union[str, Template]. The name of the template to load. It can be either a string or a Template object.\n:param parent: Optional[str]. The name of the parent template importing this template.\n:param globals: Optional[MutableMapping[str, Any]]. Additional variables available for all renders of this template. If the template has already been loaded and cached, its globals are updated with any new items.\n:return: Template. The loaded template object."}, "tests": ["tests/test_imports.py::TestIncludes::test_context_include_with_overrides"], "indent": 8}
{"namespace": "pythonforandroid.prerequisites.OpenSSLPrerequisite.darwin_checker", "type": "method", "project_path": "Utilities/python-for-android", "completion_path": "Utilities/python-for-android/pythonforandroid/prerequisites.py", "signature_position": [269, 269], "body_position": [270, 275], "dependency": {"intra_class": ["pythonforandroid.prerequisites.OpenSSLPrerequisite.homebrew_formula_name"], "intra_file": ["pythonforandroid.prerequisites.Prerequisite._darwin_get_brew_formula_location_prefix"], "cross_file": []}, "requirement": {"Functionality": "Check if the OpenSSL prerequisite is met on a Darwin (MacOS) system. It checks if the Homebrew formula for OpenSSL is installed.", "Arguments": ":param self: OpenSSLPrerequisite. An instance of the OpenSSLPrerequisite class.\n:return: bool. True if the OpenSSL prerequisite is met, False otherwise."}, "tests": ["tests/test_prerequisites.py::TestOpenSSLPrerequisite::test_darwin_checker"], "indent": 8}
{"namespace": "mingus.containers.note.Note.to_hertz", "type": "method", "project_path": "Multimedia/mingus", "completion_path": "Multimedia/mingus/mingus/containers/note.py", "signature_position": [226, 226], "body_position": [233, 234], "dependency": {"intra_class": ["mingus.containers.note.Note.__int__"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function converts a given Note instance to Hertz (frequency in cycles per second).\n", "Arguments": ":param self: Note. An instance of the Note class.\n:param standard_pitch: float. The pitch of A-4, from which the rest of the notes are calculated. It defaults to 440 if not specified.\n:return: float. The frequency of the Note in Hertz.\n"}, "tests": ["tests/unit/containers/test_note.py::test_Note::test_to_hertz"], "indent": 8}
{"namespace": "jinja2.environment.Environment.from_string", "type": "method", "project_path": "Internet/Jinja2", "completion_path": "Internet/Jinja2/src/jinja2/environment.py", "signature_position": [1086, 1091], "body_position": [1103, 1105], "dependency": {"intra_class": ["jinja2.environment.Environment.compile", "jinja2.environment.Environment.make_globals", "jinja2.environment.Environment.template_class"], "intra_file": ["jinja2.environment.Template.from_code"], "cross_file": []}, "requirement": {"Functionality": "This function loads a template from a source string without using the loader. It compiles the source string into a template and returns an instance of the Template class.", "Arguments": ":param self: Environment. An instance of the Environment class.\n:param source: Union[str, nodes.Template]. The Jinja source to compile into a template.\n:param globals: Optional[MutableMapping[str, Any]]. Extra variables available for all renders of this template. If the template has already been loaded and cached, its globals are updated with any new items.\n:param template_class: Optional[Type[Template]]. The class of the template to be returned. If not specified, the default template class of the environment is used.\n:return: Template. The loaded template instance."}, "tests": ["tests/test_security.py::TestSandbox::test_attr_filter", "tests/test_security.py::TestSandbox::test_unary_operator_intercepting", "tests/test_security.py::TestStringFormat::test_basic_format_safety", "tests/test_security.py::TestStringFormat::test_safe_format_all_okay", "tests/test_security.py::TestStringFormat::test_empty_braces_format"], "indent": 8}
{"namespace": "wal_e.worker.pg.wal_transfer.WalTransferGroup.start", "type": "method", "project_path": "System/wal-e", "completion_path": "System/wal-e/wal_e/worker/pg/wal_transfer.py", "signature_position": [146, 146], "body_position": [149, 162], "dependency": {"intra_class": ["wal_e.worker.pg.wal_transfer.WalTransferGroup._complete_execution", "wal_e.worker.pg.wal_transfer.WalTransferGroup.closed", "wal_e.worker.pg.wal_transfer.WalTransferGroup.expect", "wal_e.worker.pg.wal_transfer.WalTransferGroup.greenlets", "wal_e.worker.pg.wal_transfer.WalTransferGroup.transferer"], "intra_file": [], "cross_file": ["wal_e.exception.UserCritical"]}, "requirement": {"Functionality": "This function starts the transfer process for a specified wal segment. It creates a gevent.Greenlet instance to execute the transferer function with the given segment as an argument. It then adds the gevent.Greenlet instance to the set of greenlets and starts the execution.", "Arguments": ":param self: WalTransferGroup. An instance of the WalTransferGroup class.\n:param segment: The wal segment to transfer.\n:return: No return values."}, "tests": ["tests/test_wal_transfer.py::test_simple_upload", "tests/test_wal_transfer.py::test_multi_upload", "tests/test_wal_transfer.py::test_multi_pipeline_fail", "tests/test_wal_transfer.py::test_start_after_join", "tests/test_wal_transfer.py::test_multi_explicit_fail"], "indent": 8}
{"namespace": "chatette.cli.interactive_commands.unhide_command.UnhideCommand.execute", "type": "method", "project_path": "Communications/chatette", "completion_path": "Communications/chatette/chatette/cli/interactive_commands/unhide_command.py", "signature_position": [14, 14], "body_position": [19, 55], "dependency": {"intra_class": ["chatette.cli.interactive_commands.unhide_command.UnhideCommand.execute_on_unit"], "intra_file": [], "cross_file": ["chatette.cli.interactive_commands.command_strategy.CommandStrategy", "chatette.cli.interactive_commands.command_strategy.CommandStrategy.command_tokens", "chatette.cli.interactive_commands.command_strategy.CommandStrategy.get_regex_name", "chatette.cli.interactive_commands.command_strategy.CommandStrategy.get_unit_type_from_str", "chatette.cli.interactive_commands.command_strategy.CommandStrategy.print_wrapper", "chatette.cli.interactive_commands.command_strategy.CommandStrategy.split_exact_unit_name", "chatette.cli.interactive_commands.hide_command.HideCommand", "chatette.cli.interactive_commands.hide_command.HideCommand.stored_units", "chatette.cli.terminal_writer.TerminalWriter.write", "chatette.cli.terminal_writer.TerminalWriter.error_log"]}, "requirement": {"Functionality": "This function implements the command `unhide` which restores a unit definition that was hidden from the AST. It takes input arguments and performs certain actions based on the input. Initially, the function checks if the number of command tokens is less than three. It determines the unit type from the second command token and validate the type of unit. It tries to interpret the third command token as a regular expression and execute the restoration process on the unit with different regular expression conditions.", "Arguments": ":param self: UnhideCommand. An instance of the UnhideCommand class.\n:return: No return values."}, "tests": ["tests/unit-testing/cli/interactive_commands/test_hide_command.py::test_variations", "tests/unit-testing/cli/interactive_commands/test_hide_command.py::test_execute", "tests/unit-testing/cli/interactive_commands/test_hide_command.py::test_err"], "indent": 8}
{"namespace": "mingus.core.notes.reduce_accidentals", "type": "function", "project_path": "Multimedia/mingus", "completion_path": "Multimedia/mingus/mingus/core/notes.py", "signature_position": [101, 101], "body_position": [108, 119], "dependency": {"intra_class": [], "intra_file": ["mingus.core.notes.int_to_note", "mingus.core.notes.note_to_int"], "cross_file": ["mingus.core.mt_exceptions.NoteFormatError"]}, "requirement": {"Functionality": "This function reduces any extra accidentals in a given note to proper notes.\n", "Arguments": ":param note: String. The note with accidentals\n:return: String. The reduced note without extra accidentals.\n"}, "tests": ["tests/unit/core/test_notes.py::test_notes::test_reduce_accidentals"], "indent": 4}
{"namespace": "mrjob.job.MRJob.run_combiner", "type": "method", "project_path": "System/mrjob", "completion_path": "System/mrjob/mrjob/job.py", "signature_position": [769, 769], "body_position": [784, 787], "dependency": {"intra_class": ["mrjob.job.MRJob._wrap_protocols", "mrjob.job.MRJob.combine_pairs"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function runs the combiner for the given step. It reads lines using the input protocol, combines them, and writes the combined output using the output protocol.\nThis function first selects the input and output protocol based on the given step and the combiner type. Then it iterates over the key-value pairs from the combine pairs. For each key-value pair, it writes the combined output using the output protocol.\n", "Arguments": ":param step_num: int. The index of the step to run (0-indexed).\n:return: no return values.\n"}, "tests": ["tests/test_job.py::StepNumTestCase::test_wrong_type_of_step"], "indent": 8}
{"namespace": "datasette.app.Datasette.check_visibility", "type": "method", "project_path": "Database/datasette", "completion_path": "Database/datasette/datasette/app.py", "signature_position": [726, 734], "body_position": [736, 753], "dependency": {"intra_class": ["datasette.app.Datasette.ensure_permissions"], "intra_file": [], "cross_file": ["datasette.utils.asgi.Forbidden"]}, "requirement": {"Functionality": "This function checks the visibility of a resource for a given actor. It determines whether the actor can see the resource and whether the resource is private (visible only to the actor) or visible to everyone.", "Arguments": ":param self: Datasette. An instance of the Datasette class.\n:param actor: Dict. The actor for whom the visibility is checked.\n:param action: Optional[str]. The action to be performed on the resource. Defaults to None.\n:param resource: Optional[Union[str, Tuple[str, str]]]. The resource for which visibility is checked. Defaults to None.\n:param permissions: Optional[Sequence[Union[Tuple[str, Union[str, Tuple[str, str]]], str]]]. The permissions to be checked. Defaults to None.\n:return: Tuple[bool, bool]. A tuple containing two boolean values - visible (whether the actor can see the resource) and private (whether the resource is private)."}, "tests": ["tests/test_internals_datasette.py::test_datasette_ensure_permissions_check_visibility"], "indent": 8}
{"namespace": "mssqlcli.packages.sqlcompletion.suggest_type", "type": "function", "project_path": "Database/mssql-cli", "completion_path": "Database/mssql-cli/mssqlcli/packages/sqlcompletion.py", "signature_position": [133, 133], "body_position": [141, 160], "dependency": {"intra_class": [], "intra_file": ["mssqlcli.packages.sqlcompletion.Path", "mssqlcli.packages.sqlcompletion.SqlStatement", "mssqlcli.packages.sqlcompletion.SqlStatement.__init__", "mssqlcli.packages.sqlcompletion.SqlStatement.last_token", "mssqlcli.packages.sqlcompletion.SqlStatement.parsed", "mssqlcli.packages.sqlcompletion.SqlStatement.text_before_cursor", "mssqlcli.packages.sqlcompletion.SqlStatement.word_before_cursor", "mssqlcli.packages.sqlcompletion.suggest_based_on_last_token", "mssqlcli.packages.sqlcompletion.suggest_special"], "cross_file": []}, "requirement": {"Functionality": "This function suggests the completion type and scope based on the input text and the text before the cursor. It first checks if the input text starts with \"\\\\i \", and if so, it suggests a Path type. Then, it creates a SqlStatement instance with the input text and text before the cursor. If the SqlStatement is successfully parsed, it checks for special commands and handles them separately. Finally, it suggests the completion type and scope based on the last token of the SqlStatement.", "Arguments": ":param full_text: String. The full text that has been typed so far.\n:param text_before_cursor: String. The text before the cursor.\n:return: Tuple. A tuple with a type of entity ('table', 'column', etc.) and a scope. For a column category, the scope will be a list of tables."}, "tests": ["tests/test_sqlcompletion.py::SqlCompletionTests::test_where_in_suggests_columns", "tests/test_sqlcompletion.py::SqlCompletionTests::test_on_suggests_aliases_and_join_conditions", "tests/test_sqlcompletion.py::SqlCompletionTests::test_3_statements_2nd_current", "tests/test_sqlcompletion.py::SqlCompletionTests::test_statements_with_cursor_before_function_body", "tests/test_sqlcompletion.py::SqlCompletionTests::test_sub_select_suggests_keyword"], "indent": 4}
{"namespace": "pycoin.services.providers.providers_for_config_string", "type": "function", "project_path": "Security/pycoin", "completion_path": "Security/pycoin/pycoin/services/providers.py", "signature_position": [120, 120], "body_position": [121, 128], "dependency": {"intra_class": [], "intra_file": ["pycoin.services.providers.provider_for_descriptor_and_netcode"], "cross_file": []}, "requirement": {"Functionality": "This function takes a config string and a netcode as input and returns a list of providers. It iterates over each descriptor in the config string, gets the provider for that descriptor and netcode, and appends it to the list of providers. If a provider cannot be parsed for a descriptor, a warning is raised.", "Arguments": ":param config_string: String. The config string containing descriptors.\n:param netcode: The netcode to be used for provider lookup.\n:return: List of providers. The list of providers corresponding to the descriptors in the config string."}, "tests": ["tests/services/services_test.py::ServicesTest::test_env"], "indent": 4}
{"namespace": "mopidy.ext.validate_extension_data", "type": "function", "project_path": "Multimedia/Mopidy", "completion_path": "Multimedia/Mopidy/mopidy/ext.py", "signature_position": [271, 271], "body_position": [278, 357], "dependency": {"intra_class": [], "intra_file": ["mopidy.ext.Extension.validate_environment", "mopidy.ext.ExtensionData", "mopidy.ext.ExtensionData.config_defaults", "mopidy.ext.ExtensionData.config_schema", "mopidy.ext.ExtensionData.entry_point", "mopidy.ext.ExtensionData.extension", "mopidy.ext.logger"], "cross_file": ["mopidy.exceptions.ExtensionError", "mopidy.ext.Extension.ext_name", "mopidy.config", "mopidy.config.types.Boolean", "mopidy.config.types.ConfigValue", "mopidy.exceptions"]}, "requirement": {"Functionality": "This function validates the dependencies and environment of an extension. It checks if the extension's entry point name matches its extension name, if the required dependencies are installed, if the environment is valid, and if the extension has a valid config schema and default config.", "Arguments": ":param data: ExtensionData. The data of the extension to be validated.\n:return: bool. True if the extension is valid and should be run, False otherwise."}, "tests": ["tests/test_ext.py::TestValidateExtensionData::test_extenions_validate_environment_error", "tests/test_ext.py::TestValidateExtensionData::test_extenions_validate_environment_exception", "tests/test_ext.py::TestValidateExtensionData::test_entry_point_require_exception"], "indent": 4}
{"namespace": "mopidy.config.load", "type": "function", "project_path": "Multimedia/Mopidy", "completion_path": "Multimedia/Mopidy/mopidy/config/__init__.py", "signature_position": [107, 107], "body_position": [108, 116], "dependency": {"intra_class": [], "intra_file": ["mopidy.config._load", "mopidy.config._schemas", "mopidy.config._validate", "mopidy.config.read"], "cross_file": ["mopidy.config.keyring", "mopidy.config.keyring.fetch"]}, "requirement": {"Functionality": "This function loads configuration files and validates them against a set of schemas. It first determines the configuration directory based on the current file path. Then, it reads the default configuration file and appends it to an empty list. Then, it extends the list using ext_defaults. Next, it loads the configuration files, combines them with the default configurations and any overrides, and stores the result in the variable \"raw_config\". After that, it appends the external schemas to the list of schemas and validates the \"raw_config\" against the schemas.", "Arguments": ":param files: List of strings. The paths to the configuration files to be loaded.\n:param ext_schemas: List of strings. The paths to the external schemas to be used for validation.\n:param ext_defaults: List of strings. The paths to the external default configuration files.\n:param overrides: List of strings. The additional configuration overrides.\n:return: The validated configuration."}, "tests": ["tests/http/test_extension.py::test_default_config_is_valid"], "indent": 4}
{"namespace": "mrjob.logs.task._parse_task_syslog", "type": "function", "project_path": "System/mrjob", "completion_path": "System/mrjob/mrjob/logs/task.py", "signature_position": [340, 340], "body_position": [357, 358], "dependency": {"intra_class": [], "intra_file": ["mrjob.logs.task._parse_task_syslog_records"], "cross_file": ["mrjob.logs.log4j._parse_hadoop_log4j_records"]}, "requirement": {"Functionality": "Parses an error out of a syslog file (or a Spark stderr file). \n", "Arguments": ":param lines: List of strings. The lines of the syslog file.\n:return: Dict. A dictionary containing the parsed information. It may contain the following keys:check_stdout, hadoop_error, split.\n"}, "tests": ["tests/logs/test_task.py::ParseTaskSyslogTestCase::test_spark_application_failed", "tests/logs/test_task.py::ParseTaskSyslogTestCase::test_opening_file", "tests/logs/test_task.py::ParseTaskSyslogTestCase::test_yarn_error", "tests/logs/test_task.py::ParseTaskSyslogTestCase::test_empty", "tests/logs/test_task.py::ParseTaskSyslogTestCase::test_spark_executor_exception"], "indent": 4}
{"namespace": "bentoml._internal.runner.strategy.DefaultStrategy.get_worker_count", "type": "method", "project_path": "Scientific-Engineering/bentoml", "completion_path": "Scientific-Engineering/bentoml/src/bentoml/_internal/runner/strategy.py", "signature_position": [61, 66], "body_position": [67, 101], "dependency": {"intra_class": [], "intra_file": ["bentoml._internal.runner.strategy.logger"], "cross_file": ["bentoml._internal.resource.get_resource", "bentoml._internal.resource.system_resources", "bentoml._internal.runner.runnable.Runnable"]}, "requirement": {"Functionality": "This function calculates the number of workers needed based on the given parameters. It first checks if there is a resource request for Nvidia GPUs and if the runnable class supports Nvidia GPUs. If so, it calculates the number of workers based on the number of available Nvidia GPUs and the workers per resource value. If not, it checks if there are CPUs available and if the runnable class supports CPUs. If so, it calculates the number of workers based on the number of available CPUs and the workers per resource value. If none of the conditions are met, it raises a ValueError indicating that there are no known supported resources available for the runnable class.", "Arguments": ":param cls: DefaultStrategy. The class itself.\n:param runnable_class: Type[Runnable]. The class of the runnable object.\n:param resource_request: Union[Dict[str, Any], None]. The resource request for the runnable object. Defaults to None.\n:param workers_per_resource: Union[int, float]. The number of workers per resource.\n:return: int. The number of workers needed based on the given parameters."}, "tests": ["tests/unit/_internal/runner/test_strategy.py::test_default_gpu_strategy", "tests/unit/_internal/runner/test_strategy.py::test_default_cpu_strategy"], "indent": 8}
{"namespace": "mopidy.config.types.String.serialize", "type": "method", "project_path": "Multimedia/Mopidy", "completion_path": "Multimedia/Mopidy/mopidy/config/types.py", "signature_position": [114, 114], "body_position": [115, 119], "dependency": {"intra_class": [], "intra_file": ["mopidy.config.types._TransformedValue", "mopidy.config.types.encode"], "cross_file": []}, "requirement": {"Functionality": "Serialize a value into a string representation. If the value is None, an empty string is returned. If the value is transformed, the original value is used for serialization. The value is then encoded into a string representation.", "Arguments": ":param self: String. An instance of the String class.\n:param value: Any. The value to be serialized.\n:param display: Bool. Whether to display the serialized value. Defaults to False.\n:return: str. The string representation of the serialized value."}, "tests": ["tests/config/test_types.py::TestString::test_serialize_transformed_value", "tests/config/test_types.py::TestString::test_serialize_handles_escapes", "tests/config/test_types.py::TestString::test_serialize_decodes_bytes", "tests/config/test_types.py::TestString::test_serialize_returns_text", "tests/config/test_types.py::TestString::test_serialize_none"], "indent": 8}
{"namespace": "mssqlcli.packages.parseutils.ctes.extract_ctes", "type": "function", "project_path": "Database/mssql-cli", "completion_path": "Database/mssql-cli/mssqlcli/packages/parseutils/ctes.py", "signature_position": [49, 49], "body_position": [59, 93], "dependency": {"intra_class": [], "intra_file": ["mssqlcli.packages.parseutils.ctes.get_cte_from_token", "mssqlcli.packages.parseutils.ctes.token_start_pos"], "cross_file": []}, "requirement": {"Functionality": "This function extracts constant table expressions (CTEs) from a given SQL query. It parses the query using a parser and checks if the first meaningful token is \"WITH\", which indicates the presence of CTEs. It then extracts the CTEs from the query and returns them as a list of TableExpression namedtuples. The function also returns the remaining SQL text after the CTEs have been stripped.", "Arguments": ":param sql: String. The SQL query from which to extract CTEs.\n:return: Tuple. The first element is a list of TableExpression namedtuples representing the extracted CTEs. The second element is the remaining SQL text after the CTEs have been stripped."}, "tests": ["tests/parseutils/test_ctes.py::test_simple_cte_extraction", "tests/parseutils/test_ctes.py::test_cte_extraction_around_comments", "tests/parseutils/test_ctes.py::test_multiple_cte_extraction"], "indent": 4}
{"namespace": "fs.wildcard.imatch", "type": "function", "project_path": "System/fs", "completion_path": "System/fs/fs/wildcard.py", "signature_position": [41, 42], "body_position": [53, 58], "dependency": {"intra_class": [], "intra_file": ["fs.wildcard._PATTERN_CACHE", "fs.wildcard._translate"], "cross_file": []}, "requirement": {"Functionality": "This function tests whether a given name matches a wildcard pattern in a case-insensitive manner. It uses regular expressions to match the pattern against the name.", "Arguments": ":param pattern: Text. A wildcard pattern to match against the name.\n:param name: Text. A filename to test against the pattern.\n:return: bool. True if the filename matches the pattern, False otherwise."}, "tests": ["tests/test_wildcard.py::TestFNMatch::test_wildcard"], "indent": 4}
{"namespace": "boltons.cacheutils.LRI.pop", "type": "method", "project_path": "Utilities/boltons", "completion_path": "Utilities/boltons/boltons/cacheutils.py", "signature_position": [268, 269], "body_position": [270, 279], "dependency": {"intra_class": ["boltons.cacheutils.LRI._lock", "boltons.cacheutils.LRI._remove_from_ll"], "intra_file": ["boltons.cacheutils._MISSING"], "cross_file": []}, "requirement": {"Functionality": "Pop the key in the LRI instance and return the corresponding value. If the key is not found and the default value is not passed, the exception is re-raised. This function bypasses the hit count and miss count.\n", "Arguments": ":param self: LRI, an instance of the LRI class.\n:param key: The key to remove in the instance.\n:param default: The value to return if the key is not found in the instance. Defaults to _UNSET.\n:return: The value corresponding to the key.\n"}, "tests": ["tests/test_cacheutils.py::test_lru_basic"], "indent": 8}
{"namespace": "awesome_autodl.autodl_topic2papers", "type": "function", "project_path": "Database/awesome-autodl", "completion_path": "Database/awesome-autodl/awesome_autodl/__init__.py", "signature_position": [58, 58], "body_position": [59, 76], "dependency": {"intra_class": [], "intra_file": ["awesome_autodl.autodl_topic2path"], "cross_file": []}, "requirement": {"Functionality": "This function loads YAML files containing information about papers related to different topics in the AutoDL field. It creates an OrderedDict where each key represents a topic and the corresponding value is a list of AutoDLpaper objects created from the data in the YAML file.", "Arguments": ":param: No input parameters.\n:return: OrderedDict. A dictionary where each key represents a topic and the corresponding value is a list of AutoDLpaper objects."}, "tests": ["tests/test_format.py::TestFormat::test_simple"], "indent": 4}
{"namespace": "fs.info.Info.stem", "type": "method", "project_path": "System/fs", "completion_path": "System/fs/fs/info.py", "signature_position": [245, 246], "body_position": [255, 258], "dependency": {"intra_class": ["fs.info.Info.get"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function returns the stem of the name, which is the name minus any suffixes. It retrieves the name from the \"basic\" section of the instance and removes any suffixes by splitting the name at the first dot.", "Arguments": ":param self: Info. An instance of the Info class.\n:return: Text. The stem of the name."}, "tests": ["tests/test_info.py::TestInfo::test_suffix"], "indent": 8}
{"namespace": "mrjob.fs.hadoop.HadoopFilesystem.mkdir", "type": "method", "project_path": "System/mrjob", "completion_path": "System/mrjob/mrjob/fs/hadoop.py", "signature_position": [286, 286], "body_position": [287, 298], "dependency": {"intra_class": ["mrjob.fs.hadoop.HadoopFilesystem.get_hadoop_version", "mrjob.fs.hadoop.HadoopFilesystem.invoke_hadoop"], "intra_file": ["mrjob.fs.hadoop._HADOOP_FILE_EXISTS_RE"], "cross_file": ["mrjob.compat.uses_yarn"]}, "requirement": {"Functionality": "Create a directory in the Hadoop filesystem. It uses Hadoop 'fs -mkdir' command (additionally with '-p' option on Hadoop 2) to create the directory. If the command fails except for the case where the directory already exists, it raises an IOError: 'Could not mkdir {path}'.", "Arguments": ":param self: HadoopFilesystem. An instance of the HadoopFilesystem class.\n:param path: str. The path of the directory to be created.\n:return: No return values."}, "tests": ["tests/fs/test_hadoop.py::HadoopFSTestCase::test_mkdir"], "indent": 8}
{"namespace": "boto.dynamodb.batch.Batch.to_dict", "type": "method", "project_path": "Internet/boto", "completion_path": "Internet/boto/boto/dynamodb/batch.py", "signature_position": [58, 58], "body_position": [62, 80], "dependency": {"intra_class": ["boto.dynamodb.batch.Batch.attributes_to_get", "boto.dynamodb.batch.Batch.consistent_read", "boto.dynamodb.batch.Batch.keys", "boto.dynamodb.batch.Batch.table"], "intra_file": [], "cross_file": ["boto.dynamodb.layer2", "boto.dynamodb.layer2.Layer2.build_key_from_values", "boto.dynamodb.schema"]}, "requirement": {"Functionality": "This function converts a Batch object into the format required for Layer1.", "Arguments": ":param self: Batch. An instance of the Batch class.\n:return: dict. The Batch object converted into the required format for Layer1."}, "tests": ["tests/unit/dynamodb/test_batch.py::TestBatchObjects::test_batch_to_dict", "tests/unit/dynamodb/test_batch.py::TestBatchObjects::test_batch_consistent_read_defaults_to_false"], "indent": 8}
{"namespace": "mrjob.job.MRJob.steps", "type": "method", "project_path": "System/mrjob", "completion_path": "System/mrjob/mrjob/job.py", "signature_position": [497, 497], "body_position": [517, 546], "dependency": {"intra_class": ["mrjob.job.MRJob.spark_args"], "intra_file": [], "cross_file": ["mrjob.step.MRStep", "mrjob.step.SparkStep", "mrjob.step._JOB_STEP_FUNC_PARAMS"]}, "requirement": {"Functionality": "This function redefines the steps of the MRJob class to create a multi-step job. If the steps are not redefined, a one-step job will be automatically created using any of the redefined mapper, reducer, and other related methods.\nThe function creates a dictionary of redefined methods, excluding those that are not redefined. For special cases where the spark method is redefined, a SparkStep is created. MRStep takes commands as strings, but the user defines them in the class as functions that return strings, so the function calls these functions and updates the kwargs dictionary accordingly. Finally, the function returns a list of MRStep objects constructed with the updated kwargs.\n", "Arguments": ":param self: MRJob. An instance of MRJob class.\n:return: List of MRStep. A list of steps constructed with MRStep or other classes in mrjob.step.\n"}, "tests": ["tests/test_job.py::StepsTestCase::test_spark_and_streaming_dont_mix", "tests/test_job.py::StepsTestCase::test_spark_and_spark_args_methods", "tests/test_job.py::StepsTestCase::test_spark_args_ignored_without_spark", "tests/test_job.py::StepsTestCase::test_spark_method"], "indent": 8}
{"namespace": "kinto.core.resource.Resource.plural_post", "type": "method", "project_path": "Internet/kinto", "completion_path": "Internet/kinto/kinto/core/resource/__init__.py", "signature_position": [411, 411], "body_position": [428, 454], "dependency": {"intra_class": ["kinto.core.resource.Resource._add_timestamp_header", "kinto.core.resource.Resource._get_object_or_404", "kinto.core.resource.Resource._raise_412_if_modified", "kinto.core.resource.Resource.model", "kinto.core.resource.Resource.object_id", "kinto.core.resource.Resource.postprocess", "kinto.core.resource.Resource.process_object", "kinto.core.resource.Resource.request"], "intra_file": [], "cross_file": ["kinto.core.resource.model.Model.create_object", "kinto.core.events.ACTIONS", "kinto.core.events.ACTIONS.CREATE", "kinto.core.events.ACTIONS.READ"]}, "requirement": {"Functionality": "This function is the \"POST\" endpoint for creating an object in a model. It first checks if the new object id conflicts with an existing one. If it does, the existing object is returned with a status code of 200. If the \"If-Match\" header is provided and the objects have been modified in the meantime, a \"HTTPPreconditionFailed\" exception is raised. If the object id is specified, it is added to the posted body and the existing object is looked up. If the object exists, it is returned with a status code of 200. If the object does not exist, the new object is processed, created, and returned with a status code of 201.", "Arguments": ":param self: Resource. An instance of the Resource class.\n:return: The created or existing object with the appropriate status code."}, "tests": ["tests/core/resource/test_model.py::CreateTest::test_create_object_returns_at_least_id_and_last_modified", "tests/core/resource/test_sync.py::SinceModifiedTest::test_filter_from_last_modified_is_exclusive", "tests/core/resource/test_model.py::CreateTest::test_new_objects_are_linked_to_owner", "tests/core/resource/test_sync.py::SinceModifiedTest::test_delete_timestamp_header_is_equal_to_last_deleted", "tests/core/resource/test_sync.py::SinceModifiedTest::test_objects_created_during_fetch_are_above_fetch_timestamp"], "indent": 8}
{"namespace": "mrjob.job.MRJob.run_mapper", "type": "method", "project_path": "System/mrjob", "completion_path": "System/mrjob/mrjob/job.py", "signature_position": [754, 754], "body_position": [764, 767], "dependency": {"intra_class": ["mrjob.job.MRJob._wrap_protocols", "mrjob.job.MRJob.map_pairs"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function runs the mapper and final mapper action for the given step in the MRJob class. It picks the input and output protocol, reads lines, and writes the key-value pairs.\nUses a method to pick the input and output protocol. It then iterates over the key-value pairs from its map pairs and writes each pair using the output protocol.\n", "Arguments": ":param step_num: int. Specifies which step to run (0-indexed).\n:return: no return values.\n"}, "tests": ["tests/test_job.py::StepNumTestCase::test_nonexistent_steps", "tests/test_job.py::StepNumTestCase::test_wrong_type_of_step", "tests/test_job.py::ProtocolsTestCase::test_mapper_raw_value_to_json"], "indent": 8}
{"namespace": "mingus.core.chords.determine", "type": "function", "project_path": "Multimedia/mingus", "completion_path": "Multimedia/mingus/mingus/core/chords.py", "signature_position": [920, 920], "body_position": [925, 942], "dependency": {"intra_class": [], "intra_file": ["mingus.core.chords.determine_extended_chord5", "mingus.core.chords.determine_extended_chord6", "mingus.core.chords.determine_extended_chord7", "mingus.core.chords.determine_polychords", "mingus.core.chords.determine_seventh", "mingus.core.chords.determine_triad"], "cross_file": ["mingus.core.intervals", "mingus.core.intervals.determine"]}, "requirement": {"Functionality": "This function determines the name of a chord based on the number of notes in the chord.\nUse a series of conditional statements to determine the chord name based on the chord length.\n", "Arguments": ":param chord: List of strings. The list of notes in the chord.\n:param shorthand: Bool. Whether to use shorthand notation for chord names.\n:param no_inversions: Bool. Whether to exclude inversions from the chord name.\n:param no_polychords: Bool. Whether to exclude polychords from the chord name.\n:return: List of strings. The determined chord name.\n"}, "tests": ["tests/unit/core/test_chords.py::test_chords::test_determine"], "indent": 4}
{"namespace": "sacred.config.config_scope.dedent_function_body", "type": "function", "project_path": "Utilities/sacred", "completion_path": "Utilities/sacred/sacred/config/config_scope.py", "signature_position": [167, 167], "body_position": [168, 179], "dependency": {"intra_class": [], "intra_file": ["sacred.config.config_scope.is_empty_or_comment"], "cross_file": []}, "requirement": {"Functionality": "This function dedents the body of a function. It first splits the body into individual lines, then finds the common indentation by examining the first non-empty and non-comment line. After that, it dedents each line by removing the common indentation, and finally joins the dedented lines back together.", "Arguments": ":param body: str. The body of the function to be dedented.\n:return: str. The dedented body of the function."}, "tests": ["tests/test_config/test_config_scope.py::test_dedent_body"], "indent": 4}
{"namespace": "authlib.oauth2.rfc6749.util.list_to_scope", "type": "function", "project_path": "Internet/Authlib", "completion_path": "Internet/Authlib/authlib/oauth2/rfc6749/util.py", "signature_position": [6, 6], "body_position": [8, 12], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["authlib.common.encoding.to_unicode"]}, "requirement": {"Functionality": "This function converts a list of scopes into a space-separated string. It checks if the input scope is of type set, tuple, or list, and then joins the elements of the scope with a space separator. If the scope is None, it returns None. Otherwise, it converts the scope to Unicode and returns it.", "Arguments": ":param scope: The input scope to be converted.\n:return: str. The converted space-separated string representation of the scope."}, "tests": ["tests/core/test_oauth2/test_rfc6749_misc.py::OAuth2UtilTest::test_list_to_scope"], "indent": 4}
{"namespace": "mrjob.conf.load_opts_from_mrjob_confs", "type": "function", "project_path": "System/mrjob", "completion_path": "System/mrjob/mrjob/conf.py", "signature_position": [306, 306], "body_position": [324, 341], "dependency": {"intra_class": [], "intra_file": ["mrjob.conf.load_opts_from_mrjob_conf", "mrjob.conf.log"], "cross_file": []}, "requirement": {"Functionality": "This function loads a list of dictionaries representing the options in a given list of mrjob config files for a specific runner. It returns a list of tuples, where each tuple contains the path of the config file and its corresponding values. If a path is not found, it uses (None, {}) as its value and if the runner alias is also specified, it logs a warning message: 'No config specified for {runner alias} runner'.", "Arguments": ":param runner_alias: str. The identifier of the runner type.\n:param conf_paths: List or None. The locations of the config files to load. If None, it looks for a config file in the default locations.\n:return: List of tuples. Each tuple contains the path of the config file and its corresponding values."}, "tests": ["tests/test_conf.py::MRJobBasicConfTestCase::test_symlink_to_duplicate_conf_path", "tests/test_conf.py::MRJobBasicConfTestCase::test_duplicate_conf_path", "tests/test_conf.py::MRJobBasicConfTestCase::test_conf_path_order_beats_include"], "indent": 4}
{"namespace": "boto.ec2.networkinterface.NetworkInterface.update", "type": "method", "project_path": "Internet/boto", "completion_path": "Internet/boto/boto/ec2/networkinterface.py", "signature_position": [172, 172], "body_position": [183, 191], "dependency": {"intra_class": ["boto.ec2.networkinterface.NetworkInterface._update", "boto.ec2.networkinterface.NetworkInterface.connection", "boto.ec2.networkinterface.NetworkInterface.id", "boto.ec2.networkinterface.NetworkInterface.status"], "intra_file": [], "cross_file": ["boto.ec2.connection.EC2Connection.get_all_network_interfaces"]}, "requirement": {"Functionality": "This function updates the data associated with a NetworkInterface instance by querying EC2. It retrieves the data for the specified ENI ID from EC2 and updates the instance with the new data.", "Arguments": ":param self: NetworkInterface. An instance of the NetworkInterface class.\n:param validate: bool. By default, if EC2 returns no data about the ENI, the update method returns quietly. If the validate parameter is set to True, it will raise a ValueError exception if no data is returned from EC2.\n:param dry_run: bool. Whether to perform a dry run of the update operation. Defaults to False.\n:return: str. The status of the NetworkInterface after the update."}, "tests": ["tests/unit/ec2/test_networkinterface.py::NetworkInterfaceTests::test_update_with_result_set_greater_than_0_updates_dict", "tests/unit/ec2/test_networkinterface.py::NetworkInterfaceTests::test_update_returns_status", "tests/unit/ec2/test_networkinterface.py::NetworkInterfaceTests::test_update_with_validate_true_raises_value_error"], "indent": 8}
{"namespace": "pyramid.registry.Introspector.get_category", "type": "method", "project_path": "Internet/pyramid", "completion_path": "Internet/pyramid/src/pyramid/registry.py", "signature_position": [136, 136], "body_position": [137, 147], "dependency": {"intra_class": ["pyramid.registry.Introspector._categories", "pyramid.registry.Introspector.related"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function retrieves a category from the Introspector instance based on the given category name. It then sorts the values in the category based on the sort key and returns a list of dictionaries containing the introspectable values and their related values.", "Arguments": ":param self: Introspector. An instance of the Introspector class.\n:param category_name: str. The name of the category to retrieve.\n:param default: Any. The default value to return if the category is not found. Defaults to None.\n:param sort_key: Callable. The key function used for sorting the values in the category. Defaults to None. If it is None, the order of the values will be used for sorting.\n:return: List[dict]. A list of dictionaries containing the introspectable values (with the key 'introspectable') and their related values (with the key 'related')."}, "tests": ["tests/test_registry.py::TestIntrospector::test_get_category_returns_default_on_miss", "tests/test_registry.py::TestIntrospector::test_get_category", "tests/test_registry.py::TestIntrospector::test_get_category_with_sortkey"], "indent": 8}
{"namespace": "kinto.core.resource.Resource.get", "type": "method", "project_path": "Internet/kinto", "completion_path": "Internet/kinto/kinto/core/resource/__init__.py", "signature_position": [497, 497], "body_position": [512, 524], "dependency": {"intra_class": ["kinto.core.resource.Resource._add_cache_header", "kinto.core.resource.Resource._add_timestamp_header", "kinto.core.resource.Resource._extract_partial_fields", "kinto.core.resource.Resource._get_object_or_404", "kinto.core.resource.Resource._raise_304_if_not_modified", "kinto.core.resource.Resource._raise_400_if_invalid_id", "kinto.core.resource.Resource._raise_412_if_modified", "kinto.core.resource.Resource.model", "kinto.core.resource.Resource.object_id", "kinto.core.resource.Resource.postprocess", "kinto.core.resource.Resource.request"], "intra_file": [], "cross_file": ["kinto.core.utils.dict_subset"]}, "requirement": {"Functionality": "This function is the \"GET\" endpoint for retrieving an object. It performs several checks and operations before returning the object. It checks if the object is found, if it has been modified, and if any partial fields need to be extracted. It then adds a timestamp header and a cache header to the response and returns the object. If have partial fields, it extracts them from the object as the result object. Depending on the situation, different error labels may be raised.", "Arguments": ":param self: Resource. An instance of the Resource class.\n:return: The retrieved object."}, "tests": ["tests/core/resource/test_object.py::GetTest::test_etag_contains_object_timestamp", "tests/core/resource/test_object.py::MergePatchTest::test_merge_patch_removes_attribute_if_none", "tests/core/resource/test_object.py::MergePatchTest::test_patch_doesnt_remove_attribute_if_not_merge_header", "tests/core/resource/test_object.py::UnknownObjectTest::test_get_object_unknown_raises_404", "tests/core/resource/test_object.py::GetTest::test_get_object_returns_all_fields"], "indent": 8}
{"namespace": "wikipediaapi.WikipediaPage.__repr__", "type": "method", "project_path": "Communications/Wikipedia-API", "completion_path": "Communications/Wikipedia-API/wikipediaapi/__init__.py", "signature_position": [1068, 1068], "body_position": [1069, 1071], "dependency": {"intra_class": ["wikipediaapi.WikipediaPage._called", "wikipediaapi.WikipediaPage.pageid", "wikipediaapi.WikipediaPage.title"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function returns a string representation of a WikipediaPage object. It checks if any recorded methods have been called, and if so, it includes the title, pageid, and ns in the string: \"{title} (id: {page id}, ns: {ns})\". Otherwise, it includes only the title and ns attributes in the string: \"{title} (id: ??, ns: {ns})\"", "Arguments": ":param self: WikipediaPage. An instance of the WikipediaPage class.\n:return: String. The string representation of the WikipediaPage object."}, "tests": ["tests/wikipedia_page_test.py::TestWikipediaPage::test_repr_after_fetching", "tests/wikipedia_page_test.py::TestWikipediaPage::test_repr_before_fetching"], "indent": 8}
{"namespace": "jc.cli.JcCli.about_jc", "type": "method", "project_path": "Utilities/jc", "completion_path": "Utilities/jc/jc/cli.py", "signature_position": [262, 262], "body_position": [264, 284], "dependency": {"intra_class": [], "intra_file": ["jc.cli.info", "jc.cli.info.author", "jc.cli.info.author_email", "jc.cli.info.copyright", "jc.cli.info.description", "jc.cli.info.license", "jc.cli.info.version", "jc.cli.info.website"], "cross_file": ["jc.jc_types.JSONDictType", "jc.lib.all_parser_info", "jc.lib.parser_mod_list", "jc.lib.plugin_parser_mod_list", "jc.lib.standard_parser_mod_list", "jc.lib.streaming_parser_mod_list"]}, "requirement": {"Functionality": "This function returns a dictionary containing information about the jc library and the contents of each parser.info. It includes details such as the library name, version, description, author, author email, website, copyright, license, Python version, Python path, parser count, standard parser count, streaming parser count, plugin parser count, and all parser information.", "Arguments": ":param: No input parameters.\n:return: JSONDictType. A dictionary containing information about the jc library and parser.info."}, "tests": ["tests/test_jc_cli.py::MyTests::test_cli_about_jc"], "indent": 8}
{"namespace": "pyramid.i18n.LocalizerRequestMixin.locale_name", "type": "method", "project_path": "Internet/pyramid", "completion_path": "Internet/pyramid/src/pyramid/i18n.py", "signature_position": [376, 376], "body_position": [377, 378], "dependency": {"intra_class": [], "intra_file": ["pyramid.i18n.negotiate_locale_name"], "cross_file": []}, "requirement": {"Functionality": "This function returns the name of the locale based on the negotiation with the client.", "Arguments": ":param self: LocalizerRequestMixin. An instance of the LocalizerRequestMixin class.\n:return: String. The name of the locale."}, "tests": ["tests/test_i18n.py::TestLocalizerRequestMixin::test_default_localizer"], "indent": 8}
{"namespace": "rest_framework.fields.Field.run_validation", "type": "method", "project_path": "Internet/djangorestframework", "completion_path": "Internet/djangorestframework/rest_framework/fields.py", "signature_position": [534, 534], "body_position": [544, 549], "dependency": {"intra_class": ["rest_framework.fields.Field.run_validators", "rest_framework.fields.Field.to_internal_value", "rest_framework.fields.Field.validate_empty_values"], "intra_file": ["rest_framework.fields.empty"], "cross_file": []}, "requirement": {"Functionality": "This function is used to validate a simple representation and return the internal value. It first checks if the provided data is empty. If it is empty, it returns the data as is. If not, it converts the data to the internal value and runs validators on the value. Finally, it returns the validated value.", "Arguments": ":param self: Field. An instance of the Field class.\n:param data: Any. The data to be validated. It may be empty if no representation was included in the input.\n:return: Any. The validated internal value."}, "tests": ["tests/test_fields.py::TestEmpty::test_not_required", "tests/test_fields.py::TestEmpty::test_required", "tests/test_fields.py::TestDictField::test_allow_empty_disallowed", "tests/test_fields.py::TestEmpty::test_default", "tests/test_fields.py::TestBooleanField::test_disallow_unhashable_collection_types"], "indent": 8}
{"namespace": "boto.ec2.connect_to_region", "type": "function", "project_path": "Internet/boto", "completion_path": "Internet/boto/boto/ec2/__init__.py", "signature_position": [47, 47], "body_position": [61, 68], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["boto.ec2.connection.EC2Connection", "boto.regioninfo.RegionInfo", "boto.regioninfo.connect"]}, "requirement": {"Functionality": "This function connects to a specific region and returns an EC2Connection object.", "Arguments": ":param region_name: str. The name of the region to connect to.\n:param **kw_params: Additional parameters that are passed on to the connect method of the region object.\n:return: EC2Connection or None. A connection to the given region, or None if an invalid region name is given."}, "tests": ["tests/unit/test_connect_to_region.py::TestEC2Connection::test_connect_to_region"], "indent": 4}
{"namespace": "imapclient.imapclient.IMAPClient.expunge", "type": "method", "project_path": "Communications/IMAPClient", "completion_path": "Communications/IMAPClient/imapclient/imapclient.py", "signature_position": [1488, 1488], "body_position": [1521, 1528], "dependency": {"intra_class": ["imapclient.imapclient.IMAPClient._command_and_check", "imapclient.imapclient.IMAPClient._consume_until_tagged_response", "imapclient.imapclient.IMAPClient._imap", "imapclient.imapclient.IMAPClient.use_uid"], "intra_file": ["imapclient.imapclient.join_message_ids"], "cross_file": []}, "requirement": {"Functionality": "This function is used to expunge messages from the selected folder in an IMAP client. If no messages are specified, it removes all messages with the \"\\Deleted\" flag set. If messages are specified, it removes the specified messages with the \"\\Deleted\" flag set. The function returns the server response message followed by a list of expunge responses. The implementation takes into account whether the client is using UIDs or not.", "Arguments": ":param self: IMAPClient. An instance of the IMAPClient class.\n:param messages: List of int or str. The messages to be expunged. Defaults to None.\n:return: Tuple. The server response message followed by a list of expunge responses if no messages are specified. None if messages are specified."}, "tests": ["tests/test_imapclient.py::TestExpunge::test_expunge", "tests/test_imapclient.py::TestExpunge::test_id_expunge"], "indent": 8}
{"namespace": "mingus.core.progressions.substitute", "type": "function", "project_path": "Multimedia/mingus", "completion_path": "Multimedia/mingus/mingus/core/progressions.py", "signature_position": [426, 426], "body_position": [436, 504], "dependency": {"intra_class": [], "intra_file": ["mingus.core.progressions.interval_diff", "mingus.core.progressions.parse_string", "mingus.core.progressions.skip", "mingus.core.progressions.substitute", "mingus.core.progressions.tuple_to_string"], "cross_file": []}, "requirement": {"Functionality": "This function generates a list of possible substitutions for the element at index `substitute_index` in the given `progression`. It considers different harmonic substitutions and recursively adds substitutions if `depth` is greater than 0.\nUsing a set of predefined harmonic substitutions. It checks the suffix of the element and applies the corresponding substitutions based on the suffix.\n", "Arguments": ":param progression: List of strings. The given musical progression.\n:param substitute_index: Int. The index of the element in the progression to be substituted.\n:param depth: Int. The depth of recursion. It determines how many levels of substitutions are applied. Defaults to 0.\n:return: List of strings. The list of possible substitutions for the element at `substitute_index`.\n"}, "tests": ["tests/unit/core/test_progressions.py::test_progressions::test_substitute"], "indent": 4}
{"namespace": "boltons.cacheutils.LRI.popitem", "type": "method", "project_path": "Utilities/boltons", "completion_path": "Utilities/boltons/boltons/cacheutils.py", "signature_position": [281, 281], "body_position": [282, 285], "dependency": {"intra_class": ["boltons.cacheutils.LRI._lock", "boltons.cacheutils.LRI._remove_from_ll"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function removes and returns a (key, value) pair from the LRI class instance.\n", "Arguments": ":param self: LRI, an instance of the LRI class.\n:return: tuple. The removed (key, value) pair from the LRI instance.\n"}, "tests": ["tests/test_cacheutils.py::test_lru_basic"], "indent": 8}
{"namespace": "alembic.script.revision.RevisionMap.get_revision", "type": "method", "project_path": "Database/alembic", "completion_path": "Database/alembic/alembic/script/revision.py", "signature_position": [558, 558], "body_position": [572, 577], "dependency": {"intra_class": ["alembic.script.revision.RevisionMap._resolve_revision_number", "alembic.script.revision.RevisionMap._revision_for_ident"], "intra_file": ["alembic.script.revision.MultipleHeads", "alembic.script.revision.MultipleHeads.__init__", "alembic.script.revision.Revision"], "cross_file": []}, "requirement": {"Functionality": "This function retrieves a specific revision from the RevisionMap instance with the given revision id. It first resolves the given id to the current head or base revision if a symbolic name is provided. If the id matches multiple revisions, it raises a multiple heads exception. It then returns the Revision instance corresponding to the resolved id.", "Arguments": ":param self: RevisionMap. An instance of the RevisionMap class.\n:param id_: Optional[str]. The revision id or symbolic name to retrieve. Defaults to None.\n:return: Optional[Revision]. The Revision instance corresponding to the given id, or None if the id is not found."}, "tests": ["tests/test_revision.py::LabeledBranchTest::test_retrieve_branch_revision", "tests/test_revision.py::BranchTravellingTest::test_ancestor_nodes", "tests/test_revision.py::APITest::test_invalid_datatype", "tests/test_revision.py::APITest::test_get_revision_head_multiple", "tests/test_revision.py::APITest::test_get_revision_heads_multiple"], "indent": 8}
{"namespace": "mingus.core.intervals.major_seventh", "type": "function", "project_path": "Multimedia/mingus", "completion_path": "Multimedia/mingus/mingus/core/intervals.py", "signature_position": [231, 231], "body_position": [232, 233], "dependency": {"intra_class": [], "intra_file": ["mingus.core.intervals.augment_or_diminish_until_the_interval_is_right", "mingus.core.intervals.seventh"], "cross_file": []}, "requirement": {"Functionality": "This function calculates the major seventh interval for a given note. It first determines the seventh interval based on the note's root and the root \"C\". Then, it adjusts the note by augmenting or diminishing it until the interval is equal to 11.", "Arguments": ":param note: String. The note for which the major seventh interval is calculated.\n:return: String. The note with the major seventh interval."}, "tests": ["tests/unit/core/test_intervals.py::test_intervals::test_major_seventh"], "indent": 4}
{"namespace": "boto.dynamodb2.fields.GlobalBaseIndexField.schema", "type": "method", "project_path": "Internet/boto", "completion_path": "Internet/boto/boto/dynamodb2/fields.py", "signature_position": [235, 235], "body_position": [260, 265], "dependency": {"intra_class": ["boto.dynamodb2.fields.GlobalBaseIndexField.throughput"], "intra_file": ["boto.dynamodb2.fields.BaseIndexField", "boto.dynamodb2.fields.BaseIndexField.schema"], "cross_file": []}, "requirement": {"Functionality": "This function returns the schema structure that DynamoDB expects for a global base index field. It first gets a base schema structure from its parent class, and then adds the provisioned throughput information to the base schema.", "Arguments": ":param self: GlobalBaseIndexField. An instance of the GlobalBaseIndexField class.\n:return: Dictionary. The schema structure that DynamoDB expects for the global base index field."}, "tests": ["tests/unit/dynamodb2/test_table.py::IndexFieldTestCase::test_global_all_index", "tests/unit/dynamodb2/test_table.py::IndexFieldTestCase::test_global_keys_only_index"], "indent": 8}
{"namespace": "boto.dynamodb2.items.Item.get_raw_keys", "type": "method", "project_path": "Internet/boto", "completion_path": "Internet/boto/boto/dynamodb2/items.py", "signature_position": [240, 240], "body_position": [246, 251], "dependency": {"intra_class": ["boto.dynamodb2.items.Item._dynamizer", "boto.dynamodb2.items.Item.get_keys"], "intra_file": [], "cross_file": ["boto.dynamodb.types.Dynamizer.encode"]}, "requirement": {"Functionality": "This function returns a dictionary of the keys and their corresponding values in DynamoDB-style format. It iterates over the keys and values and encodes the values before adding them to the dictionary.", "Arguments": ":param self: Item. An instance of the Item class.\n:return: Dict. A dictionary containing the keys and their corresponding encoded values in DynamoDB-style format."}, "tests": ["tests/unit/dynamodb2/test_table.py::ItemTestCase::test_get_raw_keys"], "indent": 8}
{"namespace": "boto.dynamodb2.table.Table.delete", "type": "method", "project_path": "Internet/boto", "completion_path": "Internet/boto/boto/dynamodb2/table.py", "signature_position": [610, 610], "body_position": [624, 625], "dependency": {"intra_class": ["boto.dynamodb2.table.Table.connection", "boto.dynamodb2.table.Table.table_name"], "intra_file": [], "cross_file": ["boto.dynamodb2.layer1.DynamoDBConnection.delete_table"]}, "requirement": {"Functionality": "This function deletes a table in DynamoDB. It uses the connection object to delete the table with the specified table name.", "Arguments": ":param self: Table. An instance of the Table class.\n:return: Bool. Returns True on success."}, "tests": ["tests/unit/dynamodb2/test_table.py::TableTestCase::test_delete"], "indent": 8}
{"namespace": "googleapiclient._helpers.update_query_params", "type": "function", "project_path": "Internet/google-api-python-client", "completion_path": "Internet/google-api-python-client/googleapiclient/_helpers.py", "signature_position": [166, 166], "body_position": [183, 188], "dependency": {"intra_class": [], "intra_file": ["googleapiclient._helpers.parse_unique_urlencoded"], "cross_file": []}, "requirement": {"Functionality": "This function updates a URI with new query parameters. It takes a URI and a dictionary of query parameters as input. If a key from the dictionary is repeated in the URI, the URI is considered invalid and an error occurs. If the URI is valid, each value from the dictionary will replace the corresponding value in the query parameters (if it exists).", "Arguments": ":param uri: string. A valid URI, with potential existing query parameters.\n:param params: dict. A dictionary of query parameters.\n:return: string. The same URI but with the new query parameters added."}, "tests": ["tests/test__helpers.py::Test_update_query_params::test_update_query_params_no_params", "tests/test__helpers.py::Test_update_query_params::test_update_query_params_replace_param", "tests/test__helpers.py::Test_update_query_params::test_update_query_params_repeated_params", "tests/test__helpers.py::Test_update_query_params::test_update_query_params_existing_params"], "indent": 4}
{"namespace": "boltons.ioutils.SpooledStringIO.write", "type": "method", "project_path": "Utilities/boltons", "completion_path": "Utilities/boltons/boltons/ioutils.py", "signature_position": [411, 411], "body_position": [412, 422], "dependency": {"intra_class": ["boltons.ioutils.SpooledStringIO._tell", "boltons.ioutils.SpooledStringIO.buffer", "boltons.ioutils.SpooledStringIO.len", "boltons.ioutils.SpooledStringIO.rollover", "boltons.ioutils.SpooledStringIO.tell"], "intra_file": ["boltons.ioutils.SpooledIOBase._checkClosed", "boltons.ioutils.SpooledIOBase._max_size", "boltons.ioutils.text_type"], "cross_file": []}, "requirement": {"Functionality": "This function writes a string to the SpooledStringIO instance. It first checks if the instance is closed. Then, it checks if the input string is of type text_type. If not, it raises a TypeError: 'str expected, got {type of s}'. It then checks if writing the string will exceed the maximum size of the instance. If so, it rolls over the instance to a temp file. Finally, it writes the string to the buffer and updates the current position.", "Arguments": ":param self: SpooledStringIO. An instance of the SpooledStringIO class.\n:param s: String. The string to be written to the instance.\n:return: No return value."}, "tests": ["tests/test_ioutils.py::TestSpooledStringIO::test_seek_codepoints_large_SEEK_END", "tests/test_ioutils.py::TestSpooledStringIO::test_compare_not_equal_instances", "tests/test_ioutils.py::TestSpooledStringIO::test_len_no_rollover", "tests/test_ioutils.py::TestSpooledStringIO::test_seek_codepoints_SEEK_END", "tests/test_ioutils.py::TestSpooledStringIO::test_iter"], "indent": 8}
{"namespace": "alembic.testing.env.multi_heads_fixture", "type": "function", "project_path": "Database/alembic", "completion_path": "Database/alembic/alembic/testing/env.py", "signature_position": [382, 382], "body_position": [388, 468], "dependency": {"intra_class": [], "intra_file": ["alembic.testing.env.write_script"], "cross_file": ["alembic.script.ScriptDirectory.from_config", "alembic.script.ScriptDirectory.generate_revision", "alembic.util", "alembic.util.rev_id"]}, "requirement": {"Functionality": "This function creates a multiple head fixture from the three-revs fixture. It generates three new revisions (d, e, f) based on the existing revisions (a, b, c) and writes the corresponding scripts for each revision.", "Arguments": ":param cfg: The configuration object.\n:param a: The head revision.\n:param b: The base revision.\n:param c: The other revision.\n:return: The generated revisions (d, e, f)."}, "tests": ["tests/test_command.py::RevisionEnvironmentTest::test_merge_cmd_revision_environment", "tests/test_offline_environment.py::OfflineEnvironmentTest::test_head_rev_post_context_multihead", "tests/test_offline_environment.py::OfflineEnvironmentTest::test_destination_rev_pre_context_multihead", "tests/test_offline_environment.py::OfflineEnvironmentTest::test_destination_rev_post_context_multihead", "tests/test_offline_environment.py::OfflineEnvironmentTest::test_head_rev_pre_context_multihead"], "indent": 4}
{"namespace": "pycoin.satoshi.stackops.do_OP_HASH256", "type": "function", "project_path": "Security/pycoin", "completion_path": "Security/pycoin/pycoin/satoshi/stackops.py", "signature_position": [131, 131], "body_position": [132, 133], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["pycoin.encoding.hash.double_sha256"]}, "requirement": {"Functionality": "Pop the top item from the stack, calculate its sha256 value, and append the result back to the stack.\n", "Arguments": ":param stack: List, a stack where the operation is performed.\n:return: No return values.\n"}, "tests": ["tests/script/stackops_test.py::StackOpsTest::test_do_OP_HASH256"], "indent": 4}
{"namespace": "pyramid.url.URLMethodsMixin.route_url", "type": "method", "project_path": "Internet/pyramid", "completion_path": "Internet/pyramid/src/pyramid/url.py", "signature_position": [112, 112], "body_position": [245, 270], "dependency": {"intra_class": [], "intra_file": ["pyramid.url._join_elements", "pyramid.url.parse_url_overrides"], "cross_file": ["pyramid.interfaces.IRoutesMapper", "pyramid.threadlocal.get_current_registry", "pyramid.interfaces.IRoutesMapper.get_route", "pyramid.interfaces.IRoute.generate", "pyramid.interfaces.IRoute.pregenerator", "pyramid.registry"]}, "requirement": {"Functionality": "This function generates a fully qualified URL for a named route configuration in a Pyramid application. It takes the route name as the first positional argument and additional positional arguments as path segments. It uses keyword arguments to supply values for dynamic path elements in the route definition. It raises a KeyError exception if the URL cannot be generated for any reason.", "Arguments": ":param self: URLMethodsMixin. An instance of the URLMethodsMixin class.\n:param route_name: String. The name of the route configuration.\n:param *elements: Tuple of strings. Additional positional arguments that are appended to the URL as path segments.\n:param **kw: Keyword arguments. Values that match dynamic path elements in the route definition.\n:return: String. The generated fully qualified URL for the named route configuration."}, "tests": ["tests/test_url.py::TestURLMethodsMixin::test_route_url_with_host", "tests/test_url.py::TestURLMethodsMixin::test_route_url_with_scheme", "tests/test_url.py::TestURLMethodsMixin::test_route_url_with_elements", "tests/test_url.py::TestURLMethodsMixin::test_route_url_with_query", "tests/test_url.py::TestURLMethodsMixin::test_route_url_with_anchor_app_url_elements_and_query"], "indent": 8}
{"namespace": "msticpy.config.query_editor.QueryParameterEditWidget.delete_parameter", "type": "method", "project_path": "Security/msticpy", "completion_path": "Security/msticpy/msticpy/config/query_editor.py", "signature_position": [299, 299], "body_position": [301, 305], "dependency": {"intra_class": ["msticpy.config.query_editor.QueryParameterEditWidget._blank_parameter", "msticpy.config.query_editor.QueryParameterEditWidget._changed_data", "msticpy.config.query_editor.QueryParameterEditWidget.param_container", "msticpy.config.query_editor.QueryParameterEditWidget.parameter_dropdown"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function deletes a parameter item from the QueryParameterEditWidget instance. It removes the parameter from the parameters dictionary and clears the input widgets. It also sets the changed data flag to True.", "Arguments": ":param self: QueryParameterEditWidget. An instance of the QueryParameterEditWidget class.\n:param button: The button that triggered the delete action. It is not used in the function.\n:return: No return values."}, "tests": ["tests/config/test_query_editor.py::test_remove_parameter"], "indent": 8}
{"namespace": "sslyze.plugins.heartbleed_plugin._HeartbleedCliConnector.result_to_console_output", "type": "method", "project_path": "System/sslyze", "completion_path": "System/sslyze/sslyze/plugins/heartbleed_plugin.py", "signature_position": [54, 54], "body_position": [55, 62], "dependency": {"intra_class": [], "intra_file": ["sslyze.plugins.heartbleed_plugin.HeartbleedScanResult", "sslyze.plugins.heartbleed_plugin.HeartbleedScanResult.is_vulnerable_to_heartbleed", "sslyze.plugins.plugin_base.ScanCommandCliConnector._format_field"], "cross_file": []}, "requirement": {"Functionality": "This function takes a HeartbleedScanResult object as input and converts it into a list of strings that represent the result in a console output format. It formats the title and the vulnerability status of the Heartbleed scan result.", "Arguments": ":param cls: The class object of _HeartbleedCliConnector.\n:param result: HeartbleedScanResult. The Heartbleed scan result object.\n:return: List of strings. The console output representation of the Heartbleed scan result."}, "tests": ["tests/plugins_tests/test_heartbleed_plugin.py::TestHeartbleedPlugin::test_vulnerable"], "indent": 8}
{"namespace": "sacred.ingredient.Ingredient.gather_commands", "type": "method", "project_path": "Utilities/sacred", "completion_path": "Utilities/sacred/sacred/ingredient.py", "signature_position": [300, 300], "body_position": [310, 314], "dependency": {"intra_class": ["sacred.ingredient.Ingredient.post_process_name", "sacred.ingredient.Ingredient.traverse_ingredients", "sacred.ingredient.Ingredient.commands"], "intra_file": [], "cross_file": ["sacred.utils.join_paths"]}, "requirement": {"Functionality": "This function collects all commands from the Ingredient instance and its sub-ingredients. It iterates through each ingredient and its commands, and yields the full name of the command and the corresponding captured function.", "Arguments": ":param self: Ingredient. An instance of the Ingredient class.\n:return: Yields a tuple containing the full name of the command (cmd_name) and the corresponding captured function (cmd)."}, "tests": ["tests/test_ingredients.py::test_gather_commands"], "indent": 8}
{"namespace": "mingus.core.notes.remove_redundant_accidentals", "type": "function", "project_path": "Multimedia/mingus", "completion_path": "Multimedia/mingus/mingus/core/notes.py", "signature_position": [122, 122], "body_position": [131, 144], "dependency": {"intra_class": [], "intra_file": ["mingus.core.notes.augment", "mingus.core.notes.diminish"], "cross_file": []}, "requirement": {"Functionality": "Remove redundant sharps and flats from the given note.\n", "Arguments": ":param note: str. The musical note with possible redundant sharps and flats.\n:return: str. The note with the redundant sharps and flats removed.\n"}, "tests": ["tests/unit/core/test_notes.py::test_notes::test_remove_redundant_accidentals"], "indent": 4}
{"namespace": "imapclient.imapclient.IMAPClient.thread", "type": "method", "project_path": "Communications/IMAPClient", "completion_path": "Communications/IMAPClient/imapclient/imapclient.py", "signature_position": [1203, 1203], "body_position": [1220, 1230], "dependency": {"intra_class": ["imapclient.imapclient.IMAPClient._raw_command_untagged", "imapclient.imapclient.IMAPClient.has_capability"], "intra_file": ["imapclient.imapclient._normalise_search_criteria"], "cross_file": ["imapclient.exceptions", "imapclient.exceptions.CapabilityError", "imapclient.response_parser.parse_response", "imapclient.util.to_bytes"]}, "requirement": {"Functionality": "Return a list of message threads from the currently selected folder that match the specified criteria. Each returned thread is a list of message IDs.\n", "Arguments": ":param algorithm: String, the threading algorithm to use. It defaults to \"REFERENCES\" if not specified.\n:param criteria: String, the search criteria to match the messages. It defaults to \"ALL\" if not specified.\n:param charset: String, the character set to be used. It defaults to \"UTF-8\" if not specified.\n:return: List[Tuple], each tuple represents a message thread, where each element of the tuple is a message ID. For example, \"((1, 2), (3,), (4, 5, 6))\".\n"}, "tests": ["tests/test_thread.py::TestThread::test_unsupported_algorithm", "tests/test_thread.py::TestThread::test_no_thread_support", "tests/test_thread.py::TestThread::test_defaults", "tests/test_thread.py::TestThread::test_all_args"], "indent": 8}
{"namespace": "twilio.twiml.voice_response.Gather.say", "type": "method", "project_path": "Communications/twilio-fatisar", "completion_path": "Communications/twilio-fatisar/twilio/twiml/voice_response.py", "signature_position": [1884, 1884], "body_position": [1896, 1898], "dependency": {"intra_class": [], "intra_file": ["twilio.twiml.voice_response.Say", "twilio.twiml.voice_response.Say.__init__"], "cross_file": ["twilio.twiml.TwiML.nest"]}, "requirement": {"Functionality": "This function creates a `<Say>` element with the given parameters. It nests the `<Say>` element within the current `<Gather>` element.", "Arguments": ":param self: Gather. An instance of the Gather class.\n:param message: String. The message to be said.\n:param voice: String. The voice to be used for saying the message.\n:param loop: Integer. The number of times to loop the message.\n:param language: String. The language of the message.\n:param kwargs: Additional attributes for the `<Say>` element.\n:return: `<Say>` element. The created `<Say>` element."}, "tests": ["tests/unit/twiml/test_voice_response.py::TestGather::test_gather_say", "tests/unit/twiml/test_voice_response.py::TestGather::test_nested_say_play_pause"], "indent": 8}
{"namespace": "dash.development.base_component.Component._traverse", "type": "method", "project_path": "Software-Development/dash", "completion_path": "Software-Development/dash/dash/development/base_component.py", "signature_position": [319, 319], "body_position": [321, 322], "dependency": {"intra_class": ["dash.development.base_component.Component._traverse_with_paths"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function traverses the tree structure of a Component instance and yields the second value in each item in the tree.", "Arguments": ":param self: Component. An instance of the Component class.\n:return: Yields each item in the tree."}, "tests": ["tests/unit/development/test_base_component.py::test_debc011_traverse_with_tuples", "tests/unit/development/test_base_component.py::test_debc010_traverse_full_tree"], "indent": 8}
{"namespace": "rest_framework.fields.DateTimeField.to_representation", "type": "method", "project_path": "Internet/djangorestframework", "completion_path": "Internet/djangorestframework/rest_framework/fields.py", "signature_position": [1178, 1178], "body_position": [1179, 1194], "dependency": {"intra_class": ["rest_framework.fields.DateTimeField.enforce_timezone"], "intra_file": [], "cross_file": ["rest_framework.ISO_8601", "rest_framework.settings.api_settings"]}, "requirement": {"Functionality": "This function converts a datetime value to its representation based on the specified format. It first checks if the value is empty, and if so, returns None. Then, it checks the output format and if it is None or the value is already a string, it returns the value as is. Otherwise, it enforces the timezone on the value and formats it based on the output format.", "Arguments": ":param self: DateTimeField. An instance of the DateTimeField class.\n:param value: The datetime value to be converted.\n:return: The representation of the datetime value based on the specified format."}, "tests": ["tests/test_fields.py::TestCustomTimezoneForDateTimeField::test_should_render_date_time_in_default_timezone"], "indent": 8}
{"namespace": "pycoin.blockchain.BlockChain.BlockChain.tuple_for_index", "type": "method", "project_path": "Security/pycoin", "completion_path": "Security/pycoin/pycoin/blockchain/BlockChain.py", "signature_position": [61, 61], "body_position": [62, 73], "dependency": {"intra_class": ["pycoin.blockchain.BlockChain.BlockChain._locked_chain", "pycoin.blockchain.BlockChain.BlockChain._longest_chain_cache", "pycoin.blockchain.BlockChain.BlockChain._longest_local_block_chain", "pycoin.blockchain.BlockChain.BlockChain.length", "pycoin.blockchain.BlockChain.BlockChain.parent_hash", "pycoin.blockchain.BlockChain.BlockChain.weight_lookup"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function returns a tuple containing information about a block in the blockchain at the given index. It first checks if the index is negative, and if so, it adjusts it to be a positive index relative to the end of the blockchain. Then, it checks if the index is within the range of the locked chain. If it is, it returns the corresponding block from the locked chain. If the index is outside the range of the locked chain, it retrieves the block from the longest local block chain or the longest chain cache, depending on the index value. Finally, it looks up the weight of the block using the weight lookup dictionary and returns a tuple containing the block's hash, parent hash, and weight.", "Arguments": ":param self: BlockChain. An instance of the BlockChain class.\n:param index: Integer. The index of the block to retrieve.\n:return: Tuple. A tuple containing the block's hash, parent hash, and weight."}, "tests": ["tests/blockchain_test.py::BlockchainTestCase::test_large", "tests/blockchain_test.py::BlockchainTestCase::test_chain_locking", "tests/blockchain_test.py::BlockchainTestCase::test_basic"], "indent": 8}
{"namespace": "bplustree.memory.FileMemory.get_node", "type": "method", "project_path": "Database/bplustree", "completion_path": "Database/bplustree/bplustree/memory.py", "signature_position": [125, 125], "body_position": [137, 147], "dependency": {"intra_class": ["bplustree.memory.FileMemory._cache", "bplustree.memory.FileMemory._read_page", "bplustree.memory.FileMemory._tree_conf", "bplustree.memory.FileMemory._wal"], "intra_file": ["bplustree.memory.WAL.get_page"], "cross_file": ["bplustree.node.Node", "bplustree.node.Node.from_page_data", "bplustree.node.Node.page"]}, "requirement": {"Functionality": "This function retrieves a node from storage. It first checks if the node is present in the cache. If not, it retrieves the data from the storage and creates a Node object using the data. The created node is then added to the cache for future use.", "Arguments": ":param self: FileMemory. An instance of the FileMemory class.\n:param page: int. The page number of the node to retrieve.\n:return: Node. The retrieved node."}, "tests": ["tests/test_memory.py::test_file_memory_write_transaction", "tests/test_memory.py::test_file_memory_node"], "indent": 8}
{"namespace": "alembic.operations.ops.DropColumnOp.to_column", "type": "method", "project_path": "Database/alembic", "completion_path": "Database/alembic/alembic/operations/ops.py", "signature_position": [2215, 2217], "body_position": [2218, 2221], "dependency": {"intra_class": ["alembic.operations.ops.DropColumnOp._reverse", "alembic.operations.ops.DropColumnOp.column_name"], "intra_file": [], "cross_file": ["alembic.operations.ops.AddColumnOp.column", "alembic.operations.schemaobj", "alembic.operations.schemaobj.SchemaObjects", "alembic.operations.schemaobj.SchemaObjects.column", "alembic.runtime.migration.MigrationContext"]}, "requirement": {"Functionality": "This function converts the DropColumnOp instance into a Column object. If the reverse option is available, it returns the column of the reverse. Otherwise, it creates a schema based on the `migration_context` parameter and uses its method to create a column object with the specified column name and NULLTYPE.", "Arguments": ":param self: DropColumnOp. An instance of the DropColumnOp class.\n:param migration_context: Optional. An instance of the MigrationContext class. It represents the current migration context. Defaults to None.\n:return: Column."}, "tests": ["tests/test_autogen_diffs.py::OrigObjectTest::test_add_column", "tests/test_autogen_diffs.py::OrigObjectTest::test_drop_column"], "indent": 8}
{"namespace": "pyinfra.api.facts.get_facts", "type": "function", "project_path": "System/pyinfra", "completion_path": "System/pyinfra/pyinfra/api/facts.py", "signature_position": [161, 161], "body_position": [162, 181], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["pyinfra.api.inventory.Inventory.iter_active_hosts", "pyinfra.api.state.State.inventory", "pyinfra.progress.progress_spinner"]}, "requirement": {"Functionality": "This function retrieves facts for a given state. It iterates over the active hosts in the state's inventory and spawns a greenlet for each host to retrieve the facts. It then waits for the greenlets to complete and stores the results in a dictionary.", "Arguments": ":param state: State. An instance of the State class. The state for which to retrieve the facts.\n:param *args: Variable length argument list. Additional arguments to pass to the get_fact function.\n:param **kwargs: Arbitrary keyword arguments. Additional keyword arguments to pass to the get_fact function.\n:return: dict. A dictionary containing the retrieved facts, with the host as the key and the facts as the value."}, "tests": ["tests/test_api/test_api_facts.py::TestFactsApi::test_get_fact_executor_mixed_arguments", "tests/test_api/test_api_facts.py::TestFactsApi::test_get_fact_current_op_global_arguments", "tests/test_api/test_api_facts.py::TestFactsApi::test_get_fact_error_ignore", "tests/test_api/test_api_facts.py::TestFactsApi::test_get_fact_executor_host_data_arguments", "tests/test_api/test_api_facts.py::TestFactsApi::test_get_fact"], "indent": 4}
{"namespace": "mingus.core.intervals.major_second", "type": "function", "project_path": "Multimedia/mingus", "completion_path": "Multimedia/mingus/mingus/core/intervals.py", "signature_position": [173, 173], "body_position": [174, 175], "dependency": {"intra_class": [], "intra_file": ["mingus.core.intervals.augment_or_diminish_until_the_interval_is_right", "mingus.core.intervals.second"], "cross_file": []}, "requirement": {"Functionality": "This function calculates the major second interval for a given note. It first determines the second interval between the given note and \"C\". Then, it adjusts the interval by augmenting or diminishing it until it becomes a major second.", "Arguments": ":param note: String. The note for which the major second interval is to be calculated.\n:return: The adjusted major second interval for the given note."}, "tests": ["tests/unit/core/test_intervals.py::test_intervals::test_major_seconds"], "indent": 4}
{"namespace": "jwt.algorithms.HMACAlgorithm.to_jwk", "type": "method", "project_path": "Utilities/PyJWT", "completion_path": "Utilities/PyJWT/jwt/algorithms.py", "signature_position": [278, 278], "body_position": [279, 287], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["jwt.types.JWKDict", "jwt.utils.base64url_encode", "jwt.utils.force_bytes"]}, "requirement": {"Functionality": "This function converts a key object to a JSON Web Key (JWK) representation. It creates a JWK dictionary with the key value and key type, and returns it as a JSON string or dictionary based on the value of the `as_dict` parameter.", "Arguments": ":param key_obj: str or bytes. The key object to be converted to JWK.\n:param as_dict: bool. Optional parameter to specify whether to return the JWK as a dictionary or JSON string. Defaults to False.\n:return: Union[JWKDict, str]. The JWK representation of the key object. If `as_dict` is True, it returns a dictionary. Otherwise, it returns a JSON string."}, "tests": ["tests/test_algorithms.py::TestAlgorithms::test_hmac_to_jwk_returns_correct_values"], "indent": 8}
{"namespace": "mrjob.conf.combine_dicts", "type": "function", "project_path": "System/mrjob", "completion_path": "System/mrjob/mrjob/conf.py", "signature_position": [435, 435], "body_position": [441, 454], "dependency": {"intra_class": [], "intra_file": ["mrjob.conf.ClearedValue", "mrjob.conf._strip_clear_tag"], "cross_file": []}, "requirement": {"Functionality": "This function combines zero or more dictionaries into a single dictionary. Values from dictionaries later in the list take precedence over values earlier in the list. If a dictionary is passed as None, it will be ignored. If the value is specified to be a cleared value whose value is None, it will be removed from the dictionary.", "Arguments": ":param dicts: Variable number of dictionaries to be combined.\n:return: dict. The combined dictionary."}, "tests": ["tests/test_conf.py::CombineDictsTestCase::test_later_values_take_precedence", "tests/test_conf.py::CombineDictsTestCase::test_None_value", "tests/test_conf.py::CombineDictsTestCase::test_dont_accept_wrapped_dicts", "tests/test_hadoop.py::EnvForStepTestCase::test_spark_step", "tests/test_conf.py::CombineDictsTestCase::test_deleted_value"], "indent": 4}
{"namespace": "falcon.inspect.inspect_middleware", "type": "function", "project_path": "Internet/falcon", "completion_path": "Internet/falcon/falcon/inspect.py", "signature_position": [160, 160], "body_position": [170, 200], "dependency": {"intra_class": [], "intra_file": ["falcon.inspect.MiddlewareClassInfo", "falcon.inspect.MiddlewareClassInfo.__init__", "falcon.inspect.MiddlewareInfo", "falcon.inspect.MiddlewareInfo.__init__", "falcon.inspect.MiddlewareMethodInfo", "falcon.inspect.MiddlewareMethodInfo.__init__", "falcon.inspect.MiddlewareTreeInfo", "falcon.inspect.MiddlewareTreeInfo.__init__", "falcon.inspect.MiddlewareTreeItemInfo", "falcon.inspect.MiddlewareTreeItemInfo.__init__", "falcon.inspect._get_source_info", "falcon.inspect._get_source_info_and_name"], "cross_file": ["falcon.app.App", "falcon.app_helpers.prepare_middleware", "falcon.app.App._ASGI", "falcon.app.App._independent_middleware", "falcon.app.App._unprepared_middleware", "falcon.app_helpers"]}, "requirement": {"Functionality": "This function inspects the middleware components of an application. It prepares the middleware components and gathers information about them, including the middleware tree and the middleware classes.", "Arguments": ":param app: falcon.App. The application to inspect. Works with both falcon.App and falcon.asgi.App.\n:return: MiddlewareInfo. Information about the app's middleware components."}, "tests": ["tests/test_inspect.py::TestStringVisitor::test_middleware_tree_item", "tests/test_inspect.py::TestStringVisitor::test_middleware_class_no_methods", "tests/test_inspect.py::TestStringVisitor::test_middleware_tree_no_resource", "tests/test_inspect.py::TestInspectApp::test_middleware", "tests/test_inspect.py::TestStringVisitor::test_middleware_tree_response_only"], "indent": 4}
{"namespace": "rq.serializers.resolve_serializer", "type": "function", "project_path": "Scientific-Engineering/rq", "completion_path": "Scientific-Engineering/rq/rq/serializers.py", "signature_position": [24, 24], "body_position": [36, 49], "dependency": {"intra_class": [], "intra_file": ["rq.serializers.DefaultSerializer"], "cross_file": ["rq.utils.import_attribute"]}, "requirement": {"Functionality": "This function checks the user-defined serializer for the presence of 'dumps' and 'loads' methods. If these methods are not found, it raises a NotImplementedError. If the serializer is not provided, it returns the default pickle serializer. If a string path to a serializer is provided, it loads and returns that serializer. The returned serializer objects implement the 'dumps' and 'loads' methods.", "Arguments": ":param serializer: Optional. Union of Type[DefaultSerializer] and str. The serializer to resolve. Defaults to None.\n:return: Type[DefaultSerializer]. An object that implements the SerializerProtocol."}, "tests": ["tests/test_serializers.py::TestSerializers::test_resolve_serializer"], "indent": 4}
{"namespace": "alembic.command.upgrade", "type": "function", "project_path": "Database/alembic", "completion_path": "Database/alembic/alembic/command.py", "signature_position": [358, 363], "body_position": [378, 398], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["alembic.config.Config", "alembic.runtime.environment.EnvironmentContext", "alembic.script.ScriptDirectory.from_config", "alembic.script.ScriptDirectory.run_env", "alembic.util", "alembic.util.CommandError"]}, "requirement": {"Functionality": "Upgrade the database to a later version. It creates a script directory based on the given configuration and then runs the upgrade process using the specified revision, SQL mode, and tag.", "Arguments": ":param config: Config. An instance of the Config class.\n:param revision: str. The target revision or range for SQL mode.\n:param sql: bool. If True, use SQL mode.\n:param tag: Optional[str]. An arbitrary tag that can be intercepted by custom env.py scripts.\n:return: None."}, "tests": ["tests/test_postgresql.py::PGOfflineEnumTest::test_offline_inline_enum_create", "tests/test_script_consumption.py::EncodingTest::test_encode", "tests/test_environment.py::EnvironmentTest::test_sql_mode_parameters", "tests/test_postgresql.py::PGOfflineEnumTest::test_offline_distinct_enum_create", "tests/test_command.py::UpgradeDowngradeStampTest::test_version_from_middle_update"], "indent": 4}
{"namespace": "imapclient.imapclient.IMAPClient.append", "type": "method", "project_path": "Communications/IMAPClient", "completion_path": "Communications/IMAPClient/imapclient/imapclient.py", "signature_position": [1395, 1395], "body_position": [1412, 1424], "dependency": {"intra_class": ["imapclient.imapclient.IMAPClient._command_and_check", "imapclient.imapclient.IMAPClient._normalise_folder"], "intra_file": ["imapclient.imapclient.seq_to_parenstr"], "cross_file": ["imapclient.datetime_util.datetime_to_INTERNALDATE", "imapclient.util.to_bytes", "imapclient.util.to_unicode"]}, "requirement": {"Functionality": "Append a message to the specified folder in the IMAP server. \n", "Arguments": ":param self: IMAPClient, an instance of IMAPClient class.\n:param folder: String, the name of the folder to which the message should be appended.\n:param msg: String, a string contains the full message including header.\n:param flags: Tuple, a sequence of message flags to set. Defaults to an empty tuple if not specified.\n:param msg_time: Datetime, an instance of datatime class. The date and time to set on the message. Defaults to None if not specified. If msg_time contains timezone information (tzinfo), this will be honoured. Otherwise the local machine's time zone sent to the server.\n:return: The APPEND response returned by the server.\n"}, "tests": ["tests/test_imapclient.py::TestAppend::test_with_msg_time", "tests/test_imapclient.py::TestAppend::test_without_msg_time"], "indent": 8}
{"namespace": "zulipterminal.ui_tools.buttons.TopButton.keypress", "type": "method", "project_path": "Communications/zulip-term", "completion_path": "Communications/zulip-term/zulipterminal/ui_tools/buttons.py", "signature_position": [91, 91], "body_position": [92, 96], "dependency": {"intra_class": ["zulipterminal.ui_tools.buttons.TopButton.activate"], "intra_file": [], "cross_file": ["zulipterminal.config.keys.is_command_key", "zulipterminal.urwid_types.urwid_Size"]}, "requirement": {"Functionality": "Handle keypress events for the TopButton class. If the key is the \"ENTER\" key, it activates the button. Otherwise, it calls the keypress method of the superclass to handle the keypress event.", "Arguments": ":param self: TopButton. An instance of the TopButton class.\n:param size: urwid_Size. The size of the widget.\n:param key: str. The key that was pressed.\n:return: Optional[str]. If the key is the \"ENTER\" key, it returns None. Otherwise, it returns the result of the keypress method of the superclass."}, "tests": ["tests/ui_tools/test_buttons.py::TestEmojiButton::test_keypress_emoji_button"], "indent": 8}
{"namespace": "boltons.strutils.indent", "type": "function", "project_path": "Utilities/boltons", "completion_path": "Utilities/boltons/boltons/strutils.py", "signature_position": [729, 729], "body_position": [740, 742], "dependency": {"intra_class": [], "intra_file": ["boltons.strutils.iter_splitlines"], "cross_file": []}, "requirement": {"Functionality": "This function indents each line of the given text with the specified margin string. It allows for selectively applying indentation based on a condition for each line. \n", "Arguments": ":param text: str. The text to be indented.\n:param margin: str. The string to prepend to each line as indentation.\n:param newline: str. The newline character used to rejoin the lines. It defaults to \"\\n\".\n:param key: callable. A function called on each line to determine whether to indent it. It defaults to bool, which ensures that empty lines do not get whitespace added.\n:return: str. The indented text.\n"}, "tests": ["tests/test_strutils.py::test_indent"], "indent": 4}
{"namespace": "pyramid.registry.Introspector.categorized", "type": "method", "project_path": "Internet/pyramid", "completion_path": "Internet/pyramid/src/pyramid/registry.py", "signature_position": [149, 149], "body_position": [150, 158], "dependency": {"intra_class": ["pyramid.registry.Introspector.categories", "pyramid.registry.Introspector.get_category"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function categorizes the data in the Introspector instance based on the categories. It returns the name and introspectables (sorted by the sort key) of each category as a list of tuples.", "Arguments": ":param self: Introspector. An instance of the Introspector class.\n:param sort_key: Optional. The key to sort the categories. Defaults to None.\n:return: List[Tuple[str, List[Dict[str, Any]]]]. Each tuple contains the category name and the corresponding data for that category."}, "tests": ["tests/test_registry.py::TestIntrospector::test_categorized"], "indent": 8}
{"namespace": "boto.directconnect.connect_to_region", "type": "function", "project_path": "Internet/boto", "completion_path": "Internet/boto/boto/directconnect/__init__.py", "signature_position": [38, 38], "body_position": [39, 42], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["boto.directconnect.layer1.DirectConnectConnection", "boto.regioninfo.connect"]}, "requirement": {"Functionality": "Connect to a specific region using the DirectConnectConnection class from the boto library. It creates the connection with the specified parameters.", "Arguments": ":param region_name: String. The name of the region to connect to.\n:param **kw_params: Additional keyword arguments that can be passed to the connect function.\n:return: The connection object for the specified region."}, "tests": ["tests/unit/test_connect_to_region.py::TestDirectconnectConnection::test_connect_to_region"], "indent": 4}
{"namespace": "sacred.utils.format_sacred_error", "type": "function", "project_path": "Utilities/sacred", "completion_path": "Utilities/sacred/sacred/utils.py", "signature_position": [592, 592], "body_position": [593, 600], "dependency": {"intra_class": [], "intra_file": ["sacred.utils.format_filtered_stacktrace", "sacred.utils.SacredError.print_usage", "sacred.utils.SacredError.print_traceback", "sacred.utils.SacredError.filter_traceback"], "cross_file": []}, "requirement": {"Functionality": "This function formats a SacredError object into a string representation. It creates a list of lines to be included in the final formatted error message. The lines include the short usage message and the filtered stacktrace (if specified) or the exception type and message (if not specified).", "Arguments": ":param e: SacredError. The SacredError object to be formatted.\n:param short_usage: String. The short usage message to be included in the formatted error message.\n:return: String. The formatted error message."}, "tests": ["tests/test_exceptions.py::test_format_sacred_error", "tests/test_exceptions.py::test_chained_error"], "indent": 4}
{"namespace": "datasette.facets.ColumnFacet.suggest", "type": "method", "project_path": "Database/datasette", "completion_path": "Database/datasette/datasette/facets.py", "signature_position": [159, 159], "body_position": [160, 208], "dependency": {"intra_class": [], "intra_file": ["datasette.facets.Facet.database", "datasette.facets.Facet.ds", "datasette.facets.Facet.get_columns", "datasette.facets.Facet.get_configs", "datasette.facets.Facet.get_facet_size", "datasette.facets.Facet.get_row_count", "datasette.facets.Facet.params", "datasette.facets.Facet.request", "datasette.facets.Facet.sql"], "cross_file": ["datasette.database.QueryInterrupted", "datasette.utils.escape_sqlite", "datasette.utils.path_with_added_args", "datasette.app.Datasette.absolute_url", "datasette.app.Datasette.execute", "datasette.app.Datasette.setting", "datasette.app.Datasette.urls", "datasette.url_builder.Urls.path"]}, "requirement": {"Functionality": "This function suggests facets for a given column in a dataset. It retrieves the row count and columns from the dataset, determines the facet size, and then iterates through each column. For each column, it constructs a SQL query to retrieve distinct values and their counts. If the number of distinct values is between 1 and the row count, and the number of distinct values is less than or equal to the facet size, and at least one distinct value has a count greater than 1, it adds the column as a suggested facet. Finally, it returns a list of suggested facets.", "Arguments": ":param self: ColumnFacet. An instance of the ColumnFacet class.\n:return: List of dictionaries. A list of dictionaries representing the suggested facets. Each dictionary contains the name of the column and a toggle URL for enabling the facet."}, "tests": ["tests/test_facets.py::test_column_facet_suggest_skip_if_enabled_by_metadata", "tests/test_facets.py::test_column_facet_suggest", "tests/test_facets.py::test_column_facet_suggest_skip_if_already_selected"], "indent": 8}
{"namespace": "pyramid.util.InstancePropertyHelper.add_property", "type": "method", "project_path": "Internet/pyramid", "completion_path": "Internet/pyramid/src/pyramid/util.py", "signature_position": [175, 175], "body_position": [181, 182], "dependency": {"intra_class": ["pyramid.util.InstancePropertyHelper.make_property", "pyramid.util.InstancePropertyHelper.properties"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function adds a new property configuration to the InstancePropertyHelper instance. It creates a property based on the given callable and adds it to the property dictionary of the class.", "Arguments": ":param self: InstancePropertyHelper. An instance of the InstancePropertyHelper class.\n:param callable: The callable object that will be used to create the property.\n:param name: str. The name of the property. If not specified, it will be generated based on the callable. Defaults to None.\n:param reify: bool. Whether the property should be reified. Defaults to False.\n:return: No return values."}, "tests": ["tests/test_util.py::Test_InstancePropertyHelper::test_add_property", "tests/test_util.py::Test_InstancePropertyHelper::test_apply_multiple_times"], "indent": 8}
{"namespace": "pyramid.authentication.BasicAuthAuthenticationPolicy.unauthenticated_userid", "type": "method", "project_path": "Internet/pyramid", "completion_path": "Internet/pyramid/src/pyramid/authentication.py", "signature_position": [1334, 1334], "body_position": [1336, 1338], "dependency": {"intra_class": [], "intra_file": ["pyramid.authentication.extract_http_basic_credentials", "pyramid.authentication.extract_http_basic_credentials.username"], "cross_file": []}, "requirement": {"Functionality": "This function extracts the username from the authorization request header and returns it as the unauthenticated user ID.", "Arguments": ":param self: BasicAuthAuthenticationPolicy. An instance of the BasicAuthAuthenticationPolicy class.\n:param request: The HTTP request object.\n:return: String. The username extracted from the \"Authorization\" request header."}, "tests": ["tests/test_authentication.py::TestBasicAuthAuthenticationPolicy::test_unauthenticated_userid"], "indent": 8}
{"namespace": "chatette.parsing.SlotDefBuilder.create_concrete", "type": "method", "project_path": "Communications/chatette", "completion_path": "Communications/chatette/chatette/parsing/__init__.py", "signature_position": [148, 148], "body_position": [149, 155], "dependency": {"intra_class": [], "intra_file": ["chatette.parsing.UnitDefBuilder._build_modifiers_repr", "chatette.parsing.UnitDefBuilder._check_information", "chatette.parsing.UnitDefBuilder.identifier", "chatette.parsing.UnitDefBuilder.variation"], "cross_file": ["chatette.units.ast.AST", "chatette.units.modifiable.definitions.slot.SlotDefinition", "chatette.utils.Singleton.get_or_create", "chatette.utils.UnitType", "chatette.utils.UnitType.slot"]}, "requirement": {"Functionality": "This function creates a concrete SlotDefinition object based on the given conditions. It first checks if the necessary information is provided. If a variation is specified, it retrieves the definitions from the AST and checks if the identifier exists. If it does, it returns the corresponding SlotDefinition object. Otherwise, it creates a new SlotDefinition object with the identifier and the modifiers representation.", "Arguments": ":param self: SlotDefBuilder. An instance of the SlotDefBuilder class.\n:return: SlotDefinition. The created SlotDefinition object."}, "tests": ["tests/unit-testing/parsing/test_init.py::TestSlotDefBuilder::test_create_concrete", "tests/unit-testing/parsing/test_init.py::TestSlotDefBuilder::test_new_variation"], "indent": 8}
{"namespace": "zulipterminal.helper.open_media", "type": "function", "project_path": "Communications/zulip-term", "completion_path": "Communications/zulip-term/zulipterminal/helper.py", "signature_position": [807, 807], "body_position": [811, 830], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["zulipterminal.platform_code.successful_GUI_return_code", "zulipterminal.core.Controller.report_error"]}, "requirement": {"Functionality": "This function is a helper function that opens a media file using a specified tool. It creates a command to run the tool with the given media file path, and then executes the command using the `subprocess.run()` function. It checks the exit status of the process and reports any errors to the controller.", "Arguments": ":param controller: Any. The controller object that handles error reporting.\n:param tool: str. The name or path of the tool to be used to open the media file.\n:param media_path: str. The path of the media file to be opened.\n:return: No return values."}, "tests": ["tests/helper/test_helper.py::test_open_media", "tests/helper/test_helper.py::test_open_media_tool_exception"], "indent": 4}
{"namespace": "sqlitedict.SqliteDict.update", "type": "method", "project_path": "Database/sqlitedict", "completion_path": "Database/sqlitedict/sqlitedict.py", "signature_position": [328, 328], "body_position": [329, 343], "dependency": {"intra_class": ["sqlitedict.SqliteDict.autocommit", "sqlitedict.SqliteDict.commit", "sqlitedict.SqliteDict.conn", "sqlitedict.SqliteDict.flag", "sqlitedict.SqliteDict.tablename", "sqlitedict.SqliteDict.update"], "intra_file": ["sqlitedict.SqliteMultithread.executemany"], "cross_file": []}, "requirement": {"Functionality": "Update the SqliteDict instance with the given items and keyword arguments. It first checks if the instance is read-only, and if so, raises a RuntimeError. Then it encodes the keys and values of the items, and executes a SQL statement to update the items in the database. If there are any keyword arguments, it recursively calls the update function with those arguments. Finally, if the autocommit flag is set, it commits the changes to the database.", "Arguments": ":param self: SqliteDict. An instance of the SqliteDict class.\n:param items: Tuple or dictionary. The items to update in the instance. Defaults to an empty tuple.\n:param kwds: Keyword arguments. Additional items to update in the instance.\n:return: No return values."}, "tests": ["tests/test_temp_db.py::TempSqliteDictTest::test_clear_data", "tests/test_temp_db.py::TempSqliteDictTest::test_update_records"], "indent": 8}
{"namespace": "sumy.summarizers.text_rank.TextRankSummarizer._to_words_set", "type": "method", "project_path": "Internet/sumy", "completion_path": "Internet/sumy/sumy/summarizers/text_rank.py", "signature_position": [83, 83], "body_position": [84, 85], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["sumy.summarizers._summarizer.AbstractSummarizer.normalize_word", "sumy.summarizers._summarizer.AbstractSummarizer.stem_word", "sumy.models.dom._sentence.Sentence.words"]}, "requirement": {"Functionality": "This function takes a sentence as input and converts it into a set of words. It normalizes each word in the sentence and removes any stop words. The function then returns the set of stemmed words.", "Arguments": ":param self: TextRankSummarizer. An instance of the TextRankSummarizer class.\n:param sentence: Sentence. The sentence to be converted into a set of words.\n:return: List. The set of stemmed words in the sentence after removing stop words."}, "tests": ["tests/test_summarizers/test_text_rank.py::test_stop_words_correctly_removed"], "indent": 8}
{"namespace": "pyramid.authentication.RepozeWho1AuthenticationPolicy.authenticated_userid", "type": "method", "project_path": "Internet/pyramid", "completion_path": "Internet/pyramid/src/pyramid/authentication.py", "signature_position": [220, 220], "body_position": [230, 265], "dependency": {"intra_class": ["pyramid.authentication.RepozeWho1AuthenticationPolicy._get_identity", "pyramid.authentication.RepozeWho1AuthenticationPolicy.callback"], "intra_file": ["pyramid.authentication.CallbackAuthenticationPolicy._clean_principal", "pyramid.authentication.CallbackAuthenticationPolicy._log", "pyramid.authentication.CallbackAuthenticationPolicy.debug"], "cross_file": []}, "requirement": {"Functionality": "This function returns the authenticated user ID based on the provided request. It checks if the identity is None, if the user ID is None, and if the user ID is allowed by the security policy. If a callback is registered, it only returns the user ID if the callback returns a non-None value.", "Arguments": ":param self: RepozeWho1AuthenticationPolicy. An instance of the RepozeWho1AuthenticationPolicy class.\n:param request: The request object.\n:return: The authenticated user ID or None."}, "tests": ["tests/test_authentication.py::TestRepozeWho1AuthenticationPolicy::test_authenticated_userid_with_callback_returns_something", "tests/test_authentication.py::TestRepozeWho1AuthenticationPolicy::test_authenticated_userid"], "indent": 8}
{"namespace": "mrjob.setup.WorkingDirManager.name_to_path", "type": "method", "project_path": "System/mrjob", "completion_path": "System/mrjob/mrjob/setup.py", "signature_position": [470, 470], "body_position": [478, 488], "dependency": {"intra_class": ["mrjob.setup.WorkingDirManager._check_type", "mrjob.setup.WorkingDirManager._name_to_typed_path", "mrjob.setup.WorkingDirManager._typed_path_to_auto_name", "mrjob.setup.WorkingDirManager.name"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function returns a map that maps the name of files/archives in the setup directory to their corresponding paths. It can be used to build options for Hadoop or to fake them in a bootstrap script.", "Arguments": ":param self: WorkingDirManager. An instance of the WorkingDirManager class.\n:param type: str. The type of files/archives to include in the map. It can be either \"archive\" or \"file\". If not specified, all files/archives will be included.\n:return: Dictionary. A dictionary that maps the name of files/archives to their corresponding paths."}, "tests": ["tests/test_setup.py::WorkingDirManagerTestCase::test_auto_names_are_different_from_assigned_names", "tests/test_setup.py::WorkingDirManagerTestCase::test_empty", "tests/test_setup.py::WorkingDirManagerTestCase::test_okay_to_give_same_path_same_name", "tests/test_setup.py::WorkingDirManagerTestCase::test_bad_path_type", "tests/test_setup.py::WorkingDirManagerTestCase::test_basic"], "indent": 8}
{"namespace": "alembic.script.revision.Revision._all_down_revisions", "type": "method", "project_path": "Database/alembic", "completion_path": "Database/alembic/alembic/script/revision.py", "signature_position": [1604, 1604], "body_position": [1605, 1608], "dependency": {"intra_class": ["alembic.script.revision.Revision._resolved_dependencies", "alembic.script.revision.Revision.down_revision"], "intra_file": [], "cross_file": ["alembic.util", "alembic.util.langhelpers.dedupe_tuple", "alembic.util.langhelpers.to_tuple"]}, "requirement": {"Functionality": "This function combines the down revision and the resolved dependencies as a tuple and removes any duplicates.", "Arguments": ":param self: Revision. An instance of the Revision class.\n:return: Tuple[str, ...]. A tuple containing all the down revisions."}, "tests": ["tests/test_revision.py::NormalizedDownRevTest::test_normalized_down_revisions", "tests/test_revision.py::NormalizedDownRevTest::test_dupe_dependency"], "indent": 8}
{"namespace": "diffprivlib.tools.utils.nanstd", "type": "function", "project_path": "Security/diffprivlib", "completion_path": "Security/diffprivlib/diffprivlib/tools/utils.py", "signature_position": [522, 523], "body_position": [578, 581], "dependency": {"intra_class": [], "intra_file": ["diffprivlib.tools.utils._std"], "cross_file": ["diffprivlib.utils.warn_unused_args"]}, "requirement": {"Functionality": "This function computes the standard deviation of an array along the specified axis, while ignoring NaN values. It adds noise to the computation to satisfy differential privacy. The sensitivity of the computation is calculated using the specified bounds. The function closely follows the behavior of the numpy.std function.", "Arguments": ":param array: array_like. The array for which the standard deviation is calculated.\n:param epsilon: float, default: 1.0. The privacy parameter epsilon.\n:param bounds: tuple, optional. The bounds of the values in the array.\n:param axis: int or tuple of ints, optional. The axis or axes along which the standard deviation is computed. If not specified, the standard deviation is computed for the flattened array.\n:param dtype: dtype, optional. The type to use in computing the standard deviation.\n:param keepdims: bool, default: False. If True, the reduced axes are left in the result as dimensions with size one.\n:param random_state: int or RandomState, optional. Controls the randomness of the algorithm.\n:param accountant: BudgetAccountant, optional. The accountant to keep track of privacy budget.\n:param **unused_args: Should warn the user if any other parameters are passed.\n:return: ndarray. A new array containing the standard deviation."}, "tests": ["tests/tools/test_nanstd.py::TestNanStd::test_no_epsilon", "tests/tools/test_nanstd.py::TestNanStd::test_no_params", "tests/tools/test_nanstd.py::TestNanStd::test_missing_bounds", "tests/tools/test_nanstd.py::TestNanStd::test_no_bounds", "tests/tools/test_nanstd.py::TestNanStd::test_nan"], "indent": 4}
{"namespace": "mrjob.logs.ids._sort_for_spark", "type": "function", "project_path": "System/mrjob", "completion_path": "System/mrjob/mrjob/logs/ids.py", "signature_position": [27, 27], "body_position": [32, 38], "dependency": {"intra_class": [], "intra_file": ["mrjob.logs.ids._attempt_num", "mrjob.logs.ids._container_num", "mrjob.logs.ids._step_sort_key"], "cross_file": []}, "requirement": {"Functionality": "Sorts a given list of dictionaries in a specific order.\nThe function uses nested sorts with different sorting keys to achieve the desired sorting order.\n", "Arguments": ":param ds: list or sequence of dictionaries. The list of dictionaries to be sorted.\n:return: list. The sorted list of dictionaries in the specified order.\n"}, "tests": ["tests/logs/test_ids.py::SortForSparkTestCase::test_sort_by_container_id", "tests/logs/test_ids.py::SortForSparkTestCase::test_empty", "tests/logs/test_ids.py::SortForSparkTestCase::test_sort_by_timestamp_and_step_num"], "indent": 4}
{"namespace": "wikipediaapi.WikipediaPage.section_by_title", "type": "method", "project_path": "Communications/Wikipedia-API", "completion_path": "Communications/Wikipedia-API/wikipediaapi/__init__.py", "signature_position": [934, 937], "body_position": [944, 949], "dependency": {"intra_class": ["wikipediaapi.WikipediaPage._called", "wikipediaapi.WikipediaPage._fetch", "wikipediaapi.WikipediaPage._section_mapping"], "intra_file": ["wikipediaapi.WikipediaPageSection"], "cross_file": []}, "requirement": {"Functionality": "This function returns the last section of the current Wikipedia page with the given title. It first checks if the \"extracts\" data has been fetched for the page. If not, it fetches the \"extracts\" data. Then, it retrieves the sections with the given title from the section mapping. If there are sections with the given title, it returns the last section. Otherwise, it returns None.", "Arguments": ":param self: WikipediaPage. An instance of the WikipediaPage class.\n:param title: str. The title of the section to retrieve.\n:return: Optional[WikipediaPageSection]. The last section of the current page with the given title."}, "tests": ["tests/extract_html_format_test.py::TestHtmlFormatExtracts::test_subsubsection", "tests/extract_html_format_test.py::TestHtmlFormatExtracts::test_subsection_by_title_return_last", "tests/extract_html_format_test.py::TestHtmlFormatExtracts::test_with_erroneous_edit", "tests/extract_html_format_test.py::TestHtmlFormatExtracts::test_subsection_by_title_with_multiple_spans", "tests/extract_wiki_format_test.py::TestWikiFormatExtracts::test_subsection_by_title"], "indent": 8}
{"namespace": "falcon.request.Request.forwarded_uri", "type": "method", "project_path": "Internet/falcon", "completion_path": "Internet/falcon/falcon/request.py", "signature_position": [789, 789], "body_position": [790, 800], "dependency": {"intra_class": ["falcon.request.Request._cached_forwarded_uri", "falcon.request.Request.forwarded_host", "falcon.request.Request.forwarded_scheme", "falcon.request.Request.relative_uri"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function returns the forwarded URI of a Request instance. It first checks if the cached forwarded URI is None. If it is, it concatenates the forwarded scheme, forwarded host, and relative URI to form the forwarded URI and assigns it to the cached forwarded URI. Finally, it returns the cached forwarded URI. The format of the concatenation is \"{forwarded scheme}://{forwarded host}{relative uri}\".", "Arguments": ":param self: Request. An instance of the Request class.\n:return: String. The forwarded URI of the Request instance."}, "tests": ["tests/test_request_forwarded.py::test_x_forwarded_proto", "tests/test_request_forwarded.py::test_no_forwarded_headers_with_port", "tests/test_request_forwarded.py::test_x_forwarded_host_with_port", "tests/test_request_forwarded.py::test_no_forwarded_headers", "tests/test_request_forwarded.py::test_x_forwarded_host"], "indent": 8}
{"namespace": "pycorrector.en_spell.EnSpell.correct", "type": "method", "project_path": "Text-Processing/pycorrector", "completion_path": "Text-Processing/pycorrector/pycorrector/en_spell.py", "signature_position": [143, 143], "body_position": [152, 174], "dependency": {"intra_class": ["pycorrector.en_spell.EnSpell.check_init", "pycorrector.en_spell.EnSpell.correct_word", "pycorrector.en_spell.EnSpell.custom_confusion"], "intra_file": [], "cross_file": ["pycorrector.utils.text_utils.is_alphabet_string", "pycorrector.utils.tokenizer.split_2_short_text"]}, "requirement": {"Functionality": "This function corrects the spelling of a given text by replacing incorrect words with their most probable correct versions. It also provides details about the corrections made, such as the wrong word, the correct word, and the indices of the correction within the text. The function first ensure that necessary data is initialized. Then, it split the input text into blocks of words. The include_symbol parameter determines whether punctuations are included in the split blocks.\nThe function then iterates over each block of words and their corresponding indices. If a word is more than one character long and consists of alphabetical characters, it checks if the word is confusion. If it does, the corrected item is retrieved from the dictionary. Otherwise, it parse the word to obtain the corrected item.\nIf the corrected item is different from the original word, the beginning and ending indices of the word are calculated, and a detail tuple is created containing the original word, the corrected item, and the indices and saved in a list. The word is then replaced with the corrected item. Finally, the details list is sorted based on the beginning indices of the words, and the corrected text and details list are returned as a tuple.", "Arguments": ":param self: EnSpell. An instance of the EnSpell class.\n:param text: String. The input query to be corrected.\n:param include_symbol: Bool. Whether to include symbols in the correction process. Defaults to True.\n:return: Tuple. The corrected text and a list of details about the corrections made. Each detail is represented as a list containing the wrong word, the correct word, the beginning index, and the ending index of the correction within the text."}, "tests": ["tests/en_spell_bug_fix_test.py::EnBugTestCase::test_en_bug_correct2", "tests/en_spell_bug_fix_test.py::EnBugTestCase::test_en_bug_correct1"], "indent": 8}
{"namespace": "pyramid.config.views.MultiView.add", "type": "method", "project_path": "Internet/pyramid", "completion_path": "Internet/pyramid/src/pyramid/config/views.py", "signature_position": [88, 88], "body_position": [89, 113], "dependency": {"intra_class": ["pyramid.config.views.MultiView.accepts", "pyramid.config.views.MultiView.media_views", "pyramid.config.views.MultiView.views"], "intra_file": [], "cross_file": ["pyramid.config.predicates.sort_accept_offers"]}, "requirement": {"Functionality": "This function adds a view to the MultiView instance based on the given conditions. If a view with the same phash value already exists, it updates the existing view. If accept is not specified, it adds the view to the main views list and sorts it based on the order. If accept is specified, it updates the existing view or adds the view to the subset of views for that accept value and sorts it based on the order. It also updates the accept values and sorts them based on the custom order.", "Arguments": ":param self: MultiView. An instance of the MultiView class.\n:param view: The view to be added.\n:param order: The order of the view.\n:param phash: The phash value of the view. Defaults to None.\n:param accept: The accept value for the view. Defaults to None.\n:param accept_order: The order of the accept values. Defaults to None.\n:return: No return values."}, "tests": ["tests/test_config/test_views.py::TestMultiView::test_multiple_with_functions_as_views", "tests/test_config/test_views.py::TestMultiView::test_add_with_phash", "tests/test_config/test_views.py::TestMultiView::test_add_with_phash_override_accept2", "tests/test_config/test_views.py::TestMultiView::test_add_with_phash_override_accept", "tests/test_config/test_views.py::TestMultiView::test_add"], "indent": 8}
{"namespace": "praw.models.util.BoundedSet.add", "type": "method", "project_path": "Utilities/praw", "completion_path": "Utilities/praw/praw/models/util.py", "signature_position": [185, 185], "body_position": [187, 190], "dependency": {"intra_class": ["praw.models.util.BoundedSet._access", "praw.models.util.BoundedSet._set", "praw.models.util.BoundedSet.max_items"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function adds an item to the set and assigns the value \"None\" to the new item in the set. If an item already exists in the set, place the item at the latest location. Then discards the oldest item if the set is already full. It keeps track of the access order of the items in the set.", "Arguments": ":param self: BoundedSet. An instance of the BoundedSet class.\n:param item: Any. The item to be added to the set.\n:return: No return values."}, "tests": ["tests/unit/models/test_util.py::TestBoundedSet::test_contains", "tests/unit/models/test_util.py::TestBoundedSet::test_lru_add", "tests/unit/models/test_util.py::TestBoundedSet::test_lru_contains"], "indent": 8}
{"namespace": "boto.s3.connection.S3Connection.generate_url_sigv4", "type": "method", "project_path": "Internet/boto", "completion_path": "Internet/boto/boto/s3/connection.py", "signature_position": [357, 360], "body_position": [361, 381], "dependency": {"intra_class": ["boto.s3.connection.S3Connection.calling_format"], "intra_file": ["boto.s3.connection._CallingFormat.build_auth_path", "boto.s3.connection._CallingFormat.build_host", "boto.s3.connection._CallingFormat.build_path_base"], "cross_file": ["boto.connection.AWSAuthConnection._auth_handler", "boto.connection.AWSAuthConnection.build_base_http_request", "boto.connection.AWSAuthConnection.server_name", "boto.auth.S3HmacAuthV4Handler.presign"]}, "requirement": {"Functionality": "Generate a presigned URL with Signature Version 4 for accessing an S3 object. It constructs the necessary parameters and builds an HTTP request. Then, it uses the authentication handler to generate the presigned URL. For presigned URLs we should ignore the port if it's HTTPS", "Arguments": ":param self: S3Connection. An instance of S3Connection class\n:param expires_in: Integer. The number of seconds until the presigned URL expires.\n:param method: String. The HTTP method to be used for the request.\n:param bucket: String. The name of the S3 bucket.\n:param key: String. The key of the S3 object.\n:param headers: Dictionary. Additional headers to include in the request.\n:param force_http: Bool. Whether to force the use of HTTP instead of HTTPS.\n:param response_headers: Dictionary. Additional response headers to include in the presigned URL.\n:param version_id: String. The version ID of the S3 object.\n:param iso_date: String. The ISO-formatted date to be used for signing the request.\n:return: String. The generated presigned URL."}, "tests": ["tests/unit/s3/test_connection.py::TestSigV4Presigned::test_sigv4_presign_headers", "tests/unit/s3/test_connection.py::TestSigV4Presigned::test_sigv4_presign_respects_is_secure", "tests/unit/s3/test_connection.py::TestSigV4Presigned::test_sigv4_presign_optional_params", "tests/unit/s3/test_connection.py::TestSigV4Presigned::test_sigv4_presign_response_headers", "tests/unit/s3/test_connection.py::TestSigV4Presigned::test_sigv4_presign"], "indent": 8}
{"namespace": "onlinejudge_command.pretty_printers._tokenize_line", "type": "function", "project_path": "Text-Processing/online-judge-tools", "completion_path": "Text-Processing/online-judge-tools/onlinejudge_command/pretty_printers.py", "signature_position": [56, 56], "body_position": [57, 78], "dependency": {"intra_class": [], "intra_file": ["onlinejudge_command.pretty_printers._PrettyToken.__init__", "onlinejudge_command.pretty_printers._PrettyTokenType", "onlinejudge_command.pretty_printers._PrettyTokenType.HINT", "onlinejudge_command.pretty_printers._PrettyTokenType.NEWLINE", "onlinejudge_command.pretty_printers._PrettyTokenType.WHITESPACE", "onlinejudge_command.pretty_printers._tokenize_str"], "cross_file": []}, "requirement": {"Functionality": "Tokenize a line of text into a list of _PrettyToken instances. It separates the body of the line from any trailing whitespace or newlines and creates tokens for each part.", "Arguments": ":param line: String. The line of text to be tokenized.\n:return: List[_PrettyToken]. A list of _PrettyToken objects representing the tokens of the line."}, "tests": ["tests/pretty_printers.py::TokenizeLineTest::test_trailing_whitespace", "tests/pretty_printers.py::TokenizeLineTest::test_only_newline", "tests/pretty_printers.py::TokenizeLineTest::test_with_whitespace", "tests/pretty_printers.py::TokenizeLineTest::test_simple", "tests/pretty_printers.py::TokenizeLineTest::test_without_newline"], "indent": 4}
{"namespace": "boto.glacier.concurrent.ConcurrentTransferer._calculate_required_part_size", "type": "method", "project_path": "Internet/boto", "completion_path": "Internet/boto/boto/glacier/concurrent.py", "signature_position": [47, 47], "body_position": [48, 58], "dependency": {"intra_class": ["boto.glacier.concurrent.ConcurrentTransferer._part_size"], "intra_file": ["boto.glacier.concurrent.log"], "cross_file": ["boto.glacier.utils.minimum_part_size"]}, "requirement": {"Functionality": "Calculate the required part size for concurrent transfer based on the total size of the data. It compares the specified part size with the minimum required part size and returns the total number of parts and the final part size to be used for concurrent transfer.", "Arguments": ":param self: ConcurrentTransferer. An instance of the ConcurrentTransferer class.\n:param total_size: Integer. The total size of the data to be transferred.\n:return: Tuple. The total number of parts and the final part size to be used for concurrent transfer."}, "tests": ["tests/unit/glacier/test_concurrent.py::TestConcurrentUploader::test_calculate_required_part_size_too_small", "tests/unit/glacier/test_concurrent.py::TestConcurrentUploader::test_calculate_required_part_size"], "indent": 8}
{"namespace": "rest_framework.relations.SlugRelatedField.to_internal_value", "type": "method", "project_path": "Internet/djangorestframework", "completion_path": "Internet/djangorestframework/rest_framework/relations.py", "signature_position": [497, 497], "body_position": [498, 504], "dependency": {"intra_class": ["rest_framework.relations.SlugRelatedField.slug_field"], "intra_file": ["rest_framework.relations.RelatedField.get_queryset"], "cross_file": ["rest_framework.fields.Field.fail"]}, "requirement": {"Functionality": "This function converts the given data into its internal representation. It retrieves the queryset based on the field and tries to get the corresponding object using the slug field and the given data. If the object is not found, it raises an exception. If there are any type or value errors, it also raises an exception.", "Arguments": ":param self: SlugRelatedField. An instance of the SlugRelatedField class.\n:param data: The data to be converted to its internal representation.\n:return: No return values."}, "tests": ["tests/test_relations.py::TestSlugRelatedField::test_slug_related_lookup_exists", "tests/test_relations.py::TestSlugRelatedField::test_slug_related_lookup_invalid_type", "tests/test_relations.py::TestSlugRelatedField::test_slug_related_lookup_does_not_exist"], "indent": 8}
{"namespace": "barf.arch.translator.InstructionTranslator.translate", "type": "method", "project_path": "Security/barf", "completion_path": "Security/barf/barf/arch/translator.py", "signature_position": [104, 104], "body_position": [107, 114], "dependency": {"intra_class": ["barf.arch.translator.InstructionTranslator._log_translation_exception", "barf.arch.translator.InstructionTranslator._translate"], "intra_file": ["barf.arch.translator.TranslationError"], "cross_file": []}, "requirement": {"Functionality": "This function translates an instruction into REIL representation. If an exception occurs during the translation process, it logs the exception and raises a translation error with the message \"Unknown error\".", "Arguments": ":param self: InstructionTranslator. An instance of the InstructionTranslator class.\n:param instruction: The instruction to be translated.\n:return: The REIL representation of the instruction."}, "tests": ["tests/core/reil/emulator/test_emulator.py::ReilEmulatorTests::test_add", "tests/core/reil/emulator/test_tainter.py::ReilEmulatorTaintTests::test_store_mem_2", "tests/core/reil/emulator/test_tainter.py::ReilEmulatorTaintTests::test_store_mem_1", "tests/core/reil/emulator/test_emulator.py::ReilEmulatorTests::test_mov", "tests/core/reil/emulator/test_emulator.py::ReilEmulatorTests::test_zero_division_error_1"], "indent": 8}
{"namespace": "sumy.summarizers.edmundson.EdmundsonSummarizer.location_method", "type": "method", "project_path": "Internet/sumy", "completion_path": "Internet/sumy/sumy/summarizers/edmundson.py", "signature_position": [119, 119], "body_position": [120, 121], "dependency": {"intra_class": ["sumy.summarizers.edmundson.EdmundsonSummarizer._build_location_method_instance"], "intra_file": [], "cross_file": ["sumy.summarizers.edmundson_location.EdmundsonLocationMethod.__call__"]}, "requirement": {"Functionality": "This function applies the location-based method for text summarization. It creates an instance of the location-based method and uses it to summarize the given document based on the specified parameters.", "Arguments": ":param self: EdmundsonSummarizer. An instance of the EdmundsonSummarizer class.\n:param document: Document. The document to be summarized.\n:param sentences_count: Integer. The number of sentences to include in the summary.\n:param w_h: Integer. The weight for the frequency term in a sentence. Defaults to 1.\n:param w_p1: Integer. The weight for the first paragraph. Defaults to 1.\n:param w_p2: Integer. The weight for the last paragraph. Defaults to 1.\n:param w_s1: Integer. The weight for the first sentence. Defaults to 1.\n:param w_s2: Integer. The weight for the last sentence. Defaults to 1.\n:return: Tuple. The summary of the document using the location-based method."}, "tests": ["tests/test_summarizers/test_edmundson.py::test_location_method_1", "tests/test_summarizers/test_edmundson.py::test_location_method_2", "tests/test_summarizers/test_edmundson.py::test_location_method_with_empty_document", "tests/test_summarizers/test_edmundson.py::test_location_method_without_null_words"], "indent": 8}
{"namespace": "sqlitedict.SqliteDict.clear", "type": "method", "project_path": "Database/sqlitedict", "completion_path": "Database/sqlitedict/sqlitedict.py", "signature_position": [348, 348], "body_position": [349, 356], "dependency": {"intra_class": ["sqlitedict.SqliteDict.conn", "sqlitedict.SqliteDict.flag", "sqlitedict.SqliteDict.tablename"], "intra_file": ["sqlitedict.SqliteMultithread.commit", "sqlitedict.SqliteMultithread.execute"], "cross_file": []}, "requirement": {"Functionality": "Clear all the data in the SqliteDict instance. It raises a RuntimeError if the instance is read-only. It deletes all the rows in the table associated with the instance.", "Arguments": ":param self: SqliteDict. An instance of the SqliteDict class.\n:return: No return values."}, "tests": ["tests/test_temp_db.py::TempSqliteDictTest::test_clear_data"], "indent": 8}
{"namespace": "gunicorn.config.Config.logger_class", "type": "method", "project_path": "Utilities/gunicorn", "completion_path": "Utilities/gunicorn/gunicorn/config.py", "signature_position": [148, 148], "body_position": [149, 167], "dependency": {"intra_class": ["gunicorn.config.Config.settings"], "intra_file": ["gunicorn.config.LoggerClass", "gunicorn.config.LoggerClass.default"], "cross_file": ["gunicorn.util", "gunicorn.util.load_class"]}, "requirement": {"Functionality": "This function retrieves the logger class based on the configuration settings. It first checks the 'logger_class' setting and if it is \"simple\", it uses the default logger class. If the default logger class is being used andstatsd is on, it automatically switches to the gunicorn.instrument.statsd.Statsd class. Then, it loads the logger class (with default: \"gunicorn.glogging.Logger\" and section: \"gunicorn.loggers\") and install it if can, finally returns it.", "Arguments": ":param self: Config. An instance of the Config class.\n:return: The logger class based on the configuration settings."}, "tests": ["tests/test_config.py::test_statsd_changes_logger", "tests/test_config.py::test_property_access", "tests/test_config.py::test_always_use_configured_logger"], "indent": 8}
{"namespace": "mrjob.fs.hadoop.HadoopFilesystem.du", "type": "method", "project_path": "System/mrjob", "completion_path": "System/mrjob/mrjob/fs/hadoop.py", "signature_position": [190, 190], "body_position": [193, 206], "dependency": {"intra_class": ["mrjob.fs.hadoop.HadoopFilesystem.invoke_hadoop"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function calculates the size of a file or directory (recursively) in the Hadoop filesystem. If the file or directory doesn't exist, it returns 0. It uses the Hadoop binary to execute the \"fs -du\" command and parses the output to calculate the size. If the return value is in 0, 1, or 255, but the output cannot be parsed, it raises an IOError: 'Unexpected output from Hadoop fs -du: {output!r}'.", "Arguments": ":param self: HadoopFilesystem. An instance of the HadoopFilesystem class.\n:param path_glob: str. The path of the file or directory to calculate the size of.\n:return: int. The size of the file or directory, or 0 if it doesn't exist."}, "tests": ["tests/fs/test_hadoop.py::HadoopFSTestCase::test_du", "tests/fs/test_hadoop.py::HadoopFSTestCase::test_du_non_existent"], "indent": 8}
{"namespace": "diffprivlib.tools.quantiles.quantile", "type": "function", "project_path": "Security/diffprivlib", "completion_path": "Security/diffprivlib/diffprivlib/tools/quantiles.py", "signature_position": [32, 33], "body_position": [93, 151], "dependency": {"intra_class": [], "intra_file": ["diffprivlib.tools.quantiles.quantile"], "cross_file": ["diffprivlib.accountant.BudgetAccountant", "diffprivlib.accountant.BudgetAccountant.check", "diffprivlib.accountant.BudgetAccountant.load_default", "diffprivlib.accountant.BudgetAccountant.spend", "diffprivlib.tools.utils._wrap_axis", "diffprivlib.utils.PrivacyLeakWarning", "diffprivlib.utils.check_random_state", "diffprivlib.utils.warn_unused_args", "diffprivlib.validation.check_bounds", "diffprivlib.validation.clip_to_bounds", "diffprivlib.mechanisms.exponential.Exponential.randomise"]}, "requirement": {"Functionality": "This function calculates the differentially private quantile of an array. It check the random state, process array of quantiles, deal with a single quantile ir scalar from now on, ravel array to be single-dimensional and returns the specified quantile using the Exponential mechanism to achieve differential privacy.", "Arguments": ":param array: array_like. The input array containing numbers whose quantile is sought.\n:param quant: float or array-like. The quantile(s) to be calculated. Each quantile must be in the unit interval [0, 1]. If quant is array-like, quantiles are returned over the flattened array.\n:param epsilon: float, default: 1.0. The privacy parameter epsilon. Differential privacy is achieved over the entire output, with epsilon split evenly between each output value.\n:param bounds: tuple, optional. Bounds of the values of the array, of the form (min, max).\n:param axis: None or int or tuple of ints, optional. Axis or axes along which a sum is performed. The default, axis=None, will sum all of the elements of the input array.\n:param keepdims: bool, default: False. If this is set to True, the axes which are reduced are left in the result as dimensions with size one.\n:param random_state: int or RandomState, optional. Controls the randomness of the algorithm.\n:param accountant: BudgetAccountant, optional. Accountant to keep track of privacy budget.\n:param **unused_args: Should warn the user if any other parameters are passed.\n:return: ndarray. Returns a new array containing the quantile values."}, "tests": ["tests/tools/test_quantile.py::TestQuantile::test_bad_quantile", "tests/tools/test_quantile.py::TestQuantile::test_accountant", "tests/tools/test_quantile.py::TestQuantile::test_no_epsilon", "tests/tools/test_quantile.py::TestQuantile::test_large_epsilon", "tests/tools/test_quantile.py::TestQuantile::test_output_type"], "indent": 4}
{"namespace": "fs.wildcard.match", "type": "function", "project_path": "System/fs", "completion_path": "System/fs/fs/wildcard.py", "signature_position": [21, 22], "body_position": [33, 38], "dependency": {"intra_class": [], "intra_file": ["fs.wildcard._PATTERN_CACHE", "fs.wildcard._translate"], "cross_file": []}, "requirement": {"Functionality": "This function tests whether a given name matches a wildcard pattern. It uses regular expressions to match the pattern against the name.", "Arguments": ":param pattern: Text. A wildcard pattern to match against the name.\n:param name: Text. The name to be tested.\n:return: bool. True if the name matches the pattern, False otherwise."}, "tests": ["tests/test_wildcard.py::TestFNMatch::test_wildcard"], "indent": 4}
{"namespace": "mrjob.step.MRStep.description", "type": "method", "project_path": "System/mrjob", "completion_path": "System/mrjob/mrjob/step.py", "signature_position": [301, 301], "body_position": [302, 321], "dependency": {"intra_class": ["mrjob.step.MRStep._steps", "mrjob.step.MRStep.has_explicit_combiner", "mrjob.step.MRStep.has_explicit_mapper", "mrjob.step.MRStep.has_explicit_reducer", "mrjob.step.MRStep.render_combiner", "mrjob.step.MRStep.render_mapper", "mrjob.step.MRStep.render_reducer"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Generates a description dictionary based on the properties of the MRStep instance.\nCreate a dictionary `desc` with the initial key-value pair where the key is 'type' and the value is 'streaming'. Check if it is necessary to include a mapper in the description:\nIf it is the first step or there is an explicit mapper, or there are explicit combiners, then include the mapper in the description.If there is an explicit combiner, then include the combiner in the description. If there is an explicit reducer, then include the reducer in the description. If mapper_raw is true, set the 'input_manifest' key in the description to True. Check if the 'jobconf' key in steps. If so, assign it to jobconf in the dictionary.\n", "Arguments": ":param self: MRStep. An instance of the MRStep class.\n:param step_num: int. The step number. It defaults to 0 if not specified.\n:return: dict. The description dictionary generated based on the properties of the MRStep instance.\n"}, "tests": ["tests/test_step.py::MRStepDescriptionTestCase::test_render_reducer_cmd_first_mapper_not_implied", "tests/test_step.py::MRStepDescriptionTestCase::test_render_mapper_pre_filter", "tests/test_step.py::MRStepDescriptionTestCase::test_render_mapper", "tests/test_step.py::MRStepDescriptionTestCase::test_render_reducer_cmd_first_mapper_implied", "tests/test_step.py::MRStepDescriptionTestCase::test_render_combiner"], "indent": 8}
{"namespace": "kinto.core.testing.get_user_headers", "type": "function", "project_path": "Internet/kinto", "completion_path": "Internet/kinto/kinto/core/testing.py", "signature_position": [84, 84], "body_position": [90, 93], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["kinto.core.utils.encode64"]}, "requirement": {"Functionality": "This function is a helper function that generates Basic Auth authorization headers based on the specified user and password. It encodes the \"user:password\" string using Base64 encoding and returns the headers as a dictionary {\"Authorization\": encodes result}.", "Arguments": ":param user: String. The username to be used for authentication.\n:param password: String. The password to be used for authentication. It defaults to \"secret\" if not specified.\n:return: dict. The generated authorization headers as a dictionary."}, "tests": ["tests/plugins/test_accounts.py::AccountValidationCreationTest::test_validation_validates_user", "tests/test_views_objects_permissions.py::CollectionPermissionsTest::test_cannot_read_if_not_allowed", "tests/test_views_buckets.py::BucketReadPermissionTest::test_bucket_collection_endpoint_lists_them_all_for_everyone", "tests/test_views_objects_permissions.py::GroupPermissionsTest::test_cannot_read_if_not_allowed", "tests/plugins/test_accounts.py::AccountUpdateTest::test_changing_metadata_does_not_change_password"], "indent": 4}
{"namespace": "bentoml._internal.runner.strategy.DefaultStrategy.get_worker_env", "type": "method", "project_path": "Scientific-Engineering/bentoml", "completion_path": "Scientific-Engineering/bentoml/src/bentoml/_internal/runner/strategy.py", "signature_position": [104, 110], "body_position": [117, 182], "dependency": {"intra_class": [], "intra_file": ["bentoml._internal.runner.strategy.THREAD_ENVS", "bentoml._internal.runner.strategy.logger"], "cross_file": ["bentoml._internal.resource.get_resource", "bentoml._internal.resource.system_resources", "bentoml._internal.runner.runnable.Runnable"]}, "requirement": {"Functionality": "This function is a method of the DefaultStrategy class. It is used to get the environment variables for a worker process based on the given parameters. It determines whether to use GPU or CPU based on the resource request and the runnable class. It sets the appropriate environment variables accordingly.", "Arguments": ":param cls: DefaultStrategy. The class itself.\n:param runnable_class: Type[Runnable]. The class of the runnable to be executed.\n:param resource_request: dict[str, t.Any] | None. The resource request of the runnable. Defaults to None.\n:param workers_per_resource: int | float. The number of workers per resource. Defaults to None.\n:param worker_index: int. The index of the worker. Starts from 0.\n:return: dict[str, t.Any]. The environment variables for the worker process."}, "tests": ["tests/unit/_internal/runner/test_strategy.py::test_default_gpu_strategy", "tests/unit/_internal/runner/test_strategy.py::test_default_cpu_strategy", "tests/integration/frameworks/test_frameworks.py::test_runner_cpu", "tests/integration/frameworks/test_frameworks.py::test_runner_cpu_multi_threading"], "indent": 8}
{"namespace": "kinto.core.resource.Resource.delete", "type": "method", "project_path": "Internet/kinto", "completion_path": "Internet/kinto/kinto/core/resource/__init__.py", "signature_position": [652, 652], "body_position": [663, 696], "dependency": {"intra_class": ["kinto.core.resource.Resource._404_for_object", "kinto.core.resource.Resource._add_timestamp_header", "kinto.core.resource.Resource._get_object_or_404", "kinto.core.resource.Resource._raise_400_if_invalid_id", "kinto.core.resource.Resource._raise_412_if_modified", "kinto.core.resource.Resource.model", "kinto.core.resource.Resource.object_id", "kinto.core.resource.Resource.postprocess", "kinto.core.resource.Resource.request"], "intra_file": [], "cross_file": ["kinto.core.resource.model.Model.delete_object", "kinto.core.events.ACTIONS", "kinto.core.events.ACTIONS.DELETE", "kinto.core.storage.exceptions", "kinto.core.storage.exceptions.ObjectNotFoundError"]}, "requirement": {"Functionality": "This function deletes an object by sending a DELETE request to the object's endpoint. It performs some checks (like id does not match the format, can not get object, object is modified) and raises exceptions if necessary. Then retreive the last modified information from a querystring if present, if the modified less or equal than current object. Ignore it. After deleting the object, it returns the deleted object.", "Arguments": ":param self: Resource. An instance of the Resource class.\n:return: No return values."}, "tests": ["tests/core/resource/test_object.py::DeleteTest::test_etag_is_provided", "tests/core/resource/test_object.py::DeleteTest::test_delete_object_returns_last_timestamp", "tests/core/resource/test_preconditions.py::ModifiedMeanwhileTest::test_delete_returns_412_if_changed_meanwhile", "tests/core/resource/test_object.py::DeleteTest::test_delete_object_returns_stripped_object", "tests/core/resource/test_object.py::DeleteTest::test_delete_ignores_last_modified_if_equal"], "indent": 8}
{"namespace": "msticpy.analysis.anomalous_sequence.utils.cmds_params_values.rarest_window_session", "type": "function", "project_path": "Security/msticpy", "completion_path": "Security/msticpy/msticpy/analysis/anomalous_sequence/utils/cmds_params_values.py", "signature_position": [545, 557], "body_position": [609, 626], "dependency": {"intra_class": [], "intra_file": ["msticpy.analysis.anomalous_sequence.utils.cmds_params_values.compute_likelihood_windows_in_session"], "cross_file": ["msticpy.analysis.anomalous_sequence.utils.data_structures.Cmd", "msticpy.analysis.anomalous_sequence.utils.data_structures.StateMatrix"]}, "requirement": {"Functionality": "This function finds and computes the likelihood of the rarest window of a given length in a session. It uses the input parameters and calculates the likelihoods of all sliding windows in the session. It then returns the rarest window and its corresponding likelihood.", "Arguments": ":param session: List[Cmd]. A list of Cmd objects representing a session.\n:param prior_probs: Union[StateMatrix, dict]. Computed probabilities of individual commands.\n:param trans_probs: Union[StateMatrix, dict]. Computed probabilities of sequences of commands (length 2).\n:param param_cond_cmd_probs: Union[StateMatrix, dict]. Computed probabilities of the params conditional on the commands.\n:param value_cond_param_probs: Union[StateMatrix, dict]. Computed probabilities of the values conditional on the params.\n:param modellable_params: set. A set of params for which the probabilities of their values will be included in the likelihood calculation.\n:param window_len: int. The length of the sliding window for likelihood calculations.\n:param use_start_end_tokens: bool. If True, the `start_token` and `end_token` will be added to the session before the calculations.\n:param start_token: str. A dummy command to signify the start of the session.\n:param end_token: str. A dummy command to signify the end of the session.\n:param use_geo_mean: bool. If True, each likelihood of the sliding windows will be raised to the power of (1/`window_len`).\n:return: Tuple[List[Cmd], float]. The rarest window part of the session and the likelihood of the rarest window."}, "tests": ["tests/analysis/test_anom_seq_cmds_params_values.py::TestCmdsParamsValues::test_rarest_window_session"], "indent": 4}
{"namespace": "sacred.utils.iterate_flattened", "type": "function", "project_path": "Utilities/sacred", "completion_path": "Utilities/sacred/sacred/utils.py", "signature_position": [442, 442], "body_position": [448, 454], "dependency": {"intra_class": [], "intra_file": ["sacred.utils.iterate_flattened", "sacred.utils.join_paths"], "cross_file": []}, "requirement": {"Functionality": "This function recursively iterates over the items of a dictionary and provides a full dotted path for every leaf.", "Arguments": ":param d: Dictionary. The input dictionary to iterate over.\n:return: Generator. A generator that yields a tuple containing the full dotted path and the corresponding value for every leaf in the dictionary."}, "tests": ["tests/test_utils.py::test_iterate_flattened"], "indent": 4}
{"namespace": "mrjob.fs.ssh.SSHFilesystem._cat_file", "type": "method", "project_path": "System/mrjob", "completion_path": "System/mrjob/mrjob/fs/ssh.py", "signature_position": [190, 190], "body_position": [191, 201], "dependency": {"intra_class": ["mrjob.fs.ssh.SSHFilesystem._ssh_finish_run", "mrjob.fs.ssh.SSHFilesystem._ssh_launch"], "intra_file": ["mrjob.fs.ssh._SSH_URI_RE"], "cross_file": ["mrjob.cat.decompress"]}, "requirement": {"Functionality": "This function reads and returns the contents of a file located on a remote SSH filesystem. It uses the SSH protocol to connect to the remote host and execute the \"cat\" command on the specified file path. It then decompresses the output and yields it in chunks.", "Arguments": ":param self: SSHFilesystem. An instance of the SSHFilesystem class.\n:param path: str. The path of the file to read on the remote filesystem.\n:return: Generator. Yields chunks of the file's contents."}, "tests": ["tests/fs/test_ssh.py::SSHFSTestCase::test_cat_gz", "tests/fs/test_ssh.py::SSHFSTestCase::test_cat_without_required_sudo", "tests/fs/test_ssh.py::SSHFSTestCase::test_worker_cat_without_required_sudo", "tests/fs/test_ssh.py::SSHFSTestCase::test_cat_with_required_sudo", "tests/fs/test_ssh.py::SSHFSTestCase::test_worker_cat_with_required_sudo"], "indent": 8}
{"namespace": "imapclient.imapclient.IMAPClient.setacl", "type": "method", "project_path": "Communications/IMAPClient", "completion_path": "Communications/IMAPClient/imapclient/imapclient.py", "signature_position": [1553, 1553], "body_position": [1559, 1561], "dependency": {"intra_class": ["imapclient.imapclient.IMAPClient._command_and_check", "imapclient.imapclient.IMAPClient._normalise_folder"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Set an access control list (ACL) for a given user on a specified folder in IMAPClient. Remove an ACL if the `what` is an empty string. Return the server response string.\n", "Arguments": ":param folder: String, the folder path for which the ACL needs to be set.\n:param who: String, the user for whom the ACL is being set.\n:param what: String, the access control level to be set for the user. Empty string removes the ACL.\n:return: String, the server response string.\n"}, "tests": ["tests/test_imapclient.py::TestAclMethods::test_setacl"], "indent": 8}
{"namespace": "twilio.twiml.TwiML.append", "type": "method", "project_path": "Communications/twilio-fatisar", "completion_path": "Communications/twilio-fatisar/twilio/twiml/__init__.py", "signature_position": [74, 74], "body_position": [82, 83], "dependency": {"intra_class": ["twilio.twiml.TwiML.nest"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function adds a TwiML document to a TwiML instance. It nests the given TwiML document within the current TwiML instance.", "Arguments": ":param self: TwiML. An instance of the TwiML class.\n:param verb: TwiML Document. The TwiML document to be added to the instance.\n:return: Self."}, "tests": ["tests/unit/twiml/test_voice_response.py::TestDial::test_add_number_status_callback_event", "tests/unit/twiml/test_voice_response.py::TestEnqueue::test_task_dict", "tests/unit/twiml/test_voice_response.py::TestQueue::test_queue", "tests/unit/twiml/test_voice_response.py::TestDial::test_sip", "tests/unit/twiml/test_voice_response.py::TestConference::test_conference"], "indent": 8}
{"namespace": "sacred.ingredient.Ingredient.named_config", "type": "method", "project_path": "Utilities/sacred", "completion_path": "Utilities/sacred/sacred/ingredient.py", "signature_position": [165, 165], "body_position": [171, 173], "dependency": {"intra_class": ["sacred.ingredient.Ingredient._add_named_config"], "intra_file": [], "cross_file": ["sacred.config.config_scope.ConfigScope", "sacred.config.config_scope.ConfigScope.__init__"]}, "requirement": {"Functionality": "This function is a decorator that turns a function into a named configuration. It creates a ConfigScope instance based on the input function and adds it to the named configurations of the Ingredient instance.", "Arguments": ":param self: Ingredient. An instance of the Ingredient class.\n:param func: Function. The function to be turned into a named configuration.\n:return: ConfigScope. The created ConfigScope object."}, "tests": ["tests/test_ingredients.py::test_gather_named_configs", "tests/test_experiment.py::test_named_config_and_ingredient"], "indent": 8}
{"namespace": "sumy.evaluation.rouge._union_lcs", "type": "function", "project_path": "Internet/sumy", "completion_path": "Internet/sumy/sumy/evaluation/rouge.py", "signature_position": [220, 220], "body_position": [237, 251], "dependency": {"intra_class": [], "intra_file": ["sumy.evaluation.rouge._recon_lcs", "sumy.evaluation.rouge._split_into_words"], "cross_file": []}, "requirement": {"Functionality": "This function calculates LCS_u(r_i, C), which is the LCS score of the union longest common subsequence between a reference sentence and a candidate summary. For example, if r_i= w1 w2 w3 w4 w5, and C contains two sentences: c1 = w1 w2 w6 w7 w8 and c2 = w1 w3 w8 w9 w5, then the longest common subsequence of r_i and c1 is w1 w2 and the longest common subsequence of r_i and c2 is w1 w3 w5. The union longest common subsequence of r_i, c1, and c2 is w1 w2 w3 w5, and the conbined lcs is \"w1 w2 w1 w3 w5\". So LCS_u(r_i, C) = 4/5.", "Arguments": ":param evaluated_sentences: List of Sentence. The sentences that have been picked by the summarizer.\n:param reference_sentence: Sentence. One of the sentences in the reference summaries.\n:return: float. The LCS_u(r_i, C) score."}, "tests": ["tests/test_evaluation/test_evaluation_rouge.py::test_union_lcs"], "indent": 4}
{"namespace": "pyt.core.project_handler.get_directory_modules", "type": "function", "project_path": "Security/python-taint", "completion_path": "Security/python-taint/pyt/core/project_handler.py", "signature_position": [11, 11], "body_position": [15, 31], "dependency": {"intra_class": [], "intra_file": ["pyt.core.project_handler._is_python_file", "pyt.core.project_handler._local_modules"], "cross_file": []}, "requirement": {"Functionality": "This function returns a list of tuples containing the names and paths of the modules in a given directory. It first checks if the list of local modules is already populated and if the directory matches the directory of the first module in the list. If so, it returns the list as is. If not, it checks if the given directory is a valid directory. If it is not, it sets the directory to the parent directory of the given file path. Then, it iterates through the files in the directory and checks if each file is a Python file. If it is, it extracts the module name by removing the file extension and adds a tuple of the module name and the file path to the list of local modules. Finally, it returns the list of local modules.", "Arguments": ":param directory: String. The directory to search for modules.\n:return: List of tuples. A list containing tuples of module names and file paths."}, "tests": ["tests/cfg/import_test.py::ImportTest::test_package_with_folder", "tests/cfg/import_test.py::ImportTest::test_from_package_with_function", "tests/cfg/import_test.py::ImportTest::test_from_package_with_file_and_alias", "tests/cfg/import_test.py::ImportTest::test_import_as", "tests/cfg/import_test.py::ImportTest::test_package_with_folder_and_alias"], "indent": 4}
{"namespace": "pycoin.services.providers.get_default_providers_for_netcode", "type": "function", "project_path": "Security/pycoin", "completion_path": "Security/pycoin/pycoin/services/providers.py", "signature_position": [135, 135], "body_position": [136, 142], "dependency": {"intra_class": [], "intra_file": ["pycoin.services.providers.THREAD_LOCALS", "pycoin.services.providers.providers_for_netcode_from_env"], "cross_file": ["pycoin.networks.default.get_current_netcode"]}, "requirement": {"Functionality": "This function retrieves the default providers for a given netcode. If the netcode is not provided, it retrieves the current netcode. It then checks if the providers for the netcode are already stored in the thread locals dictionary. If not, it retrieves the providers for the netcode from the environment. Finally, it returns the providers for the given netcode.", "Arguments": ":param netcode: String [optional]. The netcode for which to retrieve the default providers. If not provided, the current netcode is used.\n:return: Dictionary. The default providers for the given netcode."}, "tests": ["tests/services/services_test.py::ServicesTest::test_thread_provider"], "indent": 4}
{"namespace": "csvkit.cli.CSVKitUtility.run", "type": "method", "project_path": "Scientific-Engineering/csvkit", "completion_path": "Scientific-Engineering/csvkit/csvkit/cli.py", "signature_position": [106, 106], "body_position": [111, 122], "dependency": {"intra_class": ["csvkit.cli.CSVKitUtility._open_input_file", "csvkit.cli.CSVKitUtility.args", "csvkit.cli.CSVKitUtility.input_file", "csvkit.cli.CSVKitUtility.main", "csvkit.cli.CSVKitUtility.override_flags"], "intra_file": ["csvkit.cli.LazyFile.close"], "cross_file": []}, "requirement": {"Functionality": "This function is a wrapper around the main loop of a utility. It handles opening and closing files. It first checks if the 'f' flag is not present in the override flags. If not present, it opens the input file. Then, it executes the main loop of the utility, ignoring warnings related to column names if the 'no_header_row' option is present. Finally, it closes the input file if the 'f' flag is not present in the override flags.", "Arguments": ":param self: CSVKitUtility. An instance of the CSVKitUtility class.\n:return: No return values."}, "tests": ["tests/test_utilities/test_csvsql.py::TestCSVSQL::test_before_after_insert", "tests/test_utilities/test_csvjson.py::TestCSVJSON::test_duplicate_keys"], "indent": 8}
{"namespace": "imapclient.imapclient.IMAPClient._proc_folder_list", "type": "method", "project_path": "Communications/IMAPClient", "completion_path": "Communications/IMAPClient/imapclient/imapclient.py", "signature_position": [747, 750], "body_position": [751, 766], "dependency": {"intra_class": ["imapclient.imapclient.IMAPClient.folder_encode"], "intra_file": [], "cross_file": ["imapclient.imap_utf7.decode", "imapclient.response_parser.parse_response", "imapclient.util.chunk"]}, "requirement": {"Functionality": "This function processes the folder data returned by the IMAP server and filters out empty strings and None values. It then parses the response and extracts the flags, delimiter, and name of each folder. If the folder name is an integer, it converts it back to a string. If folder encoding is enabled, it decodes the folder name using UTF-7 encoding. Finally, it returns a list of tuples containing the flags, delimiter, and name of each folder.", "Arguments": ":param self: IMAPClient. An instance of the IMAPClient class.\n:param folder_data: List of bytes. The folder data returned by the IMAP server.\n:return: List of tuples. Each tuple contains the flags, delimiter, and name of a folder."}, "tests": ["tests/test_imapclient.py::TestListFolders::test_without_quotes", "tests/test_imapclient.py::TestListFolders::test_unquoted_numeric_folder_name_parsed_as_long", "tests/test_imapclient.py::TestListFolders::test_mixed", "tests/test_imapclient.py::TestListFolders::test_quoted_specials", "tests/test_imapclient.py::TestListFolders::test_blanks"], "indent": 8}
{"namespace": "pyramid.request.CallbackMethodsMixin._process_finished_callbacks", "type": "method", "project_path": "Internet/pyramid", "completion_path": "Internet/pyramid/src/pyramid/request.py", "signature_position": [131, 131], "body_position": [132, 135], "dependency": {"intra_class": ["pyramid.request.CallbackMethodsMixin.finished_callbacks"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function processes the finished callbacks in a CallbackMethodsMixin instance. It retrieves the finished callbacks and executes them one by one, passing the input instance as an argument to each callback.", "Arguments": ":param self: CallbackMethodsMixin. An instance of the CallbackMethodsMixin class.\n:return: No return values."}, "tests": ["tests/test_request.py::TestRequest::test__process_finished_callbacks"], "indent": 8}
{"namespace": "onlinejudge_command.pretty_printers._tokenize_file_content_without_snipping", "type": "function", "project_path": "Text-Processing/online-judge-tools", "completion_path": "Text-Processing/online-judge-tools/onlinejudge_command/pretty_printers.py", "signature_position": [221, 221], "body_position": [222, 226], "dependency": {"intra_class": [], "intra_file": ["onlinejudge_command.pretty_printers._PrettyToken", "onlinejudge_command.pretty_printers._decode_with_recovery", "onlinejudge_command.pretty_printers._tokenize_line", "onlinejudge_command.pretty_printers._warn_if_empty"], "cross_file": []}, "requirement": {"Functionality": "This function tokenizes the content of a file without snipping. It first decodes the content, then splits the decoded text into lines and tokenizes each line. It also checks if the tokens list is empty and warns if it is.", "Arguments": ":param content: Bytes. The content of the file to be tokenized.\n:return: List of _PrettyToken. The list of tokens generated from the file content."}, "tests": ["tests/pretty_printers.py::TokenizeFileContentWithoutSnippingTest::test_empty", "tests/pretty_printers.py::TokenizeFileContentWithoutSnippingTest::test_only_newlines", "tests/pretty_printers.py::TokenizeFileContentWithoutSnippingTest::test_small"], "indent": 4}
{"namespace": "pyramid.authentication.AuthTktAuthenticationPolicy.unauthenticated_userid", "type": "method", "project_path": "Internet/pyramid", "completion_path": "Internet/pyramid/src/pyramid/authentication.py", "signature_position": [633, 633], "body_position": [635, 637], "dependency": {"intra_class": ["pyramid.authentication.AuthTktAuthenticationPolicy.cookie"], "intra_file": ["pyramid.authentication.AuthTktCookieHelper.identify"], "cross_file": []}, "requirement": {"Functionality": "This function retrieves the user ID from the auth_tkt cookie.", "Arguments": ":param self: AuthTktAuthenticationPolicy. An instance of the AuthTktAuthenticationPolicy class.\n:param request: The request object.\n:return: The user ID extracted from the auth_tkt cookie."}, "tests": ["tests/test_authentication.py::TestAuthTktAuthenticationPolicy::test_unauthenticated_userid"], "indent": 8}
{"namespace": "mrjob.fs.local.LocalFilesystem.exists", "type": "method", "project_path": "System/mrjob", "completion_path": "System/mrjob/mrjob/fs/local.py", "signature_position": [59, 59], "body_position": [60, 61], "dependency": {"intra_class": [], "intra_file": ["mrjob.fs.local._from_file_uri"], "cross_file": []}, "requirement": {"Functionality": "Check if a file or directory exists in the local filesystem. It converts the input path_glob from a file URI to a local filesystem path and then checks if any files or directories match the given path_glob.", "Arguments": ":param self: LocalFilesystem. An instance of the LocalFilesystem class.\n:param path_glob: String. The file or directory path to check. It can contain wildcards (*) to match multiple files or directories.\n:return: Bool. True if at least one file or directory matches the path_glob, False otherwise."}, "tests": ["tests/fs/test_local.py::LocalFSTestCase::test_rm_file_by_uri", "tests/fs/test_local.py::LocalFSTestCase::test_exists_no", "tests/fs/test_local.py::LocalFSTestCase::test_rm_file", "tests/fs/test_local.py::LocalFSTestCase::test_rm_dir", "tests/fs/test_local.py::LocalFSTestCase::test_touchz"], "indent": 8}
{"namespace": "sslyze.plugins.certificate_info._cli_connector._CertificateInfoCliConnector.result_to_console_output", "type": "method", "project_path": "System/sslyze", "completion_path": "System/sslyze/sslyze/plugins/certificate_info/_cli_connector.py", "signature_position": [69, 69], "body_position": [70, 84], "dependency": {"intra_class": ["sslyze.plugins.certificate_info._cli_connector._CertificateInfoCliConnector._cert_deployment_to_console_output"], "intra_file": ["sslyze.plugins.certificate_info.implementation.CertificateInfoScanResult.certificate_deployments", "sslyze.plugins.certificate_info.implementation.CertificateInfoScanResult.hostname_used_for_server_name_indication"], "cross_file": ["sslyze.plugins.plugin_base.ScanCommandCliConnector._format_field", "sslyze.plugins.plugin_base.ScanCommandCliConnector._format_title"]}, "requirement": {"Functionality": "This function takes a CertificateInfoScanResult object as input and converts the result into a list of strings that can be displayed on the console. It includes information about the hostname sent for SNI and the number of certificates detected. It also iterates through each certificate deployment and adds the formatted information to the result list.", "Arguments": ":param cls: _CertificateInfoCliConnector. The class object of _CertificateInfoCliConnector.\n:param result: CertificateInfoScanResult. The result of a certificate information scan.\n:return: List of strings. The formatted result that can be displayed on the console."}, "tests": ["tests/plugins_tests/certificate_info/test_certificate_algorithms.py::TestCertificateAlgorithms::test_ed25519_certificate", "tests/plugins_tests/certificate_info/test_certificate_algorithms.py::TestCertificateAlgorithms::test_rsa_certificate", "tests/plugins_tests/certificate_info/test_certificate_algorithms.py::TestCertificateAlgorithms::test_invalid_certificate_bad_name", "tests/plugins_tests/certificate_info/test_certificate_algorithms.py::TestCertificateAlgorithms::test_ecdsa_certificate"], "indent": 8}
{"namespace": "boltons.setutils.IndexedSet.index", "type": "method", "project_path": "Utilities/boltons", "completion_path": "Utilities/boltons/boltons/setutils.py", "signature_position": [466, 466], "body_position": [468, 472], "dependency": {"intra_class": ["boltons.setutils.IndexedSet._get_apparent_index", "boltons.setutils.IndexedSet.item_index_map"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function returns the index of a value in the IndexedSet instance. If the value is not present in the instance, it raises a ValueError: '{val!r} is not in {type name}'.", "Arguments": ":param self: IndexedSet. An instance of the IndexedSet class.\n:param val: The value to get the index of.\n:return: The index of the value in the IndexedSet instance."}, "tests": ["tests/test_setutils.py::test_iset_index_method"], "indent": 8}
{"namespace": "faker.utils.checksums.calculate_luhn", "type": "function", "project_path": "Software-Development/Faker", "completion_path": "Software-Development/Faker/faker/utils/checksums.py", "signature_position": [18, 18], "body_position": [22, 23], "dependency": {"intra_class": [], "intra_file": ["faker.utils.checksums.luhn_checksum"], "cross_file": []}, "requirement": {"Functionality": "This function calculates the checksum using Luhn's algorithm for a given partial number. It multiplies the partial number by 10, calculates the checksum, and returns the check digit. If the check digit is 0, it returns the check digit itself. Otherwise, it returns 10 minus the check digit.", "Arguments": ":param partial_number: float. The partial number for which the checksum needs to be calculated.\n:return: int. The calculated check digit using Luhn's algorithm."}, "tests": ["tests/utils/test_utils.py::UtilsTestCase::test_luhn_checksum"], "indent": 4}
{"namespace": "tools.cgrep.compare_tokens", "type": "function", "project_path": "Security/capirca", "completion_path": "Security/capirca/tools/cgrep.py", "signature_position": [397, 397], "body_position": [409, 423], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["capirca.lib.nacaddr.IP", "capirca.lib.naming.Naming.GetNet", "capirca.lib.nacaddr"]}, "requirement": {"Functionality": "This function compares two network objects against each other. It retrieves the network and service definitions from the database based on the options provided. It then compares the two network objects and returns the meta information and the differences between the two objects.", "Arguments": ":param options: The options sent to the script.\n:param db: The network and service definitions from the database.\n:return: A tuple containing the meta information (first object, second object, union of those two) and the differences between the two network objects."}, "tests": ["tests/lib/cgrep_test.py::CgrepTest::test_compare_same_token"], "indent": 2}
{"namespace": "pyramid.authorization.ACLAuthorizationPolicy.principals_allowed_by_permission", "type": "method", "project_path": "Internet/pyramid", "completion_path": "Internet/pyramid/src/pyramid/authorization.py", "signature_position": [77, 77], "body_position": [82, 84], "dependency": {"intra_class": ["pyramid.authorization.ACLAuthorizationPolicy.helper"], "intra_file": ["pyramid.authorization.ACLHelper.principals_allowed_by_permission"], "cross_file": []}, "requirement": {"Functionality": "This function returns the set of principals that are explicitly granted the specified permission according to the ACL (Access Control List) attached to the context and any inherited ACLs based on the lineage.", "Arguments": ":param self: ACLAuthorizationPolicy. An instance of the ACLAuthorizationPolicy class.\n:param context: The context object to which the ACL is attached.\n:param permission: The name of the permission.\n:return: Set of principals. The set of principals that are explicitly granted the specified permission."}, "tests": ["tests/test_authorization.py::TestACLAuthorizationPolicy::test_principals_allowed_by_permission", "tests/test_authorization.py::TestACLAuthorizationPolicy::test_principals_allowed_by_permission_deny_permission_in_acl", "tests/test_authorization.py::TestACLAuthorizationPolicy::test_principals_allowed_by_permission_callable_acl", "tests/test_authorization.py::TestACLAuthorizationPolicy::test_principals_allowed_by_permission_direct", "tests/test_authorization.py::TestACLAuthorizationPolicy::test_principals_allowed_by_permission_deny_not_permission_in_acl"], "indent": 8}
{"namespace": "pythonforandroid.prerequisites.OpenSSLPrerequisite.darwin_pkg_config_location", "type": "method", "project_path": "Utilities/python-for-android", "completion_path": "Utilities/python-for-android/pythonforandroid/prerequisites.py", "signature_position": [277, 277], "body_position": [278, 281], "dependency": {"intra_class": ["pythonforandroid.prerequisites.OpenSSLPrerequisite.homebrew_formula_name"], "intra_file": ["pythonforandroid.prerequisites.Prerequisite._darwin_get_brew_formula_location_prefix"], "cross_file": []}, "requirement": {"Functionality": "This function returns the location of the pkg-config directory for OpenSSL on macOS. It constructs the path by combining the prefix location of the Homebrew formula for OpenSSL and the \"lib/pkgconfig\" directory.", "Arguments": ":param self: OpenSSLPrerequisite. An instance of the OpenSSLPrerequisite class.\n:return: String. The location of the pkg-config directory for OpenSSL on macOS."}, "tests": ["tests/test_prerequisites.py::TestOpenSSLPrerequisite::test_darwin_pkg_config_location"], "indent": 8}
{"namespace": "alembic.autogenerate.compare._compare_server_default", "type": "function", "project_path": "Database/alembic", "completion_path": "Database/alembic/alembic/autogenerate/compare.py", "signature_position": [1125, 1133], "body_position": [1134, 1209], "dependency": {"intra_class": [], "intra_file": ["alembic.autogenerate.api.AutogenContext.migration_context", "alembic.autogenerate.compare._compare_computed_default", "alembic.autogenerate.compare._compare_identity_default", "alembic.autogenerate.compare._render_server_default_for_compare", "alembic.autogenerate.compare._warn_computed_not_supported", "alembic.autogenerate.compare.log", "alembic.operations.ops.AlterColumnOp.existing_server_default", "alembic.operations.ops.AlterColumnOp.modify_server_default"], "cross_file": ["alembic.autogenerate.api.AutogenContext", "alembic.operations.ops.AlterColumnOp", "alembic.runtime.migration.MigrationContext._compare_server_default", "alembic.util.sqla_compat", "alembic.util.sqla_compat._server_default_is_computed", "alembic.util.sqla_compat._server_default_is_identity", "alembic.util.sqla_compat.has_computed_reflection"]}, "requirement": {"Functionality": "This function compares the server default values of two columns in a database table. It checks if the server default values are different and modifies the alter_column_op object accordingly.", "Arguments": ":param autogen_context: AutogenContext. The autogenerate context.\n:param alter_column_op: AlterColumnOp. The alter column operation object.\n:param schema: Optional string. The schema of the table.\n:param tname: Union[quoted_name, str]. The name of the table.\n:param cname: Union[quoted_name, str]. The name of the column.\n:param conn_col: Column[Any]. The column object from the database connection.\n:param metadata_col: Column[Any]. The column object from the metadata.\n:return: Optional bool. Returns None."}, "tests": ["tests/test_mysql.py::MySQLOpTest::test_alter_column_modify_programmatic_default"], "indent": 4}
{"namespace": "boto.dynamodb2.table.Table.batch_get", "type": "method", "project_path": "Internet/boto", "completion_path": "Internet/boto/boto/dynamodb2/table.py", "signature_position": [1504, 1504], "body_position": [1544, 1547], "dependency": {"intra_class": ["boto.dynamodb2.table.Table._batch_get", "boto.dynamodb2.table.Table.max_batch_get"], "intra_file": [], "cross_file": ["boto.dynamodb2.results.BatchGetResultSet", "boto.dynamodb2.results.ResultSet.to_call"]}, "requirement": {"Functionality": "This function fetches multiple specific items in batch from a table. It takes a list of dictionaries as the keys parameter, where each dictionary consists of the key values to specify. It also accepts optional parameters such as consistent (boolean) for specifying whether to use strongly consistent read or not, and attributes (tuple) for specifying the attributes to fetch from DynamoDB. It returns a ResultSet object that handles the pagination of results.", "Arguments": ":param self: Table. An instance of the Table class.\n:param keys: List of dictionaries. The keys values to specify for fetching items.\n:param consistent: Bool. Whether to use strongly consistent read. Defaults to False.\n:param attributes: Tuple. The attributes to fetch from DynamoDB.\n:return: ResultSet. The ResultSet object that handles the pagination of results."}, "tests": ["tests/unit/dynamodb2/test_table.py::TableTestCase::test_batch_get"], "indent": 8}
{"namespace": "diffprivlib.tools.quantiles.percentile", "type": "function", "project_path": "Security/diffprivlib", "completion_path": "Security/diffprivlib/diffprivlib/tools/quantiles.py", "signature_position": [154, 155], "body_position": [211, 219], "dependency": {"intra_class": [], "intra_file": ["diffprivlib.tools.quantiles.quantile"], "cross_file": ["diffprivlib.utils.warn_unused_args"]}, "requirement": {"Functionality": "This function computes the differentially private percentile of an array. It calls the quantile with the percentile value calculated as percent / 100 and validate the value, ensuring that the calculated percentile values fall within the acceptable range.", "Arguments": ":param array: array_like. An array containing numbers whose percentile is sought.\n:param percent: float or array-like. The percentile or list of percentiles sought. Each percentile must be in the range [0, 100]. If percent is array-like, percentiles are returned over the flattened array.\n:param epsilon: float, default: 1.0. The privacy parameter epsilon. Differential privacy is achieved over the entire output, with epsilon split evenly between each output value.\n:param bounds: tuple, optional. The bounds of the values of the array, in the form (min, max).\n:param axis: None or int or tuple of ints, optional. The axis or axes along which the sum is performed. The default, axis=None, sums all the elements of the input array. If axis is negative, it counts from the last to the first axis. If axis is a tuple of ints, a sum is performed on all the specified axes.\n:param keepdims: bool, default: False. If True, the axes which are reduced are left in the result as dimensions with size one. With this option, the result will broadcast correctly against the input array.\n:param random_state: int or RandomState, optional. Controls the randomness of the algorithm. To obtain deterministic behavior during randomization, random_state has to be fixed to an integer.\n:param accountant: BudgetAccountant, optional. An accountant to keep track of the privacy budget.\n:param **unused_args: Should warn the user if any other parameters are passed.\n:return: ndarray. Returns a new array containing the percentile values."}, "tests": ["tests/tools/test_percentile.py::TestPercentile::test_bad_percents", "tests/tools/test_percentile.py::TestPercentile::test_random_state", "tests/tools/test_percentile.py::TestPercentile::test_simple", "tests/tools/test_percentile.py::TestPercentile::test_uniform_array"], "indent": 4}
{"namespace": "mrjob.job.MRJob.increment_counter", "type": "method", "project_path": "System/mrjob", "completion_path": "System/mrjob/mrjob/job.py", "signature_position": [548, 548], "body_position": [562, 585], "dependency": {"intra_class": ["mrjob.job.MRJob.stderr"], "intra_file": [], "cross_file": ["mrjob.py2.integer_types", "mrjob.py2.string_types"]}, "requirement": {"Functionality": "This function is used to increment a counter in Hadoop streaming by printing to stderr. It takes in the counter group, counter description, and the amount by which the counter should be incremented. It replaces commas in the counter group and counter description with semicolons to avoid confusion with Hadoop streaming. Then, it constructs a line using a specified format - \"reporter:counter:{group},{counter},{amount}\\n\". The line is outputted through the standard error stream of the input MRJob instance.", "Arguments": ":param self: MRJob. An instance of the MRJob class.\n:param group: str. The counter group.\n:param counter: str. The description of the counter.\n:param amount: int. The amount by which the counter should be incremented. Defaults to 1.\n:return: No return values."}, "tests": ["tests/test_job.py::CountersAndStatusTestCase::test_negative_and_zero_counters", "tests/test_job.py::CountersAndStatusTestCase::test_commas_in_counters", "tests/test_job.py::CountersAndStatusTestCase::test_bad_counter_amounts", "tests/test_job.py::CountersAndStatusTestCase::test_counters_and_status"], "indent": 8}
{"namespace": "boto.cognito.sync.connect_to_region", "type": "function", "project_path": "Internet/boto", "completion_path": "Internet/boto/boto/cognito/sync/__init__.py", "signature_position": [38, 38], "body_position": [39, 42], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["boto.cognito.sync.layer1.CognitoSyncConnection", "boto.regioninfo.connect"]}, "requirement": {"Functionality": "Connect to a specific region using the CognitoSyncConnection class. It calls the connect function with the specified parameters and returns the connection object.", "Arguments": ":param region_name: String. The name of the region to connect to.\n:param **kw_params: Additional keyword arguments that can be passed to the connect function.\n:return: CognitoSyncConnection. The connection object for the specified region."}, "tests": ["tests/unit/test_connect_to_region.py::TestCognitoSyncConnection::test_connect_to_region"], "indent": 4}
{"namespace": "fs._ftp_parse.parse", "type": "function", "project_path": "System/fs", "completion_path": "System/fs/fs/_ftp_parse.py", "signature_position": [67, 67], "body_position": [68, 75], "dependency": {"intra_class": [], "intra_file": ["fs._ftp_parse.parse_line"], "cross_file": []}, "requirement": {"Functionality": "Parse a list of lines and extract information from each line that is not blank.\n", "Arguments": ":param lines: List[String], the input list of lines to be parsed.\n:return: List, the list of parsed information extracted from the input lines.\n"}, "tests": ["tests/test_ftp_parse.py::TestFTPParse::test_parse", "tests/test_ftp_parse.py::TestFTPParse::test_decode_linux_sticky", "tests/test_ftp_parse.py::TestFTPParse::test_decode_windowsnt", "tests/test_ftp_parse.py::TestFTPParse::test_decode_linux", "tests/test_ftp_parse.py::TestFTPParse::test_decode_linux_suid"], "indent": 4}
{"namespace": "alembic.operations.ops.DropConstraintOp.to_constraint", "type": "method", "project_path": "Database/alembic", "completion_path": "Database/alembic/alembic/operations/ops.py", "signature_position": [176, 176], "body_position": [177, 189], "dependency": {"intra_class": ["alembic.operations.ops.DropConstraintOp._reverse", "alembic.operations.ops.DropConstraintOp.constraint_name", "alembic.operations.ops.DropConstraintOp.schema", "alembic.operations.ops.DropConstraintOp.table_name"], "intra_file": ["alembic.operations.ops.AddConstraintOp.to_constraint"], "cross_file": ["alembic.util.sqla_compat", "alembic.util.sqla_compat._table_for_constraint"]}, "requirement": {"Functionality": "Converts a DropConstraintOp instance to a Constraint instance. It first checks if the reverse operation is present. If it is, it converts the reverse operation to a Constraint instance and sets the name, table name, and schema of the constraint. Then it returns the constraint. If the reverse operation is not present, it raises a ValueError.", "Arguments": ":param self: DropConstraintOp. An instance of the DropConstraintOp class.\n:return: Constraint. The converted Constraint instance."}, "tests": ["tests/test_autogen_diffs.py::OrigObjectTest::test_drop_check", "tests/test_autogen_diffs.py::OrigObjectTest::test_drop_unique", "tests/test_op.py::ObjectFromToTest::test_create_unique_constraint_add_kw", "tests/test_op.py::ObjectFromToTest::test_drop_unique_constraint_change_name", "tests/test_autogen_diffs.py::OrigObjectTest::test_add_unique"], "indent": 8}
{"namespace": "playhouse.db_url.parse", "type": "function", "project_path": "Software-Development/peewee", "completion_path": "Software-Development/peewee/playhouse/db_url.py", "signature_position": [87, 87], "body_position": [88, 89], "dependency": {"intra_class": [], "intra_file": ["playhouse.db_url.parseresult_to_dict"], "cross_file": []}, "requirement": {"Functionality": "This function takes a URL as input and parses it. It then convert the parsed result into a dictionary using the parsed result and unquote password which determines whether the password in the URL should be unquoted or not.", "Arguments": ":param url: String. The URL to be parsed.\n:param unquote_password: Bool. Whether to unquote the password in the URL. Defaults to False.\n:return: Dictionary. The parsed URL as a dictionary."}, "tests": ["tests/db_url.py::TestDBUrl::test_db_url_quoted_password", "tests/db_url.py::TestDBUrl::test_db_url_parse"], "indent": 4}
{"namespace": "csvkit.convert.fixed.fixed2csv", "type": "function", "project_path": "Scientific-Engineering/csvkit", "completion_path": "Scientific-Engineering/csvkit/csvkit/convert/fixed.py", "signature_position": [10, 10], "body_position": [30, 59], "dependency": {"intra_class": [], "intra_file": ["csvkit.convert.fixed.FixedWidthReader", "csvkit.convert.fixed.FixedWidthReader.__init__"], "cross_file": []}, "requirement": {"Functionality": "This function converts a fixed-width file to a CSV file using a CSV-formatted schema description. It reads the fixed-width file, parses it based on the provided schema, and writes the parsed data to a CSV file. If an output file is not specified, the function returns the complete parsed data as a string.", "Arguments": ":param f: File object. The fixed-width file to be converted to CSV.\n:param schema: CSV-formatted schema description. A CSV file that specifies the column names, starting indices, and lengths of each column in the fixed-width file.\n:param output: File object [optional]. The output CSV file where the parsed data will be written. If not specified, the parsed data will be returned as a string.\n:param skip_lines: Integer [optional]. The number of lines to skip from the top of the fixed-width file.\n:param kwargs: Additional keyword arguments [optional]. Additional arguments that can be passed to the function.\n:return: String or None. If an output file is specified, the function returns None. If an output file is not specified, the function returns the complete parsed data as a string."}, "tests": ["tests/test_convert/test_fixed.py::TestFixed::test_fixed", "tests/test_convert/test_fixed.py::TestFixed::test_fixed_skip_lines", "tests/test_convert/test_fixed.py::TestFixed::test_fixed_streaming"], "indent": 4}
{"namespace": "boltons.strutils.multi_replace", "type": "function", "project_path": "Utilities/boltons", "completion_path": "Utilities/boltons/boltons/strutils.py", "signature_position": [1266, 1266], "body_position": [1279, 1280], "dependency": {"intra_class": [], "intra_file": ["boltons.strutils.MultiReplace", "boltons.strutils.MultiReplace.__init__", "boltons.strutils.MultiReplace.sub"], "cross_file": []}, "requirement": {"Functionality": "This function is a shortcut to invoke the MultiReplace class in a single call. It creates an instance of MultiReplace with the given substitution map and optional keyword arguments, and then performs the multi-replacement on the input text.", "Arguments": ":param text: String. The input text to perform the multi-replacement on.\n:param sub_map: Dictionary. A dictionary mapping substrings to their corresponding replacements.\n:param kwargs: Additional keyword arguments that can be passed to the MultiReplace class.\n:return: String. The input text after performing the multi-replacement."}, "tests": ["tests/test_strutils.py::TestMultiReplace::test_shortcut_function"], "indent": 4}
{"namespace": "mistune.create_markdown", "type": "function", "project_path": "Text-Processing/mistune", "completion_path": "Text-Processing/mistune/src/mistune/__init__.py", "signature_position": [20, 20], "body_position": [37, 46], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["mistune.inline_parser.InlineParser", "mistune.markdown.Markdown", "mistune.renderers.html.HTMLRenderer"]}, "requirement": {"Functionality": "Create a Markdown instance based on the given condition. \n", "Arguments": ":param escape: Bool, whether to escape HTML if the renderer is set to \"html\". \n:param hard_wrap: Bool, whether to break every new line into <br> if the renderer is set to \"html\".\n:param renderer: renderer instance, default is HTMLRenderer.\n:param plugins: List, a list of plugins.\n"}, "tests": ["tests/test_directives.py::TestCustomizeToc::test_fenced_toc", "tests/test_misc.py::TestMiscCases::test_before_parse_hooks", "tests/test_directives.py::TestCustomizeToc::test_rst_toc", "tests/test_hooks.py::TestTocHook::test_customize_heading_id_func", "tests/test_misc.py::TestMiscCases::test_escape_html"], "indent": 4}
{"namespace": "principalmapper.querying.local_policy_simulation._matches_after_expansion", "type": "function", "project_path": "Security/principalmapper", "completion_path": "Security/principalmapper/principalmapper/querying/local_policy_simulation.py", "signature_position": [908, 909], "body_position": [917, 927], "dependency": {"intra_class": [], "intra_file": ["principalmapper.querying.local_policy_simulation._compose_pattern"], "cross_file": ["principalmapper.util.case_insensitive_dict.CaseInsensitiveDict"]}, "requirement": {"Functionality": "This function is a helper function that checks if a given string matches another string based on certain conditions. It handles matching with respect to wildcards, variables, and regular expressions, like replace a '${' + key + '}' pattern to value in condition_keys.", "Arguments": ":param string_to_check: str. The string that needs to be checked.\n:param string_to_check_against: str. The string that the first string is checked against.\n:param condition_keys: Optional[CaseInsensitiveDict]. A dictionary of condition keys and their corresponding values. These values can be used for variable substitution in the second string. Defaults to None.\n:return: bool. True if the first string matches the second string based on the conditions, False otherwise."}, "tests": ["tests/test_local_policy_sim.py::TestLocalPolicyVariableExpansions::test_qmark_expansion", "tests/test_local_policy_sim.py::TestLocalPolicyVariableExpansions::test_asterisk_expansion", "tests/test_local_policy_sim.py::TestLocalPolicyVariableExpansions::test_var_expansion"], "indent": 4}
{"namespace": "mrjob.compat.uses_yarn", "type": "function", "project_path": "System/mrjob", "completion_path": "System/mrjob/mrjob/compat.py", "signature_position": [718, 718], "body_position": [721, 722], "dependency": {"intra_class": [], "intra_file": ["mrjob.compat.version_gte"], "cross_file": []}, "requirement": {"Functionality": "Check if the given version is a YARN version of Hadoop.\n", "Arguments": ":param version: String. The version number to be checked.\n:return: Bool. True if the version is a YARN version, False otherwise.\n"}, "tests": ["tests/test_compat.py::UsesYarnTestCase::test_uses_yarn"], "indent": 4}
{"namespace": "datasette.app.Datasette.add_database", "type": "method", "project_path": "Database/datasette", "completion_path": "Database/datasette/datasette/app.py", "signature_position": [415, 415], "body_position": [416, 432], "dependency": {"intra_class": ["datasette.app.Datasette.databases"], "intra_file": [], "cross_file": ["datasette.database.Database.suggest_name"]}, "requirement": {"Functionality": "This function adds a new database to the Datasette instance. It first creates a copy of the existing databases, then assigns a unique name to the new database if no name is provided. If a name is provided, it checks if the name already exists and appends a number to make it unique. It then assigns the name and route to the new database, adds it to the copied databases dictionary, and assigns the copied dictionary back to the instance.", "Arguments": ":param self: Datasette. An instance of the Datasette class.\n:param db: The database to be added.\n:param name: String [optional]. The name to be assigned to the new database. If not provided, a unique name will be generated.\n:param route: String [optional]. The route to be assigned to the new database. If not provided, the name will be used as the route.\n:return: The added database."}, "tests": ["tests/test_facets.py::test_facet_size", "tests/test_facets.py::test_json_array_with_blanks_and_nulls", "tests/test_facets.py::test_array_facet_handle_duplicate_tags", "tests/test_internals_datasette.py::test_num_sql_threads_zero"], "indent": 8}
{"namespace": "rest_framework.fields.CharField.to_internal_value", "type": "method", "project_path": "Internet/djangorestframework", "completion_path": "Internet/djangorestframework/rest_framework/fields.py", "signature_position": [753, 756], "body_position": [757, 760], "dependency": {"intra_class": ["rest_framework.fields.CharField.trim_whitespace"], "intra_file": ["rest_framework.fields.Field.fail"], "cross_file": []}, "requirement": {"Functionality": "This function converts the input data into an internal value for a CharField instance. It checks if the data is a boolean or not an instance of string, integer, or float. If it is, it raises an exception. Otherwise, it converts the data into a string and strips whitespace if necessary.", "Arguments": ":param self: CharField. An instance of the CharField class.\n:param data: The input data to be converted.\n:return: The internal value of the data."}, "tests": ["tests/test_fields.py::TestCharField::test_trim_whitespace_disabled", "tests/test_fields.py::TestCharField::test_trim_whitespace_default"], "indent": 8}
{"namespace": "boto.glacier.utils.compute_hashes_from_fileobj", "type": "function", "project_path": "Internet/boto", "completion_path": "Internet/boto/boto/glacier/utils.py", "signature_position": [110, 110], "body_position": [128, 145], "dependency": {"intra_class": [], "intra_file": ["boto.glacier.utils.bytes_to_hex", "boto.glacier.utils.tree_hash"], "cross_file": []}, "requirement": {"Functionality": "This function computes the linear and tree hash of a file-like object in a single pass. It reads the file in chunks and updates the linear hash and tree hash accordingly.", "Arguments": ":param fileobj: A file-like object that represents the file to compute the hashes from.\n:param chunk_size: Integer. The size of the chunks to use for the tree hash. It also determines the buffer size used to read from the file. Defaults to 1024 * 1024.\n:return: Tuple. A tuple of (linear_hash, tree_hash), where both hashes are returned in hexadecimal format."}, "tests": ["tests/unit/glacier/test_utils.py::TestFileHash::test_compute_hash_tempfile_py3"], "indent": 4}
{"namespace": "datasette.app.Datasette.render_template", "type": "method", "project_path": "Database/datasette", "completion_path": "Database/datasette/datasette/app.py", "signature_position": [988, 990], "body_position": [991, 1084], "dependency": {"intra_class": ["datasette.app.Datasette._asset_urls", "datasette.app.Datasette._crumb_items", "datasette.app.Datasette._startup_invoked", "datasette.app.Datasette.app_css_hash", "datasette.app.Datasette.jinja_env", "datasette.app.Datasette.setting", "datasette.app.Datasette.urls"], "intra_file": [], "cross_file": ["datasette.plugins.pm", "datasette.utils.await_me_maybe", "datasette.utils.display_actor", "datasette.utils.format_bytes", "datasette.utils.asgi.Request.actor", "datasette.utils.asgi.Request.args", "datasette.utils.asgi.Request.cookies"]}, "requirement": {"Functionality": "This function renders a template using the Datasette instance. It first checks if the startup has been invoked, and if not, raises an exception. Then, it prepares the context for the template by adding various variables and values. It also calls hooks to get any extra body scripts and template variables. Finally, it renders the template with the prepared context and returns the result.", "Arguments": ":param self: Datasette. An instance of the Datasette class.\n:param templates: Template or str. The template(s) to render. It can be a Template instance or a string representing the template name.\n:param context: dict. The context variables to be passed to the template. Defaults to None.\n:param request: Request. The request object associated with the rendering. Defaults to None.\n:param view_name: str. The name of the view being rendered. Defaults to None.\n:return: str. The rendered template as a string."}, "tests": ["tests/test_internals_datasette.py::test_datasette_render_template_no_request"], "indent": 8}
{"namespace": "boltons.socketutils.NetstringSocket.write_ns", "type": "method", "project_path": "Utilities/boltons", "completion_path": "Utilities/boltons/boltons/socketutils.py", "signature_position": [701, 701], "body_position": [702, 706], "dependency": {"intra_class": ["boltons.socketutils.NetstringSocket.bsock", "boltons.socketutils.NetstringSocket.maxsize"], "intra_file": ["boltons.socketutils.BufferedSocket.send", "boltons.socketutils.NetstringMessageTooLong", "boltons.socketutils.NetstringMessageTooLong.__init__"], "cross_file": []}, "requirement": {"Functionality": "This function writes a netstring payload to the socket. It first checks if the payload size exceeds the maximum size allowed. If it does, it raises a netstring message too-long exception. Otherwise, it encodes the payload size as a string in ASCII, appends it with a colon and the payload, and appends a comma at the end. Finally, it sends the resulting data through the socket.", "Arguments": ":param self: NetstringSocket. An instance of the NetstringSocket class.\n:param payload: The payload to be written to the socket.\n:return: No return value."}, "tests": ["tests/test_socketutils.py::test_socketutils_netstring", "tests/test_socketutils.py::test_socketutils_netstring_timeout"], "indent": 8}
{"namespace": "alembic.operations.ops.DropTableOp.from_table", "type": "method", "project_path": "Database/alembic", "completion_path": "Database/alembic/alembic/operations/ops.py", "signature_position": [1333, 1335], "body_position": [1336, 1348], "dependency": {"intra_class": ["alembic.operations.ops.DropTableOp.__init__"], "intra_file": ["alembic.operations.ops.CreateTableOp", "alembic.operations.ops.CreateTableOp.from_table"], "cross_file": []}, "requirement": {"Functionality": "This function creates a DropTableOp instance based on the given table. It extracts the necessary information from the table object and uses it to initialize the DropTableOp instance.", "Arguments": ":param cls: Class. The class of the DropTableOp instance.\n:param table: Table. The table object from which the DropTableOp instance is created.\n:param _namespace_metadata: Optional MetaData. The metadata associated with the table. Defaults to None.\n:return: DropTableOp. The created DropTableOp instance."}, "tests": ["tests/test_op.py::ObjectFromToTest::test_drop_table_add_kw", "tests/test_autogen_render.py::AutogenRenderTest::test_render_drop_table", "tests/test_op.py::ObjectFromToTest::test_drop_table", "tests/test_autogen_diffs.py::OrigObjectTest::test_drop_table", "tests/test_autogen_render.py::AutogenRenderTest::test_render_drop_table_w_schema"], "indent": 8}
{"namespace": "exodus_bundler.bundling.Bundle.add_file", "type": "method", "project_path": "System/exodus-bundler", "completion_path": "System/exodus-bundler/src/exodus_bundler/bundling.py", "signature_position": [718, 718], "body_position": [734, 763], "dependency": {"intra_class": ["exodus_bundler.bundling.Bundle.add_file", "exodus_bundler.bundling.Bundle.chroot", "exodus_bundler.bundling.Bundle.file_factory", "exodus_bundler.bundling.Bundle.files", "exodus_bundler.bundling.Bundle.linker_files"], "intra_file": ["exodus_bundler.bundling.logger"], "cross_file": ["exodus_bundler.errors.UnexpectedDirectoryError"]}, "requirement": {"Functionality": "This function adds an additional file to the bundle. If the file corresponds to an ELF binary, all of its dependencies will also be pulled into the bundle. The function handles both absolute and relative paths, as well as binary names in `PATH`. Directories will be included recursively for non-entry point dependencies.", "Arguments": ":param self: Bundle. An instance of the Bundle class.\n:param path: str. The path of the file to be added. It can be an absolute path, relative path, or a binary name in `PATH`.\n:param entry_point: str, optional. The name of the bundle entry point for an executable. If `True`, the executable's basename will be used.\n:return: The `File` that was added, or `None` if it was a directory that was added recursively."}, "tests": ["tests/test_bundling.py::test_file_symlink", "tests/test_bundling.py::test_bundle_add_file", "tests/test_bundling.py::test_bundle_hash", "tests/test_bundling.py::test_bundle_file_factory"], "indent": 8}
{"namespace": "pyinfra.operations.files.rsync", "type": "function", "project_path": "System/pyinfra", "completion_path": "System/pyinfra/pyinfra/operations/files.py", "signature_position": [670, 670], "body_position": [685, 692], "dependency": {"intra_class": [], "intra_file": ["pyinfra.operations.files.show_rsync_warning"], "cross_file": ["pyinfra.api.host.Host.check_can_rsync"]}, "requirement": {"Functionality": "This function uses the \"rsync\" command to synchronize a local directory to a remote system. It calls the \"rsync\" binary on the system to perform the synchronization.", "Arguments": ":param src: String. The source directory to sync.\n:param dest: String. The destination directory to sync to.\n:param flags: List of strings. Optional. The flags to pass to the \"rsync\" command. Defaults to [\"-ax\", \"--delete\"].\n:return: Generator. Yields an instance of the RsyncCommand class."}, "tests": ["tests/test_api/test_api_operations.py::TestOperationsApi::test_rsync_op", "tests/test_api/test_api_operations.py::TestOperationsApi::test_rsync_op_failure", "tests/test_api/test_api_operations.py::TestOperationsApi::test_rsync_op_with_strict_host_key_checking_disabled_and_custom_config_file", "tests/test_api/test_api_operations.py::TestOperationsApi::test_rsync_op_with_sanitized_custom_config_file", "tests/test_api/test_api_operations.py::TestOperationsApi::test_rsync_op_with_strict_host_key_checking_disabled"], "indent": 4}
{"namespace": "pythonforandroid.prerequisites.LibtoolPrerequisite.darwin_checker", "type": "method", "project_path": "Utilities/python-for-android", "completion_path": "Utilities/python-for-android/pythonforandroid/prerequisites.py", "signature_position": [325, 325], "body_position": [326, 329], "dependency": {"intra_class": [], "intra_file": ["pythonforandroid.prerequisites.Prerequisite._darwin_get_brew_formula_location_prefix"], "cross_file": []}, "requirement": {"Functionality": "Check if the libtool formula is installed on a Darwin system. It gets the location prefix of the libtool formula and returns True if it is not None.", "Arguments": ":param self: LibtoolPrerequisite. An instance of the LibtoolPrerequisite class.\n:return: Bool. True if the libtool formula is installed, False otherwise."}, "tests": ["tests/test_prerequisites.py::TestLibtoolPrerequisite::test_darwin_checker"], "indent": 8}
{"namespace": "dash.development._py_components_generation.js_to_py_type", "type": "function", "project_path": "Software-Development/dash", "completion_path": "Software-Development/dash/dash/development/_py_components_generation.py", "signature_position": [655, 655], "body_position": [671, 691], "dependency": {"intra_class": [], "intra_file": ["dash.development._py_components_generation.map_js_to_py_types_flow_types", "dash.development._py_components_generation.map_js_to_py_types_prop_types"], "cross_file": []}, "requirement": {"Functionality": "This function converts JavaScript types to Python types for the component definition. It takes a type object as input and determines whether to use Flow types or PropTypes. It then maps the JavaScript types to the corresponding Python types and returns the Python type string.", "Arguments": ":param type_object: dict. The react-docgen-generated prop type dictionary.\n:param is_flow_type: bool. Indicates whether the prop uses Flow types. If False, PropTypes are used.\n:param indent_num: int. The number of indents to use for the docstring for the prop.\n:return: str. The Python type string."}, "tests": ["tests/unit/development/test_flow_metadata_conversions.py::test_docgen_to_python_args", "tests/unit/development/test_metadata_conversions.py::test_docgen_to_python_args"], "indent": 4}
{"namespace": "mingus.containers.note.Note.from_hertz", "type": "method", "project_path": "Multimedia/mingus", "completion_path": "Multimedia/mingus/mingus/containers/note.py", "signature_position": [236, 236], "body_position": [242, 247], "dependency": {"intra_class": ["mingus.containers.note.Note.name", "mingus.containers.note.Note.octave"], "intra_file": [], "cross_file": ["mingus.core.notes", "mingus.core.notes.int_to_note"]}, "requirement": {"Functionality": "This function sets the Note name and pitch by calculating them from the hertz value. It uses the standard_pitch argument to set the pitch of A-4, from which the rest of the notes are calculated.\n", "Arguments": ":param self: Note, an instance of the Note class.\n:param hertz: float, the hertz value, representing the frequency of the Note.\n:param standard_pitch: float, representing the pitch of A-4. It defaults to 440 if not specified.\n:return: Note, the instance of the Note class with the name and octave set based on the hertz value.\n"}, "tests": ["tests/unit/containers/test_note.py::test_Note::test_from_hertz"], "indent": 8}
{"namespace": "asyncssh.auth_keys.SSHAuthorizedKeys.validate", "type": "method", "project_path": "Security/asyncssh", "completion_path": "Security/asyncssh/asyncssh/auth_keys.py", "signature_position": [278, 280], "body_position": [283, 289], "dependency": {"intra_class": ["asyncssh.auth_keys.SSHAuthorizedKeys._ca_entries", "asyncssh.auth_keys.SSHAuthorizedKeys._user_entries", "asyncssh.auth_keys._SSHAuthorizedKeyEntry.match_options"], "intra_file": [], "cross_file": ["asyncssh.public_key.SSHKey"]}, "requirement": {"Functionality": "This function validates whether a public key or certificate authority (CA) is valid for authentication. It checks if the provided key matches any of the entries in the SSHAuthorizedKeys instance and if the match options (client host, client address, and certificate principals) are satisfied.", "Arguments": ":param self: SSHAuthorizedKeys. An instance of the SSHAuthorizedKeys class.\n:param key: SSHKey. The public key or CA to validate.\n:param client_host: str. The hostname of the client.\n:param client_addr: str. The IP address of the client.\n:param cert_principals: Optional[Sequence[str]]. A sequence of certificate principals.\n:param ca: bool. Whether the key is a CA or not. Defaults to False.\n:return: Optional[Mapping[str, object]]. The options associated with the matching entry, or None if no match is found."}, "tests": ["tests/test_auth_keys.py::_TestAuthorizedKeys::test_options"], "indent": 8}
{"namespace": "prometheus_client.multiprocess.MultiProcessCollector.merge", "type": "method", "project_path": "System/prometheus-client", "completion_path": "System/prometheus-client/prometheus_client/multiprocess.py", "signature_position": [36, 36], "body_position": [43, 44], "dependency": {"intra_class": ["prometheus_client.multiprocess.MultiProcessCollector._accumulate_metrics", "prometheus_client.multiprocess.MultiProcessCollector._read_metrics"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Merge metrics from given mmap files. By default, histograms are accumulated, but if writing the merged data back to mmap files, use accumulate=False to avoid compound accumulation.", "Arguments": ":param files: List of str. The mmap files to merge metrics from.\n:param accumulate: Bool. Whether to accumulate histograms. Defaults to True.\n:return: The merged metrics."}, "tests": ["tests/test_multiprocess.py::TestMultiProcess::test_merge_no_accumulate"], "indent": 8}
{"namespace": "barf.analysis.gadgets.finder.GadgetFinder.find", "type": "method", "project_path": "Security/barf", "completion_path": "Security/barf/barf/analysis/gadgets/finder.py", "signature_position": [74, 74], "body_position": [77, 88], "dependency": {"intra_class": ["barf.analysis.gadgets.finder.GadgetFinder._architecture", "barf.analysis.gadgets.finder.GadgetFinder._find_arm_candidates", "barf.analysis.gadgets.finder.GadgetFinder._find_x86_candidates", "barf.analysis.gadgets.finder.GadgetFinder._instrs_depth", "barf.analysis.gadgets.finder.GadgetFinder._max_bytes"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function finds gadgets based on the given start and end addresses. It sets the maximum number of bytes and the depth of instructions to be considered. Then, it calls the appropriate method based on the architecture to find the candidates. Finally, it sorts the candidates based on their addresses and returns the sorted list.", "Arguments": ":param self: GadgetFinder. An instance of the GadgetFinder class.\n:param start_address: The starting address to search for gadgets.\n:param end_address: The ending address to search for gadgets.\n:param byte_depth: Integer. The maximum number of bytes to consider for each gadget. It defaults to 20 if not specified.\n:param instrs_depth: Integer. The depth of instructions to consider for each gadget. It defaults to 2 if not specified.\n:return: List of gadgets. The list of gadgets found, sorted by their addresses."}, "tests": ["tests/analysis/gadgets/test_gadget_x86.py::GadgetClassifierTests::test_arithmetic_load_add_3", "tests/analysis/gadgets/test_gadget_x86.py::GadgetClassifierTests::test_arithmetic_load_add_1", "tests/analysis/gadgets/test_gadget_x86.py::GadgetClassifierTests::test_load_constant_2", "tests/analysis/gadgets/test_gadget_x86.py::GadgetClassifierTests::test_move_register_3", "tests/analysis/gadgets/test_gadget_x86.py::GadgetClassifierTests::test_move_register_4"], "indent": 8}
{"namespace": "bentoml._internal.runner.container.NdarrayContainer.from_batch_payloads", "type": "method", "project_path": "Scientific-Engineering/bentoml", "completion_path": "Scientific-Engineering/bentoml/src/bentoml/_internal/runner/container.py", "signature_position": [335, 339], "body_position": [340, 341], "dependency": {"intra_class": ["bentoml._internal.runner.container.NdarrayContainer.batches_to_batch", "bentoml._internal.runner.container.NdarrayContainer.from_payload"], "intra_file": ["bentoml._internal.runner.container.Payload"], "cross_file": []}, "requirement": {"Functionality": "This function takes a sequence of payloads and a batch dimension as input and returns a tuple containing an NdarrayContainer object and a list of integers. It first creates a list of NdarrayContainer objects for each payload in the input sequence. Then, it converts the list of batches into a single batch with the specified batch dimension.", "Arguments": ":param cls: NdarrayContainer. The class itself.\n:param payloads: Sequence of Payload objects. The payloads to be processed.\n:param batch_dim: Integer. The dimension along which the batches should be combined. Defaults to 0.\n:return: Tuple containing an NdarrayContainer object and a list of integers. The NdarrayContainer object represents the combined batch, and the list of integers represents the shape of the combined batch."}, "tests": ["tests/unit/_internal/runner/test_container.py::test_ndarray_container"], "indent": 8}
{"namespace": "wikipediaapi.WikipediaPage.sections_by_title", "type": "method", "project_path": "Communications/Wikipedia-API", "completion_path": "Communications/Wikipedia-API/wikipediaapi/__init__.py", "signature_position": [951, 954], "body_position": [961, 966], "dependency": {"intra_class": ["wikipediaapi.WikipediaPage._called", "wikipediaapi.WikipediaPage._fetch", "wikipediaapi.WikipediaPage._section_mapping"], "intra_file": ["wikipediaapi.WikipediaPageSection"], "cross_file": []}, "requirement": {"Functionality": "This function returns all sections of the current Wikipedia page with a given title. It first checks if the \"extracts\" data has been fetched for the page. If not, it fetches the \"extracts\" data. Then, it retrieves the sections with the given title from the section mapping. If no sections are found, an empty list is returned.", "Arguments": ":param self: WikipediaPage. An instance of the WikipediaPage class.\n:param title: str. The title of the section to retrieve.\n:return: List[WikipediaPageSection]. A list of WikipediaPageSection objects representing the sections with the given title."}, "tests": ["tests/extract_html_format_test.py::TestHtmlFormatExtracts::test_subsections_by_title"], "indent": 8}
{"namespace": "alembic.command.ensure_version", "type": "function", "project_path": "Database/alembic", "completion_path": "Database/alembic/alembic/command.py", "signature_position": [721, 721], "body_position": [732, 744], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["alembic.config.Config", "alembic.runtime.environment.EnvironmentContext", "alembic.script.ScriptDirectory.from_config", "alembic.script.ScriptDirectory.run_env"]}, "requirement": {"Functionality": "This function ensures that the alembic version table exists. It creates the version table if it doesn't already exist.", "Arguments": ":param config: Config. An instance of the Config class.\n:param sql: Bool. Whether to use \"--sql\" mode. Defaults to False.\n:return: None."}, "tests": ["tests/test_command.py::EnureVersionTest::test_ensure_version", "tests/test_command.py::EnureVersionTest::test_ensure_version_called_twice", "tests/test_command.py::EnureVersionTest::test_sql_ensure_version"], "indent": 4}
{"namespace": "alembic.testing.fixtures.capture_engine_context_buffer", "type": "function", "project_path": "Database/alembic", "completion_path": "Database/alembic/alembic/testing/fixtures.py", "signature_position": [106, 106], "body_position": [107, 128], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["alembic.testing.env._sqlite_file_db", "alembic.environment.EnvironmentContext", "alembic.environment.EnvironmentContext.configure"]}, "requirement": {"Functionality": "This function captures the engine context buffer by writing the executed SQL statements into a buffer. It creates a SQLite database engine, connects to it, and sets up a listener to write the executed statements into the buffer. It also updates the input parameters and configures the environment context. Finally, it yields the buffer.", "Arguments": ":param **kw: Keyword arguments. Additional parameters that can be passed to the function.\n:return: A buffer object that contains the executed SQL statements."}, "tests": ["tests/test_command.py::StampMultipleHeadsTest::test_online_stamp_multi_rev_from_real_ancestor", "tests/test_command.py::StampMultipleHeadsTest::test_online_stamp_version_already_there", "tests/test_command.py::StampMultipleHeadsTest::test_online_stamp_multi_rev_nonsensical", "tests/test_command.py::StampMultipleHeadsTest::test_stamp_purge"], "indent": 4}
{"namespace": "jinja2.environment.Template.render", "type": "method", "project_path": "Internet/Jinja2", "completion_path": "Internet/Jinja2/src/jinja2/environment.py", "signature_position": [1269, 1269], "body_position": [1279, 1301], "dependency": {"intra_class": ["jinja2.environment.Template.environment", "jinja2.environment.Template.new_context", "jinja2.environment.Template.render_async", "jinja2.environment.Template.root_render_func"], "intra_file": ["jinja2.environment.Environment.is_async", "jinja2.environment.Environment.concat", "jinja2.environment.Environment.handle_exception"], "cross_file": []}, "requirement": {"Functionality": "This method renders a template with the given context. It can also render the template asynchronously if the environment is set to async. The rendered template is returned as a string.", "Arguments": ":param self: Template. An instance of the Template class.\n:param args: Any. Variable length arguments that can be passed to a dict constructor.\n:param kwargs: Any. Variable length keyword arguments that can be passed to a dict constructor.\n:return: str. The rendered template as a string."}, "tests": ["tests/test_security.py::TestSandbox::test_attr_filter", "tests/test_security.py::TestSandbox::test_unary_operator_intercepting", "tests/test_security.py::TestStringFormat::test_basic_format_safety", "tests/test_imports.py::TestIncludes::test_context_include_with_overrides", "tests/test_security.py::TestStringFormat::test_empty_braces_format"], "indent": 8}
{"namespace": "imapclient.imap_utf7.decode", "type": "function", "project_path": "Communications/IMAPClient", "completion_path": "Communications/IMAPClient/imapclient/imap_utf7.py", "signature_position": [62, 62], "body_position": [69, 98], "dependency": {"intra_class": [], "intra_file": ["imapclient.imap_utf7.AMPERSAND_ORD", "imapclient.imap_utf7.DASH_ORD", "imapclient.imap_utf7.base64_utf7_decode"], "cross_file": []}, "requirement": {"Functionality": "This function decodes a folder name from IMAP modified UTF-7 encoding to Unicode. It takes a string or bytes as input and always returns a Unicode string. If the input is not of type bytes or str, it is returned unchanged.", "Arguments": ":param s: Union[bytes, str]. The input string or bytes to be decoded.\n:return: str. The decoded folder name in Unicode."}, "tests": ["tests/test_imap_utf7.py::IMAP4UTF7TestCase::test_printable_singletons", "tests/test_imap_utf7.py::IMAP4UTF7TestCase::test_decode"], "indent": 4}
{"namespace": "imapclient.imapclient.IMAPClient.folder_status", "type": "method", "project_path": "Communications/IMAPClient", "completion_path": "Communications/IMAPClient/imapclient/imapclient.py", "signature_position": [1002, 1002], "body_position": [1012, 1022], "dependency": {"intra_class": ["imapclient.imapclient.IMAPClient._command_and_check", "imapclient.imapclient.IMAPClient._normalise_folder"], "intra_file": ["imapclient.imapclient.as_pairs", "imapclient.imapclient.normalise_text_list"], "cross_file": ["imapclient.response_parser.parse_response"]}, "requirement": {"Functionality": "This function returns the status of a specified folder in an IMAPClient instance. It queries the specified status items \"(\"MESSAGES\", \"RECENT\", \"UIDNEXT\", \"UIDVALIDITY\", \"UNSEEN\")\" for the folder and returns a dictionary with keys matching the queried items.", "Arguments": ":param self: IMAPClient. An instance of the IMAPClient class.\n:param folder: String. The name of the folder to query the status for.\n:param what: List of strings. A sequence of status items to query. It defaults to ['MESSAGES', 'RECENT', 'UIDNEXT', 'UIDVALIDITY', 'UNSEEN'] if not specified.\n:return: Dictionary. A dictionary of the status items for the folder with keys matching the queried items."}, "tests": ["tests/test_folder_status.py::TestFolderStatus::test_basic", "tests/test_folder_status.py::TestFolderStatus::test_literal", "tests/test_folder_status.py::TestFolderStatus::test_extra_response"], "indent": 8}
{"namespace": "pyramid.path.Resolver.get_package_name", "type": "method", "project_path": "Internet/pyramid", "completion_path": "Internet/pyramid/src/pyramid/path.py", "signature_position": [106, 106], "body_position": [107, 111], "dependency": {"intra_class": ["pyramid.path.Resolver.package"], "intra_file": ["pyramid.path.CALLER_PACKAGE", "pyramid.path.caller_package"], "cross_file": []}, "requirement": {"Functionality": "This function returns the name of the package based on the package in a Resolver instance. If the package value is set to CALLER_PACKAGE, it retrieves the name of the caller package. Otherwise, it retrieves the name of the package specified in the package of the Resolver instance.", "Arguments": ":param self: Resolver. An instance of the Resolver class.\n:return: String. The name of the package."}, "tests": ["tests/test_path.py::TestResolver::test_get_package_name_caller_package", "tests/test_path.py::TestResolver::test_get_package_name_string"], "indent": 8}
{"namespace": "bentoml._internal.models.model.Model.create", "type": "method", "project_path": "Scientific-Engineering/bentoml", "completion_path": "Scientific-Engineering/bentoml/src/bentoml/_internal/models/model.py", "signature_position": [138, 150], "body_position": [174, 198], "dependency": {"intra_class": ["bentoml._internal.models.model.Model.__init__"], "intra_file": ["bentoml._internal.models.model.ModelInfo", "bentoml._internal.models.model.ModelInfo.__init__", "bentoml._internal.models.model.ModelOptions"], "cross_file": ["bentoml._internal.tag.Tag", "bentoml._internal.tag.Tag.from_taglike", "bentoml._internal.tag.Tag.make_new_version", "bentoml._internal.tag.Tag.name", "bentoml._internal.tag.Tag.version"]}, "requirement": {"Functionality": "This function creates a new instance of the Model class and saves it to the model store. It takes various input parameters to configure the model instance and its associated metadata.", "Arguments": ":param cls: Type[Model]. The class object of the Model class.\n:param name: Union[Tag, str]. The name of the model in the target model store. If a Tag object is provided, the version will be automatically generated.\n:param module: str. The import path of the module used for saving/loading this model.\n:param api_version: str. The version of the API associated with this model.\n:param signatures: ModelSignaturesType. The signatures of the model, specifying the input and output types.\n:param labels: Optional[Dict[str, str]]. User-defined labels for managing models.\n:param options: Optional[ModelOptions]. Default options for loading this model, defined by the runner implementation.\n:param custom_objects: Optional[Dict[str, Any]]. User-defined additional Python objects to be saved alongside the model.\n:param metadata: Optional[Dict[str, Any]]. User-defined metadata for storing model training context information or model evaluation metrics.\n:param context: ModelContext. The environment context managed by BentoML for loading the model.\n:return: Model. The created Model instance in the temporary filesystem."}, "tests": ["tests/unit/_internal/models/test_model.py::test_model_creationtime", "tests/unit/_internal/models/test_model.py::test_model_version", "tests/unit/_internal/models/test_model.py::test_model_equal"], "indent": 8}
{"namespace": "pyramid.scripts.proutes.PRoutesCommand._get_mapper", "type": "method", "project_path": "Internet/pyramid", "completion_path": "Internet/pyramid/src/pyramid/scripts/proutes.py", "signature_position": [306, 306], "body_position": [307, 310], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["pyramid.config.Configurator", "pyramid.config.routes.RoutesConfiguratorMixin.get_routes_mapper"]}, "requirement": {"Functionality": "This function returns the routes mapper object associated with the given registry.", "Arguments": ":param self: PRoutesCommand. An instance of the PRoutesCommand class.\n:param registry: The registry object.\n:return: The routes mapper object associated with the given registry."}, "tests": ["tests/test_scripts/test_proutes.py::TestPRoutesCommand::test__get_mapper"], "indent": 8}
{"namespace": "mssqlcli.packages.parseutils.tables.extract_tables", "type": "function", "project_path": "Database/mssql-cli", "completion_path": "Database/mssql-cli/mssqlcli/packages/parseutils/tables.py", "signature_position": [121, 121], "body_position": [127, 146], "dependency": {"intra_class": [], "intra_file": ["mssqlcli.packages.parseutils.tables.extract_from_part", "mssqlcli.packages.parseutils.tables.extract_table_identifiers"], "cross_file": []}, "requirement": {"Functionality": "This function extracts the table names from an SQL statement. It uses the sqlparse library to parse the SQL statement and then extracts the table names from the parsed result.", "Arguments": ":param sql: String. The SQL statement to extract table names from.\n:return: Tuple of TableReference namedtuples. The extracted table names from the SQL statement."}, "tests": ["tests/parseutils/test_parseutils.py::test_simple_select_with_cols_multiple_qualified_tables", "tests/parseutils/test_parseutils.py::test_simple_function_as_table", "tests/parseutils/test_parseutils.py::test_incomplete_join_clause", "tests/parseutils/test_parseutils.py::test_complex_table_and_function", "tests/parseutils/test_parseutils.py::test_simple_schema_qualified_function_as_table"], "indent": 4}
{"namespace": "imapclient.imapclient.IMAPClient.get_gmail_labels", "type": "method", "project_path": "Communications/IMAPClient", "completion_path": "Communications/IMAPClient/imapclient/imapclient.py", "signature_position": [1274, 1274], "body_position": [1284, 1286], "dependency": {"intra_class": ["imapclient.imapclient.IMAPClient._filter_fetch_dict", "imapclient.imapclient.IMAPClient.fetch"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function returns the label set for each message in the currently selected folder. It fetches the X-GM-LABELS attribute for the given messages from the IMAP server and filters the response to get the label information. It then decodes the labels using UTF-7 encoding and returns a dictionary with message IDs as keys and label sets as values.", "Arguments": ":param self: IMAPClient. An instance of the IMAPClient class.\n:param messages: List of bytes. The messages for which to retrieve the labels.\n:return: Dictionary. A dictionary mapping message IDs to label sets."}, "tests": ["tests/test_store.py::TestGmailLabels::test_get"], "indent": 8}
{"namespace": "mingus.containers.note_container.NoteContainer.from_progression_shorthand", "type": "method", "project_path": "Multimedia/mingus", "completion_path": "Multimedia/mingus/mingus/containers/note_container.py", "signature_position": [155, 155], "body_position": [165, 174], "dependency": {"intra_class": ["mingus.containers.note_container.NoteContainer.add_notes", "mingus.containers.note_container.NoteContainer.empty"], "intra_file": [], "cross_file": ["mingus.core.progressions", "mingus.core.progressions.to_chords"]}, "requirement": {"Functionality": "This function clears the NoteContainer and adds notes to it based on the given progression shorthand.\n", "Arguments": ":param self: NoteContainer. An instance of the NoteContainer class.\n:param shorthand: str. The progression shorthand describing the notes to be added.\n:param key: str. The key to be used for the progression shorthand. It defaults to \"C\" if not specified.\n:return: NoteContainer. The modified instance of the NoteContainer.\n"}, "tests": ["tests/unit/containers/test_note_containers.py::test_NoteContainers::test_from_progression_shorthand"], "indent": 8}
{"namespace": "mrjob.logs.errors._merge_and_sort_errors", "type": "function", "project_path": "System/mrjob", "completion_path": "System/mrjob/mrjob/logs/errors.py", "signature_position": [101, 101], "body_position": [107, 136], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["mrjob.logs.ids._time_sort_key"]}, "requirement": {"Functionality": "This function merges errors from one or more lists of errors and returns them sorted by recency.\nThis function first initializes a dictionary to save errors. Then, it iterates through each error in the given list of errors and merge them by container id. If an error does not have container id, it generates a key based on the error's time. Finally it uses a custom key sort function to prioritize task errors and sort the errors based on their keys.\n", "Arguments": ":param errors: List of dictionaries. One or more lists of errors to be merged and sorted.\n:param attempt_to_container_id: Dictionary. A dictionary mapping attempt_id to container_id.\n:return: List of dictionaries. The merged and sorted list of errors.\n"}, "tests": ["tests/logs/test_errors.py::MergeAndSortErrorsTestCase::test_merge_errors", "tests/logs/test_errors.py::MergeAndSortErrorsTestCase::test_can_merge_with_incomplete_ids", "tests/logs/test_errors.py::MergeAndSortErrorsTestCase::test_attempt_to_container_id", "tests/logs/test_errors.py::MergeAndSortErrorsTestCase::test_single_error", "tests/logs/test_errors.py::MergeAndSortErrorsTestCase::test_empty"], "indent": 4}
{"namespace": "pyramid.testing.DummySession.get_csrf_token", "type": "method", "project_path": "Internet/pyramid", "completion_path": "Internet/pyramid/src/pyramid/testing.py", "signature_position": [265, 265], "body_position": [266, 269], "dependency": {"intra_class": ["pyramid.testing.DummySession.new_csrf_token"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function retrieves the CSRF token from the session. If the token is not found in the session, a new CSRF token is generated and returned.", "Arguments": ":param self: DummySession. An instance of the DummySession class.\n:return: The CSRF token."}, "tests": ["tests/test_testing.py::TestDummySession::test_get_csrf_token", "tests/test_csrf.py::Test_check_csrf_token::test_success_header", "tests/test_testing.py::TestDummySession::test_get_csrf_token_generates_token", "tests/test_csrf.py::Test_check_csrf_token::test_success_default_header", "tests/test_csrf.py::Test_check_csrf_token_without_defaults_configured::test_success_token"], "indent": 8}
{"namespace": "boto.cloudsearchdomain.connect_to_region", "type": "function", "project_path": "Internet/boto", "completion_path": "Internet/boto/boto/cloudsearchdomain/__init__.py", "signature_position": [38, 38], "body_position": [39, 42], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["boto.cloudsearchdomain.layer1.CloudSearchDomainConnection", "boto.regioninfo.connect"]}, "requirement": {"Functionality": "Connect to a specific region in the cloud search domain. It creates a connection to the cloud search domain in the specified region using the provided parameters.", "Arguments": ":param region_name: String. The name of the region to connect to.\n:param **kw_params: Additional keyword arguments that can be passed to the connection.\n:return: CloudSearchDomainConnection. The connection to the cloud search domain in the specified region."}, "tests": ["tests/unit/test_connect_to_region.py::TestCloudsearchDomainConnection::test_connect_to_region"], "indent": 4}
{"namespace": "lux.action.default.register_default_actions", "type": "function", "project_path": "Scientific-Engineering/lux", "completion_path": "Scientific-Engineering/lux/lux/action/default.py", "signature_position": [1, 1], "body_position": [2, 29], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["lux.action.correlation.correlation", "lux.action.custom.custom", "lux.action.enhance.enhance", "lux.action.filter.add_filter", "lux.action.generalize.generalize", "lux.action.temporal.temporal", "lux.action.univariate.univariate", "lux._config.config", "lux._config.config.Config.register_action", "lux"]}, "requirement": {"Functionality": "This function registers default actions for the Lux library. It imports various action modules and defines display conditions for each action. Then, it globally registers each action with its corresponding display condition.", "Arguments": ":param: No input parameters.\n:return: No return values."}, "tests": ["tests/test_config.py::test_remove_default_actions"], "indent": 4}
{"namespace": "boltons.listutils.BarrelList.pop", "type": "method", "project_path": "Utilities/boltons", "completion_path": "Utilities/boltons/boltons/listutils.py", "signature_position": [162, 162], "body_position": [163, 177], "dependency": {"intra_class": ["boltons.listutils.BarrelList._balance_list", "boltons.listutils.BarrelList._translate_index", "boltons.listutils.BarrelList.lists"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Remove and return an item from the BarrelList based on the specified indexes.\n", "Arguments": ":param self: BarrelList, an instance of BarrelList class.\n:param *a: Tuple, the index of the item to be popped. Default is an empty tuple.\n:return: The item that is removed and returned from the BarrelList. No return values if the list is empty or the index is invalid.\n"}, "tests": ["tests/test_listutils.py::test_barrel_list"], "indent": 8}
{"namespace": "bentoml._internal.configuration.helpers.expand_env_var_in_values", "type": "function", "project_path": "Scientific-Engineering/bentoml", "completion_path": "Scientific-Engineering/bentoml/src/bentoml/_internal/configuration/helpers.py", "signature_position": [186, 186], "body_position": [187, 193], "dependency": {"intra_class": [], "intra_file": ["bentoml._internal.configuration.helpers.expand_env_var", "bentoml._internal.configuration.helpers.expand_env_var_in_values"], "cross_file": []}, "requirement": {"Functionality": "This function expands environment variables in the values of a given dictionary. It iterates through each key-value pair in the dictionary and checks the type of the value including \"mutable mapping\", \"string\" and \"sequence\". Then it calls the corresponding functions.", "Arguments": ":param d: MutableMapping[str, Any]. A dictionary-like object with string keys and arbitrary values.\n:return: No return values."}, "tests": ["tests/unit/_internal/configuration/test_helpers.py::test_expand_env_in_values"], "indent": 4}
{"namespace": "datasette.facets.ArrayFacet.suggest", "type": "method", "project_path": "Database/datasette", "completion_path": "Database/datasette/datasette/facets.py", "signature_position": [303, 303], "body_position": [304, 368], "dependency": {"intra_class": [], "intra_file": ["datasette.facets.Facet.database", "datasette.facets.Facet.ds", "datasette.facets.Facet.get_columns", "datasette.facets.Facet.get_configs", "datasette.facets.Facet.params", "datasette.facets.Facet.request", "datasette.facets.Facet.sql"], "cross_file": ["datasette.database.QueryInterrupted", "datasette.utils.escape_sqlite", "datasette.utils.path_with_added_args", "datasette.app.Datasette.absolute_url", "datasette.app.Datasette.execute", "datasette.app.Datasette.setting", "datasette.app.Datasette.urls", "datasette.url_builder.Urls.path"]}, "requirement": {"Functionality": "This function suggests array facets based on the given SQL query and parameters. It retrieves the columns from the query, checks if each column is already enabled as a facet, and then checks if every value in the column is either null or a JSON array. If these conditions are met, it further checks that the first 100 arrays in the column contain only strings. If all these conditions are satisfied, it adds the column as a suggested array facet to the list of suggested facets.", "Arguments": ":param self: ArrayFacet. An instance of the ArrayFacet class.\n:return: List of dictionaries. A list of suggested array facets, where each dictionary contains the name of the facet, its type, and a toggle URL."}, "tests": ["tests/test_facets.py::test_array_facet_suggest_not_if_all_empty_arrays", "tests/test_facets.py::test_array_facet_suggest"], "indent": 8}
{"namespace": "falcon.cmd.inspect_app.route_main", "type": "function", "project_path": "Internet/falcon", "completion_path": "Internet/falcon/falcon/cmd/inspect_app.py", "signature_position": [89, 89], "body_position": [90, 94], "dependency": {"intra_class": [], "intra_file": ["falcon.cmd.inspect_app.main"], "cross_file": []}, "requirement": {"Functionality": "This function is the main entry point for routing. It prints two deprecation messages ('The \"falcon-print-routes\" command is deprecated. ', 'Please use \"falcon-inspect-app\"') and then calls the main function.", "Arguments": ":param: No input parameters.\n:return: No return values."}, "tests": ["tests/test_cmd_inspect_app.py::test_route_main"], "indent": 4}
{"namespace": "jc.cli.JcCli.yaml_out", "type": "method", "project_path": "Utilities/jc", "completion_path": "Utilities/jc/jc/cli.py", "signature_position": [340, 340], "body_position": [346, 380], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["jc.utils.warning_message", "jc.utils"]}, "requirement": {"Functionality": "This function returns a YAML formatted string. If the ruamel.yaml library is installed, it uses it to format the string with color codes. If the library is not installed, it falls back to JSON formatting with a warning message.", "Arguments": ":param self: JcCli. An instance of the JcCli class.\n:return: str. The YAML formatted string."}, "tests": ["tests/test_jc_cli.py::MyTests::test_cli_yaml_out", "tests/test_jc_cli.py::MyTests::test_cli_yaml_out_mono"], "indent": 8}
{"namespace": "kinto.core.views.batch.BatchPayloadSchema.deserialize", "type": "method", "project_path": "Internet/kinto", "completion_path": "Internet/kinto/kinto/core/views/batch.py", "signature_position": [59, 59], "body_position": [61, 69], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["kinto.core.utils.merge_dicts"]}, "requirement": {"Functionality": "This function is a method of the BatchPayloadSchema class. It deserializes the received data and merges the defaults with the requests. It then returns the deserialized data.", "Arguments": ":param self: BatchPayloadSchema. An instance of the BatchPayloadSchema class.\n:param cstruct: dict. The data to be deserialized. Defaults to colander.null.\n:return: The deserialized data after merging the defaults with the requests."}, "tests": ["tests/core/test_views_batch.py::BatchSchemaTest::test_defaults_path_is_applied_to_requests", "tests/core/test_views_batch.py::BatchSchemaTest::test_body_is_an_arbitrary_mapping", "tests/core/test_views_batch.py::BatchSchemaTest::test_request_headers_are_preserved", "tests/core/test_views_batch.py::BatchSchemaTest::test_defaults_body_is_applied_to_requests", "tests/core/test_views_batch.py::BatchSchemaTest::test_defaults_values_do_not_overwrite_requests_values"], "indent": 8}
{"namespace": "datasette.app.Datasette.ensure_permissions", "type": "method", "project_path": "Database/datasette", "completion_path": "Database/datasette/datasette/app.py", "signature_position": [691, 695], "body_position": [701, 724], "dependency": {"intra_class": ["datasette.app.Datasette.permission_allowed"], "intra_file": [], "cross_file": ["datasette.utils.asgi.Forbidden"]}, "requirement": {"Functionality": "This function ensures that the given actor has the required permissions to perform certain actions on specified resources. It iterates through the list of permissions and checks if each permission is allowed for the actor. If any of the checks fail, it raises a forbidden exception.", "Arguments": ":param self: Datasette. An instance of the Datasette class.\n:param actor: Dict. The actor for whom the permissions are being checked. It can be None or a dictionary.\n:param permissions: Sequence. A sequence of permissions to be checked. Each permission can be a string representing an action or a tuple/list of two items representing an action and a resource.\n:return: No return values."}, "tests": ["tests/test_internals_datasette.py::test_datasette_ensure_permissions_check_visibility"], "indent": 8}
{"namespace": "boto.dynamodb2.table.Table.describe", "type": "method", "project_path": "Internet/boto", "completion_path": "Internet/boto/boto/dynamodb2/table.py", "signature_position": [332, 332], "body_position": [355, 379], "dependency": {"intra_class": ["boto.dynamodb2.table.Table._introspect_global_indexes", "boto.dynamodb2.table.Table._introspect_indexes", "boto.dynamodb2.table.Table._introspect_schema", "boto.dynamodb2.table.Table.connection", "boto.dynamodb2.table.Table.global_indexes", "boto.dynamodb2.table.Table.indexes", "boto.dynamodb2.table.Table.schema", "boto.dynamodb2.table.Table.table_name", "boto.dynamodb2.table.Table.throughput"], "intra_file": [], "cross_file": ["boto.dynamodb2.layer1.DynamoDBConnection.describe_table"]}, "requirement": {"Functionality": "This function describes the current structure of a table in DynamoDB. It retrieves information about the table's schema, indexes, throughput, and other details from DynamoDB. The function also updates the corresponding attributes of the Table instance. The function returns the full raw data structure from DynamoDB.", "Arguments": ":param self: Table. An instance of the Table class.\n:return: The full raw data structure of the table from DynamoDB."}, "tests": ["tests/unit/dynamodb2/test_table.py::TableTestCase::test_describe"], "indent": 8}
{"namespace": "alembic.operations.ops.DropConstraintOp.from_constraint", "type": "method", "project_path": "Database/alembic", "completion_path": "Database/alembic/alembic/operations/ops.py", "signature_position": [157, 157], "body_position": [158, 174], "dependency": {"intra_class": ["alembic.operations.ops.DropConstraintOp.__init__"], "intra_file": ["alembic.operations.ops.AddConstraintOp", "alembic.operations.ops.AddConstraintOp.from_constraint"], "cross_file": ["alembic.util.sqla_compat", "alembic.util.sqla_compat._table_for_constraint", "alembic.util.sqla_compat.constraint_name_or_none"]}, "requirement": {"Functionality": "This function creates a DropConstraintOp instance based on the given constraint. It determines the type of constraint and creates the instance with the corresponding parameters.", "Arguments": ":param cls: type. The DropConstraintOp class.\n:param constraint: Constraint. The constraint object to create the DropConstraintOp instance from.\n:return: DropConstraintOp. The created DropConstraintOp instance."}, "tests": ["tests/test_autogen_render.py::AutogenRenderTest::test_drop_fk_constraint", "tests/test_autogen_diffs.py::OrigObjectTest::test_drop_check", "tests/test_postgresql.py::PostgresqlAutogenRenderTest::test_drop_exclude_constraint", "tests/test_op.py::ObjectFromToTest::test_drop_unique_constraint_change_name", "tests/test_autogen_render.py::AutogenRenderTest::test_drop_unique_constraint_schema"], "indent": 8}
{"namespace": "mssqlcli.jsonrpc.jsonrpcclient.JsonRpcReader.read_response", "type": "method", "project_path": "Database/mssql-cli", "completion_path": "Database/mssql-cli/mssqlcli/jsonrpc/jsonrpcclient.py", "signature_position": [261, 261], "body_position": [270, 296], "dependency": {"intra_class": ["mssqlcli.jsonrpc.jsonrpcclient.JsonRpcReader.needs_more_data", "mssqlcli.jsonrpc.jsonrpcclient.JsonRpcReader.read_next_chunk", "mssqlcli.jsonrpc.jsonrpcclient.JsonRpcReader.read_offset", "mssqlcli.jsonrpc.jsonrpcclient.JsonRpcReader.read_state", "mssqlcli.jsonrpc.jsonrpcclient.JsonRpcReader.trim_buffer_and_resize", "mssqlcli.jsonrpc.jsonrpcclient.JsonRpcReader.try_read_content", "mssqlcli.jsonrpc.jsonrpcclient.JsonRpcReader.try_read_headers"], "intra_file": ["mssqlcli.jsonrpc.jsonrpcclient.ReadState", "mssqlcli.jsonrpc.jsonrpcclient.ReadState.Content", "mssqlcli.jsonrpc.jsonrpcclient.ReadState.Header", "mssqlcli.jsonrpc.jsonrpcclient.logger"], "cross_file": []}, "requirement": {"Functionality": "This function reads a JSON RPC message from a buffer. It iterates through a loop, attempting to read the header and content until it successfully retrieves both. After that, it trims the buffer, parses the content as JSON, and returns the resulting object. If any step fails, it logs the error and raises a ValueError.", "Arguments": ":param self: JsonRpcReader. An instance of the JsonRpcReader class.\n:return: JSON object. The deserialized JSON object read from the buffer."}, "tests": ["tests/jsonrpc/test_jsonrpc.py::JsonRpcTest::test_nested_request", "tests/jsonrpc/test_jsonrpc.py::JsonRpcTest::test_basic_response", "tests/jsonrpc/test_jsonrpc.py::JsonRpcTest::test_stream_closes_during_read_and_write", "tests/jsonrpc/test_jsonrpc.py::JsonRpcTest::test_max_buffer_resize", "tests/jsonrpc/test_jsonrpc.py::JsonRpcTest::test_trigger_buffer_resize"], "indent": 8}
{"namespace": "pycoin.crack.bip32.crack_bip32", "type": "function", "project_path": "Security/pycoin", "completion_path": "Security/pycoin/pycoin/crack/bip32.py", "signature_position": [22, 22], "body_position": [23, 29], "dependency": {"intra_class": [], "intra_file": ["pycoin.crack.bip32.ascend_bip32"], "cross_file": ["pycoin.key.BIP32Node.BIP32Node.subkey_for_path"]}, "requirement": {"Functionality": "This function cracks a BIP32 public node by iterating through a given path and updating the secret exponent. It returns a new BIP32 public node with the updated secret exponent.", "Arguments": ":param bip32_pub_node: BIP32PublicNode. The BIP32 public node to crack.\n:param secret_exponent: int. The secret exponent to update.\n:param path: str. The path to iterate through.\n:return: BIP32PublicNode. The new BIP32 public node with the updated secret exponent."}, "tests": ["tests/crack_bip32_test.py::CrackBIP32Test::test_crack_bip32"], "indent": 4}
{"namespace": "rows.fields.JSONField.deserialize", "type": "method", "project_path": "Text-Processing/rows", "completion_path": "Text-Processing/rows/rows/fields.py", "signature_position": [470, 470], "body_position": [471, 475], "dependency": {"intra_class": ["rows.fields.JSONField.TYPE"], "intra_file": ["rows.fields.Field", "rows.fields.Field.deserialize"], "cross_file": []}, "requirement": {"Functionality": "Deserialize a JSONField value. It first calls the parent class's deserialize method to perform basic deserialization. Then, it checks if the deserialized value is None or already an instance of required type. If so, it returns the value as is. Otherwise, it convert the value into a Python object.", "Arguments": ":param cls: Class. The JSONField class itself.\n:param value: Any. The value to be deserialized.\n:param *args: Any. Additional positional arguments.\n:param **kwargs: Any. Additional keyword arguments.\n:return: Any. The deserialized value."}, "tests": ["tests/tests_fields.py::FieldsTestCase::test_JSONField"], "indent": 8}
{"namespace": "twtxt.config.Config.create_config", "type": "method", "project_path": "Communications/twtxt", "completion_path": "Communications/twtxt/twtxt/config.py", "signature_position": [63, 63], "body_position": [73, 93], "dependency": {"intra_class": ["twtxt.config.Config.__init__", "twtxt.config.Config.write_config"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Create a new configuration file at the specified location with the given parameters. It creates a new configuration file using the configparser module and sets the values for various sections and options based on the input parameters.", "Arguments": ":param cls: Class. The class object.\n:param cfgfile: String. The path to the configuration file.\n:param nick: String. The nickname to use for own tweets.\n:param twtfile: String. The path to the local twtxt file.\n:param twturl: String. The URL to the remote twtxt file.\n:param disclose_identity: Bool. If True, the user's id will be disclosed.\n:param add_news: Bool. If True, follow the twtxt news feed.\n:return: Config. The created Config instance."}, "tests": ["tests/test_config.py::test_create_config"], "indent": 8}
{"namespace": "boltons.tbutils.print_exception", "type": "function", "project_path": "Utilities/boltons", "completion_path": "Utilities/boltons/boltons/tbutils.py", "signature_position": [651, 651], "body_position": [663, 670], "dependency": {"intra_class": [], "intra_file": ["boltons.tbutils.TracebackInfo", "boltons.tbutils.TracebackInfo.__str__", "boltons.tbutils.TracebackInfo.from_traceback", "boltons.tbutils.format_exception_only"], "cross_file": []}, "requirement": {"Functionality": "This function prints the exception information, including the stack trace and the type and value of the exception. It also handles special cases for SyntaxError, where it prints the line where the syntax error occurred with a caret indicating the approximate position of the error.", "Arguments": ":param etype: The type of the exception.\n:param value: The value of the exception.\n:param tb: The traceback object.\n:param limit: Optional. The maximum number of stack trace entries to print. Defaults to None.\n:param file: Optional. The file object to which the output is written. Defaults to sys.stderr.\n:return: No return values."}, "tests": ["tests/test_tbutils.py::test_exception_info"], "indent": 4}
{"namespace": "gunicorn.http.body.Body.read", "type": "method", "project_path": "Utilities/gunicorn", "completion_path": "Utilities/gunicorn/gunicorn/http/body.py", "signature_position": [202, 202], "body_position": [203, 224], "dependency": {"intra_class": ["gunicorn.http.body.Body.buf", "gunicorn.http.body.Body.getsize", "gunicorn.http.body.Body.reader", "gunicorn.http.body.LengthReader.read"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Read a specified number of bytes from the Body instance. First, the function get the size to read. If the size is 0, it returns an empty byte string b\"\" since there is nothing to read. If the size is less than the current position of the buffer, it means that the requested size has been reached or exceeded. In this case, it retrieves the data from the buffer, splits it into two parts - 'ret' and 'rest', and updates the buffer by writing the remaining data into a new BytesIO object. It then returns the 'ret' part. If the size is greater than the current position of the buffer, it means that the requested data is not currently available in the buffer. In this case, it reads data from the reader object in blocks of 1024 bytes and writes it to the buffer until either all the data has been read or the requested size has been reached. Finally, it retrieves the data from the buffer, splits it into two parts - 'ret' and 'rest', updates the buffer by writing the remaining data into a new BytesIO object, and returns the 'ret' part.", "Arguments": ":param self: Body. An instance of the Body class.\n:param size: Integer. The number of bytes to read from the Body instance. Defaults to None.\n:return: Bytes. The read data from the Body instance."}, "tests": ["tests/test_http.py::test_readline_buffer_loaded", "tests/test_http.py::test_readline_buffer_loaded_with_size"], "indent": 8}
{"namespace": "boltons.ioutils.SpooledIOBase.writelines", "type": "method", "project_path": "Utilities/boltons", "completion_path": "Utilities/boltons/boltons/ioutils.py", "signature_position": [114, 114], "body_position": [120, 122], "dependency": {"intra_class": ["boltons.ioutils.SpooledIOBase._checkClosed", "boltons.ioutils.SpooledIOBase.write"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Write each line in the input iterable to the buffer of a SpooledIOBase instance. It does not add line separators.\n", "Arguments": ":param self: SpooledIOBase, an instance of SpooledIOBase class.\n:param lines: iterable, lines to be written to the file.\n:return: No return values.\n"}, "tests": ["tests/test_ioutils.py::TestSpooledBytesIO::test_writelines", "tests/test_ioutils.py::TestSpooledStringIO::test_writelines"], "indent": 8}
{"namespace": "kinto.plugins.accounts.utils.get_cached_reset_password", "type": "function", "project_path": "Internet/kinto", "completion_path": "Internet/kinto/kinto/plugins/accounts/utils.py", "signature_position": [55, 55], "body_position": [57, 62], "dependency": {"intra_class": [], "intra_file": ["kinto.plugins.accounts.utils.ACCOUNT_RESET_PASSWORD_CACHE_KEY"], "cross_file": ["kinto.core.utils.hmac_digest", "kinto.core.cache", "kinto.core.utils"]}, "requirement": {"Functionality": "This function retrieves the reset password for a given username from the cache. It first generates a cache key using the username and a secret key. Then, it retrieves the corresponding value from the cache using the cache key.", "Arguments": ":param username: String. The username for which to retrieve the reset password.\n:param registry: Dictionary. The registry containing the settings and cache.\n:return: The reset password value retrieved from the cache."}, "tests": ["tests/plugins/test_accounts.py::AccountValidationCreationTest::test_reset_password_sends_email", "tests/plugins/test_accounts.py::AccountValidationCreationTest::test_use_reset_password_to_change_password"], "indent": 4}
{"namespace": "falcon.request.Request.subdomain", "type": "method", "project_path": "Internet/falcon", "completion_path": "Internet/falcon/falcon/request.py", "signature_position": [872, 873], "body_position": [874, 875], "dependency": {"intra_class": ["falcon.request.Request.host"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function extracts the subdomain from the host of a Request instance. It splits the host string into three parts: the subdomain, the separator (.), and the remainder of the string. If the separator is found, it returns the subdomain; otherwise, it returns None.", "Arguments": ":param self: Request. An instance of the Request class.\n:return: String or None. The extracted subdomain from the host, or None if no subdomain is found."}, "tests": ["tests/test_request_attrs.py::TestRequestAttributes::test_subdomain"], "indent": 8}
{"namespace": "alembic.operations.schemaobj.SchemaObjects.index", "type": "method", "project_path": "Database/alembic", "completion_path": "Database/alembic/alembic/operations/schemaobj.py", "signature_position": [241, 248], "body_position": [249, 260], "dependency": {"intra_class": ["alembic.operations.schemaobj.SchemaObjects.metadata"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function creates an Index object based on the given parameters. It first creates a Table object using the provided tablename and schema, and then creates an Index object using the table and column names. The function returns the created Index object.", "Arguments": ":param self: SchemaObjects. An instance of the `SchemaObjects` class.\n:param name: Optional string. The name of the index.\n:param tablename: Optional string. The name of the table to create the index on.\n:param columns: Sequence of strings, TextClause, or ColumnElement. The columns to include in the index.\n:param schema: Optional string. The schema of the table.\n:param **kw: Additional keyword arguments that can be passed to the Index object.\n:return: Index. The created Index object."}, "tests": ["tests/test_op.py::ObjectFromToTest::test_drop_index", "tests/test_op.py::ObjectFromToTest::test_create_index_add_kw", "tests/test_op.py::ObjectFromToTest::test_drop_index_add_kw", "tests/test_op.py::ObjectFromToTest::test_create_index"], "indent": 8}
{"namespace": "kinto.plugins.accounts.views.validation.on_account_activated", "type": "function", "project_path": "Internet/kinto", "completion_path": "Internet/kinto/kinto/plugins/accounts/views/validation.py", "signature_position": [121, 121], "body_position": [122, 135], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["kinto.plugins.accounts.mails.Emailer", "kinto.plugins.accounts.mails.Emailer.send_confirmation"]}, "requirement": {"Functionality": "This function is triggered when an account is activated. It checks if the account validation setting is enabled. If it is enabled, it iterates through the impacted objects in the event and checks if the old account was validated or if the new account is not validated. If either of these conditions is true, it skips to the next impacted object. If neither condition is true, it sends a confirmation email to the account.", "Arguments": ":param event: The event object containing information about the account activation.\n:return: No return values."}, "tests": ["tests/plugins/test_accounts.py::AccountValidationCreationTest::test_user_validation_listener"], "indent": 4}
{"namespace": "falcon.asgi.reader.BufferedReader.read_until", "type": "method", "project_path": "Internet/falcon", "completion_path": "Internet/falcon/falcon/asgi/reader.py", "signature_position": [289, 289], "body_position": [290, 297], "dependency": {"intra_class": ["falcon.asgi.reader.BufferedReader._consume_delimiter", "falcon.asgi.reader.BufferedReader._iter_delimited", "falcon.asgi.reader.BufferedReader._read_from"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Read data from the BufferedReader instance until a specified delimiter is encountered. It reads data from the internal iterator that yields chunks of data until the delimiter is found or the specified size is reached. If consume_delimiter is True, it also consumes the delimiter from the input data.", "Arguments": ":param self: BufferedReader. An instance of the BufferedReader class.\n:param delimiter: The delimiter to search for in the input data.\n:param size: Integer. The maximum number of bytes to read. Defaults to -1, which means read until the delimiter is found.\n:param consume_delimiter: Bool. Whether to consume the delimiter from the input data. Defaults to False.\n:return: The data read from the BufferedReader instance until the delimiter is encountered."}, "tests": ["tests/asgi/test_buffered_reader.py::test_read_until_shared_boundary"], "indent": 8}
{"namespace": "zulipterminal.ui_tools.boxes.WriteBox._to_box_autocomplete", "type": "method", "project_path": "Communications/zulip-term", "completion_path": "Communications/zulip-term/zulipterminal/ui_tools/boxes.py", "signature_position": [431, 431], "body_position": [432, 452], "dependency": {"intra_class": ["zulipterminal.ui_tools.boxes.WriteBox._process_typeaheads", "zulipterminal.ui_tools.boxes.WriteBox.view"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function takes a text and a state as input and returns a string for autocomplete. It performs the following steps:\n1. Get the list of users from the view.\n2. Split the text by comma and get the most recent recipient for autocomplete.\n3. Find the users that match the latest text.\n4. Append the autocompleted recipients to the string containing the previous recipients.\n5. Get the full names of the matching users.\n6. Process the typeaheads using the updated recipients, state, and user names.", "Arguments": ":param self: WriteBox. An instance of the WriteBox class.\n:param text: String. The input text for autocomplete.\n:param state: Optional[int]. The state for autocomplete. Defaults to None.\n:return: Optional[str]. The string for autocomplete."}, "tests": ["tests/ui_tools/test_boxes.py::TestWriteBox::test__to_box_autocomplete", "tests/ui_tools/test_boxes.py::TestWriteBox::test__to_box_autocomplete_with_multiple_recipients"], "indent": 8}
{"namespace": "viztracer.tracer._VizTracer.start", "type": "method", "project_path": "System/viztracer", "completion_path": "System/viztracer/src/viztracer/tracer.py", "signature_position": [244, 244], "body_position": [245, 252], "dependency": {"intra_class": ["viztracer.tracer._VizTracer._tracer", "viztracer.tracer._VizTracer.config", "viztracer.tracer._VizTracer.enable", "viztracer.tracer._VizTracer.exclude_files", "viztracer.tracer._VizTracer.include_files", "viztracer.tracer._VizTracer.log_print", "viztracer.tracer._VizTracer.overload_print", "viztracer.tracer._VizTracer.parsed"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Start the input VizTracer instance. It sets the enable flag to True and the parsed flag to False. If the log print is True, it overloads the print function. It checks if both included files and excluded files are specified, and raises an exception if they are. It then enables the config and starts the tracer.", "Arguments": ":param self: _VizTracer. An instance of the _VizTracer class.\n:return: No return values."}, "tests": ["tests/test_tracer.py::TestCircularBuffer::test_wrap", "tests/test_tracer.py::TestTracerFeature::test_log_gc", "tests/test_tracer.py::TestTracerFilter::test_include_exclude_exception", "tests/test_basic.py::TestTracerBasic::test_builtin_func", "tests/test_tracer.py::TestTracerFeature::test_log_func_retval"], "indent": 8}
{"namespace": "boto.s3.bucket.Bucket.get_tags", "type": "method", "project_path": "Internet/boto", "completion_path": "Internet/boto/boto/s3/bucket.py", "signature_position": [1829, 1829], "body_position": [1830, 1837], "dependency": {"intra_class": ["boto.s3.bucket.Bucket.get_xml_tags"], "intra_file": [], "cross_file": ["boto.handler", "boto.handler.XmlHandler", "boto.s3.tagging.Tags"]}, "requirement": {"Functionality": "This function retrieves the tags associated with a bucket. It sends a request to get the XML tags of the bucket and parses the response to extract the tags.", "Arguments": ":param self: Bucket. An instance of the Bucket class.\n:param headers: Dict. Optional headers to include in the request.\n:return: Tags. The tags associated with the bucket."}, "tests": ["tests/unit/s3/test_tagging.py::TestS3Tagging::test_parse_tagging_response"], "indent": 8}
{"namespace": "pyramid.config.Configurator.scan", "type": "method", "project_path": "Internet/pyramid", "completion_path": "Internet/pyramid/src/pyramid/config/__init__.py", "signature_position": [799, 806], "body_position": [868, 879], "dependency": {"intra_class": ["pyramid.config.Configurator.maybe_dotted", "pyramid.config.Configurator.venusian"], "intra_file": [], "cross_file": ["pyramid.path.caller_package"]}, "requirement": {"Functionality": "This function scans a Python package and its subpackages for objects marked with configuration decoration. It uses the Venusian library to perform the scanning and executes the corresponding decorator callbacks. The decorated objects found during the scan will influence the current configuration state.", "Arguments": ":param self: Configurator. An instance of the Configurator class.\n:param package: Optional. The Python package or module object to scan. If None, the package of the caller is used.\n:param categories: Tuple of strings. The Venusian 'scan categories' to use during scanning. Defaults to ('pyramid').\n:param onerror: Optional. Venusian 'onerror' callback function to influence error behavior during scanning.\n:param ignore: Optional. Venusian 'ignore' value to ignore specific modules, packages, or global objects during scanning.\n:param **kw: Additional keyword arguments to pass to the Venusian Scanner object's constructor.\n:return: No return values."}, "tests": ["tests/test_config/test_init.py::ConfiguratorTests::test_scan_integration_dottedname_package", "tests/test_config/test_init.py::ConfiguratorTests::test_scan_integration", "tests/test_integration.py::WGSIAppPlusViewConfigTests::test_scanned", "tests/test_config/test_init.py::ConfiguratorTests::test_scan_integration_with_extra_kw", "tests/test_config/test_init.py::ConfiguratorTests::test_scan_integration_with_onerror"], "indent": 8}
{"namespace": "pyinfra.operations.files.get", "type": "function", "project_path": "System/pyinfra", "completion_path": "System/pyinfra/pyinfra/operations/files.py", "signature_position": [717, 723], "body_position": [748, 773], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["pyinfra.api.util.get_file_sha1", "pyinfra.facts.files.File", "pyinfra.facts.files.Sha1File", "pyinfra.api.host.Host.get_fact", "pyinfra.api.state.State.get_temp_filename"]}, "requirement": {"Functionality": "This function is used to download a file from a remote system. It takes the source file path and the destination file path as input parameters and provides options to add the deploy directory, create the local directory if it doesn't exist, and force the download even if the local copy matches. It also includes an example and a note about the suitability of this operation for large files.", "Arguments": ":param src: String. The remote filename to download.\n:param dest: String. The local filename to download the file to.\n:param add_deploy_dir: Bool. Whether the destination is relative to the deploy directory. Defaults to True.\n:param create_local_dir: Bool. Whether to create the local directory if it doesn't exist. Defaults to False.\n:param force: Bool. Whether to always download the file, even if the local copy matches. Defaults to False.\n:return: No return values."}, "tests": ["tests/test_api/test_api_operations.py::TestOperationsApi::test_file_download_op"], "indent": 4}
{"namespace": "ydata_profiling.report.presentation.flavours.html.image.HTMLImage.render", "type": "method", "project_path": "Software-Development/pandas-profiling", "completion_path": "Software-Development/pandas-profiling/src/ydata_profiling/report/presentation/flavours/html/image.py", "signature_position": [6, 6], "body_position": [7, 8], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["ydata_profiling.report.presentation.flavours.html.templates", "ydata_profiling.report.presentation.flavours.html.templates.template"]}, "requirement": {"Functionality": "Render the HTML content of an image. It uses a template file called \"diagram.html\" and passes the content of the image as arguments to the template.", "Arguments": ":param self: HTMLImage. An instance of the HTMLImage class.\n:return: str. The rendered HTML content of the image."}, "tests": ["tests/unit/test_renderable.py::test_html_image"], "indent": 8}
{"namespace": "imapclient.imapclient.IMAPClient.enable", "type": "method", "project_path": "Communications/IMAPClient", "completion_path": "Communications/IMAPClient/imapclient/imapclient.py", "signature_position": [537, 537], "body_position": [553, 567], "dependency": {"intra_class": ["imapclient.imapclient.IMAPClient._imap", "imapclient.imapclient.IMAPClient._raw_command_untagged", "imapclient.imapclient.IMAPClient.capabilities"], "intra_file": [], "cross_file": ["imapclient.exceptions.IllegalStateError", "imapclient.exceptions"]}, "requirement": {"Functionality": "This function enables one or more server-side capability extensions in the IMAPClient instance. It sends an ENABLE command to the server with the requested extensions and returns a list of the successfully enabled extensions.", "Arguments": ":param self: IMAPClient. An instance of the IMAPClient class.\n:param capabilities: Variable number of strings. The capability extensions to enable on the server.\n:return: List of strings. The requested extensions that were successfully enabled on the server."}, "tests": ["tests/test_enable.py::TestEnable::test_success", "tests/test_enable.py::TestEnable::test_failed1", "tests/test_enable.py::TestEnable::test_multiple", "tests/test_enable.py::TestEnable::test_failed2", "tests/test_enable.py::TestEnable::test_wrong_state"], "indent": 8}
{"namespace": "diffprivlib.accountant.BudgetAccountant.check", "type": "method", "project_path": "Security/diffprivlib", "completion_path": "Security/diffprivlib/diffprivlib/accountant.py", "signature_position": [275, 275], "body_position": [297, 311], "dependency": {"intra_class": ["diffprivlib.accountant.BudgetAccountant.__min_epsilon", "diffprivlib.accountant.BudgetAccountant.delta", "diffprivlib.accountant.BudgetAccountant.epsilon", "diffprivlib.accountant.BudgetAccountant.remaining", "diffprivlib.accountant.BudgetAccountant.spent_budget", "diffprivlib.accountant.BudgetAccountant.total"], "intra_file": [], "cross_file": ["diffprivlib.utils.Budget", "diffprivlib.utils.BudgetError", "diffprivlib.validation.check_epsilon_delta"]}, "requirement": {"Functionality": "This function checks if the provided (epsilon, delta) values can be spent without exceeding the budget ceiling of the BudgetAccountant instance. It performs various checks and calculations to determine if the budget can be spent or if a budget error should be raised \"Privacy spend of ({epsilon},{delta}) not permissible; will exceed remaining privacy budget. Use {class name}.{method for remaining budget}() to check remaining budget.\"", "Arguments": ":param self: BudgetAccountant. An instance of the BudgetAccountant class.\n:param epsilon: float. The epsilon budget spend to check.\n:param delta: float. The delta budget spend to check.\n:return: bool. True if the budget can be spent."}, "tests": ["tests/test_BudgetAccountant.py::TestBudgetAccountant::test_spent_budget", "tests/test_BudgetAccountant.py::TestBudgetAccountant::test_inf_spend"], "indent": 8}
{"namespace": "imapclient.imapclient._normalise_search_criteria", "type": "function", "project_path": "Communications/IMAPClient", "completion_path": "Communications/IMAPClient/imapclient/imapclient.py", "signature_position": [1826, 1826], "body_position": [1827, 1850], "dependency": {"intra_class": [], "intra_file": ["imapclient.imapclient._normalise_search_criteria", "imapclient.imapclient._quoted", "imapclient.imapclient._quoted.maybe"], "cross_file": ["imapclient.datetime_util.format_criteria_date", "imapclient.exceptions", "imapclient.exceptions.InvalidCriteriaError", "imapclient.util.to_bytes"]}, "requirement": {"Functionality": "This function normalizes the search criteria by converting them into a standardized format. It handles different types of criteria and converts them accordingly including \"int, str, datatime, list, tuple, bytes\". If no criteria are specified, it raises the corresponding error. If no character set is specified, it defaults to \"us-ascii\".", "Arguments": ":param criteria: The search criteria to be normalized. It can be a string, bytes, list, tuple, int, datetime, or date.\n:param charset: The character set to be used for encoding. Defaults to \"us-ascii\" if not specified.\n:return: A list of normalized search criteria."}, "tests": ["tests/test_util_functions.py::Test_normalise_search_criteria::test_empty", "tests/test_util_functions.py::Test_normalise_search_criteria::test_None"], "indent": 4}
{"namespace": "pyinfra.api.connect.connect_all", "type": "function", "project_path": "System/pyinfra", "completion_path": "System/pyinfra/pyinfra/api/connect.py", "signature_position": [11, 11], "body_position": [19, 46], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["pyinfra.api.state.State.activate_host", "pyinfra.api.state.State.fail_hosts", "pyinfra.api.state.State.inventory", "pyinfra.progress.progress_spinner"]}, "requirement": {"Functionality": "This function connects to all the configured servers in parallel. It reads and writes the inventory of the input State instance. It activates the hosts that are initially connected to and updates the state accordingly.", "Arguments": ":param state: State. The state object containing the inventory to connect to.\n:return: No return values."}, "tests": ["tests/test_connectors/test_ssh.py::TestSSHConnector::test_connect_with_rsa_ssh_key_password_from_prompt", "tests/test_connectors/test_ssh.py::TestSSHConnector::test_connect_with_missing_ssh_key", "tests/test_api/test_api_facts.py::TestFactsApi::test_get_fact_current_op_global_arguments", "tests/test_connectors/test_ssh.py::TestSSHConnector::test_connect_with_rsa_ssh_key_wrong_password", "tests/test_connectors/test_docker.py::TestDockerConnector::test_connect_all"], "indent": 4}
{"namespace": "mingus.core.keys.get_key_signature", "type": "function", "project_path": "Multimedia/mingus", "completion_path": "Multimedia/mingus/mingus/core/keys.py", "signature_position": [79, 79], "body_position": [85, 91], "dependency": {"intra_class": [], "intra_file": ["mingus.core.keys.is_valid_key", "mingus.core.keys.keys"], "cross_file": ["mingus.core.mt_exceptions.NoteFormatError"]}, "requirement": {"Functionality": "This function returns the key signature for a given key. It assigns a value of 0 for the key of C (major) or a (minor), negative numbers for flat key signatures, and positive numbers for sharp key signatures.\n", "Arguments": ":param key: str. The key for which the key signature is to be determined. It defaults to \"C\" if not specified.\n:return: int. The key signature for the given key.\n"}, "tests": ["tests/unit/core/test_keys.py::test_keys::test_get_key_signature"], "indent": 4}
{"namespace": "diffprivlib.models.standard_scaler._incremental_mean_and_var", "type": "function", "project_path": "Security/diffprivlib", "completion_path": "Security/diffprivlib/diffprivlib/models/standard_scaler.py", "signature_position": [58, 59], "body_position": [60, 92], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["diffprivlib.accountant.BudgetAccountant"]}, "requirement": {"Functionality": "This function calculates the incremental mean and variance of a given dataset. It takes into account the previous mean, variance, and sample count, and updates them based on the new data increment.", "Arguments": ":param X: Array-like. The input dataset.\n:param epsilon: Float. The privacy parameter for the mean and variance calculations.\n:param bounds: Tuple. The lower and upper bounds for the dataset values.\n:param last_mean: Float. The previous mean of the dataset.\n:param last_variance: Float. The previous variance of the dataset.\n:param last_sample_count: Int. The previous sample count of the dataset.\n:param random_state: RandomState. The random state for the calculations. Defaults to None.\n:return: Tuple. The updated mean, variance, and sample count of the dataset."}, "tests": ["tests/models/test_incremental_mean_and_var.py::TestIncrementalMeanAndVar::test_duplicate_dataset", "tests/models/test_incremental_mean_and_var.py::TestIncrementalMeanAndVar::test_inf_epsilon", "tests/models/test_incremental_mean_and_var.py::TestIncrementalMeanAndVar::test_no_range", "tests/models/test_incremental_mean_and_var.py::TestIncrementalMeanAndVar::test_increment_inf_epsilon", "tests/models/test_incremental_mean_and_var.py::TestIncrementalMeanAndVar::test_different_results"], "indent": 4}
{"namespace": "mrjob.conf.combine_path_lists", "type": "function", "project_path": "System/mrjob", "completion_path": "System/mrjob/mrjob/conf.py", "signature_position": [525, 525], "body_position": [532, 542], "dependency": {"intra_class": [], "intra_file": ["mrjob.conf.combine_lists"], "cross_file": ["mrjob.util.expand_path"]}, "requirement": {"Functionality": "This function combines multiple path sequences into a single list. It resolves `~` (home dir) and environment variables, and expands globs that refer to the local filesystem. It can take single strings as well as lists.", "Arguments": ":param path_seqs: Variable number of sequences. The path sequences to be combined.\n:return: List. The combined list of paths after resolving `~`, environment variables, and expanding globs."}, "tests": ["tests/test_conf.py::CombineAndExpandPathsTestCase::test_combine_path_lists", "tests/test_conf.py::CombineAndExpandPathsTestCase::test_globbing", "tests/test_conf.py::CombineAndExpandPathsTestCase::test_combine_path_lists_on_strings", "tests/test_conf.py::CombineAndExpandPathsTestCase::test_combine_path_lists_empty"], "indent": 4}
{"namespace": "feedparser.api._open_resource", "type": "function", "project_path": "Text-Processing/feedparser", "completion_path": "Text-Processing/feedparser/feedparser/api.py", "signature_position": [76, 76], "body_position": [110, 137], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["feedparser.http", "feedparser.http.get"]}, "requirement": {"Functionality": "This function takes in a URL, pathname to local or network file, or string as input and returns a stream object. It provides a uniform way to handle different types of input sources. The returned object has standard read methods (read, readline, readlines) and should be closed using the .close() method when no longer needed.", "Arguments": ":param url_file_stream_or_string: The input source, which can be a URL, filename, or string.\n:param etag: The value of the If-None-Match request header. Defaults to None.\n:param modified: The value of the If-Modified-Since request header. Can be a tuple of 9 integers or a date string. Defaults to None.\n:param agent: The value of the User-Agent request header. Defaults to None.\n:param referrer: The value of the Referer request header. Defaults to None.\n:param handlers: A list of handlers used to build a urllib2 opener. Defaults to None.\n:param request_headers: A dictionary of HTTP request headers that override the values generated by FeedParser. Defaults to None.\n:param result: A placeholder for the result. Defaults to None.\n:return: A bytes object representing the stream."}, "tests": ["tests/runtests.py::TestOpenResource::test_fileobj", "tests/runtests.py::TestOpenResource::test_string", "tests/runtests.py::TestOpenResource::test_unicode_1", "tests/runtests.py::TestOpenResource::test_http_client_basic_auth_type_error", "tests/runtests.py::TestOpenResource::test_unicode_2"], "indent": 4}
{"namespace": "alembic.autogenerate.api.compare_metadata", "type": "function", "project_path": "Database/alembic", "completion_path": "Database/alembic/alembic/autogenerate/api.py", "signature_position": [45, 45], "body_position": [166, 167], "dependency": {"intra_class": [], "intra_file": ["alembic.autogenerate.api.produce_migrations"], "cross_file": ["alembic.operations.ops.MigrationScript.upgrade_ops", "alembic.runtime.migration.MigrationContext", "alembic.operations.ops.OpContainer.as_diffs"]}, "requirement": {"Functionality": "This function compares a database schema to the schema given in a MetaData instance. It uses a MigrationContext object to provide database connectivity and optional comparison functions for datatypes and server defaults. The function returns a list of \"diff\" directives, each representing individual differences between the two schemas.", "Arguments": ":param context: MigrationContext. An instance of the MigrationContext class that provides database connectivity and comparison functions.\n:param metadata: MetaData. An instance of the MetaData class that represents the database schema to compare against.\n:return: Any. The return format is a list of \"diff\" directives representing the differences between the two schemas."}, "tests": ["tests/test_autogen_diffs.py::CompareServerDefaultTest::test_server_default_yes_positives"], "indent": 4}
{"namespace": "exodus_bundler.bundling.Elf.dependencies", "type": "method", "project_path": "System/exodus-bundler", "completion_path": "System/exodus-bundler/src/exodus_bundler/bundling.py", "signature_position": [399, 399], "body_position": [401, 411], "dependency": {"intra_class": ["exodus_bundler.bundling.Elf.direct_dependencies", "exodus_bundler.bundling.Elf.linker_file", "exodus_bundler.bundling.Elf.find_direct_dependencies"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function runs the linker for the files iteratively and returns a set of all library dependencies. It starts with a set of direct dependencies and then iteratively finds the dependencies of those dependencies until no new dependencies are found.", "Arguments": ":param self: Elf. An instance of the Elf class.\n:return: Set. A set of all library dependencies."}, "tests": ["tests/test_bundling.py::test_elf_dependencies"], "indent": 8}
{"namespace": "pyramid.renderers.RendererHelper.render_to_response", "type": "method", "project_path": "Internet/pyramid", "completion_path": "Internet/pyramid/src/pyramid/renderers.py", "signature_position": [466, 466], "body_position": [467, 468], "dependency": {"intra_class": ["pyramid.renderers.RendererHelper._make_response", "pyramid.renderers.RendererHelper.render"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function takes a value, system values, and an optional request parameter as inputs. It renders the value using an input RendererHelper instance. It then creates a response and returns it.", "Arguments": ":param self: RendererHelper. An instance of the RendererHelper class.\n:param value: The value to be rendered.\n:param system_values: The system values to be used during rendering.\n:param request: Optional. The request object. Defaults to None.\n:return: The response generated by rendering the value."}, "tests": ["tests/test_renderers.py::TestRendererHelper::test_render_to_response"], "indent": 8}
{"namespace": "boto.dynamodb2.table.Table.delete_item", "type": "method", "project_path": "Internet/boto", "completion_path": "Internet/boto/boto/dynamodb2/table.py", "signature_position": [855, 855], "body_position": [907, 917], "dependency": {"intra_class": ["boto.dynamodb2.table.Table._build_filters", "boto.dynamodb2.table.Table._encode_keys", "boto.dynamodb2.table.Table.connection", "boto.dynamodb2.table.Table.table_name"], "intra_file": [], "cross_file": ["boto.dynamodb2.exceptions.ConditionalCheckFailedException", "boto.dynamodb2.layer1.DynamoDBConnection.delete_item", "boto.dynamodb2.types.FILTER_OPERATORS", "boto.dynamodb2.exceptions"]}, "requirement": {"Functionality": "This function deletes a single item from a table in DynamoDB. It allows for conditional deletes, where the item is only deleted if specific conditions are met. The function takes in the expected attribute values of the item to be deleted and the key attributes of the item. It returns True if the delete operation is successful and False if the conditional delete fails.", "Arguments": ":param self: Table. An instance of the Table class.\n:param expected: Dictionary. Optional. A dictionary of expected attribute value conditions.\n:param conditional_operator: String. Optional. The conditional operator to apply to the expected attribute value conditions. Defaults to 'AND'.\n:param kwargs: Key attributes of the item to be deleted.\n:return: Bool. True if the delete operation is successful, False if the conditional delete fails."}, "tests": ["tests/unit/dynamodb2/test_table.py::TableTestCase::test_delete_item_conditionally", "tests/unit/dynamodb2/test_table.py::TableTestCase::test_delete_item"], "indent": 8}
{"namespace": "boto.awslambda.connect_to_region", "type": "function", "project_path": "Internet/boto", "completion_path": "Internet/boto/boto/awslambda/__init__.py", "signature_position": [37, 37], "body_position": [38, 41], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["boto.awslambda.layer1.AWSLambdaConnection", "boto.regioninfo.connect"]}, "requirement": {"Functionality": "Connect to a specific region using the AWSLambdaConnection class from the boto library. It creates a connection to the AWS Lambda service in the specified region.", "Arguments": ":param region_name: String. The name of the region to connect to.\n:param **kw_params: Additional keyword arguments that can be passed to the connection class.\n:return: AWSLambdaConnection. The connection object to the AWS Lambda service in the specified region."}, "tests": ["tests/unit/test_connect_to_region.py::TestConnectAwslambda::test_connect_to_region"], "indent": 4}
{"namespace": "mssqlcli.jsonrpc.jsonrpcclient.JsonRpcClient.shutdown", "type": "method", "project_path": "Database/mssql-cli", "completion_path": "Database/mssql-cli/mssqlcli/jsonrpc/jsonrpcclient.py", "signature_position": [169, 169], "body_position": [173, 183], "dependency": {"intra_class": ["mssqlcli.jsonrpc.jsonrpcclient.JsonRpcClient.cancel", "mssqlcli.jsonrpc.jsonrpcclient.JsonRpcClient.request_queue", "mssqlcli.jsonrpc.jsonrpcclient.JsonRpcClient.request_thread", "mssqlcli.jsonrpc.jsonrpcclient.JsonRpcClient.writer"], "intra_file": ["mssqlcli.jsonrpc.jsonrpcclient.JsonRpcWriter.close", "mssqlcli.jsonrpc.jsonrpcclient.logger"], "cross_file": []}, "requirement": {"Functionality": "This function shuts down the JsonRpcClient instance. It sets the cancel flag to True, enqueues None to unblock background threads, waits for the request thread to finish, closes the underlying writer, and logs a message indicating the shutdown.", "Arguments": ":param self: JsonRpcClient. An instance of the JsonRpcClient class.\n:return: No return values."}, "tests": ["tests/jsonrpc/test_jsonrpcclient.py::JsonRpcClientTests::test_receive_invalid_response_exception", "tests/jsonrpc/test_jsonrpcclient.py::JsonRpcClientTests::test_normal_shutdown"], "indent": 8}
{"namespace": "zxcvbn.matching.spatial_match", "type": "function", "project_path": "Security/zxcvbn-python", "completion_path": "Security/zxcvbn-python/zxcvbn/matching.py", "signature_position": [302, 302], "body_position": [303, 307], "dependency": {"intra_class": [], "intra_file": ["zxcvbn.matching.GRAPHS", "zxcvbn.matching.RANKED_DICTIONARIES", "zxcvbn.matching.spatial_match_helper"], "cross_file": []}, "requirement": {"Functionality": "This function performs a spatial matching algorithm on a given password. It iterates through a set of predefined graphs and calls a helper function to find spatial matches in each graph. The matches are then sorted based on their position in the password.", "Arguments": ":param password: String. The password to perform spatial matching on.\n:param _graphs: Dictionary. A dictionary containing predefined graphs for spatial matching. Defaults to GRAPHS.\n:param _ranked_dictionaries: Dictionary. A dictionary containing ranked dictionaries for spatial matching. Defaults to RANKED_DICTIONARIES.\n:return: List. A sorted list of matches found in the password."}, "tests": ["tests/matching_test.py::test_spatial_matching"], "indent": 4}
{"namespace": "sslyze.plugins.certificate_info._cert_chain_analyzer._certificate_matches_hostname", "type": "function", "project_path": "System/sslyze", "completion_path": "System/sslyze/sslyze/plugins/certificate_info/_cert_chain_analyzer.py", "signature_position": [274, 274], "body_position": [277, 298], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["sslyze.plugins.certificate_info._certificate_utils.SubjectAlternativeNameExtension.dns_names", "sslyze.plugins.certificate_info._certificate_utils.SubjectAlternativeNameExtension.ip_addresses", "sslyze.plugins.certificate_info._certificate_utils.get_common_names", "sslyze.plugins.certificate_info._certificate_utils.parse_subject_alternative_name_extension"]}, "requirement": {"Functionality": "This function verifies whether the given certificate was issued for the specified hostname. It extracts the names from the certificate and creates a dictionary with the properly formatted names. Then, it check if the server_hostname matches any of the names in the certificate. If a CertificateError is raised during the matching process, it returns False.", "Arguments": ":param certificate: Certificate. The certificate to be verified.\n:param server_hostname: String. The hostname to be checked against the certificate.\n:return: Bool. True if the certificate matches the hostname, False otherwise."}, "tests": ["tests/plugins_tests/certificate_info/test_certificate_utils.py::TestCertificateUtils::test_certificate_matches_hostname_good_hostname"], "indent": 4}
{"namespace": "boltons.cacheutils.ThresholdCounter.elements", "type": "method", "project_path": "Utilities/boltons", "completion_path": "Utilities/boltons/boltons/cacheutils.py", "signature_position": [726, 726], "body_position": [730, 731], "dependency": {"intra_class": ["boltons.cacheutils.ThresholdCounter.iteritems"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function returns an iterator that yields all the common elements tracked by the counter. Each key is yielded as many times as it has been seen.", "Arguments": ":param self: ThresholdCounter. An instance of the ThresholdCounter class.\n:return: Iterator. An iterator that yields the common elements tracked by the counter."}, "tests": ["tests/test_cacheutils.py::test_threshold_counter"], "indent": 8}
{"namespace": "pyramid.path.Resolver.get_package", "type": "method", "project_path": "Internet/pyramid", "completion_path": "Internet/pyramid/src/pyramid/path.py", "signature_position": [113, 113], "body_position": [114, 118], "dependency": {"intra_class": ["pyramid.path.Resolver.package"], "intra_file": ["pyramid.path.CALLER_PACKAGE", "pyramid.path.caller_package"], "cross_file": []}, "requirement": {"Functionality": "This function returns the package that is associated with the Resolver instance. If the package is set to CALLER_PACKAGE, it retrieves the package of the caller. Otherwise, it returns the package that is set in the instance.", "Arguments": ":param self: Resolver. An instance of the Resolver class.\n:return: The package associated with the Resolver instance."}, "tests": ["tests/test_path.py::TestResolver::test_get_package_caller_package", "tests/test_path.py::TestResolver::test_get_package_string"], "indent": 8}
{"namespace": "twilio.twiml.voice_response.VoiceResponse.enqueue", "type": "method", "project_path": "Communications/twilio-fatisar", "completion_path": "Communications/twilio-fatisar/twilio/twiml/voice_response.py", "signature_position": [114, 124], "body_position": [139, 150], "dependency": {"intra_class": [], "intra_file": ["twilio.twiml.voice_response.Enqueue", "twilio.twiml.voice_response.Enqueue.__init__"], "cross_file": ["twilio.twiml.TwiML.nest"]}, "requirement": {"Functionality": "This function creates an <Enqueue> element for a VoiceResponse object. It sets various attributes of the <Enqueue> element based on the input parameters.", "Arguments": ":param self: VoiceResponse. An instance of the VoiceResponse class.\n:param name: String. The friendly name of the <Enqueue> element.\n:param action: String. The action URL of the <Enqueue> element.\n:param max_queue_size: Integer. The maximum size of the queue for the <Enqueue> element.\n:param method: String. The HTTP method to be used for the action URL.\n:param wait_url: String. The wait URL for the <Enqueue> element.\n:param wait_url_method: String. The HTTP method to be used for the wait URL.\n:param workflow_sid: String. The TaskRouter Workflow SID for the <Enqueue> element.\n:param kwargs: Additional attributes for the <Enqueue> element.\n:return: <Enqueue> element. The created <Enqueue> element."}, "tests": ["tests/unit/twiml/test_voice_response.py::TestEnqueue::test_enqueue"], "indent": 8}
{"namespace": "zulipterminal.ui_tools.buttons.MessageLinkButton._parse_narrow_link", "type": "method", "project_path": "Communications/zulip-term", "completion_path": "Communications/zulip-term/zulipterminal/ui_tools/buttons.py", "signature_position": [465, 465], "body_position": [479, 519], "dependency": {"intra_class": [], "intra_file": ["zulipterminal.ui_tools.buttons.ParsedNarrowLink"], "cross_file": ["zulipterminal.helper.hash_util_decode", "zulipterminal.ui.View.__init__"]}, "requirement": {"Functionality": "This function parses a given link and returns a dictionary with narrow parameters for supported links. If the link does not match any of the supported formats, an empty dictionary is returned.\nWe expect the fragment to be one of the following types:\na. narrow/stream/[{stream_id}-]{stream-name}\nb. narrow/stream/[{stream_id}-]{stream-name}/near/{message_id}\nc. narrow/stream/[{stream_id}-]{stream-name}/topic/{encoded.20topic.20name}\nd. narrow/stream/[{stream_id}-]{stream-name}/topic/{encoded.20topic.20name}/near/{message_id}", "Arguments": ":param cls: MessageLinkButton. The MessageLinkButton class.\n:param link: String. The link to be parsed.\n:return: ParsedNarrowLink. A dictionary with narrow parameters for supported links."}, "tests": ["tests/ui_tools/test_buttons.py::TestMessageLinkButton::test__parse_narrow_link"], "indent": 8}
{"namespace": "pyramid.testing.DummyRequest.response", "type": "method", "project_path": "Internet/pyramid", "completion_path": "Internet/pyramid/src/pyramid/testing.py", "signature_position": [398, 398], "body_position": [399, 401], "dependency": {"intra_class": ["pyramid.testing.DummyRequest.registry"], "intra_file": [], "cross_file": ["pyramid.response._get_response_factory"]}, "requirement": {"Functionality": "This function returns the response generated by the response factory using the input DummyRequest instance as the argument.", "Arguments": ":param self: DummyRequest. An instance of the DummyRequest class.\n:return: The response generated by the response factory function."}, "tests": ["tests/test_testing.py::TestDummyRequest::test_response_without_responsefactory", "tests/test_renderers.py::Test_string_renderer_factory::test_with_request_content_type_set", "tests/test_renderers.py::TestJSONP::test_render_to_jsonp_with_dot", "tests/test_renderers.py::TestJSONP::test_render_to_json", "tests/test_testing.py::TestDummyRequest::test_response_with_responsefactory"], "indent": 8}
{"namespace": "awesome_autodl.get_bib_abbrv_obj", "type": "function", "project_path": "Database/awesome-autodl", "completion_path": "Database/awesome-autodl/awesome_autodl/__init__.py", "signature_position": [79, 79], "body_position": [80, 83], "dependency": {"intra_class": [], "intra_file": ["awesome_autodl.get_bib_abbrv_file"], "cross_file": []}, "requirement": {"Functionality": "This function returns an instance of the BibAbbreviations class, which is created based on the file path obtained.", "Arguments": ":param: No input parameters.\n:return: BibAbbreviations. An instance of the BibAbbreviations class."}, "tests": ["tests/test_format.py::TestFormat::test_simple"], "indent": 4}
{"namespace": "ehforwarderbot.utils.get_config_path", "type": "function", "project_path": "Communications/ehforwarderbot", "completion_path": "Communications/ehforwarderbot/ehforwarderbot/utils.py", "signature_position": [88, 88], "body_position": [103, 110], "dependency": {"intra_class": [], "intra_file": ["ehforwarderbot.utils.get_base_path", "ehforwarderbot.utils.get_data_path"], "cross_file": ["ehforwarderbot.coordinator", "ehforwarderbot.coordinator.profile", "ehforwarderbot.types.ModuleID"]}, "requirement": {"Functionality": "This function returns the path to the configuration file based on the given module ID and extension. If the module ID is not provided, it uses the profile name from the coordinator. It also creates the path if it does not exist like \"profiles/{profile_name}/{module_id}/config.yaml\".", "Arguments": ":param module_id: ModuleID. The ID of the module. Defaults to None.\n:param ext: String. The extension name of the config file. Defaults to \"yaml\".\n:return: Path. The path to the configuration file."}, "tests": ["tests/test_channel_loading.py::test_load_config"], "indent": 4}
{"namespace": "pyramid.csrf.CookieCSRFStoragePolicy.new_csrf_token", "type": "method", "project_path": "Internet/pyramid", "completion_path": "Internet/pyramid/src/pyramid/csrf.py", "signature_position": [136, 136], "body_position": [138, 145], "dependency": {"intra_class": ["pyramid.csrf.CookieCSRFStoragePolicy._token_factory", "pyramid.csrf.CookieCSRFStoragePolicy.cookie_name"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function generates a new CSRF token and sets it into the request cookies. It also adds a response callback to set the CSRF token into the response cookies.", "Arguments": ":param self: CookieCSRFStoragePolicy. An instance of the CookieCSRFStoragePolicy class.\n:param request: The request object.\n:return: String. The generated CSRF token."}, "tests": ["tests/test_csrf.py::TestCookieCSRFStoragePolicy::test_new_cookie_csrf_with_existing_cookie_sets_cookies", "tests/test_csrf.py::TestCookieCSRFStoragePolicy::test_get_csrf_token_returns_the_new_token"], "indent": 8}
{"namespace": "pyramid.config.Configurator.__getattr__", "type": "method", "project_path": "Internet/pyramid", "completion_path": "Internet/pyramid/src/pyramid/config/__init__.py", "signature_position": [698, 699], "body_position": [700, 711], "dependency": {"intra_class": ["pyramid.config.Configurator.registry"], "intra_file": [], "cross_file": ["pyramid.config.actions.action_method"]}, "requirement": {"Functionality": "This function is a method of the Configurator class that allows accessing attributes dynamically and allow directive extension names to work. It checks if the attribute name exists in the registry's directives. If it does, it retrieves the corresponding value and performs additional actions if necessary. Finally, it returns a bound method of the retrieved value.", "Arguments": ":param self: Configurator. An instance of the Configurator class.\n:param name: String. The name of the attribute to be accessed.\n:return: Bound method. The bound method of the retrieved attribute value."}, "tests": ["tests/test_config/test_init.py::ConfiguratorTests::test___getattr__missing_when_directives_exist", "tests/test_config/test_init.py::ConfiguratorTests::test___getattr__missing_when_directives_dont_exist"], "indent": 8}
{"namespace": "fs.path.recursepath", "type": "function", "project_path": "System/fs", "completion_path": "System/fs/fs/path.py", "signature_position": [116, 117], "body_position": [133, 151], "dependency": {"intra_class": [], "intra_file": ["fs.path.abspath", "fs.path.normpath"], "cross_file": []}, "requirement": {"Functionality": "Take a path and a boolean value as input and return a list of intermediate paths from the root to the given path. \n", "Arguments": ":param path: String, the input path for which intermediate paths are to be generated.\n:param reverse: Bool, a boolean flag that specifies whether to reverse the order of the paths. Defaults to False.\n:return: List[String], a list of intermediate paths from the root to the given path.\n"}, "tests": ["tests/test_path.py::TestPathFunctions::test_recursepath"], "indent": 4}
{"namespace": "chatette.parsing.IntentDefBuilder.create_concrete", "type": "method", "project_path": "Communications/chatette", "completion_path": "Communications/chatette/chatette/parsing/__init__.py", "signature_position": [162, 162], "body_position": [163, 172], "dependency": {"intra_class": ["chatette.parsing.IntentDefBuilder.identifier", "chatette.parsing.IntentDefBuilder.nb_testing_ex", "chatette.parsing.IntentDefBuilder.nb_training_ex", "chatette.parsing.IntentDefBuilder.variation"], "intra_file": ["chatette.parsing.UnitDefBuilder._build_modifiers_repr", "chatette.parsing.UnitDefBuilder._check_information"], "cross_file": ["chatette.units.ast.AST", "chatette.units.modifiable.definitions.intent.IntentDefinition", "chatette.utils.Singleton.get_or_create", "chatette.utils.UnitType", "chatette.utils.UnitType.intent"]}, "requirement": {"Functionality": "This function creates a concrete instance of an IntentDefinition based on the given conditions. It first checks if all the necessary information is provided. If a variation is specified, it retrieves the definitions from the AST and checks if the identifier is already present. If it is, it returns the corresponding definition. Otherwise, it creates a new IntentDefinition instance with the provided identifier, modifiers representation, number of training examples, and number of testing examples.", "Arguments": ":param self: IntentDefBuilder. An instance of the IntentDefBuilder class.\n:return: IntentDefinition. The created concrete instance of IntentDefinition."}, "tests": ["tests/unit-testing/parsing/test_init.py::TestIntentDefBuilder::test_create_concrete", "tests/unit-testing/parsing/test_init.py::TestIntentDefBuilder::test_new_variation"], "indent": 8}
{"namespace": "sumy.evaluation.rouge._get_word_ngrams", "type": "function", "project_path": "Internet/sumy", "completion_path": "Internet/sumy/sumy/evaluation/rouge.py", "signature_position": [27, 27], "body_position": [28, 35], "dependency": {"intra_class": [], "intra_file": ["sumy.evaluation.rouge._get_ngrams", "sumy.evaluation.rouge._split_into_words"], "cross_file": []}, "requirement": {"Functionality": "This function takes in a positive value n and a non empty list of sentences as input. It iterates over each sentence in the sentences list and get the n-grams for each sentence. The resulting n-grams are added to a set. Finally, the function returns the set.", "Arguments": ":param n: Integer. The value of n for the n-grams.\n:param sentences: List of Sentence. The list of sentences to generate n-grams from.\n:return: Set of strings. The set of unique n-grams generated from the sentences."}, "tests": ["tests/test_evaluation/test_evaluation_rouge.py::test_get_word_ngrams", "tests/test_evaluation/test_evaluation_rouge.py::test_ngrams_for_more_sentences_should_not_return_words_at_boundaries"], "indent": 4}
{"namespace": "pycorrector.en_spell.EnSpell.correct_word", "type": "method", "project_path": "Text-Processing/pycorrector", "completion_path": "Text-Processing/pycorrector/pycorrector/en_spell.py", "signature_position": [99, 99], "body_position": [106, 109], "dependency": {"intra_class": ["pycorrector.en_spell.EnSpell.candidates", "pycorrector.en_spell.EnSpell.check_init"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function corrects the spelling of a given word by finding the most probable spelling correction. It first checks if the EnSpell instance has been initialized. Then, it calculates the probability of each candidate spelling correction for the word and sorts them in ascending order. Finally, it returns the correction with the highest probability.", "Arguments": ":param self: EnSpell. An instance of the EnSpell class.\n:param word: String. The word to be corrected.\n:return: String. The most probable spelling correction for the word."}, "tests": ["tests/en_spell_bug_fix_test.py::EnBugTestCase::test_en_bug_correct2"], "indent": 8}
{"namespace": "sacred.ingredient.Ingredient.gather_named_configs", "type": "method", "project_path": "Utilities/sacred", "completion_path": "Utilities/sacred/sacred/ingredient.py", "signature_position": [316, 318], "body_position": [328, 332], "dependency": {"intra_class": ["sacred.ingredient.Ingredient.post_process_name", "sacred.ingredient.Ingredient.traverse_ingredients", "sacred.ingredient.Ingredient.named_configs"], "intra_file": [], "cross_file": ["sacred.utils.join_paths"]}, "requirement": {"Functionality": "This function gathers all named configurations from the Ingredient instance and its sub-ingredients. It iterates through each ingredient and its named configurations to collect the configuration names and corresponding configurations.", "Arguments": ":param self: Ingredient. An instance of the Ingredient class.\n:return: Generator. A generator that yields tuples containing the full name of the named configuration and the corresponding configuration."}, "tests": ["tests/test_ingredients.py::test_gather_named_configs"], "indent": 8}
{"namespace": "pycoin.bloomfilter.BloomFilter.add_spendable", "type": "method", "project_path": "Security/pycoin", "completion_path": "Security/pycoin/pycoin/bloomfilter.py", "signature_position": [48, 48], "body_position": [49, 50], "dependency": {"intra_class": ["pycoin.bloomfilter.BloomFilter.add_item"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Add a spendable to the BloomFilter instance. It converts the spendable into bytes and adds it to the BloomFilter.", "Arguments": ":param self: BloomFilter. An instance of the BloomFilter class.\n:param spendable: The spendable to be added to the BloomFilter.\n:return: No return values."}, "tests": ["tests/bloomfilter_test.py::BloomFilterTest::test_BloomFilter"], "indent": 8}
{"namespace": "sacred.utils.convert_to_nested_dict", "type": "function", "project_path": "Utilities/sacred", "completion_path": "Utilities/sacred/sacred/utils.py", "signature_position": [537, 537], "body_position": [539, 542], "dependency": {"intra_class": [], "intra_file": ["sacred.utils.iterate_flattened", "sacred.utils.set_by_dotted_path"], "cross_file": []}, "requirement": {"Functionality": "This function converts a dictionary with dotted path keys into a corresponding nested dictionary. It iterates through the flattened dictionary and sets the values in the nested dictionary using the dotted path keys.", "Arguments": ":param dotted_dict: Dict. The dictionary with dotted path keys to be converted.\n:return: Dict. The corresponding nested dictionary."}, "tests": ["tests/test_utils.py::test_convert_to_nested_dict", "tests/test_utils.py::test_convert_to_nested_dict_nested"], "indent": 4}
{"namespace": "mrjob.fs.ssh.SSHFilesystem.ls", "type": "method", "project_path": "System/mrjob", "completion_path": "System/mrjob/mrjob/fs/ssh.py", "signature_position": [173, 173], "body_position": [174, 185], "dependency": {"intra_class": ["mrjob.fs.ssh.SSHFilesystem._ssh_finish_run", "mrjob.fs.ssh.SSHFilesystem._ssh_launch"], "intra_file": ["mrjob.fs.ssh._SSH_URI_RE"], "cross_file": ["mrjob.py2.to_unicode"]}, "requirement": {"Functionality": "List all the files in the specified path of the SSH filesystem. It uses the SSH connection to execute the \"find\" command and retrieves the file paths.", "Arguments": ":param self: SSHFilesystem. An instance of the SSHFilesystem class.\n:param path_glob: str. The path pattern to match the files.\n:return: Generator. A generator that yields the file paths in the specified path."}, "tests": ["tests/fs/test_ssh.py::SSHFSTestCase::test_ls_without_required_sudo", "tests/fs/test_ssh.py::SSHFSTestCase::test_ls_recurse", "tests/fs/test_ssh.py::SSHFSTestCase::test_worker_ls_without_required_sudo", "tests/fs/test_ssh.py::SSHFSTestCase::test_ls_empty", "tests/fs/test_ssh.py::SSHFSTestCase::test_worker_ls"], "indent": 8}
{"namespace": "mrjob.conf.dump_mrjob_conf", "type": "function", "project_path": "System/mrjob", "completion_path": "System/mrjob/mrjob/conf.py", "signature_position": [346, 346], "body_position": [361, 365], "dependency": {"intra_class": [], "intra_file": ["mrjob.conf._dump_yaml_with_clear_tags"], "cross_file": []}, "requirement": {"Functionality": "This function writes out configuration options to a file. It takes a configuration dictionary as input and writes it to the specified file object. The function supports both YAML and JSON formats for writing the configuration. If YAML is available, it uses it, otherwise it uses JSON.", "Arguments": ":param conf: dict. The configuration options to be written to the file.\n:param f: File object. The file object to write the configuration to.\n:return: No return values."}, "tests": ["tests/test_conf.py::MRJobConfNoYAMLTestCase::test_no_support_for_clear_tags", "tests/test_conf.py::MRJobBasicConfTestCase::test_nested_include", "tests/test_conf.py::MRJobBasicConfTestCase::test_include_order_beats_include", "tests/test_conf.py::MRJobConfNoYAMLTestCase::test_using_json_and_not_yaml", "tests/test_conf.py::MRJobBasicConfTestCase::test_include_relative_to_real_path"], "indent": 4}
{"namespace": "jinja2.bccache.MemcachedBytecodeCache.load_bytecode", "type": "method", "project_path": "Internet/Jinja2", "completion_path": "Internet/Jinja2/src/jinja2/bccache.py", "signature_position": [386, 386], "body_position": [387, 393], "dependency": {"intra_class": ["jinja2.bccache.MemcachedBytecodeCache.client", "jinja2.bccache.MemcachedBytecodeCache.ignore_memcache_errors", "jinja2.bccache.MemcachedBytecodeCache.prefix"], "intra_file": ["jinja2.bccache.Bucket.bytecode_from_string", "jinja2.bccache.Bucket.key", "jinja2.bccache._MemcachedClient.get"], "cross_file": []}, "requirement": {"Functionality": "Load the bytecode from the Memcached server and assign it to the given bucket. The key is generated by concatenating the prefix and the bucket key. If an exception occurs during the retrieval of the bytecode and the flag to ignore errors is not set, the exception is re-raised.", "Arguments": ":param self: MemcachedBytecodeCache. An instance of the MemcachedBytecodeCache class.\n:param bucket: Bucket. The bucket object to assign the retrieved bytecode to.\n:return: No return values."}, "tests": ["tests/test_bytecode_cache.py::TestMemcachedBytecodeCache::test_exception", "tests/test_bytecode_cache.py::TestMemcachedBytecodeCache::test_dump_load"], "indent": 8}
{"namespace": "rest_framework.serializers.Serializer.fields", "type": "method", "project_path": "Internet/djangorestframework", "completion_path": "Internet/djangorestframework/rest_framework/serializers.py", "signature_position": [345, 345], "body_position": [352, 356], "dependency": {"intra_class": ["rest_framework.serializers.Serializer.get_fields"], "intra_file": [], "cross_file": ["rest_framework.utils.serializer_helpers.BindingDict"]}, "requirement": {"Functionality": "This function returns a dictionary of field names and their corresponding field instances. It lazily evaluates the fields to avoid import issues with modules that use ModelSerializers as fields before Django's app-loading stage has run.", "Arguments": ":param: self: Serializer. An instance of the Serializer class.\n:return: Dictionary. A dictionary of {field_name: field_instance}."}, "tests": ["tests/importable/test_installed.py::test_serializer_fields_initialization"], "indent": 8}
{"namespace": "imapclient.imapclient.IMAPClient.get_flags", "type": "method", "project_path": "Communications/IMAPClient", "completion_path": "Communications/IMAPClient/imapclient/imapclient.py", "signature_position": [1232, 1232], "body_position": [1239, 1240], "dependency": {"intra_class": ["imapclient.imapclient.IMAPClient._filter_fetch_dict", "imapclient.imapclient.IMAPClient.fetch"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Return a dictionary that contains the flags set for each message in the input parameter `messages`.\n", "Arguments": ":param self: IMAPClient, an instance of IMAPClient class.\n:param messages: List, a list of message IDs for which to retrieve the flags.\n:return: Dict, a dictionary that contains the flags set for each message, structured as follows: \"{msgid1: (flag1, flag2, ...),}\".\n"}, "tests": ["tests/test_store.py::TestFlags::test_get"], "indent": 8}
{"namespace": "dash._grouping.make_grouping_by_index", "type": "function", "project_path": "Software-Development/dash", "completion_path": "Software-Development/dash/dash/_grouping.py", "signature_position": [68, 68], "body_position": [80, 110], "dependency": {"intra_class": [], "intra_file": ["dash._grouping.flatten_grouping"], "cross_file": []}, "requirement": {"Functionality": "This function creates a grouping based on the provided grouping schema. It takes a schema and a list of flat values, and uses the values from the list to populate the grouping structure defined by the schema.", "Arguments": ":param schema: The grouping schema that defines the structure of the grouping to be created.\n:param flat_values: A list of values with a length that matches the grouping length of the schema. These values will be used to populate the resulting grouping.\n:return: The created grouping structure based on the schema and flat values."}, "tests": ["tests/unit/library/test_grouping.py::test_map_grouping_mixed", "tests/unit/library/test_grouping.py::test_make_grouping_by_position_mixed", "tests/unit/library/test_grouping.py::test_make_grouping_by_position_dict", "tests/unit/library/test_grouping.py::test_make_grouping_by_position_list", "tests/unit/library/test_grouping.py::test_make_grouping_by_position_scalar"], "indent": 4}
{"namespace": "trailscraper.boto_service_definitions.operation_definition", "type": "function", "project_path": "Security/trailscraper", "completion_path": "Security/trailscraper/trailscraper/boto_service_definitions.py", "signature_position": [32, 32], "body_position": [34, 36], "dependency": {"intra_class": [], "intra_file": ["trailscraper.boto_service_definitions.service_definition_file"], "cross_file": []}, "requirement": {"Functionality": "This function returns the operation definition for a specific service and operation. It reads the service definition file for the given service name, loads the JSON content, and returns the operation definition based on the given operation name.", "Arguments": ":param servicename: String. The name of the service.\n:param operationname: String. The name of the operation.\n:return: The operation definition for the specified service and operation."}, "tests": ["tests/boto_service_definitions_test.py::test_should_find_operation_definitions"], "indent": 4}
{"namespace": "alembic.testing.env._write_config_file", "type": "function", "project_path": "Database/alembic", "completion_path": "Database/alembic/alembic/testing/env.py", "signature_position": [241, 241], "body_position": [242, 245], "dependency": {"intra_class": [], "intra_file": ["alembic.testing.env._testing_config"], "cross_file": ["alembic.config.Config.config_file_name"]}, "requirement": {"Functionality": "This function writes the given text to a configuration file. It first creates a testing configuration instance, then opens the configuration file in write mode and writes the text to it. Finally, it returns the testing configuration instance.", "Arguments": ":param text: String. The text to be written to the configuration file.\n:return: TestingConfig. The testing configuration instance."}, "tests": ["tests/test_config.py::FileConfigTest::test_config_args"], "indent": 4}
{"namespace": "mingus.containers.note_container.NoteContainer.from_chord_shorthand", "type": "method", "project_path": "Multimedia/mingus", "completion_path": "Multimedia/mingus/mingus/containers/note_container.py", "signature_position": [112, 112], "body_position": [122, 124], "dependency": {"intra_class": ["mingus.containers.note_container.NoteContainer.add_notes", "mingus.containers.note_container.NoteContainer.empty"], "intra_file": [], "cross_file": ["mingus.core.chords", "mingus.core.chords.from_shorthand"]}, "requirement": {"Functionality": "This function clears the NoteContainer and adds the notes corresponding to the shorthand notation.\n", "Arguments": ":param self: NoteContainer. An instance of the NoteContainer class.\n:param shorthand: str. The shorthand notation representing the chords.\n:return: NoteContainer. The updated NoteContainer instance.\n"}, "tests": ["tests/unit/containers/test_note_containers.py::test_NoteContainers::test_from_chord_shorthand"], "indent": 8}
{"namespace": "boto.ec2.cloudwatch.connect_to_region", "type": "function", "project_path": "Internet/boto", "completion_path": "Internet/boto/boto/ec2/cloudwatch/__init__.py", "signature_position": [48, 48], "body_position": [59, 61], "dependency": {"intra_class": [], "intra_file": ["boto.ec2.cloudwatch.CloudWatchConnection"], "cross_file": ["boto.regioninfo.connect"]}, "requirement": {"Functionality": "This function connects to a specific region and returns a CloudWatchConnection object.", "Arguments": ":param region_name: str. The name of the region to connect to.\n:param kw_params: keyword arguments. Additional parameters that can be passed to the connect function.\n:return: CloudWatchConnection or None. A connection to the specified region, or None if an invalid region name is given."}, "tests": ["tests/unit/test_connect_to_region.py::TestCloudwatchConnection::test_connect_to_region"], "indent": 4}
{"namespace": "pythonforandroid.bootstrap.Bootstrap.get_bootstrap_from_recipes", "type": "method", "project_path": "Utilities/python-for-android", "completion_path": "Utilities/python-for-android/pythonforandroid/bootstrap.py", "signature_position": [251, 251], "body_position": [256, 295], "dependency": {"intra_class": ["pythonforandroid.bootstrap.Bootstrap.get_bootstrap", "pythonforandroid.bootstrap.Bootstrap.get_usable_bootstraps_for_recipes"], "intra_file": ["pythonforandroid.bootstrap._cmp_bootstraps_by_priority", "pythonforandroid.bootstrap.expand_dependencies"], "cross_file": ["pythonforandroid.logger.info"]}, "requirement": {"Functionality": "This function selects a recommended default bootstrap from a list of recipes and returns it. It follows a set of rules to determine the appropriate bootstrap based on the given recipes. The rules are following SDL2 bootstrap if there's an sdl2 dep or \"webview\" if we depend on common web recipe.", "Arguments": ":param cls: Class. The Bootstrap class.\n:param recipes: List of strings. The list of recipes to consider when selecting the bootstrap.\n:param ctx: Context. The context in which the function is being called.\n:return: Bootstrap. The selected default bootstrap."}, "tests": ["tests/test_bootstrap.py::TestBootstrapBasic::test_get_bootstraps_from_recipes"], "indent": 8}
{"namespace": "mrjob.compat.translate_jobconf_dict", "type": "function", "project_path": "System/mrjob", "completion_path": "System/mrjob/mrjob/compat.py", "signature_position": [677, 677], "body_position": [686, 715], "dependency": {"intra_class": [], "intra_file": ["mrjob.compat.log", "mrjob.compat.translate_jobconf", "mrjob.compat.translate_jobconf_for_all_versions"], "cross_file": []}, "requirement": {"Functionality": "This function translates the configuration property names in the jobconf dictionary to match those accepted in the specified hadoop version. It also prints a warning message if any configuration property name does not match the name in the hadoop version. Finally, it combines the original jobconf with the translated jobconf and returns a map consisting of the original and translated configuration property names and values. The warning message is \"Detected hadoop configuration property names that do not match version {hadoop version}:\\nThe have been translated to the following names:\\n{translated names}\". The translated names are sorted and one variable and variant per line, separated by a colon.", "Arguments": ":param jobconf: dict. The original jobconf dictionary containing configuration property names and values.\n:param hadoop_version: str. The version of Hadoop to which the configuration property names should be translated. Defaults to None.\n:return: dict. A map consisting of the original and translated configuration property names and values."}, "tests": ["tests/test_compat.py::TranslateJobConfDictTestCase::test_hadoop_2", "tests/test_compat.py::TranslateJobConfDictTestCase::test_no_version", "tests/test_compat.py::TranslateJobConfDictTestCase::test_hadoop_1", "tests/test_compat.py::TranslateJobConfDictTestCase::test_dont_overwrite", "tests/test_compat.py::TranslateJobConfDictTestCase::test_empty"], "indent": 4}
{"namespace": "boto.configservice.connect_to_region", "type": "function", "project_path": "Internet/boto", "completion_path": "Internet/boto/boto/configservice/__init__.py", "signature_position": [38, 38], "body_position": [39, 42], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["boto.configservice.layer1.ConfigServiceConnection", "boto.regioninfo.connect"]}, "requirement": {"Functionality": "Connect to a specific region in the AWS Config service. It creates a connection to the Config service in the specified region using the provided parameters.", "Arguments": ":param region_name: String. The name of the region to connect to.\n:param **kw_params: Additional keyword arguments that can be passed to the connection.\n:return: ConfigServiceConnection. The connection object to the Config service in the specified region."}, "tests": ["tests/unit/test_connect_to_region.py::TestConfigserviceConnection::test_connect_to_region"], "indent": 4}
{"namespace": "pyramid.util.TopologicalSorter.add", "type": "method", "project_path": "Internet/pyramid", "completion_path": "Internet/pyramid/src/pyramid/util.py", "signature_position": [462, 462], "body_position": [481, 499], "dependency": {"intra_class": ["pyramid.util.TopologicalSorter.default_after", "pyramid.util.TopologicalSorter.default_before", "pyramid.util.TopologicalSorter.name2after", "pyramid.util.TopologicalSorter.name2before", "pyramid.util.TopologicalSorter.name2val", "pyramid.util.TopologicalSorter.names", "pyramid.util.TopologicalSorter.order", "pyramid.util.TopologicalSorter.remove", "pyramid.util.TopologicalSorter.req_after", "pyramid.util.TopologicalSorter.req_before"], "intra_file": ["pyramid.util.is_nonstr_iter"], "cross_file": []}, "requirement": {"Functionality": "This function adds a node to the sort input of the TopologicalSorter instance. It assigns a name and a value to the node, and specifies its position relative to other nodes in the sorting order.", "Arguments": ":param self: TopologicalSorter. An instance of the TopologicalSorter class.\n:param name: str or any hashable object. The name of the node to be added.\n:param val: Any sortable object. The value associated with the node.\n:param after: str or sequence of str. The name(s) of the node(s) that should come before the added node in the sorting order. It can also be the special sentinel value FIRST, representing the first position. Defaults to None.\n:param before: String or sequence of strings. The name(s) of the node(s) that should come after the added node in the sorting order. It can also be the special sentinel value LAST, representing the last position. Defaults to None.\n:return: No return values."}, "tests": ["tests/test_util.py::TestTopologicalSorter::test_sorted_ordering_missing_before_and_after_partials", "tests/test_util.py::TestTopologicalSorter::test_sorted_ordering_missing_after_partial", "tests/test_util.py::TestTopologicalSorter::test_sorted_ordering_conflict_indirect", "tests/test_util.py::TestTopologicalSorter::test_add", "tests/test_util.py::TestTopologicalSorter::test_sorted_ordering_with_partial_fallbacks"], "indent": 8}
{"namespace": "alembic.operations.ops.CreateIndexOp.from_index", "type": "method", "project_path": "Database/alembic", "completion_path": "Database/alembic/alembic/operations/ops.py", "signature_position": [897, 897], "body_position": [898, 906], "dependency": {"intra_class": ["alembic.operations.ops.CreateIndexOp.__init__"], "intra_file": [], "cross_file": ["alembic.util.sqla_compat", "alembic.util.sqla_compat._get_index_expressions"]}, "requirement": {"Functionality": "This function creates a CreateIndexOp instance based on the given Index object. It extracts the necessary information from the Index object and uses it to initialize the CreateIndexOp instance.", "Arguments": ":param cls: Class. The class of the CreateIndexOp instance.\n:param index: Index. The Index object from which to create the CreateIndexOp instance.\n:return: CreateIndexOp. The created CreateIndexOp instance."}, "tests": ["tests/test_postgresql.py::PostgresqlAutogenRenderTest::test_render_index_nulls_not_distinct_constraint", "tests/test_autogen_render.py::AutogenRenderTest::test_render_add_index_text", "tests/test_autogen_render.py::AutogenRenderTest::test_render_add_index_func", "tests/test_autogen_render.py::RenderNamingConventionTest::test_render_add_index", "tests/test_postgresql.py::PostgresqlAutogenRenderTest::test_jsonb_expression_in_index"], "indent": 8}
{"namespace": "alembic.script.revision.RevisionMap._topological_sort", "type": "method", "project_path": "Database/alembic", "completion_path": "Database/alembic/alembic/script/revision.py", "signature_position": [912, 916], "body_position": [924, 1014], "dependency": {"intra_class": ["alembic.script.revision.RevisionMap._revision_map"], "intra_file": ["alembic.script.revision.Revision", "alembic.script.revision.Revision._normalized_down_revisions", "alembic.script.revision.Revision._versioned_down_revisions"], "cross_file": []}, "requirement": {"Functionality": "This function performs a topological sort on a collection of Revision objects based on their dependencies. It returns a list of revision ids in the sorted order.", "Arguments": ":param self: RevisionMap. An instance of the RevisionMap class.\n:param revisions: Collection of Revision. A collection of Revision objects to be sorted.\n:param heads: Any. The heads of the revisions to be sorted.\n:return: List of str. The revision ids in the topological sorted order."}, "tests": ["tests/test_revision.py::GraphWithLoopTest::test_revision_dupe_head"], "indent": 8}
{"namespace": "msticpy.analysis.anomalous_sequence.anomalous.score_sessions", "type": "function", "project_path": "Security/msticpy", "completion_path": "Security/msticpy/msticpy/analysis/anomalous_sequence/anomalous.py", "signature_position": [19, 21], "body_position": [57, 78], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["msticpy.analysis.anomalous_sequence.model.Model", "msticpy.analysis.anomalous_sequence.model.Model.compute_rarest_windows", "msticpy.analysis.anomalous_sequence.model.Model.rare_window_likelihoods", "msticpy.analysis.anomalous_sequence.model.Model.rare_windows", "msticpy.analysis.anomalous_sequence.model.Model.train", "msticpy.common.exceptions.MsticpyException"]}, "requirement": {"Functionality": "This function models sessions using a sliding window approach within a Markov model. It takes a DataFrame as input, which should contain a column for sessions. It then trains the model using the sessions data and computes the likelihood metrics for each session based on the specified window length. The function appends two additional columns to the input DataFrame, one for the computed likelihood and another for the rarest window.", "Arguments": ":param data: pd.DataFrame. The DataFrame containing the sessions data.\n:param session_column: str. The name of the column in the DataFrame that contains the sessions.\n:param window_length: int. The length of the sliding window to use when computing the likelihood metrics for each session.\n:return: pd.DataFrame. The input DataFrame with two additional columns appended, one for the computed likelihood and another for the rarest window."}, "tests": ["tests/analysis/test_anom_seq.py::TestAnomalous::test_score_sessions"], "indent": 4}
{"namespace": "sumy._compat.to_unicode", "type": "function", "project_path": "Internet/sumy", "completion_path": "Internet/sumy/sumy/_compat.py", "signature_position": [60, 60], "body_position": [61, 67], "dependency": {"intra_class": [], "intra_file": ["sumy._compat.bytes", "sumy._compat.instance_to_unicode", "sumy._compat.unicode"], "cross_file": []}, "requirement": {"Functionality": "This function converts the input object to a Unicode string. It first checks if the object is already a Unicode string, and if so, returns it as is. If the object is a byte string, it decodes it using the \"utf-8\" encoding and returns the resulting Unicode string. If the object is neither a Unicode string nor a byte string, it calls a custom function to decode it to a Unicode string.", "Arguments": ":param object: Object. The object to be converted to a Unicode string.\n:return: Unicode string. The converted Unicode string."}, "tests": ["tests/test_summarizers/test_edmundson.py::test_title_method_1", "tests/test_utils/test_compat.py::test_str_object_to_unicode", "tests/test_summarizers/test_edmundson.py::test_key_1", "tests/test_summarizers/test_edmundson.py::test_location_method_with_empty_document", "tests/test_html_parser.py::test_annotated_text"], "indent": 4}
{"namespace": "whereami.predict.crossval", "type": "function", "project_path": "Utilities/whereami", "completion_path": "Utilities/whereami/whereami/predict.py", "signature_position": [25, 25], "body_position": [26, 39], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["whereami.get_data.get_train_data", "whereami.pipeline.get_model"]}, "requirement": {"Functionality": "Perform cross-validation on a given classifier using the specified data. First, if the input data X or labels y are not provided, the function will retrieve them from a given path. Then, if the number of samples in X is less than the number of folds, it will raise a ValueError 'There are not enough samples ({length of X}). Need at least {folds number}.'.\nNext, if no classifier model is provided, it will obtain one from the given path.\nIt then prints \"KFold folds={folds number}, running {n} times\". The function then performs cross-validation by iterating n times. In each iteration, it  evaluate the performance of the classifier on each fold, and calculates the average accuracy. After each iteration, it prints \"{iteration number (starting from 1)}/{n}: {average accuracy of the iteration}\". Finally, after all iterations are complete, it prints \"-------- total --------\" and then prints the total average accuracy obtained from all iterations and returns this value.", "Arguments": ":param clf: Classifier. The classifier to be used for cross-validation. If not provided, it retrieves the classifier from the specified path.\n:param X: Array-like. The input data features. If not provided, it retrieves the training data features from the specified path.\n:param y: Array-like. The target variable. If not provided, it retrieves the training data target variable from the specified path.\n:param folds: Integer. The number of folds to be used in cross-validation. Defaults to 10.\n:param n: Integer. The number of times to run cross-validation. Defaults to 5.\n:param path: String. The path to the training data. If not provided, the data is assumed to be already provided in X and y.\n:return: Float. The average score obtained from cross-validation."}, "tests": ["tests/all_test.py::test_crossval"], "indent": 4}
{"namespace": "faker.utils.loading.find_available_locales", "type": "function", "project_path": "Software-Development/Faker", "completion_path": "Software-Development/Faker/faker/utils/loading.py", "signature_position": [41, 41], "body_position": [42, 49], "dependency": {"intra_class": [], "intra_file": ["faker.utils.loading.list_module"], "cross_file": []}, "requirement": {"Functionality": "This function finds and returns a list of available locales based on the given list of providers. It iterates through each provider, imports the provider module, checks if it is localized, and retrieves the list of languages from the module. The available locales are then updated with the languages found and returned in sorted order.", "Arguments": ":param providers: List of strings. A list of provider paths.\n:return: List of strings. A sorted list of available locales."}, "tests": ["tests/utils/test_utils.py::UtilsTestCase::test_find_available_locales"], "indent": 4}
{"namespace": "sacred.utils.iterate_flattened_separately", "type": "function", "project_path": "Utilities/sacred", "completion_path": "Utilities/sacred/sacred/utils.py", "signature_position": [410, 410], "body_position": [418, 435], "dependency": {"intra_class": [], "intra_file": ["sacred.utils.PATHCHANGE", "sacred.utils.is_non_empty_dict", "sacred.utils.iterate_flattened_separately", "sacred.utils.join_paths"], "cross_file": []}, "requirement": {"Functionality": "This function recursively iterates over the items of a dictionary in a specific order. It first iterates over manually sorted keys, then over all items that are non-dictionary values (sorted by keys), and finally over the rest of the items (sorted by keys). It provides full dotted paths for every leaf. Before iterating into non-empty dictionary values, it also yields the key with the path change token as the value.", "Arguments": ":param dictionary: Dictionary. The dictionary to iterate over.\n:param manually_sorted_keys: List of keys. The keys that should be iterated over first, in the specified order. Defaults to an empty list.\n:return: Generator. Yields key-value pairs in the specified order, with full dotted paths for every leaf."}, "tests": ["tests/test_utils.py::test_iterate_flattened_separately"], "indent": 4}
{"namespace": "mrjob.hadoop.HadoopJobRunner._args_for_streaming_step", "type": "method", "project_path": "System/mrjob", "completion_path": "System/mrjob/mrjob/hadoop.py", "signature_position": [479, 479], "body_position": [480, 485], "dependency": {"intra_class": ["mrjob.hadoop.HadoopJobRunner.get_hadoop_bin", "mrjob.hadoop.HadoopJobRunner.get_hadoop_streaming_jar"], "intra_file": [], "cross_file": ["mrjob.bin.MRJobBinRunner._hadoop_streaming_jar_args"]}, "requirement": {"Functionality": "This function returns the arguments needed to run a Hadoop streaming step. It first checks if the Hadoop streaming jar is available. If not, it raises an exception with the error message 'no Hadoop streaming jar'. Then it constructs the command line arguments for the Hadoop streaming step: the Hadoop binary, 'jar', the Hadoop streaming jar, and the arguments for the Hadoop streaming step.", "Arguments": ":param self: HadoopJobRunner. An instance of the HadoopJobRunner class.\n:param step_num: int. The step number for which the arguments are being generated.\n:return: list. The arguments needed to run the Hadoop streaming step."}, "tests": ["tests/test_hadoop.py::StreamingArgsTestCase::test_basic_mapper_pre_yarn", "tests/test_hadoop.py::StreamingArgsTestCase::test_basic_mapper", "tests/test_hadoop.py::StreamingArgsTestCase::test_basic_reducer", "tests/test_hadoop.py::StreamingArgsTestCase::test_pre_filters", "tests/test_hadoop.py::StreamingArgsTestCase::test_pre_filter_escaping"], "indent": 8}
{"namespace": "mingus.core.intervals.is_perfect_consonant", "type": "function", "project_path": "Multimedia/mingus", "completion_path": "Multimedia/mingus/mingus/core/intervals.py", "signature_position": [507, 507], "body_position": [516, 517], "dependency": {"intra_class": [], "intra_file": ["mingus.core.intervals.measure"], "cross_file": []}, "requirement": {"Functionality": "This function checks if the interval between two notes is a perfect consonant. Perfect consonances are either unisons, perfect fourths or fifths, or octaves (which is the same as a unison in this model). Perfect fourths are usually included as well, but can be excluded if desired.\n", "Arguments": ":param note1: str. The first note.\n:param note2: str. The second note.\n:param include_fourths: bool. Whether to include perfect fourths as perfect consonances. Defaults to True. \n:return: bool. True if the interval is a perfect consonant one, False otherwise.\n"}, "tests": ["tests/unit/core/test_intervals.py::test_intervals::test_is_perfect_consonant"], "indent": 4}
{"namespace": "kinto.core.utils.instance_uri_registry", "type": "function", "project_path": "Internet/kinto", "completion_path": "Internet/kinto/kinto/core/utils.py", "signature_position": [495, 495], "body_position": [501, 503], "dependency": {"intra_class": [], "intra_file": ["kinto.core.utils.instance_uri"], "cross_file": []}, "requirement": {"Functionality": "This function returns the URI for a given resource, even if there is no request object available. It creates a dummy request object and sets the registry of the request object to the given registry. Then it find the URI.", "Arguments": ":param registry: The registry object to be set as the registry attribute of the dummy request object.\n:param resource_name: The name of the resource for which the URI is to be generated.\n:param **params: Additional parameters.\n:return: The URI for the given resource."}, "tests": ["tests/core/test_utils.py::InstanceURIRegistryTest::test_instance_uri_registry_calls_instance_uri"], "indent": 4}
{"namespace": "ydata_profiling.controller.console.main", "type": "function", "project_path": "Software-Development/pandas-profiling", "completion_path": "Software-Development/pandas-profiling/src/ydata_profiling/controller/console.py", "signature_position": [99, 99], "body_position": [107, 126], "dependency": {"intra_class": [], "intra_file": ["ydata_profiling.controller.console.parse_args"], "cross_file": ["ydata_profiling.utils.dataframe.read_pandas", "ydata_profiling.profile_report.ProfileReport", "ydata_profiling.profile_report.ProfileReport.to_file"]}, "requirement": {"Functionality": "This function is the main entry point for running another corresponding package. It takes in arguments, parses them, and generates a profiling report based on the input data.", "Arguments": ":param args: Optional list of any type. Arguments for the program. Defaults to None.\n:return: None."}, "tests": ["tests/unit/test_console.py::test_console_single_core", "tests/unit/test_console.py::test_console_minimal", "tests/unit/test_console.py::test_console_explorative", "tests/unit/test_console.py::test_double_config", "tests/issues/test_issue388.py::test_issue388"], "indent": 4}
{"namespace": "mrjob.logs.task._match_task_log_path", "type": "function", "project_path": "System/mrjob", "completion_path": "System/mrjob/mrjob/logs/task.py", "signature_position": [219, 219], "body_position": [230, 250], "dependency": {"intra_class": [], "intra_file": ["mrjob.logs.task._PRE_YARN_TASK_LOG_PATH_RE", "mrjob.logs.task._YARN_TASK_LOG_PATH_RE"], "cross_file": ["mrjob.logs.ids._to_job_id"]}, "requirement": {"Functionality": "This function checks if the given path is a task log path, including Spark logs. If it is, it returns a dictionary containing application_id and container_id (on YARN) or attempt_id (on pre-YARN Hadoop), plus log_type (either stdout, stderr, or syslog). Otherwise, it returns None. If the attempt ID is available but does not match the passed job ID, it returns None. Similarly, if the application ID is available but does not match the passed application ID, it returns None.", "Arguments": ":param path: str. The path or URI to check if it is a task log path.\n:param application_id: str. The application ID to filter the logs by (for YARN). Defaults to None.\n:param job_id: str. The job ID to filter the logs by (for pre-YARN Hadoop). Defaults to None.\n:return: dict or None. A dictionary containing the application ID, container ID or attempt ID, and the log type if the path is a task log path. Otherwise, it returns None."}, "tests": ["tests/logs/test_task.py::MatchTaskLogPathTestCase::test_yarn_syslog_gz", "tests/logs/test_task.py::MatchTaskLogPathTestCase::test_pre_yarn_stderr", "tests/logs/test_task.py::MatchTaskLogPathTestCase::test_match_yarn_stderr", "tests/logs/test_task.py::MatchTaskLogPathTestCase::test_yarn_syslog", "tests/logs/test_task.py::MatchTaskLogPathTestCase::test_pre_yarn_syslog"], "indent": 4}
{"namespace": "boltons.setutils.complement", "type": "function", "project_path": "Utilities/boltons", "completion_path": "Utilities/boltons/boltons/setutils.py", "signature_position": [475, 475], "body_position": [555, 559], "dependency": {"intra_class": [], "intra_file": ["boltons.setutils._ComplementSet", "boltons.setutils._ComplementSet.__init__", "boltons.setutils._ComplementSet.complemented"], "cross_file": []}, "requirement": {"Functionality": "This function takes a set or any other iterable and converts it into a complement set. A complement set keeps track of what it does not contain, unlike a regular set which keeps track of what it contains. The function provides examples and explanations of how complement sets work and their advantages over regular sets.", "Arguments": ":param wrapped: set. A set or any other iterable which should be turned into a complement set.\n:return: _ComplementSet. The created complement set instance."}, "tests": ["tests/test_setutils.py::test_complement_set"], "indent": 4}
{"namespace": "imapclient.imapclient.IMAPClient.idle_done", "type": "method", "project_path": "Communications/IMAPClient", "completion_path": "Communications/IMAPClient/imapclient/imapclient.py", "signature_position": [984, 984], "body_position": [998, 1000], "dependency": {"intra_class": ["imapclient.imapclient.IMAPClient._consume_until_tagged_response", "imapclient.imapclient.IMAPClient._idle_tag", "imapclient.imapclient.IMAPClient._imap"], "intra_file": ["imapclient.imapclient.logger"], "cross_file": []}, "requirement": {"Functionality": "Take the IMAP server out of IDLE mode. It sends the \"DONE\" command to the server and returns the response from the server, which includes the command text and a list of parsed idle responses received since the last call to \"idle_check()\".", "Arguments": ":param self: IMAPClient. An instance of the IMAPClient class.\n:return: Tuple. The return value is a tuple of the form (command_text, idle_responses), where command_text is the text sent by the server when the IDLE command finished and idle_responses is a list of parsed idle responses received since the last call to idle_check()."}, "tests": ["tests/test_imapclient.py::TestIdleAndNoop::test_idle_done"], "indent": 8}
{"namespace": "mackup.utils.get_dropbox_folder_location", "type": "function", "project_path": "Utilities/mackup", "completion_path": "Utilities/mackup/mackup/utils.py", "signature_position": [196, 196], "body_position": [203, 211], "dependency": {"intra_class": [], "intra_file": ["mackup.utils.error"], "cross_file": ["mackup.constants.ERROR_UNABLE_TO_FIND_STORAGE", "mackup.constants"]}, "requirement": {"Functionality": "This function tries to locate the Dropbox folder by reading the host.db file whose path is like \"{home}.dropbox/host\". It then decodes the Dropbox home path and returns it.", "Arguments": ":param: No input parameters.\n:return: str. The full path to the current Dropbox folder."}, "tests": ["tests/utils_test.py::TestMackup::test_failed_backup_location"], "indent": 4}
{"namespace": "barf.analysis.gadgets.classifier.GadgetClassifier.classify", "type": "method", "project_path": "Security/barf", "completion_path": "Security/barf/barf/analysis/gadgets/classifier.py", "signature_position": [104, 104], "body_position": [107, 121], "dependency": {"intra_class": ["barf.analysis.gadgets.classifier.GadgetClassifier._classifiers", "barf.analysis.gadgets.classifier.GadgetClassifier._classify", "barf.analysis.gadgets.classifier.GadgetClassifier._emu_iters"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function classifies gadgets based on their types. It iterates through the classifiers and tries to classify the given gadget using each classifier. If an error occurs during classification, it prints the error message and traceback. Finally, it sorts the classified gadgets and returns them.", "Arguments": ":param self: GadgetClassifier. An instance of the GadgetClassifier class.\n:param gadget: The gadget to be classified.\n:return: List of classified gadgets, sorted by their string representation."}, "tests": ["tests/analysis/gadgets/test_gadget_x86.py::GadgetClassifierTests::test_arithmetic_load_add_3", "tests/analysis/gadgets/test_gadget_x86.py::GadgetClassifierTests::test_arithmetic_load_add_1", "tests/analysis/gadgets/test_gadget_x86.py::GadgetClassifierTests::test_load_constant_2", "tests/analysis/gadgets/test_gadget_x86.py::GadgetClassifierTests::test_move_register_3", "tests/analysis/gadgets/test_gadget_x86.py::GadgetClassifierTests::test_move_register_4"], "indent": 8}
{"namespace": "tools.cgrep.group_diff", "type": "function", "project_path": "Security/capirca", "completion_path": "Security/capirca/tools/cgrep.py", "signature_position": [301, 301], "body_position": [312, 321], "dependency": {"intra_class": [], "intra_file": ["tools.cgrep.get_ip_parents"], "cross_file": []}, "requirement": {"Functionality": "This function compares two different group objects and returns the common lines, the differences from the first object to the second object, and the differences from the second object to the first object.", "Arguments": ":param options: The options sent to the script.\n:param db: The network and service definitions.\n:return: tuple. The common lines, the differences from the first object to the second object, and the differences from the second object to the first object."}, "tests": ["tests/lib/cgrep_test.py::CgrepTest::test_group_diff", "tests/lib/cgrep_test.py::CgrepTest::test_group_diff_identical"], "indent": 2}
{"namespace": "pylatex.utils._latex_item_to_string", "type": "function", "project_path": "Text-Processing/PyLaTeX", "completion_path": "Text-Processing/PyLaTeX/pylatex/utils.py", "signature_position": [204, 204], "body_position": [223, 234], "dependency": {"intra_class": [], "intra_file": ["pylatex.utils.escape_latex"], "cross_file": ["pylatex.base_classes.latex_object.LatexObject", "pylatex.base_classes", "pylatex.base_classes.latex_object.LatexObject.dumps", "pylatex.base_classes.latex_object.LatexObject.dumps_as_content"]}, "requirement": {"Functionality": "This function converts an object to a string representation in LaTeX format. It first checks if the input object is a Latex object and further convert the latex into a string. If the input object is not a Latex object, the function converts it to a string. Then, the function escapes the LaTeX special characters in the string based on the input parameter `escape` and returns the string.", "Arguments": ":param item: object. The object that needs to be converted to a string.\n:param escape: bool. Flag that indicates if escaping is needed for LaTeX special characters.\n:param as_content: bool. Indicates whether the item should be dumped as content.\n:return: NoEscape. The converted string in LaTeX format."}, "tests": ["tests/test_utils_latex_item_to_string.py::test_string", "tests/test_utils_latex_item_to_string.py::test_user_latex_object", "tests/test_utils_latex_item_to_string.py::test_foreign_object"], "indent": 4}
{"namespace": "chatette.parsing.UnitDefBuilder._build_modifiers_repr", "type": "method", "project_path": "Communications/chatette", "completion_path": "Communications/chatette/chatette/parsing/__init__.py", "signature_position": [125, 125], "body_position": [126, 128], "dependency": {"intra_class": ["chatette.parsing.UnitDefBuilder.arg_name"], "intra_file": ["chatette.parsing.ItemBuilder", "chatette.parsing.ItemBuilder._build_modifiers_repr"], "cross_file": ["chatette.modifiers.representation.ModifiersRepresentation.argument_name"]}, "requirement": {"Functionality": "This function builds the representation of modifiers for a UnitDefBuilder instance. It first gets the modifiers, then sets the argument name of the modifiers to the arg name of the UnitDefBuilder instance. Finally, it returns the modifiers.", "Arguments": ":param self: UnitDefBuilder. An instance of the UnitDefBuilder class.\n:return: The representation of modifiers for the UnitDefBuilder instance."}, "tests": ["tests/unit-testing/parsing/test_init.py::TestAliasDefBuilder::test_create_concrete", "tests/unit-testing/parsing/test_init.py::TestSlotDefBuilder::test_create_concrete", "tests/unit-testing/parsing/test_init.py::TestIntentDefBuilder::test_create_concrete"], "indent": 8}
{"namespace": "parsel.utils.extract_regex", "type": "function", "project_path": "Text-Processing/parsel", "completion_path": "Text-Processing/parsel/parsel/utils.py", "signature_position": [58, 60], "body_position": [66, 84], "dependency": {"intra_class": [], "intra_file": ["parsel.utils.flatten"], "cross_file": []}, "requirement": {"Functionality": "This function extracts a list of strings from the given text using a regular expression. It follows certain policies to determine which strings to extract:\n- If the regular expression contains a named group called \"extract\", the value of that group will be returned.\n- If the regular expression contains multiple numbered groups, all those groups will be returned as a flattened list.\n- If the regular expression doesn't contain any groups, the entire matching string will be returned.", "Arguments": ":param regex: Union[str, Pattern[str]]. The regular expression pattern to match against the text. It can be either a string or a compiled regular expression pattern.\n:param text: str. The text to search for matches.\n:param replace_entities: bool. Optional. Whether to replace HTML entities in the extracted strings. Defaults to True.\n:return: List[str]. A list of extracted strings from the text."}, "tests": ["tests/test_utils.py::test_extract_regex"], "indent": 4}
{"namespace": "mingus.containers.note.Note.from_int", "type": "method", "project_path": "Multimedia/mingus", "completion_path": "Multimedia/mingus/mingus/containers/note.py", "signature_position": [202, 202], "body_position": [211, 213], "dependency": {"intra_class": ["mingus.containers.note.Note.name", "mingus.containers.note.Note.octave"], "intra_file": [], "cross_file": ["mingus.core.notes", "mingus.core.notes.int_to_note"]}, "requirement": {"Functionality": "This function sets the Note instance based on the given integer value. It calculates the name and octave of the Note based on the integer value.\n", "Arguments": ":param self: Note. An instance of the Note class.\n:param integer: int. The integer value representing the Note.\n:return: Note. The Note instance with the name and octave set based on the given integer value.\n"}, "tests": ["tests/unit/containers/test_note.py::test_Note::test_from_int"], "indent": 8}
{"namespace": "datasette.utils.call_with_supported_arguments", "type": "function", "project_path": "Database/datasette", "completion_path": "Database/datasette/datasette/utils/__init__.py", "signature_position": [1003, 1003], "body_position": [1004, 1005], "dependency": {"intra_class": [], "intra_file": ["datasette.utils._gather_arguments"], "cross_file": []}, "requirement": {"Functionality": "This function calls the given function with the supported arguments. It gathers the arguments that are supported by the function and then calls the function with those arguments.", "Arguments": ":param fn: Function. The function to be called.\n:param kwargs: Keyword arguments. The arguments to be passed to the function.\n:return: The return value of the function call."}, "tests": ["tests/test_utils.py::test_call_with_supported_arguments"], "indent": 4}
{"namespace": "wal_e.log_help.WalELogger.fmt_logline", "type": "method", "project_path": "System/wal-e", "completion_path": "System/wal-e/wal_e/log_help.py", "signature_position": [161, 161], "body_position": [162, 179], "dependency": {"intra_class": ["wal_e.log_help.WalELogger._fmt_structured"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Format a log line with the given message, detail, hint, and structured data. It creates a list to format these information, and the forst is \"['MSG: {message}', 'DETAIL: {detail}', 'HINT: {hint}', 'STRUCTURED: {structured data}']\". Then, it joins them with a newline character to obtain the log line.", "Arguments": ":param msg: String. The main message to be included in the log line.\n:param detail: String [optional]. Additional details to be included in the log line.\n:param hint: String [optional]. A hint or suggestion related to the log message.\n:param structured: Dictionary [optional]. Additional structured data to be included in the log line.\n:return: String. The formatted log line."}, "tests": ["tests/test_log_help.py::test_fmt_logline_simple"], "indent": 8}
{"namespace": "jwt.algorithms.HMACAlgorithm.from_jwk", "type": "method", "project_path": "Utilities/PyJWT", "completion_path": "Utilities/PyJWT/jwt/algorithms.py", "signature_position": [290, 290], "body_position": [291, 304], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["jwt.exceptions.InvalidKeyError", "jwt.types.JWKDict", "jwt.utils.base64url_decode"]}, "requirement": {"Functionality": "This function takes a JWK (JSON Web Key) as input and returns the corresponding HMAC (Hash-based Message Authentication Code) key. It first checks if the input is a valid JSON string or dictionary. Then, it verifies if the key type is \"oct\" (indicating HMAC). Finally, it decodes and returns the HMAC key.", "Arguments": ":param jwk: str or JWKDict. The JWK (JSON Web Key) to extract the HMAC key from. It can be either a JSON string or a dictionary.\n:return: bytes. The extracted HMAC key."}, "tests": ["tests/test_algorithms.py::TestAlgorithms::test_hmac_from_jwk_should_raise_exception_if_not_hmac_key", "tests/test_algorithms.py::TestAlgorithms::test_hmac_jwk_should_parse_and_verify"], "indent": 8}
{"namespace": "pyramid.util.InstancePropertyHelper.apply", "type": "method", "project_path": "Internet/pyramid", "completion_path": "Internet/pyramid/src/pyramid/util.py", "signature_position": [184, 184], "body_position": [186, 187], "dependency": {"intra_class": ["pyramid.util.InstancePropertyHelper.apply_properties", "pyramid.util.InstancePropertyHelper.properties"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function applies all the configured properties to the target instance.", "Arguments": ":param self: InstancePropertyHelper. An instance of the InstancePropertyHelper class.\n:param target: The target instance to which the properties will be applied.\n:return: No return values."}, "tests": ["tests/test_util.py::Test_InstancePropertyHelper::test_add_property", "tests/test_util.py::Test_InstancePropertyHelper::test_apply_multiple_times"], "indent": 8}
{"namespace": "wikipediaapi.WikipediaPage.categorymembers", "type": "method", "project_path": "Communications/Wikipedia-API", "completion_path": "Communications/Wikipedia-API/wikipediaapi/__init__.py", "signature_position": [1047, 1047], "body_position": [1058, 1060], "dependency": {"intra_class": ["wikipediaapi.WikipediaPage._called", "wikipediaapi.WikipediaPage._categorymembers", "wikipediaapi.WikipediaPage._fetch"], "intra_file": ["wikipediaapi.PagesDict"], "cross_file": []}, "requirement": {"Functionality": "This function returns all pages belonging to the current category. It is a wrapper for the MediaWiki API's query+categorymembers module.", "Arguments": ":param self: WikipediaPage. An instance of the WikipediaPage class.\n:return: PagesDict. A dictionary containing all pages belonging to the current category."}, "tests": ["tests/categorymembers_test.py::TestCategoryMembers::test_links_multi_page_count", "tests/categorymembers_test.py::TestCategoryMembers::test_links_single_page_titles", "tests/categorymembers_test.py::TestCategoryMembers::test_links_single_page_count", "tests/categorymembers_test.py::TestCategoryMembers::test_links_multi_page_titles"], "indent": 8}
{"namespace": "rest_framework.templatetags.rest_framework.add_query_param", "type": "function", "project_path": "Internet/djangorestframework", "completion_path": "Internet/djangorestframework/rest_framework/templatetags/rest_framework.py", "signature_position": [148, 148], "body_position": [152, 155], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["rest_framework.utils.urls.replace_query_param"]}, "requirement": {"Functionality": "This function adds a query parameter to the current request URL and returns the new URL. It first gets the full path of the request URL, converts it to a URI, replaces the query parameter with the given key and value, and then escapes the URI before returning it.", "Arguments": ":param request: The current request object.\n:param key: The key of the query parameter to be added.\n:param val: The value of the query parameter to be added.\n:return: The new URL with the added query parameter."}, "tests": ["tests/test_templatetags.py::TemplateTagTests::test_add_query_param_with_non_latin_character"], "indent": 4}
{"namespace": "zxcvbn.scoring.dictionary_guesses", "type": "function", "project_path": "Security/zxcvbn-python", "completion_path": "Security/zxcvbn-python/zxcvbn/scoring.py", "signature_position": [263, 264], "body_position": [265, 271], "dependency": {"intra_class": [], "intra_file": ["zxcvbn.scoring.l33t_variations", "zxcvbn.scoring.uppercase_variations"], "cross_file": []}, "requirement": {"Functionality": "Calculate the number of guesses needed to crack a password based on the given match. It calculates the base guesses, uppercase variations, l33t variations, and reversed variations, and returns the product of these values.", "Arguments": ":param match: Dictionary. A dictionary containing information about the password match, including the rank, whether it is reversed, and other properties.\n:return: Integer. The number of guesses needed to crack the password."}, "tests": ["tests/scoring_test.py::test_dictionary_guesses"], "indent": 4}
{"namespace": "mrjob.job.MRJob.execute", "type": "method", "project_path": "System/mrjob", "completion_path": "System/mrjob/mrjob/job.py", "signature_position": [676, 678], "body_position": [679, 692], "dependency": {"intra_class": ["mrjob.job.MRJob.options", "mrjob.job.MRJob.run_combiner", "mrjob.job.MRJob.run_job", "mrjob.job.MRJob.run_mapper", "mrjob.job.MRJob.run_reducer", "mrjob.job.MRJob.run_spark"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function executes a MapReduce job based on the options specified. It checks the value of the options and calls the corresponding method to run the mapper, combiner, reducer, or spark job. If none of the options are specified, it just runs job.", "Arguments": ":param self: MRJob. An instance of the MRJob class.\n:return: No return values."}, "tests": ["tests/test_job.py::RunSparkTestCase::test_spark", "tests/test_job.py::RunSparkTestCase::test_too_many_args", "tests/test_job.py::RunSparkTestCase::test_wrong_step_num", "tests/test_job.py::RunSparkTestCase::test_too_few_args", "tests/test_job.py::RunSparkTestCase::test_wrong_step_type"], "indent": 8}
{"namespace": "falcon.inspect.inspect_app", "type": "function", "project_path": "Internet/falcon", "completion_path": "Internet/falcon/falcon/inspect.py", "signature_position": [29, 29], "body_position": [41, 46], "dependency": {"intra_class": [], "intra_file": ["falcon.inspect.AppInfo", "falcon.inspect.AppInfo.__init__", "falcon.inspect.inspect_error_handlers", "falcon.inspect.inspect_middleware", "falcon.inspect.inspect_routes", "falcon.inspect.inspect_sinks", "falcon.inspect.inspect_static_routes"], "cross_file": ["falcon.app.App", "falcon.app.App._ASGI"]}, "requirement": {"Functionality": "This function inspects an application by calling several helper functions to gather information about the routes, static routes, sinks, error handlers, and middleware of the application. It then creates an AppInfo object with the gathered information and returns it.", "Arguments": ":param app: App. The application to inspect. It can be an instance of either `falcon.App` or `falcon.asgi.App`.\n:return: AppInfo. An object containing information about the application."}, "tests": ["tests/test_inspect.py::TestStringVisitor::test_app_no_sink", "tests/test_inspect.py::TestStringVisitor::test_app_no_errors", "tests/test_inspect.py::TestStringVisitor::test_app_static_routes", "tests/test_inspect.py::TestInspectApp::test_dependent_middleware", "tests/test_inspect.py::test_info_class_repr_to_string"], "indent": 4}
{"namespace": "sumy.evaluation.rouge._recon_lcs", "type": "function", "project_path": "Internet/sumy", "completion_path": "Internet/sumy/sumy/evaluation/rouge.py", "signature_position": [81, 81], "body_position": [90, 104], "dependency": {"intra_class": [], "intra_file": ["sumy.evaluation.rouge._get_index_of_lcs", "sumy.evaluation.rouge._lcs"], "cross_file": []}, "requirement": {"Functionality": "This function returns the Longest Common Subsequence (LCS) between two sequences of words. It designs a helper function to recursively reconstruct the LCS based on a table that saves the length of LCS at any position.", "Arguments": ":param x: List of words. The first sequence of words.\n:param y: List of words. The second sequence of words.\n:return: List of words. The LCS of x and y."}, "tests": ["tests/test_evaluation/test_evaluation_rouge.py::test_recon_lcs"], "indent": 4}
{"namespace": "alembic.operations.ops.DropIndexOp.to_index", "type": "method", "project_path": "Database/alembic", "completion_path": "Database/alembic/alembic/operations/ops.py", "signature_position": [1060, 1062], "body_position": [1063, 1073], "dependency": {"intra_class": ["alembic.operations.ops.DropIndexOp._reverse", "alembic.operations.ops.DropIndexOp.index_name", "alembic.operations.ops.DropIndexOp.kw", "alembic.operations.ops.DropIndexOp.schema", "alembic.operations.ops.DropIndexOp.table_name"], "intra_file": ["alembic.operations.ops.CreateIndexOp.columns"], "cross_file": ["alembic.operations.schemaobj", "alembic.operations.schemaobj.SchemaObjects", "alembic.operations.schemaobj.SchemaObjects.index", "alembic.runtime.migration.MigrationContext"]}, "requirement": {"Functionality": "This function converts a DropIndexOp instance into an Index instance. It creates a schema object based on the given migration context and then creates an index using the index name, table name, columns, schema, and other keyword arguments provided in the DropIndexOp instance.", "Arguments": ":param self: DropIndexOp. An instance of the DropIndexOp class.\n:param migration_context: Optional. An optional MigrationContext object. Defaults to None.\n:return: Index. The created Index instance."}, "tests": ["tests/test_autogen_diffs.py::OrigObjectTest::test_create_index", "tests/test_op.py::ObjectFromToTest::test_create_index_add_kw", "tests/test_op.py::ObjectFromToTest::test_drop_index_add_kw", "tests/test_autogen_diffs.py::OrigObjectTest::test_drop_index"], "indent": 8}
{"namespace": "pyramid.util.InstancePropertyHelper.set_property", "type": "method", "project_path": "Internet/pyramid", "completion_path": "Internet/pyramid/src/pyramid/util.py", "signature_position": [170, 170], "body_position": [172, 173], "dependency": {"intra_class": ["pyramid.util.InstancePropertyHelper.apply_properties", "pyramid.util.InstancePropertyHelper.make_property"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function applies a single property to an instance. It creates a property using the given callable and optional name and reify parameters, and then applies the property to the target instance.", "Arguments": ":param cls: type. InstancePropertyHelper.\n:param target: The instance to apply the property to.\n:param callable: The callable object that defines the behavior of the property.\n:param name: str. The name of the property. If not specified, the name of the callable is used. Defaults to None.\n:param reify: bool. A boolean indicating whether the property should be reified. Defaults to False.\n:return: No return values."}, "tests": ["tests/test_util.py::Test_InstancePropertyHelper::test_callable_with_name_reify", "tests/test_util.py::Test_InstancePropertyHelper::test_callable_with_name", "tests/test_util.py::Test_InstancePropertyHelper::test_callable", "tests/test_util.py::Test_InstancePropertyHelper::test_property_with_reify", "tests/test_util.py::Test_InstancePropertyHelper::test_property_with_name"], "indent": 8}
{"namespace": "mopidy.config.types.LogColor.deserialize", "type": "method", "project_path": "Multimedia/Mopidy", "completion_path": "Multimedia/Mopidy/mopidy/config/types.py", "signature_position": [339, 339], "body_position": [340, 342], "dependency": {"intra_class": [], "intra_file": ["mopidy.config.types.decode"], "cross_file": ["mopidy.config.validators.validate_choice", "mopidy.internal.log.COLORS", "mopidy.config.validators", "mopidy.internal.log"]}, "requirement": {"Functionality": "Deserialize a value by decoding it and validating if it is a valid choice from a list of colors. It returns the lowercase value.", "Arguments": ":param self: LogColor. An instance of the LogColor class.\n:param value: The value to be deserialized.\n:return: The deserialized value."}, "tests": ["tests/config/test_types.py::TestLogColor::test_deserialize", "tests/config/test_types.py::TestLogColor::test_deserialize_enforces_choices"], "indent": 8}
{"namespace": "bentoml._internal.models.model.Model.from_fs", "type": "method", "project_path": "Scientific-Engineering/bentoml", "completion_path": "Scientific-Engineering/bentoml/src/bentoml/_internal/models/model.py", "signature_position": [219, 219], "body_position": [220, 234], "dependency": {"intra_class": ["bentoml._internal.models.model.Model.__init__", "bentoml._internal.models.model.Model.validate"], "intra_file": ["bentoml._internal.models.model.MODEL_YAML_FILENAME", "bentoml._internal.models.model.ModelInfo", "bentoml._internal.models.model.ModelInfo.from_yaml_file", "bentoml._internal.models.model.ModelInfo.tag"], "cross_file": ["bentoml.exceptions.BentoMLException"]}, "requirement": {"Functionality": "This function creates a Model instance based on the given item_fs. It reads the model information from the yaml file in the item_fs and creates a ModelInfo object. Then it creates a Model instance with the tag, model_fs, info, and _internal attributes set. Finally, it validates the created Model instance and returns it.", "Arguments": ":param cls: Type[Model]. The class object of the Model class.\n:param item_fs: FS. The file system object from which to read the model information.\n:return: Model. The created Model instance."}, "tests": ["tests/unit/_internal/models/test_model.py::test_load_bad_model", "tests/unit/_internal/models/test_model.py::test_model_export_import"], "indent": 8}
{"namespace": "mingus.core.intervals.minor_third", "type": "function", "project_path": "Multimedia/mingus", "completion_path": "Multimedia/mingus/mingus/core/intervals.py", "signature_position": [178, 178], "body_position": [179, 180], "dependency": {"intra_class": [], "intra_file": ["mingus.core.intervals.augment_or_diminish_until_the_interval_is_right", "mingus.core.intervals.third"], "cross_file": []}, "requirement": {"Functionality": "This function returns the minor third note above the given note.\n", "Arguments": ":param note: str. The starting note for calculating the minor third interval.\n:return: str. The adjusted note that represents a minor third interval above the given note.\n"}, "tests": ["tests/unit/core/test_intervals.py::test_intervals::test_minor_thirds"], "indent": 4}
{"namespace": "alembic.operations.schemaobj.SchemaObjects.unique_constraint", "type": "method", "project_path": "Database/alembic", "completion_path": "Database/alembic/alembic/operations/schemaobj.py", "signature_position": [121, 128], "body_position": [129, 140], "dependency": {"intra_class": ["alembic.operations.schemaobj.SchemaObjects.metadata"], "intra_file": [], "cross_file": ["alembic.util.sqla_compat", "alembic.util.sqla_compat._ConstraintNameDefined"]}, "requirement": {"Functionality": "Create a unique constraint on a table in the schema. It creates a table object based on the input parameters and adds a unique constraint to it. The table object is then updated with the new constraint.", "Arguments": ":param self: SchemaObjects. An instance of the `SchemaObjects` class.\n:param name: Optional. The name of the unique constraint. If not provided, a default name will be generated.\n:param source: String. The name of the table on which the unique constraint is to be created.\n:param local_cols: Sequence of strings. The names of the columns on which the unique constraint is to be applied.\n:param schema: Optional. The name of the schema in which the table resides. If not provided, the default schema will be used.\n:param kw: Additional keyword arguments that can be passed to the UniqueConstraint constructor.\n:return: UniqueConstraint. The created unique constraint object."}, "tests": ["tests/test_op.py::ObjectFromToTest::test_create_unique_constraint", "tests/test_op.py::ObjectFromToTest::test_drop_unique_constraint_change_name", "tests/test_op.py::ObjectFromToTest::test_drop_unique_constraint", "tests/test_op.py::ObjectFromToTest::test_create_unique_constraint_add_kw"], "indent": 8}
{"namespace": "dash._grouping.validate_grouping", "type": "function", "project_path": "Software-Development/dash", "completion_path": "Software-Development/dash/dash/_grouping.py", "signature_position": [201, 201], "body_position": [206, 224], "dependency": {"intra_class": [], "intra_file": ["dash._grouping.SchemaKeysValidationError", "dash._grouping.SchemaKeysValidationError.check", "dash._grouping.SchemaLengthValidationError", "dash._grouping.SchemaLengthValidationError.check", "dash._grouping.SchemaTypeValidationError", "dash._grouping.SchemaTypeValidationError.check", "dash._grouping.validate_grouping"], "cross_file": []}, "requirement": {"Functionality": "This function validates whether the provided grouping conforms to the provided schema. If full shema is none, it use the schema to replace. It recursively checks the grouping against the schema and raises an error by different type of shcema to check the grouping, full schema, path and different expected_type like type, length, set.", "Arguments": ":param grouping: The grouping to be validated.\n:param schema: The schema to validate against.\n:param full_schema: Optional. The full schema to use for validation. Defaults to the provided schema.\n:param path: Optional. The current path in the schema. Defaults to an empty tuple.\n:return: No return values. Raises a SchemaValidationError if the validation fails."}, "tests": ["tests/unit/library/test_grouping.py::test_validate_schema_mixed", "tests/unit/library/test_grouping.py::test_validate_schema_grouping_list", "tests/unit/library/test_grouping.py::test_validate_schema_dict"], "indent": 4}
{"namespace": "ydata_profiling.model.summarizer.BaseSummarizer.summarize", "type": "method", "project_path": "Software-Development/pandas-profiling", "completion_path": "Software-Development/pandas-profiling/src/ydata_profiling/model/summarizer.py", "signature_position": [34, 36], "body_position": [42, 43], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["ydata_profiling.config.Settings", "ydata_profiling.model.handler.Handler.handle"]}, "requirement": {"Functionality": "This function summarizes a given series of data based on the specified configuration and data type.", "Arguments": ":param self: BaseSummarizer. An instance of the BaseSummarizer class.\n:param config: Settings. The configuration settings for the summarization process.\n:param series: pd.Series. The series of data to be summarized.\n:param dtype: Type[VisionsBaseType]. The data type of the series.\n:return: dict. The summary of the data."}, "tests": ["tests/unit/test_summarizer.py::test_summarizer"], "indent": 8}
{"namespace": "alembic.command.merge", "type": "function", "project_path": "Database/alembic", "completion_path": "Database/alembic/alembic/command.py", "signature_position": [302, 308], "body_position": [326, 355], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["alembic.config.Config", "alembic.config.Config.get_main_option", "alembic.runtime.environment.EnvironmentContext", "alembic.script.base.Script", "alembic.script.revision._RevIdType", "alembic.script.ScriptDirectory.from_config", "alembic.script.ScriptDirectory.generate_revision", "alembic.script.ScriptDirectory.run_env", "alembic.util", "alembic.util.rev_id"]}, "requirement": {"Functionality": "This function merges two revisions together and creates a new migration file. It uses the provided input parameters to configure the merge process and generate the revision.", "Arguments": ":param config: Config. An instance of the Config class.\n:param revisions: _RevIdType. The revisions to be merged.\n:param message: Optional string. The message to apply to the new revision.\n:param branch_label: Optional _RevIdType. The label name to apply to the new revision.\n:param rev_id: Optional string. The hardcoded revision identifier instead of generating a new one.\n:return: Optional Script. The generated migration script."}, "tests": ["tests/test_command.py::RevisionEnvironmentTest::test_merge_cmd_revision_environment", "tests/test_command.py::RevisionTest::test_create_rev_autogenerate_post_merge", "tests/test_command.py::RevisionTest::test_create_rev_autogenerate_db_not_up_to_date_post_merge", "tests/test_command.py::RevisionTest::test_create_rev_plain_post_merge"], "indent": 4}
{"namespace": "pyinfra.connectors.ansible.AnsibleInventoryConnector.make_names_data", "type": "method", "project_path": "System/pyinfra", "completion_path": "System/pyinfra/pyinfra/connectors/ansible.py", "signature_position": [44, 44], "body_position": [45, 55], "dependency": {"intra_class": [], "intra_file": ["pyinfra.connectors.ansible.parse_inventory", "pyinfra.connectors.ansible.show_warning"], "cross_file": ["pyinfra.api.exceptions.InventoryError"]}, "requirement": {"Functionality": "This function reads an Ansible inventory file and returns the parsed data. It first checks if the inventory filename is provided, and if not, raises an inventory error \"No Ansible inventory filename provided!\" Then it checks if the inventory file exists, and if not, raises an InventoryError \"Could not find Ansible inventory file: {0}\". Finally, it parses the inventory file and returns the parsed data.", "Arguments": ":param inventory_filename: Optional[str]. The filename of the Ansible inventory file. Defaults to None.\n:return: The parsed data from the Ansible inventory file."}, "tests": ["tests/test_connectors/test_ansible.py::TestAnsibleConnector::test_make_names_data_ini", "tests/test_connectors/test_ansible.py::TestAnsibleConnector::test_make_names_data_no_file", "tests/test_connectors/test_ansible.py::TestAnsibleConnector::test_make_names_data_json"], "indent": 8}
{"namespace": "pyinfra.operations.files.put", "type": "function", "project_path": "System/pyinfra", "completion_path": "System/pyinfra/pyinfra/operations/files.py", "signature_position": [782, 792], "body_position": [842, 928], "dependency": {"intra_class": [], "intra_file": ["pyinfra.operations.files._create_remote_dir"], "cross_file": ["pyinfra.api.util.get_call_location", "pyinfra.api.util.get_file_sha1", "pyinfra.api.util.get_path_permissions_mode", "pyinfra.facts.files.Directory", "pyinfra.facts.files.File", "pyinfra.facts.files.Sha1File", "pyinfra.logger", "pyinfra.operations.util.files.chmod", "pyinfra.operations.util.files.chown", "pyinfra.operations.util.files.ensure_mode_int", "pyinfra.operations.util.files.unix_path_join", "pyinfra.api.host.Host.get_fact", "pyinfra.api.host.Host.noop", "pyinfra.operations.util.files", "pyinfra.api.state.State.get_temp_filename"]}, "requirement": {"Functionality": "This function uploads a local file or file-like object to a remote system. It allows for specifying various parameters such as the user, group, mode, and destination directory. It also provides options for creating the remote directory if it doesn't exist and forcing the upload even if the remote copy matches.", "Arguments": ":param src: The filename or IO-like object to upload.\n:param dest: The remote filename to upload to.\n:param user: The user to own the files.\n:param group: The group to own the files.\n:param mode: The permissions of the files. Use \"True\" to copy the local file.\n:param add_deploy_dir: Whether the src is relative to the deploy directory.\n:param create_remote_dir: Whether to create the remote directory if it doesn't exist.\n:param force: Whether to always upload the file, even if the remote copy matches.\n:param assume_exists: Whether to assume the local file exists.\n:return: No return values."}, "tests": ["tests/test_api/test_api_operations.py::TestOperationsApi::test_file_upload_op"], "indent": 4}
{"namespace": "mrjob.job.MRJob.run_job", "type": "method", "project_path": "System/mrjob", "completion_path": "System/mrjob/mrjob/job.py", "signature_position": [620, 620], "body_position": [630, 649], "dependency": {"intra_class": ["mrjob.job.MRJob._should_cat_output", "mrjob.job.MRJob.make_runner", "mrjob.job.MRJob.options", "mrjob.job.MRJob.set_up_logging", "mrjob.job.MRJob.stderr", "mrjob.job.MRJob.stdout"], "intra_file": ["mrjob.job.log"], "cross_file": ["mrjob.step.StepFailedException"]}, "requirement": {"Functionality": "This function runs all the steps of a job. It sets up logging, creates a runner, and runs the job. If any step fails, it logs the error and exits the program. If the output needs to be concatenated, it writes the output to the standard output stream.", "Arguments": ":param self: MRJob. An instance of the MRJob class.\n:return: No return values."}, "tests": ["tests/test_local.py::ExitWithoutExceptionTestCase::test_exit_42_job", "tests/test_job.py::LaunchJobTestCase::test_output", "tests/test_job.py::LaunchJobTestCase::test_output_dir_with_explicit_cat_output", "tests/test_job.py::LaunchJobTestCase::test_exit_on_step_failure", "tests/test_job.py::LaunchJobTestCase::test_pass_through_other_exceptions"], "indent": 8}
{"namespace": "kinto.core.storage.postgresql.migrator.MigratorMixin.create_or_migrate_schema", "type": "method", "project_path": "Internet/kinto", "completion_path": "Internet/kinto/kinto/core/storage/postgresql/migrator.py", "signature_position": [42, 42], "body_position": [44, 54], "dependency": {"intra_class": ["kinto.core.storage.postgresql.migrator.MigratorMixin.create_schema", "kinto.core.storage.postgresql.migrator.MigratorMixin.get_installed_version", "kinto.core.storage.postgresql.migrator.MigratorMixin.migrate_schema", "kinto.core.storage.postgresql.migrator.MigratorMixin.name", "kinto.core.storage.postgresql.migrator.MigratorMixin.schema_version"], "intra_file": ["kinto.core.storage.postgresql.migrator.logger"], "cross_file": []}, "requirement": {"Functionality": "This function either creates a new schema or migrates an existing schema based on the current version. If there is no existing version, it creates a new schema. If the current version matches the desired schema version, it logs that the schema is up-to-date. Otherwise, it migrates the schema to the desired version.", "Arguments": ":param self: MigratorMixin. An instance of the MigratorMixin class.\n:param dry_run: Bool. Whether to perform a dry run of the schema creation or migration. Defaults to False.\n:return: None."}, "tests": ["tests/core/test_storage_migrations.py::MigratorTest::test_schema_is_created_if_no_version", "tests/core/test_storage_migrations.py::MigratorTest::test_migration_files_are_listed_if_ran_with_dry_run", "tests/core/test_storage_migrations.py::MigratorTest::test_migration_fails_if_intermediary_version_is_missing", "tests/core/test_storage_migrations.py::MigratorTest::test_migration_file_is_executed_for_every_intermediary_version"], "indent": 8}
{"namespace": "prometheus_client.mmap_dict.MmapedDict.write_value", "type": "method", "project_path": "System/prometheus-client", "completion_path": "System/prometheus-client/prometheus_client/mmap_dict.py", "signature_position": [127, 127], "body_position": [128, 131], "dependency": {"intra_class": ["prometheus_client.mmap_dict.MmapedDict._init_value", "prometheus_client.mmap_dict.MmapedDict._m", "prometheus_client.mmap_dict.MmapedDict._positions"], "intra_file": ["prometheus_client.mmap_dict._pack_two_doubles"], "cross_file": []}, "requirement": {"Functionality": "This function writes a value to a key in the MmapedDict instance. If the key does not exist in the instance, it initializes the key and then writes the value and timestamp to the corresponding position in the memory-mapped file.", "Arguments": ":param self: MmapedDict. An instance of the MmapedDict class.\n:param key: The key to write the value to.\n:param value: The value to be written.\n:param timestamp: The timestamp associated with the value.\n:return: No return values."}, "tests": ["tests/test_multiprocess.py::TestMmapedDict::test_corruption_detected", "tests/test_multiprocess.py::TestMmapedDict::test_multi_expansion", "tests/test_multiprocess.py::TestMmapedDict::test_expansion", "tests/test_multiprocess.py::TestMmapedDict::test_process_restart"], "indent": 8}
{"namespace": "pyramid.authentication.RepozeWho1AuthenticationPolicy.forget", "type": "method", "project_path": "Internet/pyramid", "completion_path": "Internet/pyramid/src/pyramid/authentication.py", "signature_position": [363, 363], "body_position": [370, 374], "dependency": {"intra_class": ["pyramid.authentication.RepozeWho1AuthenticationPolicy._get_identifier", "pyramid.authentication.RepozeWho1AuthenticationPolicy._get_identity"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function is used to forget the current authenticated user. It returns headers that, if included in a response, will delete the cookie responsible for tracking the current user.", "Arguments": ":param self: RepozeWho1AuthenticationPolicy. An instance of the RepozeWho1AuthenticationPolicy class.\n:param request: The current request object.\n:return: List of headers. The headers that, if included in a response, will delete the user tracking cookie."}, "tests": ["tests/test_authentication.py::TestRepozeWho1AuthenticationPolicy::test_forget", "tests/test_authentication.py::TestRepozeWho1AuthenticationPolicy::test_forget_no_plugins"], "indent": 8}
{"namespace": "sumy._compat.to_bytes", "type": "function", "project_path": "Internet/sumy", "completion_path": "Internet/sumy/sumy/_compat.py", "signature_position": [50, 50], "body_position": [51, 57], "dependency": {"intra_class": [], "intra_file": ["sumy._compat.bytes", "sumy._compat.instance_to_bytes", "sumy._compat.unicode"], "cross_file": []}, "requirement": {"Functionality": "Convert the input object to bytes. If the object is already of type bytes, it is returned as is. If the object is of type unicode, it is encoded to UTF-8 and returned. Otherwise, the function tries to encode the object to bytes using a custom function.", "Arguments": ":param object: Object. The object to be converted to bytes.\n:return: bytes. The object converted to bytes."}, "tests": ["tests/test_utils/test_compat.py::test_unicode_object_to_bytes", "tests/test_utils/test_unicode_compatible_class.py::test_to_bytes", "tests/test_utils/test_compat.py::test_repr_object_to_bytes", "tests/test_utils/test_compat.py::test_unicode_to_bytes", "tests/test_utils/test_compat.py::test_str_object_to_bytes"], "indent": 4}
{"namespace": "twilio.jwt.taskrouter.capabilities.WorkerCapabilityToken.allow_update_activities", "type": "method", "project_path": "Communications/twilio-fatisar", "completion_path": "Communications/twilio-fatisar/twilio/jwt/taskrouter/capabilities.py", "signature_position": [59, 59], "body_position": [60, 61], "dependency": {"intra_class": ["twilio.jwt.taskrouter.capabilities.WorkerCapabilityToken.resource_url"], "intra_file": [], "cross_file": ["twilio.jwt.taskrouter.TaskRouterCapabilityToken._make_policy"]}, "requirement": {"Functionality": "This function creates a policy with the resource URL, HTTP method \"POST\", and post_filter {\"ActivitySid\": {\"required\": True}}.", "Arguments": ":param self: WorkerCapabilityToken. An instance of the WorkerCapabilityToken class.\n:return: No return values."}, "tests": ["tests/unit/jwt/test_task_router.py::WorkerCapabilityTokenTest::test_allow_activity_updates"], "indent": 8}
{"namespace": "mrjob.parse.parse_s3_uri", "type": "function", "project_path": "System/mrjob", "completion_path": "System/mrjob/mrjob/parse.py", "signature_position": [52, 52], "body_position": [60, 66], "dependency": {"intra_class": [], "intra_file": ["mrjob.parse.urlparse", "mrjob.parse.urlparse.netloc", "mrjob.parse.urlparse.path", "mrjob.parse.urlparse.scheme"], "cross_file": []}, "requirement": {"Functionality": "Parses an S3 URI and extracts the bucket and key components. If uri is not an S3 URI, raise a ValueError.\n", "Arguments": ":param uri: String. The S3 URI to be parsed.\n:return: Tuple of strings. The bucket name and the key.\n"}, "tests": ["tests/test_parse.py::URITestCase::test_parse_s3_uri"], "indent": 4}
{"namespace": "wikipediaapi.WikipediaPage.text", "type": "method", "project_path": "Communications/Wikipedia-API", "completion_path": "Communications/Wikipedia-API/wikipediaapi/__init__.py", "signature_position": [969, 969], "body_position": [975, 980], "dependency": {"intra_class": ["wikipediaapi.WikipediaPage.sections", "wikipediaapi.WikipediaPage.summary"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function returns the text of the current Wikipedia page. It first initializes the text with the summary of the page. Then, it appends the full text of each section to the text. Finally, it returns the trimmed text.", "Arguments": ":param self: WikipediaPage. An instance of the WikipediaPage class.\n:return: str. The text of the current Wikipedia page."}, "tests": ["tests/extract_html_format_test.py::TestHtmlFormatExtracts::test_text", "tests/extract_wiki_format_test.py::TestWikiFormatExtracts::test_text_and_summary_without_sections", "tests/extract_wiki_format_test.py::TestWikiFormatExtracts::test_text", "tests/extract_html_format_test.py::TestHtmlFormatExtracts::test_with_erroneous_edit"], "indent": 8}
{"namespace": "boltons.cacheutils.ThresholdCounter.most_common", "type": "method", "project_path": "Utilities/boltons", "completion_path": "Utilities/boltons/boltons/cacheutils.py", "signature_position": [733, 733], "body_position": [737, 742], "dependency": {"intra_class": ["boltons.cacheutils.ThresholdCounter.iteritems"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function returns the top \"n\" keys and counts as a list of tuples. If \"n\" is not specified, it returns all the key-count pairs.\n", "Arguments": ":param self: ThresholdCounter object\n:param n: int. The number of top keys and counts to retrieve. Defaults to None.\n:return: list of tuples. The top \"n\" keys and counts from the ThresholdCounter object.\n"}, "tests": ["tests/test_cacheutils.py::test_threshold_counter"], "indent": 8}
{"namespace": "mopidy.config.types.Pair.deserialize", "type": "method", "project_path": "Multimedia/Mopidy", "completion_path": "Multimedia/Mopidy/mopidy/config/types.py", "signature_position": [241, 241], "body_position": [242, 259], "dependency": {"intra_class": ["mopidy.config.types.Pair._optional_pair", "mopidy.config.types.Pair._required", "mopidy.config.types.Pair._separator", "mopidy.config.types.Pair._subtypes"], "intra_file": ["mopidy.config.types.decode", "mopidy.config.types.encode", "mopidy.config.types.String.deserialize"], "cross_file": ["mopidy.config.validators.validate_required", "mopidy.config.validators"]}, "requirement": {"Functionality": "Deserialize a value and return a pair of deserialized values. It first decodes the input value and removes any leading or trailing whitespace. Then, it validates the raw value based on whether it is required or not. If the raw value is empty, it returns None. If the separator is present in the raw value, it splits the value into two parts. If the optional pair flag is set, it assigns the same value to both parts. Otherwise, it raises a ValueError indicating that the config value must include the separator. Finally, it encodes and deserializes each part of the pair using the corresponding subtypes.", "Arguments": ":param self: Pair. An instance of the Pair class.\n:param value: The value to be deserialized.\n:return: Tuple. A pair of deserialized values."}, "tests": ["tests/config/test_types.py::TestPair::test_deserialize_respects_optional_separator", "tests/config/test_types.py::TestPair::test_deserialize_with_optional_custom_subtypes", "tests/config/test_types.py::TestPair::test_deserialize_enforces_required_pair_values_with_custom_separator", "tests/config/test_types.py::TestPair::test_deserialize_respects_optional_custom_separator", "tests/config/test_types.py::TestPair::test_deserialize_conversion_success"], "indent": 8}
{"namespace": "pyramid.security.PermitsResult.__repr__", "type": "method", "project_path": "Internet/pyramid", "completion_path": "Internet/pyramid/src/pyramid/security.py", "signature_position": [180, 180], "body_position": [181, 185], "dependency": {"intra_class": ["pyramid.security.PermitsResult.msg"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function overrides the default \"__repr__\" method for the PermitsResult class. It returns a string representation of the instance, including the class name, instance id, and the message. The output format is \"<{class name} instance at {instance id} with msg {message}>\"", "Arguments": ":param self: PermitsResult. An instance of the PermitsResult class.\n:return: String. A string representation of the instance."}, "tests": ["tests/test_security.py::TestACLAllowed::test_it", "tests/test_security.py::TestACLDenied::test_it", "tests/test_security.py::TestAllowed::test_it", "tests/test_security.py::TestDenied::test_it"], "indent": 8}
{"namespace": "trailscraper.boto_service_definitions.service_definition_file", "type": "function", "project_path": "Security/trailscraper", "completion_path": "Security/trailscraper/trailscraper/boto_service_definitions.py", "signature_position": [20, 20], "body_position": [23, 29], "dependency": {"intra_class": [], "intra_file": ["trailscraper.boto_service_definitions.boto_service_definition_files"], "cross_file": []}, "requirement": {"Functionality": "This function returns the path to the most recent service definition file for a given service. It first retrieves all the service definition files. Then, it filters the files based on the provided service name and a specific pattern (\"**/\" + servicename + \"/*/service-*.json\"). The filtered files are sorted in ascending order based on their names, and the path of the last file is returned.", "Arguments": ":param servicename: String. The name of the service.\n:return: String. The path to the most recent service definition file for the given service."}, "tests": ["tests/boto_service_definitions_test.py::test_should_find_most_recent_service_definition_file_for_ec2"], "indent": 4}
{"namespace": "bentoml._internal.runner.container.PandasDataFrameContainer.to_payload", "type": "method", "project_path": "Scientific-Engineering/bentoml", "completion_path": "Scientific-Engineering/bentoml/src/bentoml/_internal/runner/container.py", "signature_position": [381, 385], "body_position": [386, 415], "dependency": {"intra_class": [], "intra_file": ["bentoml._internal.runner.container.Payload"], "cross_file": ["bentoml._internal.external_typing.PdSeries", "bentoml._internal.utils.pickle.pep574_dumps", "bentoml._internal.external_typing", "bentoml._internal.runner.container.DataContainer.create_payload"]}, "requirement": {"Functionality": "This function converts a Pandas DataFrame or Series into a Payload object. It first checks if the batch dimension is 0, as PandasDataFrameContainer only supports batch_dim of 0. If the batch is a Series, it converts it into a DataFrame. Then, it creates a meta dictionary with the format set to \"pickle5\". It then performs some operations to obtain the bytes, concat_buffer_bs, and indices. If indices exist, it sets the \"with_buffer\" key in the meta dictionary to True and assigns the concat_buffer_bs, base64 encoded pickle bytes, and indices to the corresponding keys in the meta dictionary. If indices do not exist, it sets the \"with_buffer\" key to False and assigns the bs to the data variable. Finally, it creates a Payload object with the data, batch shape, and meta dictionary.", "Arguments": ":param cls: PandasDataFrameContainer. The class itself.\n:param batch: Pandas DataFrame or Series. The batch to be converted into a Payload object.\n:param batch_dim: int. The batch dimension. It must be 0 for PandasDataFrameContainer.\n:return: Payload. The created Payload object."}, "tests": ["tests/unit/_internal/runner/test_container.py::test_pandas_container"], "indent": 8}
{"namespace": "pyramid.config.views.MultiView.__call_permissive__", "type": "method", "project_path": "Internet/pyramid", "completion_path": "Internet/pyramid/src/pyramid/config/views.py", "signature_position": [138, 138], "body_position": [139, 141], "dependency": {"intra_class": ["pyramid.config.views.MultiView.match"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function is a method of the MultiView class. It is used to call the matched view with the given context and request. If the matched view is call permissive, this custom method is called instead.", "Arguments": ":param self: MultiView. An instance of the MultiView class.\n:param context: The context object to be passed to the view.\n:param request: The request object to be passed to the view.\n:return: The result of calling the matched view with the given context and request."}, "tests": ["tests/test_config/test_views.py::TestMultiView::test___call_permissive_has_no_call_permissive", "tests/test_config/test_views.py::TestMultiView::test___call_permissive_has_call_permissive"], "indent": 8}
{"namespace": "mrjob.examples.mr_text_classifier.parse_doc_filename", "type": "function", "project_path": "System/mrjob", "completion_path": "System/mrjob/mrjob/examples/mr_text_classifier.py", "signature_position": [65, 65], "body_position": [70, 85], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["mrjob.util.file_ext"]}, "requirement": {"Functionality": "This function parses a filename in a specific format and returns a dictionary containing the parsed information. The filename is expected to be in the format \"some_id-cat1-cat2-not_cat3.txt\", and should be parsed into ``dict(id='some_id', cats=dict(cat1=True, cat2=True, cat3=False))``. The function extracts the id and categories from the filename and stores them in a dictionary.", "Arguments": ":param input_uri: String. The input filename to be parsed.\n:return: Dictionary. A dictionary containing the parsed information, with keys \"id\" and \"cats\". The value of \"id\" is the extracted id from the filename, and the value of \"cats\" is another dictionary containing the categories as keys and their corresponding boolean values."}, "tests": ["tests/examples/test_mr_text_classifier.py::ParseDocFileNameTestCase::test_no_cats", "tests/examples/test_mr_text_classifier.py::ParseDocFileNameTestCase::test_with_cats", "tests/examples/test_mr_text_classifier.py::ParseDocFileNameTestCase::test_not_cat", "tests/examples/test_mr_text_classifier.py::ParseDocFileNameTestCase::test_empty"], "indent": 4}
{"namespace": "mrjob.logs.step._parse_step_syslog", "type": "function", "project_path": "System/mrjob", "completion_path": "System/mrjob/mrjob/logs/step.py", "signature_position": [252, 252], "body_position": [271, 272], "dependency": {"intra_class": [], "intra_file": ["mrjob.logs.step._parse_step_syslog_from_log4j_records"], "cross_file": ["mrjob.logs.log4j._parse_hadoop_log4j_records"]}, "requirement": {"Functionality": "A helper function that parses syslog from the \"hadoop jar\" command. It returns a dictionary with various keys(application_id, counters, errors, job_id, output_dir) depending on the information found in the syslog.\n", "Arguments": ":param lines: List of strings. The syslog lines to be parsed.\n:return: Dictionary. A dictionary with various keys that may include application_id, counters, errors, job_id, and output_dir.\n"}, "tests": ["tests/logs/test_step.py::ParseStepSyslogTestCase::test_pre_yarn", "tests/logs/test_step.py::ParseStepSyslogTestCase::test_empty", "tests/logs/test_step.py::ParseStepSyslogTestCase::test_not_a_valid_jar", "tests/logs/test_step.py::ParseStepSyslogTestCase::test_yarn"], "indent": 4}
{"namespace": "mingus.containers.note_container.NoteContainer.from_interval_shorthand", "type": "method", "project_path": "Multimedia/mingus", "completion_path": "Multimedia/mingus/mingus/containers/note_container.py", "signature_position": [130, 130], "body_position": [143, 149], "dependency": {"intra_class": ["mingus.containers.note_container.NoteContainer.add_notes", "mingus.containers.note_container.NoteContainer.empty"], "intra_file": [], "cross_file": ["mingus.containers.note.Note", "mingus.containers.note.Note.dynamics", "mingus.containers.note.Note.name", "mingus.containers.note.Note.octave", "mingus.containers.note.Note.transpose"]}, "requirement": {"Functionality": "This function empties the NoteContainer instance and adds a note to it based on the given startnote and shorthand. It first empties the NoteContainer instance and converts startnote to a Note object if its type is a string. The shorthand is used to determine the interval to transpose the startnote by. The resulting notes are then added to the NoteContainer instance.", "Arguments": ":param self: NoteContainer. An instance of the NoteContainer class.\n:param startnote: String or Note. The starting note for the interval transposition. If it is a string, it will be converted to a Note object.\n:param shorthand: String. The shorthand representation of the interval to transpose the startnote by. See core.intervals for the recognized format.\n:param up: Bool. Whether to transpose the interval up or down. Defaults to True.\n:return: NoteContainer. The modified NoteContainer instance."}, "tests": ["tests/unit/containers/test_note_containers.py::test_NoteContainers::test_from_interval_shorthand"], "indent": 8}
{"namespace": "pyramid.static.ManifestCacheBuster.manifest", "type": "method", "project_path": "Internet/pyramid", "completion_path": "Internet/pyramid/src/pyramid/static.py", "signature_position": [410, 410], "body_position": [412, 419], "dependency": {"intra_class": ["pyramid.static.ManifestCacheBuster._manifest", "pyramid.static.ManifestCacheBuster._mtime", "pyramid.static.ManifestCacheBuster.exists", "pyramid.static.ManifestCacheBuster.get_manifest", "pyramid.static.ManifestCacheBuster.getmtime", "pyramid.static.ManifestCacheBuster.manifest_path", "pyramid.static.ManifestCacheBuster.reload"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function returns the current manifest dictionary. If the reload flag is set to True, it will reload the manifest if the manifest file exists and has been modified since the last time it was loaded.", "Arguments": ":param self: ManifestCacheBuster. An instance of the ManifestCacheBuster class.\n:return: Dictionary. The current manifest dictionary."}, "tests": ["tests/test_static.py::TestManifestCacheBuster::test_invalid_manifest_with_reload"], "indent": 8}
{"namespace": "datasette.app.Datasette.invoke_startup", "type": "method", "project_path": "Database/datasette", "completion_path": "Database/datasette/datasette/app.py", "signature_position": [386, 387], "body_position": [388, 396], "dependency": {"intra_class": ["datasette.app.Datasette._startup_invoked", "datasette.app.Datasette.jinja_env"], "intra_file": [], "cross_file": ["datasette.plugins.pm", "datasette.utils.await_me_maybe"]}, "requirement": {"Functionality": "This function is used to invoke the startup process for a Datasette instance. It ensures that the necessary steps are taken to put the Datasette instance in a usable state.", "Arguments": ":param self: Datasette. An instance of the Datasette class.\n:return: No return value."}, "tests": ["tests/test_internals_datasette.py::test_datasette_render_template_no_request"], "indent": 8}
{"namespace": "boltons.cacheutils.LRI.update", "type": "method", "project_path": "Utilities/boltons", "completion_path": "Utilities/boltons/boltons/cacheutils.py", "signature_position": [304, 305], "body_position": [306, 318], "dependency": {"intra_class": ["boltons.cacheutils.LRI.__setitem__", "boltons.cacheutils.LRI._lock"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Update the LRI instance with the key-value pairs from the input dictionaries. It iterates over the keys and values of the dictionaries and adds them to the LRI instance. If the input dictionary has a callable 'keys' attribute, it uses it to iterate over the keys. Otherwise, it assumes that the input dictionary is an iterable of key-value pairs. The function also accepts keyword arguments and adds them to the LRI instance.", "Arguments": ":param self: LRI. An instance of the LRI class.\n:param E: Dictionary or iterable. The dictionary or iterable containing key-value pairs to be added to the LRI instance.\n:param F: Varable-length keyword arguments. Additional key-value pairs to be added to the LRI instance.\n:return: None."}, "tests": ["tests/test_cacheutils.py::test_lru_basic"], "indent": 8}
{"namespace": "twilio.twiml.voice_response.Dial.sip", "type": "method", "project_path": "Communications/twilio-fatisar", "completion_path": "Communications/twilio-fatisar/twilio/twiml/voice_response.py", "signature_position": [2194, 2212], "body_position": [2235, 2254], "dependency": {"intra_class": [], "intra_file": ["twilio.twiml.voice_response.Sip", "twilio.twiml.voice_response.Sip.__init__"], "cross_file": ["twilio.twiml.TwiML.nest"]}, "requirement": {"Functionality": "This function creates a `<Sip>` element based on the given parameters. It initializes an instance of the `Sip` class with the provided arguments and returns it.", "Arguments": ":param self: Dial. An instance of the `Dial` class.\n:param sip_url: String. The SIP URL.\n:param username: String. The SIP username.\n:param password: String. The SIP password.\n:param url: String. The action URL.\n:param method: String. The action URL method.\n:param status_callback_event: String. The status callback events.\n:param status_callback: String. The status callback URL.\n:param status_callback_method: String. The status callback URL method.\n:param machine_detection: Boolean. Enable machine detection or end of greeting detection.\n:param amd_status_callback_method: String. The HTTP method to use with `amd_status_callback`.\n:param amd_status_callback: String. The URL to call to send AMD status information to your application.\n:param machine_detection_timeout: Integer. The number of seconds to wait for machine detection.\n:param machine_detection_speech_threshold: Integer. The number of milliseconds for measuring stick for the length of the speech activity.\n:param machine_detection_speech_end_threshold: Integer. The number of milliseconds of silence after speech activity.\n:param machine_detection_silence_timeout: Integer. The number of milliseconds of initial silence.\n:param kwargs: Additional attributes.\n:return: Sip. The created `<Sip>` element."}, "tests": ["tests/unit/twiml/test_voice_response.py::TestDial::test_sip", "tests/unit/twiml/test_voice_response.py::TestDial::test_sip_username_password"], "indent": 8}
{"namespace": "fs.path.relativefrom", "type": "function", "project_path": "System/fs", "completion_path": "System/fs/fs/path.py", "signature_position": [543, 544], "body_position": [560, 569], "dependency": {"intra_class": [], "intra_file": ["fs.path.iteratepath"], "cross_file": []}, "requirement": {"Functionality": "This function returns a path relative to a given base path. It inserts backrefs as necessary to reach the path from the base.", "Arguments": ":param base: Text. The base path directory.\n:param path: Text. The path to make relative.\n:return: Text. The path to the base from the given path."}, "tests": ["tests/test_path.py::TestPathFunctions::test_realtivefrom"], "indent": 4}
{"namespace": "pythonforandroid.prerequisites.AutomakePrerequisite.darwin_checker", "type": "method", "project_path": "Utilities/python-for-android", "completion_path": "Utilities/python-for-android/pythonforandroid/prerequisites.py", "signature_position": [309, 309], "body_position": [310, 313], "dependency": {"intra_class": [], "intra_file": ["pythonforandroid.prerequisites.Prerequisite._darwin_get_brew_formula_location_prefix"], "cross_file": []}, "requirement": {"Functionality": "Check if the \"automake\" formula is installed on a Darwin system using Homebrew.", "Arguments": ":param self: AutomakePrerequisite. An instance of the AutomakePrerequisite class.\n:return: bool. True if the \"automake\" formula is installed, False otherwise."}, "tests": ["tests/test_prerequisites.py::TestAutomakePrerequisite::test_darwin_checker"], "indent": 8}
{"namespace": "exodus_bundler.bundling.resolve_file_path", "type": "function", "project_path": "System/exodus-bundler", "completion_path": "System/exodus-bundler/src/exodus_bundler/bundling.py", "signature_position": [200, 200], "body_position": [210, 216], "dependency": {"intra_class": [], "intra_file": ["exodus_bundler.bundling.resolve_binary"], "cross_file": ["exodus_bundler.errors.MissingFileError", "exodus_bundler.errors.UnexpectedDirectoryError"]}, "requirement": {"Functionality": "This function attempts to find a normalized path to a file. It checks if the file exists and if it is a directory. If the file is not found or if it is a directory, appropriate exceptions will be thrown.", "Arguments": ":param path: str. Either a relative or absolute path to a file, or the name of an executable if `search_environment_path` is `True`.\n:param search_environment_path: bool. Whether PATH should be used to resolve the file.\n:return: str. The normalized path to the file."}, "tests": ["tests/test_bundling.py::test_resolve_file_path"], "indent": 4}
{"namespace": "fs.path.iteratepath", "type": "function", "project_path": "System/fs", "completion_path": "System/fs/fs/path.py", "signature_position": [95, 96], "body_position": [110, 113], "dependency": {"intra_class": [], "intra_file": ["fs.path.normpath", "fs.path.relpath"], "cross_file": []}, "requirement": {"Functionality": "This function takes a path as input and iterates over its individual components. It returns a list of path components.", "Arguments": ":param path: Text. The path to iterate over. For example, '/foo/bar/baz'.\n:return: List of Text. A list of path components."}, "tests": ["tests/test_path.py::TestPathFunctions::test_iteratepath"], "indent": 4}
{"namespace": "oletools.ppt_record_parser.is_ppt", "type": "function", "project_path": "Security/oletools", "completion_path": "Security/oletools/oletools/ppt_record_parser.py", "signature_position": [143, 143], "body_position": [158, 194], "dependency": {"intra_class": [], "intra_file": ["oletools.ppt_record_parser.PptFile", "oletools.ppt_record_parser.PptRecordCurrentUser"], "cross_file": ["oletools.record_base.OleRecordStream.iter_records", "oletools.record_base.OleRecordFile.iter_streams", "oletools.record_base.OleRecordStream.close"]}, "requirement": {"Functionality": "This function determines whether a given file is a PowerPoint 2003 (ppt) OLE file. It tries to parse the file using the ppt-parse method and returns False if parsing fails. It looks for specific required streams and records in the file.", "Arguments": ":param filename: String. The name of the file or file data or data stream to be checked.\n:return: Bool. True if the file is a PowerPoint 2003 (ppt) OLE file, False otherwise."}, "tests": ["tests/ppt_parser/test_basic.py::TestBasic::test_is_ppt"], "indent": 4}
{"namespace": "boto.vpc.VPCConnection.get_all_vpc_peering_connections", "type": "method", "project_path": "Internet/boto", "completion_path": "Internet/boto/boto/vpc/__init__.py", "signature_position": [1552, 1553], "body_position": [1591, 1598], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["boto.ec2.connection.EC2Connection.build_filter_params", "boto.vpc.vpc_peering_connection.VpcPeeringConnection", "boto.connection.AWSQueryConnection.get_list", "boto.connection.AWSQueryConnection.build_list_params"]}, "requirement": {"Functionality": "This function retrieves information about VPC peering connections. It allows you to filter the results based on specific search parameters. If no filters are specified, it returns information about all VPC peering connections associated with your account.", "Arguments": ":param self: VPCConnection. An instance of the VPCConnection class.\n:param vpc_peering_connection_ids: List of strings. A list of VPC peering connection IDs to retrieve information for.\n:param filters: List of tuples. A list of filters to apply to the results. Each filter consists of a key and a value.\n:param dry_run: Bool. Set to True if the operation should not actually run.\n:return: List of VPC. A list of VPC peering connections that match the search parameters."}, "tests": ["tests/unit/vpc/test_vpc_peering_connection.py::TestDeleteVpcPeeringConnectionShortForm::test_delete_vpc_peering_connection"], "indent": 8}
{"namespace": "pythonforandroid.androidndk.AndroidNDK.llvm_prebuilt_dir", "type": "method", "project_path": "Utilities/python-for-android", "completion_path": "Utilities/python-for-android/pythonforandroid/androidndk.py", "signature_position": [24, 24], "body_position": [25, 27], "dependency": {"intra_class": ["pythonforandroid.androidndk.AndroidNDK.host_tag", "pythonforandroid.androidndk.AndroidNDK.ndk_dir"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function returns the directory path of the LLVM prebuilt files in the Android NDK. It constructs the directory path by joining the NDK directory path, \"toolchains\", \"llvm\", \"prebuilt\", and the host tag.", "Arguments": ":param self: AndroidNDK. An instance of the AndroidNDK class.\n:return: String. The directory path of the LLVM prebuilt files."}, "tests": ["tests/test_androidndk.py::TestAndroidNDK::test_llvm_prebuilt_dir"], "indent": 8}
{"namespace": "mopidy.ext.Extension.get_data_dir", "type": "method", "project_path": "Multimedia/Mopidy", "completion_path": "Multimedia/Mopidy/mopidy/ext.py", "signature_position": [109, 109], "body_position": [117, 123], "dependency": {"intra_class": ["mopidy.ext.Extension.ext_name"], "intra_file": ["mopidy.ext.Config"], "cross_file": ["mopidy.internal.path.expand_path", "mopidy.internal.path.get_or_create_dir", "mopidy.internal.path"]}, "requirement": {"Functionality": "This function is a class method that gets or creates a data directory for the extension. It uses the Mopidy config object to determine the data directory path and creates the directory if it doesn't exist.", "Arguments": ":param cls: Class. The Extension class.\n:param config: Config. The Mopidy config object.\n:return: Path. The path to the data directory for the extension."}, "tests": ["tests/test_ext.py::TestExtension::test_get_data_dir_raises_error"], "indent": 8}
{"namespace": "bentoml._internal.resource.get_resource", "type": "function", "project_path": "Scientific-Engineering/bentoml", "completion_path": "Scientific-Engineering/bentoml/src/bentoml/_internal/resource.py", "signature_position": [23, 25], "body_position": [26, 40], "dependency": {"intra_class": [], "intra_file": ["bentoml._internal.resource.Resource", "bentoml._internal.resource._RESOURCE_REGISTRY"], "cross_file": ["bentoml.exceptions.BentoMLConfigException"]}, "requirement": {"Functionality": "This function retrieves a resource from a dictionary of resources based on the specified resource kind. It first checks if the resource kind is registered in the resource registry. If it is, it retrieves the corresponding resource class. Then, it checks if the resource kind exists in the resources dictionary. If it does, it checks the value associated with the resource kind. If the value is \"system\", it creates a resource instance from the system. Otherwise, it creates a resource instance from the specified resource specification. If the validate parameter is True, it validates the created resource instance. If the resource kind does not exist in the resources dictionary, it returns None.", "Arguments": ":param resources: Dict[str, Any]. A dictionary of resources where the keys are resource kinds and the values are resource specifications.\n:param resource_kind: str. The kind of resource to retrieve.\n:param validate: bool. Whether to validate the created resource instance. Defaults to True.\n:return: Any. The retrieved resource instance or None if the resource kind does not exist in the resources dictionary."}, "tests": ["tests/unit/_internal/test_resource.py::test_get_resource"], "indent": 4}
{"namespace": "authlib.oauth2.rfc6749.util.extract_basic_authorization", "type": "function", "project_path": "Internet/Authlib", "completion_path": "Internet/Authlib/authlib/oauth2/rfc6749/util.py", "signature_position": [24, 24], "body_position": [25, 40], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["authlib.common.encoding.to_unicode"]}, "requirement": {"Functionality": "This function extracts the username and password from the Authorization header in the given headers dictionary. It first checks if the Authorization header exists and contains a space. If not, it returns None for both username and password. If the Authorization header exists and is of type 'basic', it decodes the auth_token and splits it into username and password. If the auth_token does not contain a colon, it returns the auth_token as the username and None for the password.", "Arguments": ":param headers: Dictionary. The headers dictionary containing the Authorization header.\n:return: Tuple. The extracted username and password from the Authorization header."}, "tests": ["tests/core/test_oauth2/test_rfc6749_misc.py::OAuth2UtilTest::test_extract_basic_authorization"], "indent": 4}
{"namespace": "mingus.core.progressions.substitute_major_for_minor", "type": "function", "project_path": "Multimedia/mingus", "completion_path": "Multimedia/mingus/mingus/core/progressions.py", "signature_position": [329, 329], "body_position": [341, 360], "dependency": {"intra_class": [], "intra_file": ["mingus.core.progressions.interval_diff", "mingus.core.progressions.parse_string", "mingus.core.progressions.skip", "mingus.core.progressions.tuple_to_string"], "cross_file": []}, "requirement": {"Functionality": "This function substitutes major chords for their minor equivalent based on the given progression and index.\nThe function first parses the chord progression to extract the roman numeral, accidental, and suffix of the chord at the specified index. Then, it performs the major to minor substitution by adjusting the interval and appending the appropriate suffix based on the original suffix or the 'ignore_suffix' flag.\n", "Arguments": ""}, "tests": ["tests/unit/core/test_progressions.py::test_progressions::test_substitute_major_for_minor"], "indent": 4}
{"namespace": "faker.utils.loading.find_available_providers", "type": "function", "project_path": "Software-Development/Faker", "completion_path": "Software-Development/Faker/faker/utils/loading.py", "signature_position": [52, 52], "body_position": [53, 60], "dependency": {"intra_class": [], "intra_file": ["faker.utils.loading.list_module"], "cross_file": []}, "requirement": {"Functionality": "This function takes a list of modules as input and finds the available providers. It iterates over each module in the input list, checks if the module has a package, and then creates a list of providers by joining the package name with each module name (excluding \"__pycache__\"). The function then updates a set of available providers with the newly created list and returns the sorted list of available providers.", "Arguments": ":param modules: List of ModuleType. A list of modules to search for available providers.\n:return: List of str. The sorted list of available providers."}, "tests": ["tests/utils/test_utils.py::UtilsTestCase::test_find_available_providers"], "indent": 4}
{"namespace": "boltons.tableutils.Table.extend", "type": "method", "project_path": "Utilities/boltons", "completion_path": "Utilities/boltons/boltons/tableutils.py", "signature_position": [292, 292], "body_position": [296, 300], "dependency": {"intra_class": ["boltons.tableutils.Table._data", "boltons.tableutils.Table._fill", "boltons.tableutils.Table._set_width"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function appends the given data to the end of the Table instance. It first checks if the data is empty, and if so, it returns without making any changes. Otherwise, it extends the internal data list with the given data, updates the width of the table, and fills any empty cells with empty strings.", "Arguments": ":param self: Table. An instance of the Table class.\n:param data: Iterable. The data to be appended to the table.\n:return: No return values."}, "tests": ["tests/test_tableutils.py::test_table_dicts"], "indent": 8}
{"namespace": "alembic.config.Config.print_stdout", "type": "method", "project_path": "Database/alembic", "completion_path": "Database/alembic/alembic/config.py", "signature_position": [162, 162], "body_position": [178, 183], "dependency": {"intra_class": ["alembic.config.Config.messaging_opts", "alembic.config.Config.stdout"], "intra_file": [], "cross_file": ["alembic.util", "alembic.util.messaging.write_outstream"]}, "requirement": {"Functionality": "This function is used to render a message to standard output. It takes a text string as input and formats it with additional arguments if provided. The formatted message is then output to the standard output. If no additional arguments are provided, the text is output verbatim. This function does nothing if the \"quiet\" messaging option is enabled.", "Arguments": ":param self: Config. An instance of the Config class.\n:param text: String. The text to be rendered to standard output.\n:param *arg: Additional arguments to be formatted against the provided text.\n:return: None."}, "tests": ["tests/test_config.py::StdoutOutputEncodingTest::test_plain", "tests/test_config.py::StdoutOutputEncodingTest::test_ascii_unicode", "tests/test_config.py::StdoutOutputEncodingTest::test_utf8_unicode", "tests/test_config.py::StdoutOutputEncodingTest::test_only_formats_output_with_args"], "indent": 8}
{"namespace": "boltons.ioutils.SpooledStringIO.read", "type": "method", "project_path": "Utilities/boltons", "completion_path": "Utilities/boltons/boltons/ioutils.py", "signature_position": [405, 405], "body_position": [406, 409], "dependency": {"intra_class": ["boltons.ioutils.SpooledStringIO._tell", "boltons.ioutils.SpooledStringIO.buffer", "boltons.ioutils.SpooledStringIO.len", "boltons.ioutils.SpooledStringIO.tell"], "intra_file": ["boltons.ioutils.SpooledIOBase._checkClosed"], "cross_file": []}, "requirement": {"Functionality": "Read and return the specified number of characters from the SpooledStringIO instance. It checks if the instance is closed, reads the characters from the buffer, updates the current position, and returns the characters.", "Arguments": ":param self: SpooledStringIO. An instance of the SpooledStringIO class.\n:param n: int. The number of characters to read. Defaults to -1, which means read all characters.\n:return: str. The characters read from the instance."}, "tests": ["tests/test_ioutils.py::TestSpooledStringIO::test_seek_encoded", "tests/test_ioutils.py::TestSpooledStringIO::test_tell_codepoints", "tests/test_ioutils.py::TestSpooledStringIO::test_x80_codepoint", "tests/test_ioutils.py::TestSpooledStringIO::test_codepoints_all_enc"], "indent": 8}
{"namespace": "kinto.core.utils.native_value", "type": "function", "project_path": "Internet/kinto", "completion_path": "Internet/kinto/kinto/core/utils.py", "signature_position": [118, 118], "body_position": [124, 129], "dependency": {"intra_class": [], "intra_file": ["kinto.core.utils.json", "kinto.core.utils.json.loads"], "cross_file": []}, "requirement": {"Functionality": "This function converts a string value to its corresponding native Python value. If the input value is a string, it tries to parse it as JSON and return the parsed value. If the parsing fails, it returns the original string value.", "Arguments": ":param value: str. The value to be interpreted.\n:return: The value coerced to its corresponding Python type."}, "tests": ["tests/core/test_utils.py::NativeValueTest::test_non_string_values", "tests/core/test_utils.py::NativeValueTest::test_zero_and_one_coerce_to_integers", "tests/core/test_utils.py::NativeValueTest::test_defined_string", "tests/core/test_utils.py::NativeValueTest::test_bad_string_values", "tests/core/test_utils.py::NativeValueTest::test_integer"], "indent": 4}
{"namespace": "alembic.testing.env._no_sql_testing_config", "type": "function", "project_path": "Database/alembic", "completion_path": "Database/alembic/alembic/testing/env.py", "signature_position": [201, 201], "body_position": [204, 238], "dependency": {"intra_class": [], "intra_file": ["alembic.testing.env._get_staging_directory", "alembic.testing.env._write_config_file"], "cross_file": []}, "requirement": {"Functionality": "This function generates a configuration file for no-SQL testing. It creates a configuration file with specific settings for the Alembic migration tool and logging. The file is written to a specific directory.", "Arguments": ":param dialect: String. The type of database dialect to use. It defaults to \"postgresql\" if not specified.\n:param directives: String. Additional directives to include in the configuration file.\n:return: None."}, "tests": ["tests/test_post_write.py::RunHookTest::test_empty_hooks", "tests/test_post_write.py::RunHookTest::test_generic", "tests/test_post_write.py::RunHookTest::test_exec_executable_missing", "tests/test_post_write.py::RunHookTest::test_console_scripts_entrypoint_missing", "tests/test_post_write.py::RunHookTest::test_no_type"], "indent": 4}
{"namespace": "mrjob.fs.base.Filesystem.cat", "type": "method", "project_path": "System/mrjob", "completion_path": "System/mrjob/mrjob/fs/base.py", "signature_position": [54, 54], "body_position": [61, 66], "dependency": {"intra_class": ["mrjob.fs.base.Filesystem._cat_file", "mrjob.fs.base.Filesystem.ls"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function reads and concatenates the contents of all files that match the given path pattern. It decompresses the files if necessary. The function yields the contents of the files as bytes, yields `b''` between each file.", "Arguments": ":param self: Filesystem. An instance of the Filesystem class.\n:param path_glob: String. The path pattern to match the files.\n:return: No return values. The function yields the contents of the files as bytes."}, "tests": ["tests/fs/test_base.py::CatTestCase::test_multiple_files", "tests/fs/test_local.py::LocalFSTestCase::test_put", "tests/fs/test_hadoop.py::HadoopFSTestCase::test_put"], "indent": 8}
{"namespace": "boto.dynamodb2.connect_to_region", "type": "function", "project_path": "Internet/boto", "completion_path": "Internet/boto/boto/dynamodb2/__init__.py", "signature_position": [39, 39], "body_position": [40, 43], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["boto.dynamodb2.layer1.DynamoDBConnection", "boto.regioninfo.connect"]}, "requirement": {"Functionality": "Connect to a specific region in DynamoDB using the provided region name and additional keyword parameters. It creates a connection to DynamoDB using the specified region and returns the connection object.", "Arguments": ":param region_name: String. The name of the region to connect to in DynamoDB.\n:param **kw_params: Additional keyword parameters that can be passed to the connection.\n:return: DynamoDBConnection. The connection object to the specified region in DynamoDB."}, "tests": ["tests/unit/test_connect_to_region.py::TestDynamodb2Connection::test_connect_to_unkown_region", "tests/unit/test_connect_to_region.py::TestDynamodb2Connection::test_connect_to_region"], "indent": 4}
{"namespace": "diffprivlib.tools.utils.std", "type": "function", "project_path": "Security/diffprivlib", "completion_path": "Security/diffprivlib/diffprivlib/tools/utils.py", "signature_position": [462, 463], "body_position": [516, 519], "dependency": {"intra_class": [], "intra_file": ["diffprivlib.tools.utils._std"], "cross_file": ["diffprivlib.utils.warn_unused_args"]}, "requirement": {"Functionality": "This function computes the standard deviation of the input array along the specified axis, with differential privacy. It adds noise to the computation to satisfy differential privacy requirements. The standard deviation is calculated for the flattened array by default, but can also be calculated over a specified axis. The behavior of this function closely follows the Numpy variant of `std`.", "Arguments": ":param array: array_like. The array for which the standard deviation is calculated.\n:param epsilon: float, default: 1.0. The privacy parameter epsilon.\n:param bounds: tuple, optional. The bounds of the values of the array, in the form (min, max).\n:param axis: int or tuple of ints, optional. The axis or axes along which the standard deviation is computed. The default is to compute the standard deviation of the flattened array. If a tuple of ints is provided, the standard deviation is performed over multiple axes.\n:param dtype: dtype, optional. The type to use in computing the standard deviation. For arrays of integer type, the default is float64. For arrays of float types, it is the same as the array type.\n:param keepdims: bool, default: False. If set to True, the axes which are reduced are left in the result as dimensions with size one. This allows the result to broadcast correctly against the input array.\n:param random_state: int or RandomState, optional. Controls the randomness of the algorithm. To obtain deterministic behavior during randomization, the random_state has to be fixed to an integer.\n:param accountant: BudgetAccountant, optional. An accountant to keep track of privacy budget.\n:param **unused_args: Should warn the user if any other parameters are passed.\n:return: ndarray. A new array containing the standard deviation."}, "tests": ["tests/tools/test_std.py::TestStd::test_nan", "tests/tools/test_std.py::TestStd::test_large_epsilon", "tests/tools/test_std.py::TestStd::test_missing_bounds", "tests/tools/test_std.py::TestStd::test_accountant", "tests/tools/test_std.py::TestStd::test_clipped_output"], "indent": 4}
{"namespace": "diffprivlib.accountant.BudgetAccountant.__repr__", "type": "method", "project_path": "Security/diffprivlib", "completion_path": "Security/diffprivlib/diffprivlib/accountant.py", "signature_position": [153, 153], "body_position": [154, 170], "dependency": {"intra_class": ["diffprivlib.accountant.BudgetAccountant.delta", "diffprivlib.accountant.BudgetAccountant.epsilon", "diffprivlib.accountant.BudgetAccountant.slack", "diffprivlib.accountant.BudgetAccountant.spent_budget"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function returns a string representation of the BudgetAccountant instance. It includes the values of the instance's attributes in the string representation. For epsilon, it is included if it is not equal to infinity.\nFor delta, it is included if it differs from the default value of 1. For slack, it is included if it is greater than 0. The function also checks the spent budget. If length of spent budget exceeds a certain maximum of budget, only a subset of its elements is included, followed an additional ellipsis (\"...\") to indicate truncation and a replacement of \"\" with \"\". All these attributes will then be appended in the format:{\"{attribute name}={attribute value}\" like \"delta=0.3\"}. Finally, the output format is \"BudgetAccountant({processed attributes separating each element by a comma and a space} )\"", "Arguments": ":param self: BudgetAccountant. An instance of the BudgetAccountant class.\n:param n_budget_max: Integer. The maximum number of elements to include in the spent budget. Defaults to 5.\n:return: String. The string representation of the BudgetAccountant instance."}, "tests": ["tests/test_BudgetAccountant.py::TestBudgetAccountant::test_repr"], "indent": 8}
{"namespace": "wikipediaapi.WikipediaPage.backlinks", "type": "method", "project_path": "Communications/Wikipedia-API", "completion_path": "Communications/Wikipedia-API/wikipediaapi/__init__.py", "signature_position": [1015, 1015], "body_position": [1026, 1028], "dependency": {"intra_class": ["wikipediaapi.WikipediaPage._backlinks", "wikipediaapi.WikipediaPage._called", "wikipediaapi.WikipediaPage._fetch"], "intra_file": ["wikipediaapi.PagesDict"], "cross_file": []}, "requirement": {"Functionality": "This function returns all the pages that link to the current Wikipedia page. It is a wrapper for the MediaWiki API's backlinks module.", "Arguments": ":param self: WikipediaPage. An instance of the WikipediaPage class.\n:return: PagesDict. A dictionary containing the pages that link to the current page."}, "tests": ["tests/backlinks_test.py::TestBackLinks::test_backlinks_multi_page_titles", "tests/backlinks_test.py::TestBackLinks::test_backlinks_multi_page_count", "tests/backlinks_test.py::TestBackLinks::test_backlinks_nonexistent_count", "tests/backlinks_test.py::TestBackLinks::test_backlinks_single_page_titles", "tests/backlinks_test.py::TestBackLinks::test_backlinks_single_page_count"], "indent": 8}
{"namespace": "pycoin.blockchain.ChainFinder.ChainFinder.find_ancestral_path", "type": "method", "project_path": "Security/pycoin", "completion_path": "Security/pycoin/pycoin/blockchain/ChainFinder.py", "signature_position": [85, 85], "body_position": [86, 98], "dependency": {"intra_class": ["pycoin.blockchain.ChainFinder.ChainFinder.maximum_path"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Find the ancestral path between two nodes in a chain.\n", "Arguments": ":param h1: The first node in the chain.\n:param h2: The second node in the chain.\n:param path_cache: Dict, a dictionary that caches computed paths. It is optional and defaults to an empty dictionary.\n:return: Tuple, a tuple containing two lists. The first list is the ancestral path from h1 to the common ancestor. The second list is the ancestral path from h2 to the common ancestor.\n"}, "tests": ["tests/chainfinder_test.py::ChainFinderTestCase::test_find_ancestral_path", "tests/chainfinder_test.py::ChainFinderTestCase::test_large"], "indent": 8}
{"namespace": "imapclient.imapclient.IMAPClient.noop", "type": "method", "project_path": "Communications/IMAPClient", "completion_path": "Communications/IMAPClient/imapclient/imapclient.py", "signature_position": [869, 869], "body_position": [885, 886], "dependency": {"intra_class": ["imapclient.imapclient.IMAPClient._consume_until_tagged_response", "imapclient.imapclient.IMAPClient._imap"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function executes the NOOP command in the IMAPClient instance. The NOOP command returns immediately and can be used to receive any server-side status updates or reset any auto-logout timers.", "Arguments": ":param self: IMAPClient. An instance of the IMAPClient class.\n:return: The server command response message followed by a list of status responses."}, "tests": ["tests/test_imapclient.py::TestIdleAndNoop::test_noop"], "indent": 8}
{"namespace": "imapclient.imapclient.IMAPClient.starttls", "type": "method", "project_path": "Communications/IMAPClient", "completion_path": "Communications/IMAPClient/imapclient/imapclient.py", "signature_position": [361, 361], "body_position": [378, 388], "dependency": {"intra_class": ["imapclient.imapclient.IMAPClient._checkok", "imapclient.imapclient.IMAPClient._imap", "imapclient.imapclient.IMAPClient._starttls_done", "imapclient.imapclient.IMAPClient.host", "imapclient.imapclient.IMAPClient.ssl"], "intra_file": [], "cross_file": ["imapclient.exceptions.IMAPClientAbortError", "imapclient.imap4.IMAP4WithTimeout.file", "imapclient.imap4.IMAP4WithTimeout.sock", "imapclient.tls.wrap_socket", "imapclient.exceptions", "imapclient.tls"]}, "requirement": {"Functionality": "This function switches the connection to an SSL encrypted connection by sending a STARTTLS command. It establishes an SSL connection using the provided SSL context or a default SSL context. It also checks the hostname in the server's certificate against the hostname used for connecting. If the SSL connection cannot be established or the server does not support STARTTLS, appropriate exceptions are raised.", "Arguments": ":param self: IMAPClient. An instance of the IMAPClient class.\n:param ssl_context: SSLContext. Optional. The SSL context to use for establishing the SSL connection. If not provided, a default SSL context with reasonable default settings will be used.\n:return: The response from the server after executing the STARTTLS command."}, "tests": ["tests/test_starttls.py::TestStarttls::test_fails_if_called_twice", "tests/test_starttls.py::TestStarttls::test_command_fails", "tests/test_starttls.py::TestStarttls::test_works"], "indent": 8}
{"namespace": "mopidy.internal.validation.check_instances", "type": "function", "project_path": "Multimedia/Mopidy", "completion_path": "Multimedia/Mopidy/mopidy/internal/validation.py", "signature_position": [69, 69], "body_position": [70, 72], "dependency": {"intra_class": [], "intra_file": ["mopidy.internal.validation._check_iterable"], "cross_file": ["mopidy.exceptions.ValidationError", "mopidy.exceptions"]}, "requirement": {"Functionality": "This function checks if all elements in the input argument are instances of a specified class. If any element is not an instance of the class, it raises a validation error with a specified error message.", "Arguments": ":param arg: Any. The input argument to be checked.\n:param cls: Class. The class that all elements in the input argument should be instances of.\n:param msg: String. The error message to be raised if any element is not an instance of the class. It defaults to \"Expected a list of {name}, not {arg!r}\".\n:return: No return values. It raises a validation error if any element is not an instance of the class."}, "tests": ["tests/internal/test_validation.py::test_check_instances_error_message", "tests/internal/test_validation.py::test_check_instances_with_invalid_values"], "indent": 4}
{"namespace": "jc.parsers.xrandr._parse_screen", "type": "function", "project_path": "Utilities/jc", "completion_path": "Utilities/jc/jc/parsers/xrandr.py", "signature_position": [292, 292], "body_position": [293, 312], "dependency": {"intra_class": [], "intra_file": ["jc.parsers.xrandr.Device", "jc.parsers.xrandr.Screen", "jc.parsers.xrandr._parse_device", "jc.parsers.xrandr._screen_pattern"], "cross_file": []}, "requirement": {"Functionality": "This function parses a screen definition from a list of lines. It first pops the next line from the list and checks if it matches the screen pattern. If it doesn't match, the line is appended back to the list and None is returned. If it matches, the raw matches are extracted and stored in a dictionary. Then, it iterates through the remaining lines and parses each device definition. The parsed devices are appended to the \"devices\" list in the screen dictionary. Finally, the screen dictionary is returned.", "Arguments": ":param next_lines: List of strings. The list of lines to parse the screen definition from.\n:return: Optional[Screen]. The parsed screen definition, or None if the next line doesn't match the screen pattern."}, "tests": ["tests/test_xrandr.py::XrandrTests::test_screens"], "indent": 4}
{"namespace": "sumy.summarizers.lsa.LsaSummarizer._create_dictionary", "type": "method", "project_path": "Internet/sumy", "completion_path": "Internet/sumy/sumy/summarizers/lsa.py", "signature_position": [55, 55], "body_position": [57, 60], "dependency": {"intra_class": ["sumy.summarizers.lsa.LsaSummarizer._stop_words"], "intra_file": [], "cross_file": ["sumy.summarizers._summarizer.AbstractSummarizer.normalize_word", "sumy.summarizers._summarizer.AbstractSummarizer.stem_word", "sumy.models.dom._document.ObjectDocumentModel.words"]}, "requirement": {"Functionality": "This function creates a dictionary that maps each unique word in the document to its corresponding row index. It first normalizes each word in the document and removes any stop words. Then, it creates a dictionary where the keys are the unique words and the values are their respective row indices.", "Arguments": ":param self: LsaSummarizer. An instance of the LsaSummarizer class.\n:param document: Object. The document for which the dictionary is created.\n:return: dict. A dictionary mapping unique words to their row indices."}, "tests": ["tests/test_summarizers/test_lsa.py::test_dictionary_without_stop_words"], "indent": 8}
{"namespace": "pyramid.renderers.RendererHelper.render_view", "type": "method", "project_path": "Internet/pyramid", "completion_path": "Internet/pyramid/src/pyramid/renderers.py", "signature_position": [433, 433], "body_position": [434, 443], "dependency": {"intra_class": ["pyramid.renderers.RendererHelper.name", "pyramid.renderers.RendererHelper.render_to_response"], "intra_file": [], "cross_file": ["pyramid.csrf.get_csrf_token"]}, "requirement": {"Functionality": "This function renders a view using a specified renderer. It creates a dictionary called \"system\" that contains various information related to the rendering process, such as the view, renderer name, renderer info, context, request, and CSRF token. It uses the provided response, system, and request parameters to generate the final response.", "Arguments": ":param self: RendererHelper. An instance of the RendererHelper class.\n:param request: The request object.\n:param response: The response object.\n:param view: The view to be rendered.\n:param context: The context data to be passed to the system.\n:return: No return value."}, "tests": ["tests/test_renderers.py::TestRendererHelper::test_render_view"], "indent": 8}
{"namespace": "twtxt.config.Config.from_file", "type": "method", "project_path": "Communications/twtxt", "completion_path": "Communications/twtxt/twtxt/config.py", "signature_position": [36, 36], "body_position": [41, 54], "dependency": {"intra_class": ["twtxt.config.Config.__init__", "twtxt.config.Config.check_config_sanity"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function tries to load a given config file. It first checks if the file exists, and then reads the file. It creates a Config instance with the file path and the parsed configuration. It checks the sanity of the configuration and returns the instance if it is valid.", "Arguments": ":param cls: Class. The class of the `Config` instance.\n:param file: String. The full path to the config file to load.\n:return: Config. The created `Config` instance."}, "tests": ["tests/test_config.py::test_check_config_file_sanity", "tests/test_config.py::test_from_file"], "indent": 8}
{"namespace": "ehforwarderbot.utils.get_custom_modules_path", "type": "function", "project_path": "Communications/ehforwarderbot", "completion_path": "Communications/ehforwarderbot/ehforwarderbot/utils.py", "signature_position": [113, 113], "body_position": [120, 123], "dependency": {"intra_class": [], "intra_file": ["ehforwarderbot.utils.get_base_path"], "cross_file": []}, "requirement": {"Functionality": "This function returns the path to the custom channels. It first gets the base path and appends \"modules\" to it to create the channel path. If the channel path does not exist, it creates it.", "Arguments": ":param: No input parameters.\n:return: Path. The path to the custom channels."}, "tests": ["tests/test_channel_loading.py::test_custom_path_module_loading"], "indent": 4}
{"namespace": "imapclient.imapclient.IMAPClient.set_quota", "type": "method", "project_path": "Communications/IMAPClient", "completion_path": "Communications/IMAPClient/imapclient/imapclient.py", "signature_position": [1605, 1605], "body_position": [1610, 1630], "dependency": {"intra_class": ["imapclient.imapclient.IMAPClient._raw_command_untagged"], "intra_file": ["imapclient.imapclient._parse_quota", "imapclient.imapclient._quote"], "cross_file": ["imapclient.util.to_bytes"]}, "requirement": {"Functionality": "This function sets one or more quotas on resources in an IMAPClient instance. It takes a list of Quota objects as input and constructs the necessary arguments to set the quotas. It then sends the SETQUOTA command to the IMAP server and returns the parsed response.", "Arguments": ":param self: IMAPClient. An instance of the IMAPClient class.\n:param quotas: List of Quota objects. The quotas to be set on resources.\n:return: No return values."}, "tests": ["tests/test_imapclient.py::TestQuota::test_set_quota"], "indent": 8}
{"namespace": "pyramid.csrf.SessionCSRFStoragePolicy.check_csrf_token", "type": "method", "project_path": "Internet/pyramid", "completion_path": "Internet/pyramid/src/pyramid/csrf.py", "signature_position": [86, 86], "body_position": [88, 91], "dependency": {"intra_class": ["pyramid.csrf.SessionCSRFStoragePolicy.get_csrf_token"], "intra_file": [], "cross_file": ["pyramid.util.bytes_", "pyramid.util.strings_differ"]}, "requirement": {"Functionality": "Check if the supplied CSRF token is valid by comparing it with the expected token. It converts both tokens to bytes and checks if they are equal.", "Arguments": ":param self: SessionCSRFStoragePolicy. An instance of the SessionCSRFStoragePolicy class.\n:param request: The request object.\n:param supplied_token: The CSRF token supplied by the client.\n:return: Bool. True if the supplied token is valid, False otherwise."}, "tests": ["tests/test_csrf.py::TestSessionCSRFStoragePolicy::test_check_csrf_token"], "indent": 8}
{"namespace": "asyncssh.misc.write_file", "type": "function", "project_path": "Security/asyncssh", "completion_path": "Security/asyncssh/asyncssh/misc.py", "signature_position": [225, 225], "body_position": [228, 229], "dependency": {"intra_class": [], "intra_file": ["asyncssh.misc.FilePath", "asyncssh.misc.open_file"], "cross_file": []}, "requirement": {"Functionality": "This function writes or appends data to a file with home directory expansion. It opens the file using the specified mode, writes the data to the file, and returns the number of bytes written.", "Arguments": ":param filename: FilePath. The path of the file to write or append to.\n:param data: bytes. The data to write to the file.\n:param mode: str. The mode in which to open the file. It defaults to 'wb'.\n:return: int. The number of bytes written to the file."}, "tests": ["tests/test_public_key.py::_TestPublicKeyTopLevel::test_public_key_algorithm_mismatch"], "indent": 4}
{"namespace": "fs.wildcard.get_matcher", "type": "function", "project_path": "System/fs", "completion_path": "System/fs/fs/wildcard.py", "signature_position": [101, 102], "body_position": [124, 129], "dependency": {"intra_class": [], "intra_file": ["fs.wildcard.imatch_any", "fs.wildcard.match_any"], "cross_file": []}, "requirement": {"Functionality": "Return a callable that can match names against given wildcard patterns. If the list of patterns is empty, return True when called.\n", "Arguments": ":param patterns: List[String], a list of wildcard patterns, e.g., ``[\"*.py\", \"*.pyc\"]``.\n:param case_sensitive: Bool, if True, the matching will be case sensitive. If False, the matching will be case insensitive.\n:return: Callable, a matcher that returns True if the name given as an argument matches any of the given patterns.\n"}, "tests": ["tests/test_wildcard.py::TestFNMatch::test_get_matcher"], "indent": 4}
{"namespace": "mopidy.ext.Extension.get_cache_dir", "type": "method", "project_path": "Multimedia/Mopidy", "completion_path": "Multimedia/Mopidy/mopidy/ext.py", "signature_position": [77, 77], "body_position": [85, 91], "dependency": {"intra_class": ["mopidy.ext.Extension.ext_name"], "intra_file": ["mopidy.ext.Config"], "cross_file": ["mopidy.internal.path.expand_path", "mopidy.internal.path.get_or_create_dir", "mopidy.internal.path"]}, "requirement": {"Functionality": "This function is a class method that gets or creates a cache directory for the extension. It uses the Mopidy config object to determine the cache directory path and creates the directory if it doesn't exist.", "Arguments": ":param cls: Class. The Extension class.\n:param config: Config. The Mopidy config object.\n:return: Path. The pathlib.Path object representing the cache directory path."}, "tests": ["tests/test_ext.py::TestExtension::test_get_cache_dir_raises_error"], "indent": 8}
{"namespace": "asyncssh.saslprep.saslprep", "type": "function", "project_path": "Security/asyncssh", "completion_path": "Security/asyncssh/asyncssh/saslprep.py", "signature_position": [107, 107], "body_position": [110, 116], "dependency": {"intra_class": [], "intra_file": ["asyncssh.saslprep._map_saslprep", "asyncssh.saslprep._stringprep"], "cross_file": []}, "requirement": {"Functionality": "This function implements the SASLprep profile defined in RFC 4013. It takes a string as input and applies a series of string preparation steps to it.", "Arguments": ":param s: String. The input string to be processed.\n:return: String. The processed string after applying the SASLprep profile."}, "tests": ["tests/test_saslprep.py::_TestSASLPrep::test_nonstring", "tests/test_saslprep.py::_TestSASLPrep::test_prohibited", "tests/test_saslprep.py::_TestSASLPrep::test_bidi", "tests/test_saslprep.py::_TestSASLPrep::test_map_to_whitespace", "tests/test_saslprep.py::_TestSASLPrep::test_map_to_nothing"], "indent": 4}
{"namespace": "boltons.listutils.BarrelList.sort", "type": "method", "project_path": "Utilities/boltons", "completion_path": "Utilities/boltons/boltons/listutils.py", "signature_position": [310, 312], "body_position": [313, 321], "dependency": {"intra_class": ["boltons.listutils.BarrelList._balance_list", "boltons.listutils.BarrelList.lists"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Sort the elements in the BarrelList instance. It sorts the elements in each list individually and merges them into a single sorted list. It then balance the list.", "Arguments": ":param self: BarrelList. An instance of the BarrelList class.\n:return: No return values."}, "tests": ["tests/test_listutils.py::test_barrel_list"], "indent": 8}
{"namespace": "imapclient.imapclient.IMAPClient.sort", "type": "method", "project_path": "Communications/IMAPClient", "completion_path": "Communications/IMAPClient/imapclient/imapclient.py", "signature_position": [1173, 1173], "body_position": [1195, 1201], "dependency": {"intra_class": ["imapclient.imapclient.IMAPClient._raw_command_untagged"], "intra_file": ["imapclient.imapclient._normalise_search_criteria", "imapclient.imapclient._normalise_sort_criteria"], "cross_file": ["imapclient.util.to_bytes"]}, "requirement": {"Functionality": "This function sorts the message ids from the currently selected folder based on the given sort criteria and optionally filters them based on the criteria. It uses the SORT command of the IMAP protocol to perform the sorting.", "Arguments": ":param self: IMAPClient. An instance of the IMAPClient class.\n:param sort_criteria: List of strings or a single string. The criteria to sort the message ids by. Valid values include 'ARRIVAL', 'SUBJECT', 'REVERSE SIZE', etc.\n:param criteria: String. The criteria to filter the message ids. Defaults to \"ALL\".\n:param charset: String. The character set to use for the criteria. Defaults to \"UTF-8\".\n:return: List of integers. The sorted message ids from the currently selected folder."}, "tests": ["tests/test_sort.py::TestSort::test_single_criteria", "tests/test_sort.py::TestSort::test_all_args", "tests/test_sort.py::TestSort::test_multiple_criteria"], "indent": 8}
{"namespace": "mrjob.logs.history._parse_pre_yarn_history_log", "type": "function", "project_path": "System/mrjob", "completion_path": "System/mrjob/mrjob/logs/history.py", "signature_position": [287, 287], "body_position": [294, 333], "dependency": {"intra_class": [], "intra_file": ["mrjob.logs.history._parse_pre_yarn_counters", "mrjob.logs.history._parse_pre_yarn_history_records"], "cross_file": ["mrjob.logs.counters._sum_counters"]}, "requirement": {"Functionality": "Parses a pre-YARN history file and collects useful information.\nThe function `_parse_pre_yarn_history_log` is used to extract useful information from a pre-YARN history file. It takes in a list of strings `lines` representing the lines of the history file. It initializes an empty dictionary `result` and an empty dictionary `task_to_counters`. The function iterates over each record in the parsed pre-YARN history records. It checks the type of the record and performs different operations based on the type.\nIf job is successful, it get counters for the entire job at the end, therwise, compile counters for each successful task. That is, if the record type is 'Task' and it contains 'COUNTERS' and 'TASKID' in the fields, it extracts the counters and assigns them to `task_to_counters` dictionary with the task ID as the key. If the record is FAILED, it only want FAILED (not KILLED) tasks with non-blank errors. It appends a new dictionary to a list as the value of errors key of dictionary. The dictionary contains the error message, start line, and number of lines, as well as the task attempt ID.After processing all the records, if job failed, patch together counters from successful task_to_counters.\n", "Arguments": ":param lines: List of strings. The lines of the history file.\n:return: Dict. The parsed information from the history file.\n"}, "tests": ["tests/logs/test_history.py::ParsePreYARNHistoryLogTestCase::test_ignore_killed_task_with_empty_error", "tests/logs/test_history.py::ParsePreYARNHistoryLogTestCase::test_task_counters", "tests/logs/test_history.py::ParsePreYARNHistoryLogTestCase::test_errors", "tests/logs/test_history.py::ParsePreYARNHistoryLogTestCase::test_empty", "tests/logs/test_history.py::ParsePreYARNHistoryLogTestCase::test_job_counters_beat_task_counters"], "indent": 4}
{"namespace": "dash.development._collect_nodes.collect_nodes", "type": "function", "project_path": "Software-Development/dash", "completion_path": "Software-Development/dash/dash/development/_collect_nodes.py", "signature_position": [49, 49], "body_position": [50, 74], "dependency": {"intra_class": [], "intra_file": ["dash.development._collect_nodes.collect_array", "dash.development._collect_nodes.collect_nodes", "dash.development._collect_nodes.collect_object", "dash.development._collect_nodes.collect_union", "dash.development._collect_nodes.is_node", "dash.development._collect_nodes.is_shape"], "cross_file": []}, "requirement": {"Functionality": "This function collects all the nodes in the metadata dictionary and returns them as a list. It recursively traverses the metadata dictionary and checks the type of each value to determine if it is a node, an array, a shape, a union, or an object. It appends the corresponding keys to the nodes list.", "Arguments": ":param metadata: Dictionary. The metadata dictionary containing the nodes.\n:param base: String. The base key to be used for nested nodes. Defaults to an empty string.\n:param nodes: List. The list to store the collected nodes. Defaults to an empty list.\n:return: List. The list of collected nodes."}, "tests": ["tests/unit/development/test_collect_nodes.py::test_dcn002_base_nodes", "tests/unit/development/test_collect_nodes.py::test_dcn001_collect_nodes"], "indent": 4}
{"namespace": "mssqlcli.jsonrpc.jsonrpcclient.JsonRpcReader.try_read_headers", "type": "method", "project_path": "Database/mssql-cli", "completion_path": "Database/mssql-cli/mssqlcli/jsonrpc/jsonrpcclient.py", "signature_position": [334, 334], "body_position": [345, 394], "dependency": {"intra_class": ["mssqlcli.jsonrpc.jsonrpcclient.JsonRpcReader.CR", "mssqlcli.jsonrpc.jsonrpcclient.JsonRpcReader.LF", "mssqlcli.jsonrpc.jsonrpcclient.JsonRpcReader.buffer", "mssqlcli.jsonrpc.jsonrpcclient.JsonRpcReader.buffer_end_offset", "mssqlcli.jsonrpc.jsonrpcclient.JsonRpcReader.expected_content_length", "mssqlcli.jsonrpc.jsonrpcclient.JsonRpcReader.headers", "mssqlcli.jsonrpc.jsonrpcclient.JsonRpcReader.read_offset", "mssqlcli.jsonrpc.jsonrpcclient.JsonRpcReader.read_state", "mssqlcli.jsonrpc.jsonrpcclient.JsonRpcReader.trim_buffer_and_resize"], "intra_file": ["mssqlcli.jsonrpc.jsonrpcclient.ReadState", "mssqlcli.jsonrpc.jsonrpcclient.ReadState.Content", "mssqlcli.jsonrpc.jsonrpcclient.logger"], "cross_file": []}, "requirement": {"Functionality": "This function tries to read the Header information from the internal buffer of a JsonRpcReader instance. It scans the buffer until it finds the last header containing '\\r\\n\\r\\n'. It then splits the headers by new line, extracts the key-value pairs, and stores them in the headers dictionary of the instance. It also checks if the 'content-length' header is present and stores its value in the expected content length of the instance.", "Arguments": ":param self: JsonRpcReader. An instance of the JsonRpcReader class.\n:return: bool. True if the header information was successfully read, False otherwise."}, "tests": ["tests/jsonrpc/test_jsonrpc.py::JsonRpcTest::test_read_state"], "indent": 8}
{"namespace": "mopidy.config.types.Secret.serialize", "type": "method", "project_path": "Multimedia/Mopidy", "completion_path": "Multimedia/Mopidy/mopidy/config/types.py", "signature_position": [138, 138], "body_position": [139, 141], "dependency": {"intra_class": [], "intra_file": ["mopidy.config.types.String", "mopidy.config.types.String.serialize"], "cross_file": []}, "requirement": {"Functionality": "Serialize a value based on the given condition. If the value is not None and the display flag is set to True, it returns \"********\". Otherwise, it makes the superclass to serialize that and returns the result.", "Arguments": ":param self: Secret. An instance of the Secret class.\n:param value: The value to be serialized.\n:param display: Bool. Whether to display the serialized value. Defaults to False.\n:return: The serialized value."}, "tests": ["tests/config/test_types.py::TestSecret::test_serialize_none", "tests/config/test_types.py::TestSecret::test_serialize_for_display_masks_value", "tests/config/test_types.py::TestSecret::test_serialize_transformed_value_for_display_masks_value", "tests/config/test_types.py::TestSecret::test_serialize_none_for_display", "tests/config/test_types.py::TestSecret::test_serialize_transformed_value"], "indent": 8}
{"namespace": "boto.dynamodb2.table.BatchTable.resend_unprocessed", "type": "method", "project_path": "Internet/boto", "completion_path": "Internet/boto/boto/dynamodb2/table.py", "signature_position": [1703, 1706], "body_position": [1707, 1724], "dependency": {"intra_class": ["boto.dynamodb2.table.BatchTable._unprocessed", "boto.dynamodb2.table.BatchTable.handle_unprocessed", "boto.dynamodb2.table.BatchTable.table"], "intra_file": ["boto.dynamodb2.table.Table.connection"], "cross_file": ["boto.log", "boto", "boto.dynamodb2.layer1.DynamoDBConnection.batch_write_item"]}, "requirement": {"Functionality": "Resend unprocessed items in the BatchTable instance. It iterates over the unprocessed items and sends them in batches until all items are processed.", "Arguments": ":param self: BatchTable. An instance of the BatchTable class.\n:return: No return values."}, "tests": ["tests/unit/dynamodb2/test_table.py::TableTestCase::test_batch_write_unprocessed_items"], "indent": 8}
{"namespace": "folium.utilities.get_bounds", "type": "function", "project_path": "Scientific-Engineering/folium", "completion_path": "Scientific-Engineering/folium/folium/utilities.py", "signature_position": [382, 382], "body_position": [388, 402], "dependency": {"intra_class": [], "intra_file": ["folium.utilities._locations_mirror", "folium.utilities.iter_coords", "folium.utilities.none_max", "folium.utilities.none_min"], "cross_file": []}, "requirement": {"Functionality": "This function computes the bounds of the object based on the given locations. It iterates through the coordinates of the locations and updates the bounds accordingly. The bounds are returned in the form of [[lat_min, lon_min], [lat_max, lon_max]].", "Arguments": ":param locations: The locations of the object.\n:param lonlat: Bool. Whether the coordinates are in the form of [lon, lat]. Defaults to False.\n:return: The bounds of the object in the form of [[lat_min, lon_min], [lat_max, lon_max]]."}, "tests": ["tests/test_vector_layers.py::test_polygon_marker", "tests/test_vector_layers.py::test_polyline", "tests/test_vector_layers.py::test_mulyipolyline"], "indent": 4}
{"namespace": "ydata_profiling.model.pandas.correlations_pandas.pandas_cramers_compute", "type": "function", "project_path": "Software-Development/pandas-profiling", "completion_path": "Software-Development/pandas-profiling/src/ydata_profiling/model/pandas/correlations_pandas.py", "signature_position": [85, 87], "body_position": [88, 121], "dependency": {"intra_class": [], "intra_file": ["ydata_profiling.model.pandas.correlations_pandas._cramers_corrected_stat"], "cross_file": ["ydata_profiling.config.Settings", "ydata_profiling.config.Settings.categorical_maximum_correlation_distinct"]}, "requirement": {"Functionality": "This function computes the Cramer's V correlation matrix for categorical variables in a pandas DataFrame. It first identifies the categorical variables based on the given summary dictionary and a threshold value. Then, it creates an empty correlation matrix with the identified categorical variables as both the index and columns. Next, it calculates the Cramer's V correlation coefficient for each pair of categorical variables and stores the result in the correlation matrix.", "Arguments": ":param config: Settings. An instance of the Settings class that contains the configuration parameters.\n:param df: pd.DataFrame. The pandas DataFrame containing the data.\n:param summary: dict. A dictionary that summarizes the variables in the DataFrame. It should have the variable names as keys and a dictionary with information about each variable as values.\n:return: Optional[pd.DataFrame]. The computed Cramer's V correlation matrix as a pandas DataFrame. If there are less than or equal to 1 categorical variable, None is returned."}, "tests": ["tests/unit/test_pandas/test_correlations.py::test_categorical_auto_equals_equals_cramers"], "indent": 4}
{"namespace": "trailscraper.record_sources.local_directory_record_source.LocalDirectoryRecordSource.load_from_dir", "type": "method", "project_path": "Security/trailscraper", "completion_path": "Security/trailscraper/trailscraper/record_sources/local_directory_record_source.py", "signature_position": [37, 37], "body_position": [39, 44], "dependency": {"intra_class": ["trailscraper.record_sources.local_directory_record_source.LocalDirectoryRecordSource._valid_log_files"], "intra_file": [], "cross_file": ["trailscraper.cloudtrail.LogFile.contains_events_for_timeframe", "trailscraper.cloudtrail.LogFile.records"]}, "requirement": {"Functionality": "Load all CloudTrail records from a directory within a specified date range. It iterates through all valid log files in the directory and checks if each file contains events within the specified date range. If a file meets the criteria, it retrieves the records from that file and adds them to the list of records.", "Arguments": ":param self: LocalDirectoryRecordSource. An instance of the LocalDirectoryRecordSource class.\n:param from_date: The starting date of the desired records.\n:param to_date: The ending date of the desired records.\n:return: List of CloudTrail records. The records that fall within the specified date range."}, "tests": ["tests/record_sources/local_directory_record_source_test.py::test_load_gzipped_files_including_those_that_were_delivered_only_an_hour_after_the_event_time_we_are_looking_for", "tests/record_sources/local_directory_record_source_test.py::test_load_gzipped_files_in_timeframe_from_dir", "tests/record_sources/local_directory_record_source_test.py::test_load_no_gzipped_files_outsite_timeframe_from_dir"], "indent": 8}
{"namespace": "alembic.command.history", "type": "function", "project_path": "Database/alembic", "completion_path": "Database/alembic/alembic/command.py", "signature_position": [472, 477], "body_position": [489, 538], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["alembic.config.Config", "alembic.config.Config.get_main_option", "alembic.script.ScriptDirectory.from_config", "alembic.util", "alembic.util.CommandError"]}, "requirement": {"Functionality": "This function lists the changeset scripts in chronological order. It takes a configuration instance, a revision range, a verbose flag, and an indicate_current flag as input. It uses the input parameters to display the history of changeset scripts.", "Arguments": ":param config: Config. An instance of the Config class.\n:param rev_range: Optional string. The revision range to display the history for.\n:param verbose: Bool. Whether to output in verbose mode.\n:param indicate_current: Bool. Whether to indicate the current revision.\n:return: None."}, "tests": ["tests/test_command.py::HistoryTest::test_history_indicate_current", "tests/test_command.py::HistoryTest::test_history_num_range_environment", "tests/test_command.py::HistoryTest::test_history_num_plus_relative", "tests/test_command.py::HistoryTest::test_history_num_to_head", "tests/test_command.py::HistoryTest::test_history_num_to_head_environment"], "indent": 4}
{"namespace": "mrjob.fs.local.LocalFilesystem.put", "type": "method", "project_path": "System/mrjob", "completion_path": "System/mrjob/mrjob/fs/local.py", "signature_position": [68, 68], "body_position": [70, 71], "dependency": {"intra_class": [], "intra_file": ["mrjob.fs.local._from_file_uri"], "cross_file": []}, "requirement": {"Functionality": "Copy a file from the source path to the destination path. Note to converts the input path from a file URI to a local path.", "Arguments": ":param self: LocalFilesystem. An instance of the LocalFilesystem class.\n:param src: String. The path of the source file to be copied.\n:param path: String. The destination path where the file will be copied to.\n:return: No return values."}, "tests": ["tests/fs/test_local.py::LocalFSTestCase::test_put"], "indent": 8}
{"namespace": "bentoml._internal.resource.CpuResource.from_system", "type": "method", "project_path": "Scientific-Engineering/bentoml", "completion_path": "Scientific-Engineering/bentoml/src/bentoml/_internal/resource.py", "signature_position": [105, 105], "body_position": [106, 109], "dependency": {"intra_class": [], "intra_file": ["bentoml._internal.resource.query_cgroup_cpu_count", "bentoml._internal.resource.query_os_cpu_count"], "cross_file": []}, "requirement": {"Functionality": "This function returns the number of CPU resources available in the system. It checks the operating system type and calls the appropriate function to retrieve the CPU count.", "Arguments": ":param cls: Class. The class itself.\n:return: Float. The number of CPU resources available in the system."}, "tests": ["tests/unit/_internal/test_resource.py::test_CpuResource"], "indent": 8}
{"namespace": "rows.fields.BinaryField.serialize", "type": "method", "project_path": "Text-Processing/rows", "completion_path": "Text-Processing/rows/rows/fields.py", "signature_position": [113, 113], "body_position": [114, 123], "dependency": {"intra_class": [], "intra_file": ["rows.fields.value_error"], "cross_file": []}, "requirement": {"Functionality": "Serialize a binary value into a string representation. If the value is not None, it checks if the value is of type binary. If it is, it encodes the binary value using base64 encoding and decodes it by ascii. If there is an error during encoding, it returns the original binary value. If the value is not of type binary, execute error processing. If the value is None, it returns an empty string.", "Arguments": ":param cls: BinaryField. The class itself.\n:param value: Any. The binary value to be serialized.\n:param *args: Any. Additional positional arguments.\n:param **kwargs: Any. Additional keyword arguments.\n:return: str. The serialized string representation of the binary value."}, "tests": ["tests/tests_fields.py::FieldsTestCase::test_BinaryField"], "indent": 8}
{"namespace": "zulipterminal.ui_tools.boxes.WriteBox.stream_box_edit_view", "type": "method", "project_path": "Communications/zulip-term", "completion_path": "Communications/zulip-term/zulipterminal/ui_tools/boxes.py", "signature_position": [401, 403], "body_position": [404, 414], "dependency": {"intra_class": ["zulipterminal.ui_tools.boxes.WriteBox._set_stream_write_box_style", "zulipterminal.ui_tools.boxes.WriteBox._setup_common_stream_compose", "zulipterminal.ui_tools.boxes.WriteBox.edit_mode_button", "zulipterminal.ui_tools.boxes.WriteBox.header_write_box", "zulipterminal.ui_tools.boxes.WriteBox.model", "zulipterminal.ui_tools.boxes.WriteBox.stream_write_box"], "intra_file": [], "cross_file": ["zulipterminal.ui_tools.buttons.EditModeButton", "zulipterminal.core.Controller"]}, "requirement": {"Functionality": "This function sets up the view for editing a stream box. It creates a text widget for the stream write box and sets up the common stream compose elements. It also adds an edit mode button to the header write box. Finally, it sets the style of the stream write box using a callback.", "Arguments": ":param self: WriteBox. An instance of the WriteBox class.\n:param stream_id: int. The ID of the stream.\n:param caption: str. The caption for the stream write box. Defaults to an empty string.\n:param title: str. The title for the stream write box. Defaults to an empty string.\n:return: No return values."}, "tests": ["tests/ui_tools/test_boxes.py::TestWriteBox::test_write_box_header_contents", "tests/ui_tools/test_boxes.py::TestWriteBox::test_keypress_CYCLE_COMPOSE_FOCUS"], "indent": 8}
{"namespace": "diffprivlib.validation.clip_to_bounds", "type": "function", "project_path": "Security/diffprivlib", "completion_path": "Security/diffprivlib/diffprivlib/validation.py", "signature_position": [167, 167], "body_position": [185, 200], "dependency": {"intra_class": [], "intra_file": ["diffprivlib.validation.check_bounds"], "cross_file": []}, "requirement": {"Functionality": "This function clips the examples of a 2-dimensional array to given bounds. It checks if the input array is a numpy array, then it checks the bounds and clips the array accordingly. It first checks that the bounds are indeed tuple and that shape is an integer. If these conditions are not met, the function raises a error of type. It then extracts the lower and upper bounds, ensuring they are in the correct format and adjusting them to be arrays of the specified data type (dtype). The function enforces that the lower and upper bounds must be of the same shape and dimensionality, specifically either scalar or 1-dimensional arrays.", "Arguments": ":param array: np.ndarray. The array to be clipped. After clipping, all examples have a 2-norm of at most `clip`.\n:param bounds: tuple. The bounds of the form (min, max) which the array is to be clipped to. `min` and `max` must be scalar, unless the array is 2-dimensional.\n:return: np.ndarray. The clipped array."}, "tests": ["tests/test_clip_to_bounds.py::TestClipToBounds::test_incorrect_parameterisation", "tests/test_clip_to_bounds.py::TestClipToBounds::test_bad_bounds", "tests/test_clip_to_bounds.py::TestClipToBounds::test_1d_array", "tests/test_clip_to_bounds.py::TestClipToBounds::test_iris", "tests/test_clip_to_bounds.py::TestClipToBounds::test_different_bounds"], "indent": 4}
{"namespace": "bentoml._internal.utils.validate_metadata", "type": "function", "project_path": "Scientific-Engineering/bentoml", "completion_path": "Scientific-Engineering/bentoml/src/bentoml/_internal/utils/__init__.py", "signature_position": [321, 321], "body_position": [322, 329], "dependency": {"intra_class": [], "intra_file": ["bentoml._internal.utils._validate_metadata_entry"], "cross_file": []}, "requirement": {"Functionality": "This function validates the metadata dictionary by validate each entry in the dictionary.", "Arguments": ":param metadata: MetadataDict. The metadata dictionary to be validated.\n:return: No return values."}, "tests": ["tests/unit/_internal/test_utils.py::test_validate_metadata"], "indent": 4}
{"namespace": "twitter.api.Api._TweetTextWrap", "type": "method", "project_path": "Internet/python-twitter", "completion_path": "Internet/python-twitter/twitter/api.py", "signature_position": [1431, 1434], "body_position": [1435, 1470], "dependency": {"intra_class": ["twitter.api.Api.GetHelpConfiguration", "twitter.api.Api._config"], "intra_file": ["twitter.api.CHARACTER_LIMIT"], "cross_file": ["twitter.error.TwitterError", "twitter.twitter_utils.is_url"]}, "requirement": {"Functionality": "This function takes a status message and wraps it into multiple tweets based on the character limit. It splits the status into words and checks if each word exceeds the character limit. If a word exceeds the limit, it raises an exception. It then calculates the length of the line by adding the length of each word and checks if it exceeds the character limit. If it does, it appends the line to the list of tweets and starts a new line with the current word. If it doesn't exceed the limit, it adds the word to the line. Finally, it appends the last line to the list of tweets and returns it.", "Arguments": ":param self: Api. An instance of the Api class.\n:param status: String. The status message to be wrapped into tweets.\n:param char_lim: Integer. The character limit for each tweet. Defaults to CHARACTER_LIMIT.\n:return: List of strings. The wrapped status message split into multiple tweets."}, "tests": ["tests/test_tweet_length.py::TestTweetLength::test_split_tweets"], "indent": 8}
{"namespace": "pyinfra.operations.python.call", "type": "function", "project_path": "System/pyinfra", "completion_path": "System/pyinfra/pyinfra/operations/python.py", "signature_position": [13, 13], "body_position": [46, 57], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["pyinfra.api.util.get_call_location", "pyinfra.logger"]}, "requirement": {"Functionality": "This function executes a Python function within a deploy. It takes a function, along with its arguments and keyword arguments, and yields a FunctionCommand object.", "Arguments": ":param function: The Python function to execute.\n:param args: The arguments to pass to the function.\n:param kwargs: The keyword arguments to pass to the function.\n:return: A FunctionCommand object."}, "tests": ["tests/test_api/test_api_operations.py::TestOperationsApi::test_function_call_op", "tests/test_api/test_api_operations.py::TestNestedOperationsApi::test_nested_op_api"], "indent": 4}
{"namespace": "boltons.formatutils.tokenize_format_str", "type": "function", "project_path": "Utilities/boltons", "completion_path": "Utilities/boltons/boltons/formatutils.py", "signature_position": [203, 203], "body_position": [210, 220], "dependency": {"intra_class": [], "intra_file": ["boltons.formatutils.BaseFormatField", "boltons.formatutils.BaseFormatField.__init__", "boltons.formatutils.infer_positional_format_args"], "cross_file": []}, "requirement": {"Functionality": "This function takes a format string and converts it into a list of alternating string literals and BaseFormatField tokens. It also has an option to infer anonymous positional references into explicit, numbered positional references.", "Arguments": ":param fstr: String. The format string to be tokenized.\n:param resolve_pos: Bool. Whether to infer anonymous positional references into explicit, numbered positional references. Defaults to True.\n:return: List. A list of alternating string literals and BaseFormatField tokens."}, "tests": ["tests/test_formatutils.py::test_tokenize_format_str"], "indent": 4}
{"namespace": "pyinfra.api.operations.run_ops", "type": "function", "project_path": "System/pyinfra", "completion_path": "System/pyinfra/pyinfra/api/operations.py", "signature_position": [358, 358], "body_position": [369, 382], "dependency": {"intra_class": [], "intra_file": ["pyinfra.api.operations._run_no_wait_ops", "pyinfra.api.operations._run_serial_ops", "pyinfra.api.operations._run_single_op"], "cross_file": ["pyinfra.api.state.State.get_op_order", "pyinfra.api.state.State.is_executing", "pyinfra.context.ctx_state", "pyinfra.context.ContextManager.use"]}, "requirement": {"Functionality": "This function runs all operations across all servers in a configurable manner. It allows the user to choose whether to run operations host by host, run all operations on each server in parallel without waiting, or run all operations in order, waiting at each operation for all servers to complete.", "Arguments": ":param state: State. An instance of the State class. The deploy state to execute.\n:param serial: Bool. Whether to run operations host by host. Defaults to False.\n:param no_wait: Bool. Whether to run all the ops on each server in parallel without waiting at each operation. Defaults to False.\n:return: No return values."}, "tests": ["tests/test_api/test_api_operations.py::TestNestedOperationsApi::test_nested_op_api", "tests/test_api/test_api_operations.py::TestOperationsApi::test_rsync_op", "tests/test_api/test_api_operations.py::TestOperationsApi::test_run_once_serial_op", "tests/test_api/test_api_operations.py::TestOperationsApi::test_rsync_op_with_strict_host_key_checking_disabled", "tests/test_api/test_api_operations.py::TestOperationsApi::test_file_upload_op"], "indent": 4}
{"namespace": "bplustree.tree.BPlusTree._left_record_node", "type": "method", "project_path": "Database/bplustree", "completion_path": "Database/bplustree/bplustree/tree.py", "signature_position": [278, 278], "body_position": [279, 282], "dependency": {"intra_class": ["bplustree.tree.BPlusTree.LeafNode", "bplustree.tree.BPlusTree.LonelyRootNode", "bplustree.tree.BPlusTree._mem", "bplustree.tree.BPlusTree._root_node"], "intra_file": [], "cross_file": ["bplustree.memory.FileMemory.get_node", "bplustree.node.Node.smallest_entry"]}, "requirement": {"Functionality": "This function returns the leftmost record node in the B+ tree. It starts from the root node and traverses down the tree until it reaches a node that is either a lonely root node or a leaf node.", "Arguments": ":param self: BPlusTree. An instance of the BPlusTree class.\n:return: Union['LonelyRootNode', 'LeafNode']. The leftmost record node in the B+ tree."}, "tests": ["tests/test_tree.py::test_left_record_node_in_tree"], "indent": 8}
{"namespace": "zulipterminal.ui_tools.boxes.WriteBox._topic_box_autocomplete", "type": "method", "project_path": "Communications/zulip-term", "completion_path": "Communications/zulip-term/zulipterminal/ui_tools/boxes.py", "signature_position": [454, 454], "body_position": [455, 460], "dependency": {"intra_class": ["zulipterminal.ui_tools.boxes.WriteBox._process_typeaheads", "zulipterminal.ui_tools.boxes.WriteBox.model", "zulipterminal.ui_tools.boxes.WriteBox.stream_id"], "intra_file": [], "cross_file": ["zulipterminal.helper.match_topics", "zulipterminal.model.Model.topics_in_stream"]}, "requirement": {"Functionality": "This function provides autocomplete suggestions for a given text input based on the available topics in a stream. It retrieves the list of topic names from the model and matches them with the input text to generate typeaheads. It then processes the typeaheads and returns them as suggestions.", "Arguments": ":param self: WriteBox. An instance of the WriteBox class.\n:param text: str. The input text for which autocomplete suggestions are required.\n:param state: Optional[int]. The state of the autocomplete process. Defaults to None.\n:return: Optional[str]. The generated autocomplete suggestions for the input text."}, "tests": ["tests/ui_tools/test_boxes.py::TestWriteBox::test__topic_box_autocomplete"], "indent": 8}
{"namespace": "exodus_bundler.input_parsing.extract_open_path", "type": "function", "project_path": "System/exodus-bundler", "completion_path": "System/exodus-bundler/src/exodus_bundler/input_parsing.py", "signature_position": [41, 41], "body_position": [43, 56], "dependency": {"intra_class": [], "intra_file": ["exodus_bundler.input_parsing.strip_pid_prefix"], "cross_file": []}, "requirement": {"Functionality": "This function parses a line of strace output and extracts the file path that is being opened. It checks for different prefixes in the line and extracts the file path if the line matches the expected format.", "Arguments": ":param line: str. The line of strace output to be parsed.\n:return: str or None. The file path being opened, or None if no file path is found in the line."}, "tests": ["tests/test_input_parsing.py::test_extract_open_path"], "indent": 4}
{"namespace": "sslyze.plugins.http_headers_plugin._detect_http_redirection", "type": "function", "project_path": "System/sslyze", "completion_path": "System/sslyze/sslyze/plugins/http_headers_plugin.py", "signature_position": [270, 270], "body_position": [272, 291], "dependency": {"intra_class": [], "intra_file": ["sslyze.plugins.http_headers_plugin._extract_first_header_value"], "cross_file": []}, "requirement": {"Functionality": "This function detects if an HTTP response contains a redirection to the same server. If it does, it returns the path to the new location.", "Arguments": ":param http_response: HTTPResponse. The HTTP response object.\n:param server_host_name: str. The hostname of the server.\n:param server_port: int. The port number of the server.\n:return: Optional[str]. The path to the new location if a redirection to the same server is found, otherwise None."}, "tests": ["tests/plugins_tests/test_http_headers_plugin.py::TestHttpRedirection::test_redirection_relative_url", "tests/plugins_tests/test_http_headers_plugin.py::TestHttpRedirection::test_redirection_absolute_url_same_server"], "indent": 4}
{"namespace": "mrjob.protocol._KeyCachingProtocol.read", "type": "method", "project_path": "System/mrjob", "completion_path": "System/mrjob/mrjob/protocol.py", "signature_position": [83, 83], "body_position": [91, 96], "dependency": {"intra_class": ["mrjob.protocol._KeyCachingProtocol._last_key_decoded", "mrjob.protocol._KeyCachingProtocol._last_key_encoded", "mrjob.protocol._KeyCachingProtocol._loads"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Decodes a line of raw input into a tuple of key and value.\nSplits the input line at the first occurrence of the tab character. Then it updates the last key encoded by loading the key we obtained. It also decodes the value and returns a tuple of the last key decoded and the decoded value.\n", "Arguments": ":param line: String. A line of raw input to the job, without trailing newline.\n:return: tuple. A tuple of ``(key, value)``.\n"}, "tests": ["tests/test_protocol.py::StandardJSONProtocolTestCase::test_numerical_keys_become_strs", "tests/test_protocol.py::StandardJSONProtocolTestCase::test_tuples_become_lists", "tests/test_protocol.py::ReprProtocolTestCase::test_uses_repr_format", "tests/test_protocol.py::StandardJSONProtocolTestCase::test_uses_json_format"], "indent": 8}
{"namespace": "mrjob.bin.MRJobBinRunner._task_python_bin", "type": "method", "project_path": "System/mrjob", "completion_path": "System/mrjob/mrjob/bin.py", "signature_position": [185, 185], "body_position": [188, 189], "dependency": {"intra_class": ["mrjob.bin.MRJobBinRunner._python_bin"], "intra_file": [], "cross_file": ["mrjob.runner.MRJobRunner._opts"]}, "requirement": {"Functionality": "This function returns the Python binary used to invoke a job with specific options. If the task python binary option is set, it returns the value of task python binary. Otherwise, it returns the default Python binary.", "Arguments": ":param self: MRJobBinRunner. An instance of the MRJobBinRunner class.\n:return: str. The Python binary used to invoke the job."}, "tests": ["tests/test_bin.py::TaskPythonBinTestCase::test_default", "tests/test_bin.py::TaskPythonBinTestCase::test_python_bin", "tests/test_bin.py::TaskPythonBinTestCase::test_empty_python_bin_means_default", "tests/test_bin.py::TaskPythonBinTestCase::test_task_python_bin"], "indent": 8}
{"namespace": "boto.cloudsearch2.connect_to_region", "type": "function", "project_path": "Internet/boto", "completion_path": "Internet/boto/boto/cloudsearch2/__init__.py", "signature_position": [36, 36], "body_position": [37, 40], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["boto.cloudsearch2.layer1.CloudSearchConnection", "boto.regioninfo.connect"]}, "requirement": {"Functionality": "Connect to a specific region in the cloudsearch service. It creates a connection to the cloudsearch service in the specified region using the provided parameters.", "Arguments": ":param region_name: String. The name of the region to connect to.\n:param **kw_params: Additional keyword arguments that can be passed to the connection.\n:return: CloudSearchConnection. The connection object to the cloudsearch service in the specified region."}, "tests": ["tests/unit/test_connect_to_region.py::TestCloudsearch2Connection::test_connect_to_region"], "indent": 4}
{"namespace": "twilio.twiml.messaging_response.MessagingResponse.message", "type": "method", "project_path": "Communications/twilio-fatisar", "completion_path": "Communications/twilio-fatisar/twilio/twiml/messaging_response.py", "signature_position": [21, 30], "body_position": [44, 54], "dependency": {"intra_class": [], "intra_file": ["twilio.twiml.messaging_response.Message", "twilio.twiml.messaging_response.Message.__init__"], "cross_file": ["twilio.twiml.TwiML.nest"]}, "requirement": {"Functionality": "This function creates a `<Message>` element for a MessagingResponse instance. It takes in various parameters such as the message body, phone numbers, action URL, and additional attributes, and returns the created `<Message>` element.", "Arguments": ":param self: MessagingResponse. An instance of the MessagingResponse class.\n:param body: String. The body of the message.\n:param to: String. The phone number to send the message to.\n:param from_: String. The phone number to send the message from.\n:param action: String. The action URL.\n:param method: String. The method to use for the action URL.\n:param status_callback: String. The status callback URL. Deprecated in favor of action.\n:param kwargs: Additional attributes for the `<Message>` element.\n:return: `<Message>` element. The created `<Message>` element."}, "tests": ["tests/unit/twiml/test_messaging_response.py::TestResponse::test_nested_verbs", "tests/unit/twiml/test_messaging_response.py::TestResponse::test_response", "tests/unit/twiml/test_messaging_response.py::TestResponse::test_response_chain", "tests/unit/twiml/test_messaging_response.py::TestMessage::test_body"], "indent": 8}
{"namespace": "falcon.request.Request.host", "type": "method", "project_path": "Internet/falcon", "completion_path": "Internet/falcon/falcon/request.py", "signature_position": [831, 831], "body_position": [832, 843], "dependency": {"intra_class": ["falcon.request.Request.env"], "intra_file": [], "cross_file": ["falcon.util.uri.parse_host"]}, "requirement": {"Functionality": "This function retrieves the host information from the request. It first tries to get the host information from the 'HTTP_HOST' header in the request environment. If the header is not found, it retrieves the host information from the 'SERVER_NAME' field in the request environment.", "Arguments": ":param self: Request. An instance of the Request class.\n:return: String. The host information extracted from the request."}, "tests": ["tests/test_request_attrs.py::TestRequestAttributes::test_host"], "indent": 8}
{"namespace": "pyramid.traversal.find_resource", "type": "function", "project_path": "Internet/pyramid", "completion_path": "Internet/pyramid/src/pyramid/traversal.py", "signature_position": [35, 35], "body_position": [79, 86], "dependency": {"intra_class": [], "intra_file": ["pyramid.traversal.traverse"], "cross_file": ["pyramid.util.ascii_"]}, "requirement": {"Functionality": "Given a resource object and a string or tuple representing a path, this function returns a resource in the application's resource tree at the specified path. If the path cannot be resolved (if the respective node in the resource tree does not exist), a `KeyError` will be raised.", "Arguments": ":param resource: The resource object.\n:param path: str or Tuple[str]. The path to the resource. It can be absolute (starting at the root resource) or relative (starting at the given resource). If it is a str, starting with a slash indicates an absolute path, and not starting with a slash indicates a relative path. Each path segment must be UTF-8 encoded and escaped using Python's `urllib.quote`. If it is a tuple, starting with an '' indicates an absolute path, and not starting with an '' indicates a relative path. No URL-quoting of individual path segments is required.\n:return: The resource in the application's resource tree at the specified path."}, "tests": ["tests/test_config/test_testing.py::TestingConfiguratorMixinTests::test_testing_resources"], "indent": 4}
{"namespace": "mrjob.hadoop.HadoopJobRunner.fs", "type": "method", "project_path": "System/mrjob", "completion_path": "System/mrjob/mrjob/hadoop.py", "signature_position": [192, 192], "body_position": [196, 209], "dependency": {"intra_class": ["mrjob.hadoop.HadoopJobRunner._fs"], "intra_file": [], "cross_file": ["mrjob.fs.composite.CompositeFilesystem", "mrjob.fs.composite.CompositeFilesystem.add_fs", "mrjob.fs.hadoop.HadoopFilesystem", "mrjob.fs.local.LocalFilesystem"]}, "requirement": {"Functionality": "This function returns a file system object for HDFS and the local filesystem. If the file system object has already been created, it returns it. Otherwise, it creates a CompositeFilesystem object and adds HadoopFilesystem and LocalFilesystem to it.", "Arguments": ":param self: HadoopJobRunner. An instance of the HadoopJobRunner class.\n:return: Filesystem. The Filesystem object for HDFS and the local filesystem."}, "tests": ["tests/test_hadoop.py::StreamTaskLogDirsTestCase::test_io_error_from_fs_exists", "tests/test_hadoop.py::StreamHistoryLogDirsTestCase::test_fs_exists", "tests/test_hadoop.py::StreamTaskLogDirsTestCase::test_fs_exists", "tests/test_hadoop.py::StreamHistoryLogDirsTestCase::test_io_error_from_fs_exists"], "indent": 8}
{"namespace": "pythonforandroid.graph.get_dependency_tuple_list_for_recipe", "type": "function", "project_path": "Utilities/python-for-android", "completion_path": "Utilities/python-for-android/pythonforandroid/graph.py", "signature_position": [42, 42], "body_position": [46, 61], "dependency": {"intra_class": [], "intra_file": ["pythonforandroid.graph.fix_deplist"], "cross_file": []}, "requirement": {"Functionality": "This function takes a recipe and a blacklist as input and returns a list of dependencies for the recipe. The dependencies are filtered based on the blacklist and converted into tuples and filter out blacklisted items and turn lowercase.", "Arguments": ":param recipe: The recipe for which the dependencies need to be retrieved.\n:param blacklist: Set. A set of items to be filtered out from the dependencies. Defaults to None.\n:return: List of tuples. The dependencies of the recipe after filtering and conversion into tuples."}, "tests": ["tests/test_graph.py::test_get_dependency_tuple_list_for_recipe"], "indent": 4}
{"namespace": "boto.dynamodb2.table.Table.update_global_secondary_index", "type": "method", "project_path": "Internet/boto", "completion_path": "Internet/boto/boto/dynamodb2/table.py", "signature_position": [557, 557], "body_position": [584, 608], "dependency": {"intra_class": ["boto.dynamodb2.table.Table.connection", "boto.dynamodb2.table.Table.table_name"], "intra_file": [], "cross_file": ["boto.dynamodb2.layer1.DynamoDBConnection.update_table", "boto.log", "boto"]}, "requirement": {"Functionality": "This function updates the global index(es) in DynamoDB after the table has been created. It takes a dictionary of global indexes as input and updates the read and write capacity units for each index. It then updates the table with the new global index information.", "Arguments": ":param self: Table. An instance of the Table class.\n:param global_indexes: Dictionary. A dictionary specifying the global indexes to be updated. Each key in the dictionary represents the index name, and the corresponding value is another dictionary containing the read and write capacity units for the index.\n:return: Bool. Returns True if the global indexes are successfully updated, False otherwise."}, "tests": ["tests/unit/dynamodb2/test_table.py::TableTestCase::test_update_global_secondary_index"], "indent": 8}
{"namespace": "sumy.summarizers.reduction.ReductionSummarizer.rate_sentences", "type": "method", "project_path": "Internet/sumy", "completion_path": "Internet/sumy/sumy/summarizers/reduction.py", "signature_position": [30, 30], "body_position": [31, 39], "dependency": {"intra_class": ["sumy.summarizers.reduction.ReductionSummarizer._rate_sentences_edge"], "intra_file": [], "cross_file": ["sumy.models.dom._document.ObjectDocumentModel.sentences"]}, "requirement": {"Functionality": "This function rates the sentences in a document based on their similarity. It calculates the similarity between each pair of sentences and assigns a rating to each sentence based on the similarity with other sentences.", "Arguments": ":param self: ReductionSummarizer. An instance of the ReductionSummarizer class.\n:param document: Document. The document containing the sentences to be rated.\n:return: defaultdict. A dictionary containing the ratings for each sentence."}, "tests": ["tests/test_summarizers/test_reduction.py::test_sentences_rating"], "indent": 8}
{"namespace": "boto.utils.get_instance_userdata", "type": "function", "project_path": "Internet/boto", "completion_path": "Internet/boto/boto/utils.py", "signature_position": [430, 431], "body_position": [432, 441], "dependency": {"intra_class": [], "intra_file": ["boto.utils._build_instance_metadata_url", "boto.utils.retry_url"], "cross_file": []}, "requirement": {"Functionality": "This function retrieves the user data of an instance. It builds the URL for the user data based on the input parameters and then uses the URL to retrieve the user data. If the user data is not empty, it can be further processed based on the separator provided.", "Arguments": ":param version: String. The version of the instance metadata to use. It defaults to 'latest' if not specified.\n:param sep: String. The separator used to split the user data into key-value pairs. If not specified, the user data is returned as is.\n:param url: String. The base URL for the instance metadata service. It defaults to 'http://169.254.169.254' if not specified.\n:param timeout: Float. The timeout value for the HTTP request. If not specified, the default timeout is used.\n:param num_retries: Integer. The number of retries to attempt if the HTTP request fails. It defaults to 5 if not specified.\n:return: String or Dictionary. The user data of the instance. If the separator is provided, it is returned as a dictionary of key-value pairs. Otherwise, it is returned as a string."}, "tests": ["tests/unit/utils/test_utils.py::TestLazyLoadMetadata::test_user_data_timeout", "tests/unit/utils/test_utils.py::TestLazyLoadMetadata::test_user_data"], "indent": 4}
{"namespace": "imapclient.imapclient.IMAPClient.get_quota_root", "type": "method", "project_path": "Communications/IMAPClient", "completion_path": "Communications/IMAPClient/imapclient/imapclient.py", "signature_position": [1584, 1584], "body_position": [1594, 1602], "dependency": {"intra_class": ["imapclient.imapclient.IMAPClient._imap", "imapclient.imapclient.IMAPClient._raw_command_untagged"], "intra_file": ["imapclient.imapclient.MailboxQuotaRoots", "imapclient.imapclient._parse_quota"], "cross_file": ["imapclient.response_parser.parse_response", "imapclient.util.to_bytes", "imapclient.util.to_unicode"]}, "requirement": {"Functionality": "This function retrieves the quota roots and associated quotas for a given mailbox from the IMAP server. It sends the appropriate IMAP command to the server and parses the response to extract the quota roots and quotas.", "Arguments": ":param self: IMAPClient. An instance of the IMAPClient class.\n:param mailbox: String. The name of the mailbox to retrieve the quota roots for.\n:return: Tuple. A tuple containing the MailboxQuotaRoots object, which represents the quota roots, and a list of Quota objects, which represent the associated quotas."}, "tests": ["tests/test_imapclient.py::TestQuota::test_get_quota_root"], "indent": 8}
{"namespace": "pyt.vulnerabilities.trigger_definitions_parser.parse", "type": "function", "project_path": "Security/python-taint", "completion_path": "Security/python-taint/pyt/vulnerabilities/trigger_definitions_parser.py", "signature_position": [69, 69], "body_position": [75, 82], "dependency": {"intra_class": [], "intra_file": ["pyt.vulnerabilities.trigger_definitions_parser.Definitions", "pyt.vulnerabilities.trigger_definitions_parser.Source", "pyt.vulnerabilities.trigger_definitions_parser.Sink", "pyt.vulnerabilities.trigger_definitions_parser.Sink.from_json"], "cross_file": []}, "requirement": {"Functionality": "This function parses a file to extract source and sink definitions. It reads the contents of the file, converts it into a dictionary using JSON, and then creates the sources and sinks based on the extracted data. Finally, it returns a tuple containing the created sources and sinks.", "Arguments": ":param trigger_word_file: The file to be parsed for source and sink definitions.\n:return: Definitions. A tuple containing the created sources and sinks."}, "tests": ["tests/vulnerabilities/vulnerabilities_test.py::EngineTest::test_parse"], "indent": 4}
{"namespace": "rest_framework.reverse.reverse", "type": "function", "project_path": "Internet/djangorestframework", "completion_path": "Internet/djangorestframework/rest_framework/reverse.py", "signature_position": [32, 32], "body_position": [38, 49], "dependency": {"intra_class": [], "intra_file": ["rest_framework.reverse._reverse", "rest_framework.reverse.preserve_builtin_query_params"], "cross_file": ["rest_framework.versioning.BaseVersioning.reverse"]}, "requirement": {"Functionality": "This function is used to reverse a viewname into a URL. If versioning is being used, the function passes the reverse call to the versioning scheme instance to modify the resulting URL if needed.", "Arguments": ":param viewname: The name of the view to reverse. Default to None.\n:param args: List. Positional arguments to be passed to the view. Default to None.\n:param kwargs: Dict. Keyword arguments to be passed to the view. Default to None.\n:param request: HttpRequest. The current request being processed. Default to None.\n:param format: String. The format of the URL. Default to None.\n:param extra: Dict. Extra keyword arguments to be passed to the view.\n:return: String. The reversed URL."}, "tests": ["tests/test_reverse.py::ReverseTests::test_reverse_with_versioning_scheme"], "indent": 4}
{"namespace": "pyramid.csrf.CookieCSRFStoragePolicy.get_csrf_token", "type": "method", "project_path": "Internet/pyramid", "completion_path": "Internet/pyramid/src/pyramid/csrf.py", "signature_position": [147, 147], "body_position": [150, 154], "dependency": {"intra_class": ["pyramid.csrf.CookieCSRFStoragePolicy.cookie_profile", "pyramid.csrf.CookieCSRFStoragePolicy.new_csrf_token"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function returns the currently active CSRF token from the cookies sent with the current request. If the token is not found in the cookies, a new CSRF token is generated and returned.", "Arguments": ":param self: CookieCSRFStoragePolicy. An instance of the CookieCSRFStoragePolicy class.\n:param request: The current request object.\n:return: The CSRF token."}, "tests": ["tests/test_csrf.py::TestCookieCSRFStoragePolicy::test_existing_cookie_csrf_does_not_set_cookie", "tests/test_csrf.py::TestCookieCSRFStoragePolicy::test_get_cookie_csrf_with_no_existing_cookie_sets_cookies", "tests/test_csrf.py::TestCookieCSRFStoragePolicy::test_get_cookie_csrf_nondefault_samesite", "tests/test_csrf.py::TestCookieCSRFStoragePolicy::test_get_csrf_token_returns_the_new_token"], "indent": 8}
{"namespace": "boltons.socketutils.BufferedSocket.recv_close", "type": "method", "project_path": "Utilities/boltons", "completion_path": "Utilities/boltons/boltons/socketutils.py", "signature_position": [262, 262], "body_position": [270, 284], "dependency": {"intra_class": ["boltons.socketutils.BufferedSocket._recv_lock", "boltons.socketutils.BufferedSocket.maxsize", "boltons.socketutils.BufferedSocket.rbuf", "boltons.socketutils.BufferedSocket.recv_size"], "intra_file": ["boltons.socketutils.ConnectionClosed", "boltons.socketutils.MessageTooLong", "boltons.socketutils.MessageTooLong.__init__", "boltons.socketutils._RECV_LARGE_MAXSIZE", "boltons.socketutils._UNSET"], "cross_file": []}, "requirement": {"Functionality": "This function receives data from the socket until the connection is closed, up to a specified maximum size. If more than the maximum size is received, it raises a `MessageTooLong` exception.\n", "Arguments": ":param self: BufferedSocket, an instance of the BufferedSocket class.\n:param timeout: int. The timeout value for receiving data. Defaults to `_UNSET` if not specified.\n:param maxsize: int. The maximum size of received data. Defaults to `_UNSET` if not specified.\n:return: bytes. The received data up to the maximum size specified.\n"}, "tests": ["tests/test_socketutils.py::test_short_lines"], "indent": 8}
{"namespace": "mopidy.config.types.LogLevel.serialize", "type": "method", "project_path": "Multimedia/Mopidy", "completion_path": "Multimedia/Mopidy/mopidy/config/types.py", "signature_position": [372, 372], "body_position": [373, 376], "dependency": {"intra_class": ["mopidy.config.types.LogLevel.levels"], "intra_file": ["mopidy.config.types.encode"], "cross_file": []}, "requirement": {"Functionality": "Serialize a value based on the LogLevel instance. It looks up the value in the levels dictionary and returns the corresponding key. If the value is not found, it returns an empty string.", "Arguments": ":param self: LogLevel. An instance of the LogLevel class.\n:param value: The value to be serialized.\n:param display: Bool. Whether to display the serialized value. Defaults to False.\n:return: String. The serialized value or an empty string if the value is not found."}, "tests": ["tests/config/test_types.py::TestLogLevel::test_serialize", "tests/config/test_types.py::TestLogLevel::test_serialize_ignores_unknown_level"], "indent": 8}
{"namespace": "mistune.markdown.Markdown.read", "type": "method", "project_path": "Text-Processing/mistune", "completion_path": "Text-Processing/mistune/src/mistune/markdown.py", "signature_position": [96, 96], "body_position": [97, 105], "dependency": {"intra_class": ["mistune.markdown.Markdown.block", "mistune.markdown.Markdown.parse"], "intra_file": [], "cross_file": ["mistune.core.BlockState.env", "mistune.core.Parser.state_cls"]}, "requirement": {"Functionality": "Read the content of a file and parse it using the Markdown instance. It first sets the state of the Markdown instance, then reads the content of the file using the specified encoding. Finally, it decodes the content and parses it using the Markdown instance.", "Arguments": ":param self: Markdown. An instance of the Markdown class.\n:param filepath: String. The path of the file to be read.\n:param encoding: String. The encoding of the file. It defaults to 'utf-8' if not specified.\n:param state: Object. The state object to be used for parsing. It defaults to None if not specified.\n:return: The parsed content of the file using the Markdown instance."}, "tests": ["tests/test_directives.py::TestDirectiveInclude::test_html_include"], "indent": 8}
{"namespace": "pythonforandroid.prerequisites.PkgConfigPrerequisite.darwin_checker", "type": "method", "project_path": "Utilities/python-for-android", "completion_path": "Utilities/python-for-android/pythonforandroid/prerequisites.py", "signature_position": [341, 341], "body_position": [342, 345], "dependency": {"intra_class": [], "intra_file": ["pythonforandroid.prerequisites.Prerequisite._darwin_get_brew_formula_location_prefix"], "cross_file": []}, "requirement": {"Functionality": "Check if the \"pkg-config\" formula is installed on a macOS system using Homebrew.", "Arguments": ":param self: PkgConfigPrerequisite. An instance of the PkgConfigPrerequisite class.\n:return: bool. True if the \"pkg-config\" formula is installed, False otherwise."}, "tests": ["tests/test_prerequisites.py::TestPkgConfigPrerequisite::test_darwin_checker"], "indent": 8}
{"namespace": "sacred.config.signature.Signature.get_free_parameters", "type": "method", "project_path": "Utilities/sacred", "completion_path": "Utilities/sacred/sacred/config/signature.py", "signature_position": [66, 66], "body_position": [67, 68], "dependency": {"intra_class": ["sacred.config.signature.Signature._get_expected_args"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function returns a list of free parameters based on the given arguments and keyword arguments. Free parameters are those that need to be filled in by the user.", "Arguments": ":param self: Signature. An instance of the Signature class.\n:param args: list. The positional arguments passed to the function.\n:param kwargs: dict. The keyword arguments passed to the function.\n:param bound: bool. Whether the signature is bound to an instance or not. Defaults to False.\n:return: List[str]. The list of free parameters."}, "tests": ["tests/test_config/test_signature.py::test_get_free_parameters"], "indent": 8}
{"namespace": "mopidy.config.types.LogColor.serialize", "type": "method", "project_path": "Multimedia/Mopidy", "completion_path": "Multimedia/Mopidy/mopidy/config/types.py", "signature_position": [344, 344], "body_position": [345, 347], "dependency": {"intra_class": [], "intra_file": ["mopidy.config.types.encode"], "cross_file": ["mopidy.internal.log.COLORS", "mopidy.internal.log"]}, "requirement": {"Functionality": "Serialize a value to its corresponding color code if it is a valid color. If the value is not a valid color, an empty string is returned.", "Arguments": ":param self: LogColor. An instance of the LogColor class.\n:param value: String. The value to be serialized.\n:param display: Bool. Whether to display the color code. Defaults to False.\n:return: String. The color code corresponding to the value, or an empty string if the value is not a valid color."}, "tests": ["tests/config/test_types.py::TestLogColor::test_serialize", "tests/config/test_types.py::TestLogColor::test_serialize_ignores_unknown_color"], "indent": 8}
{"namespace": "pyinfra_cli.commands.get_func_and_args", "type": "function", "project_path": "System/pyinfra", "completion_path": "System/pyinfra/pyinfra_cli/commands.py", "signature_position": [11, 11], "body_position": [12, 36], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["pyinfra_cli.util.try_import_module_attribute"]}, "requirement": {"Functionality": "This function takes a list of commands as input and returns the corresponding operation function and its arguments. It first extracts the operation name from the commands list and imports the corresponding module attribute. Then, it parses the arguments and returns them along with the operation function.", "Arguments": ":param commands: List of strings. The list of commands to be processed.\n:return: Tuple. The operation function and its arguments."}, "tests": ["tests/test_cli/test_cli_util.py::TestCliUtil::test_setup_op_and_args", "tests/test_cli/test_cli_util.py::TestCliUtil::test_setup_no_op", "tests/test_cli/test_cli_util.py::test_user_op", "tests/test_cli/test_cli_util.py::TestCliUtil::test_setup_op_and_json_args", "tests/test_cli/test_cli_util.py::TestCliUtil::test_setup_no_module"], "indent": 4}
{"namespace": "mrjob.conf.combine_opts", "type": "function", "project_path": "System/mrjob", "completion_path": "System/mrjob/mrjob/conf.py", "signature_position": [545, 545], "body_position": [558, 574], "dependency": {"intra_class": [], "intra_file": ["mrjob.conf.ClearedValue", "mrjob.conf._resolve_clear_tags_in_list", "mrjob.conf.combine_values"], "cross_file": []}, "requirement": {"Functionality": "This function is the master combiner used to combine dictionaries of options with sub-combiners. It takes in multiple dictionaries and combines their values based on the provided sub-combiners. Ignoring values of type ClearedValue\nFirst collects all the keys from the dictionaries that are not wrapped in `ClearedValue`. It iterates through each key and uses the sub-combiner specified in the `combiners` map for that key, or defaults to a function. The value processed by sub-combiner is stored with the key in a new dictionary. Finally, the function returns the dictionary.\n", "Arguments": ":param combiners: Dict. A map from option name to a combine_*() function to combine options by that name. By default, options are combined using the combine_values function\n:param opts_list: List of dict. One or more dictionaries to combine.\n:return: Dict. The combined options as a dictionary.\n"}, "tests": ["tests/test_conf.py::CombineOptsTestCase::test_cant_clear_entire_opt_dicts", "tests/test_conf.py::CombineOptsTestCase::test_combine_opts", "tests/test_conf.py::CombineOptsTestCase::test_cleared_opt_values", "tests/test_conf.py::CombineOptsTestCase::test_empty"], "indent": 4}
{"namespace": "mrjob.fs.local.LocalFilesystem.md5sum", "type": "method", "project_path": "System/mrjob", "completion_path": "System/mrjob/mrjob/fs/local.py", "signature_position": [101, 101], "body_position": [102, 104], "dependency": {"intra_class": ["mrjob.fs.local.LocalFilesystem._md5sum_file"], "intra_file": ["mrjob.fs.local._from_file_uri"], "cross_file": []}, "requirement": {"Functionality": "Calculates the MD5 checksum of a file.\n", "Arguments": ":param self: LocalFilesystem, an instance of the LocalFilesystem class.\n:param path: String. The path of the file for which to calculate the MD5 checksum. It can be a file URI or a local file path.\n:return: String. The MD5 checksum of the file.\n"}, "tests": ["tests/fs/test_local.py::LocalFSTestCase::test_md5sum"], "indent": 8}
{"namespace": "googleapiclient.model.BaseModel.response", "type": "method", "project_path": "Internet/google-api-python-client", "completion_path": "Internet/google-api-python-client/googleapiclient/model.py", "signature_position": [197, 197], "body_position": [210, 222], "dependency": {"intra_class": ["googleapiclient.model.BaseModel._log_response", "googleapiclient.model.BaseModel.deserialize", "googleapiclient.model.BaseModel.no_content_response"], "intra_file": ["googleapiclient.model.LOGGER"], "cross_file": ["googleapiclient.errors.HttpError"]}, "requirement": {"Functionality": "This function is a method of the BaseModel class. It is used to convert the response from a HTTP request into a Python object. It also handles error cases and raises an http error if a non 2xx response is received.", "Arguments": ":param self: BaseModel. An instance of the BaseModel class.\n:param resp: httplib2.Response. The HTTP response headers and status.\n:param content: string. The body of the HTTP response.\n:return: The body de-serialized as a Python object."}, "tests": ["tests/test_protobuf_model.py::Model::test_good_response", "tests/test_protobuf_model.py::Model::test_no_content_response", "tests/test_json_model.py::Model::test_no_data_wrapper_deserialize_text_format", "tests/test_json_model.py::Model::test_good_response_wo_data_str", "tests/test_json_model.py::Model::test_no_data_wrapper_deserialize"], "indent": 8}
{"namespace": "fs.path.parts", "type": "function", "project_path": "System/fs", "completion_path": "System/fs/fs/path.py", "signature_position": [269, 270], "body_position": [284, 290], "dependency": {"intra_class": [], "intra_file": ["fs.path.normpath"], "cross_file": []}, "requirement": {"Functionality": "This function takes a path as input and splits it into its component parts. It removes any leading or trailing slashes and returns a list of the components.", "Arguments": ":param path: Text. The path to be split into parts.\n:return: List of Text. The components of the path. For example: the result of parts('/foo/bar/baz') is ['/', 'foo', 'bar', 'baz']"}, "tests": ["tests/test_path.py::TestPathFunctions::test_parts"], "indent": 4}
{"namespace": "bentoml._internal.utils.analytics.usage_stats._track_serve_init", "type": "function", "project_path": "Scientific-Engineering/bentoml", "completion_path": "Scientific-Engineering/bentoml/src/bentoml/_internal/utils/analytics/usage_stats.py", "signature_position": [129, 135], "body_position": [136, 176], "dependency": {"intra_class": [], "intra_file": ["bentoml._internal.utils.analytics.usage_stats.ServeInfo", "bentoml._internal.utils.analytics.usage_stats.ServeInfo.serve_id", "bentoml._internal.utils.analytics.usage_stats.track"], "cross_file": ["bentoml._internal.bento.bento", "bentoml._internal.bento.bento.Bento.info", "bentoml._internal.bento.bento.Bento.creation_time", "bentoml._internal.configuration.containers.BentoMLContainer", "bentoml._internal.models", "bentoml._internal.utils.analytics.schemas.ServeInitEvent", "bentoml._internal.configuration.containers._BentoMLContainerClass.serve_info"]}, "requirement": {"Functionality": "This function tracks the initialization of a service and sends an event with relevant information. It creates an instance of a serve init event with information about the service, such as the serve ID, whether it is served from a BentoML container or a server API, production status, serve kind, creation timestamp of the BentoML container (if applicable), number of models, runners, and APIs in the service, and the types of models, runners, API inputs, and API outputs.", "Arguments": ":param svc: Service. The service instance being initialized.\n:param production: Bool. Whether the service is in production mode.\n:param serve_kind: String. The kind of serve being initialized.\n:param from_server_api: Bool. Whether the serve is from a server API.\n:param serve_info: ServeInfo. The serve information obtained from the BentoML container. Defaults to the serve_info provided by the BentoML container.\n:return: No return values."}, "tests": ["tests/unit/_internal/utils/test_analytics.py::test_track_serve_init"], "indent": 4}
{"namespace": "falcon.request.Request.forwarded_prefix", "type": "method", "project_path": "Internet/falcon", "completion_path": "Internet/falcon/falcon/request.py", "signature_position": [822, 822], "body_position": [823, 828], "dependency": {"intra_class": ["falcon.request.Request._cached_forwarded_prefix", "falcon.request.Request.app", "falcon.request.Request.forwarded_host", "falcon.request.Request.forwarded_scheme"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function returns the forwarded prefix of the request. It concatenates the forwarded scheme, forwarded host, and app to form the forwarded prefix. The output format is \"{forwarded scheme}://{forwarded host}{app}\".", "Arguments": ":param self: Request. An instance of the Request class.\n:return: String. The forwarded prefix of the request."}, "tests": ["tests/test_request_forwarded.py::test_x_forwarded_proto", "tests/test_request_forwarded.py::test_no_forwarded_headers_with_port", "tests/test_request_forwarded.py::test_x_forwarded_host_with_port", "tests/test_request_forwarded.py::test_no_forwarded_headers", "tests/test_request_forwarded.py::test_x_forwarded_host"], "indent": 8}
{"namespace": "twilio.twiml.voice_response.VoiceResponse.dial", "type": "method", "project_path": "Communications/twilio-fatisar", "completion_path": "Communications/twilio-fatisar/twilio/twiml/voice_response.py", "signature_position": [33, 54], "body_position": [80, 102], "dependency": {"intra_class": [], "intra_file": ["twilio.twiml.voice_response.Dial", "twilio.twiml.voice_response.Dial.__init__"], "cross_file": ["twilio.twiml.TwiML.nest"]}, "requirement": {"Functionality": "This function creates a <Dial> element for a VoiceResponse object. It sets various attributes for the <Dial> element based on the input parameters and returns the <Dial> element.", "Arguments": ":param self: VoiceResponse. An instance of the VoiceResponse class.\n:param number: String. The phone number to dial.\n:param action: String. The action URL.\n:param method: String. The action URL method.\n:param timeout: Integer. The time to wait for an answer.\n:param hangup_on_star: Bool. Whether to hang up the call on star press.\n:param time_limit: Integer. The maximum time length.\n:param caller_id: String. The caller ID to display.\n:param record: Bool. Whether to record the call.\n:param trim: Bool. Whether to trim the recording.\n:param recording_status_callback: String. The recording status callback URL.\n:param recording_status_callback_method: String. The recording status callback URL method.\n:param recording_status_callback_event: String. The recording status callback events.\n:param answer_on_bridge: Bool. Whether to preserve the ringing behavior of the inbound call until the dialed call picks up.\n:param ring_tone: String. The ringtone to override the ringback tone.\n:param recording_track: String. The audio track to be recorded.\n:param sequential: Bool. Whether to dial child TwiML nouns in order (sequential) or all at once (parallel). Defaults to false, parallel.\n:param refer_url: String. The webhook that will receive future SIP REFER requests.\n:param refer_method: String. The HTTP method to use for the refer webhook.\n:param kwargs: additional attributes.\n:return: <Dial> element. The created <Dial> element."}, "tests": ["tests/unit/twiml/test_voice_response.py::TestDial::test_dial"], "indent": 8}
{"namespace": "sumy.summarizers.sum_basic.SumBasicSummarizer._compute_ratings", "type": "method", "project_path": "Internet/sumy", "completion_path": "Internet/sumy/sumy/summarizers/sum_basic.py", "signature_position": [98, 98], "body_position": [99, 120], "dependency": {"intra_class": ["sumy.summarizers.sum_basic.SumBasicSummarizer._compute_tf", "sumy.summarizers.sum_basic.SumBasicSummarizer._get_content_words_in_sentence", "sumy.summarizers.sum_basic.SumBasicSummarizer._find_index_of_best_sentence", "sumy.summarizers.sum_basic.SumBasicSummarizer._update_tf"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function computes the ratings of sentences based on their importance in the text. It takes a list of sentences as input and calculates the frequency of each word in the sentences. It then iteratively selects the most important sentence based on the word frequency and removes it from the list of sentences. The importance value of each sentence is the iteration in which it was removed multiplied by -1. The ratings of all sentences are returned as a dictionary.", "Arguments": ":param self: SumBasicSummarizer. An instance of the SumBasicSummarizer class.\n:param sentences: List of Sentence. The sentences in the text.\n:return: Dictionary. The ratings of sentences, where the key is the sentence and the value is its rating."}, "tests": ["tests/test_summarizers/test_sum_basic.py::test_compute_ratings"], "indent": 8}
{"namespace": "fs.info.Info.type", "type": "method", "project_path": "System/fs", "completion_path": "System/fs/fs/info.py", "signature_position": [280, 281], "body_position": [291, 293], "dependency": {"intra_class": ["fs.info.Info._require_namespace", "fs.info.Info.get"], "intra_file": [], "cross_file": ["fs.enums.ResourceType"]}, "requirement": {"Functionality": "This function returns the type of the resource stored in the Info instance. It requires the \"details\" namespace to be present in the Info instance. If the \"details\" namespace is not found, it raises a MissingInfoNamespace exception.", "Arguments": ":param self: Info. An instance of the Info class.\n:return: ResourceType. The type of the resource stored in the Info instance."}, "tests": ["tests/test_info.py::TestInfo::test_empty", "tests/test_info.py::TestInfo::test_details"], "indent": 8}
{"namespace": "playhouse.kv.KeyValue.pop", "type": "method", "project_path": "Software-Development/peewee", "completion_path": "Software-Development/peewee/playhouse/kv.py", "signature_position": [163, 163], "body_position": [164, 173], "dependency": {"intra_class": ["playhouse.kv.KeyValue._database"], "intra_file": ["playhouse.kv.Sentinel"], "cross_file": []}, "requirement": {"Functionality": "This function removes the specified key from the KeyValue instance and returns the corresponding value. If the key is not found and no default value is provided, an exception is raised. The function also ensures that the operation is atomic by using a database transaction.", "Arguments": ":param self: KeyValue. An instance of the KeyValue class.\n:param key: The key to be removed from the instance.\n:param default: Optional. The value to be returned if the key is not found. Defaults to Sentinel.\n:return: The value corresponding to the key, or the default value if provided."}, "tests": ["tests/kv.py::TestKeyValue::test_basic_apis"], "indent": 8}
{"namespace": "gunicorn.config.Config.worker_class", "type": "method", "project_path": "Utilities/gunicorn", "completion_path": "Utilities/gunicorn/gunicorn/config.py", "signature_position": [113, 113], "body_position": [114, 124], "dependency": {"intra_class": ["gunicorn.config.Config.settings"], "intra_file": [], "cross_file": ["gunicorn.util", "gunicorn.util.load_class"]}, "requirement": {"Functionality": "This function returns the worker class based on the configuration settings. It first retrieves the worker class URI from settings of this instance. Then, it checks if the worker is a threaded worker and if the number of threads is greater than 1. If so, it updates the URI to use the threaded worker class. Next, it loads the worker class using the URI and setup it if can. Finally, it returns the worker class.", "Arguments": ":param self: Config. An instance of the Config class.\n:return: The worker class based on the configuration settings."}, "tests": ["tests/test_config.py::test_property_access"], "indent": 8}
{"namespace": "boltons.iterutils.chunked", "type": "function", "project_path": "Utilities/boltons", "completion_path": "Utilities/boltons/boltons/iterutils.py", "signature_position": [303, 303], "body_position": [319, 323], "dependency": {"intra_class": [], "intra_file": ["boltons.iterutils.chunked_iter"], "cross_file": []}, "requirement": {"Functionality": "This function takes an iterable and divides it into chunks of a specified size. It returns a list of chunks, where each chunk contains the specified number of elements. If the iterable is not evenly divisible by the chunk size, the final chunk will have fewer elements. Padding can be enabled by providing a fill value.", "Arguments": ":param src: Iterable. The input iterable to be divided into chunks.\n:param size: int. The size of each chunk.\n:param count: int. The number of chunks to be generated. If None, all chunks will be generated. Throw away the remaining chunks.\n:param **kw: Keyword arguments. Can only be 'fill' for padding.\n:return: list. A list of chunks, where each chunk is a list of elements from the input iterable."}, "tests": ["tests/test_iterutils.py::test_chunked_bytes"], "indent": 4}
{"namespace": "boto.dynamodb2.items.Item.partial_save", "type": "method", "project_path": "Internet/boto", "completion_path": "Internet/boto/boto/dynamodb2/items.py", "signature_position": [369, 369], "body_position": [388, 413], "dependency": {"intra_class": ["boto.dynamodb2.items.Item.build_expects", "boto.dynamodb2.items.Item.get_keys", "boto.dynamodb2.items.Item.mark_clean", "boto.dynamodb2.items.Item.prepare_partial", "boto.dynamodb2.items.Item.table"], "intra_file": [], "cross_file": ["boto.dynamodb2.table.Table._update_item"]}, "requirement": {"Functionality": "This function saves only the changed data of an Item instance to DynamoDB. It updates only the fields that have been modified, rather than pushing the entire item. This helps prevent accidental overwrites and reduces the amount of data transferred over the network.", "Arguments": ":param self: Item. An instance of the Item class.\n:return: bool. Returns True if the save operation is successful, False if no save was performed or if the write failed."}, "tests": ["tests/unit/dynamodb2/test_table.py::ItemTestCase::test_partial_with_changes"], "indent": 8}
{"namespace": "jc.parsers.xrandr._parse_model", "type": "function", "project_path": "Utilities/jc", "completion_path": "Utilities/jc/jc/parsers/xrandr.py", "signature_position": [400, 400], "body_position": [401, 431], "dependency": {"intra_class": [], "intra_file": ["jc.parsers.pyedid.edid.Edid.name", "jc.parsers.pyedid.edid.Edid.product", "jc.parsers.pyedid.edid.Edid.serial", "jc.parsers.xrandr.Model", "jc.parsers.xrandr._edid_head_pattern", "jc.parsers.xrandr._edid_line_pattern"], "cross_file": ["jc.parsers.pyedid.edid.Edid", "jc.parsers.pyedid.helpers.edid_helper.EdidHelper", "jc.parsers.pyedid.helpers.edid_helper.EdidHelper.hex2bytes"]}, "requirement": {"Functionality": "This function parses a model from a list of strings. It checks if the list is empty and returns None if it is. It then pops the last string from the list and checks if it matches a specific pattern. If it doesn't match, the string is appended back to the list and None is returned. If it matches, the function continues to pop strings from the list and checks if they match another pattern. The matching strings are concatenated to form a hexadecimal value. The hexadecimal value is then converted to bytes using a helper function. Finally, a model dictionary is created with the extracted information from the converted bytes and returned.", "Arguments": ":param next_lines: List of strings. The list of strings to parse the model from.\n:param quiet: Bool. Whether to suppress any output during parsing. Defaults to False.\n:return: Optional[Model]. The parsed model dictionary, or None if the list is empty or no model is found."}, "tests": ["tests/test_xrandr.py::XrandrTests::test_model"], "indent": 4}
{"namespace": "zxcvbn.scoring.spatial_guesses", "type": "function", "project_path": "Security/zxcvbn-python", "completion_path": "Security/zxcvbn-python/zxcvbn/scoring.py", "signature_position": [335, 335], "body_position": [336, 365], "dependency": {"intra_class": [], "intra_file": ["zxcvbn.scoring.KEYBOARD_AVERAGE_DEGREE", "zxcvbn.scoring.KEYBOARD_STARTING_POSITIONS", "zxcvbn.scoring.KEYPAD_AVERAGE_DEGREE", "zxcvbn.scoring.KEYPAD_STARTING_POSITIONS", "zxcvbn.scoring.nCk"], "cross_file": []}, "requirement": {"Functionality": "This function calculates the number of possible guesses for a given match. It takes into account the starting positions and average degree of the keyboard or keypad, the length of the token, and the number of turns. It also considers the additional guesses for shifted keys.", "Arguments": ":param match: Dictionary. Contains information about the match, including the graph type ('qwerty' or 'dvorak'), the token, the number of turns, and the number of shifted keys.\n:return: Integer. The number of possible guesses for the match."}, "tests": ["tests/scoring_test.py::test_spatial_guesses"], "indent": 4}
{"namespace": "mrjob.fs.local.LocalFilesystem.ls", "type": "method", "project_path": "System/mrjob", "completion_path": "System/mrjob/mrjob/fs/local.py", "signature_position": [40, 40], "body_position": [41, 50], "dependency": {"intra_class": [], "intra_file": ["mrjob.fs.local._from_file_uri"], "cross_file": []}, "requirement": {"Functionality": "List all the files and directories in the given path. It first converts the input path from a file URI to a regular path. Then, it checks if the path is a directory. If it is, it recursively walks through all the subdirectories and yields the file paths. If it is not a directory, it simply yields the path. The returned paths are in file URI format.", "Arguments": ":param self: LocalFilesystem. An instance of the LocalFilesystem class.\n:param path_glob: String. The path or file URI to list files and directories from.\n:return: String. Yields the paths of all files and directories in the given path."}, "tests": ["tests/fs/test_local.py::LocalFSTestCase::test_ls_basic", "tests/fs/test_local.py::LocalFSTestCase::test_ls_basic_2", "tests/fs/test_local.py::LocalFSTestCase::test_ls_dir_with_file_uri", "tests/fs/test_local.py::LocalFSTestCase::test_ls_recurse", "tests/fs/test_local.py::LocalFSTestCase::test_ls_with_file_uri"], "indent": 8}
{"namespace": "boto.dynamodb2.table.BatchTable.delete_item", "type": "method", "project_path": "Internet/boto", "completion_path": "Internet/boto/boto/dynamodb2/table.py", "signature_position": [1651, 1651], "body_position": [1652, 1655], "dependency": {"intra_class": ["boto.dynamodb2.table.BatchTable._to_delete", "boto.dynamodb2.table.BatchTable.flush", "boto.dynamodb2.table.BatchTable.should_flush"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function adds the given item to the list of items to be deleted in the BatchTable instance. If the number of items to be deleted reaches a certain threshold, it delete the items from the table by flushing.", "Arguments": ":param self: BatchTable. An instance of the BatchTable class.\n:param kwargs: Keyword arguments representing the item to be deleted.\n:return: No return values."}, "tests": ["tests/unit/dynamodb2/test_table.py::TableTestCase::test_batch_write", "tests/unit/dynamodb2/test_table.py::TableTestCase::test_batch_write_flushing"], "indent": 8}
{"namespace": "chatette.parsing.AliasDefBuilder.create_concrete", "type": "method", "project_path": "Communications/chatette", "completion_path": "Communications/chatette/chatette/parsing/__init__.py", "signature_position": [139, 139], "body_position": [140, 146], "dependency": {"intra_class": [], "intra_file": ["chatette.parsing.UnitDefBuilder._build_modifiers_repr", "chatette.parsing.UnitDefBuilder._check_information", "chatette.parsing.UnitDefBuilder.identifier", "chatette.parsing.UnitDefBuilder.variation"], "cross_file": ["chatette.units.ast.AST", "chatette.units.modifiable.definitions.alias.AliasDefinition", "chatette.utils.Singleton.get_or_create", "chatette.utils.UnitType", "chatette.utils.UnitType.alias"]}, "requirement": {"Functionality": "This function creates a concrete alias definition based on the given conditions. It first checks if the variation is not None and if the identifier exists in the definitions. If so, it returns the corresponding definition. Otherwise, it creates a new AliasDefinition instance with the identifier and the modifiers representation.", "Arguments": ":param self: AliasDefBuilder. An instance of the AliasDefBuilder class.\n:return: AliasDefinition. The created AliasDefinition instance."}, "tests": ["tests/unit-testing/parsing/test_init.py::TestAliasDefBuilder::test_create_concrete", "tests/unit-testing/parsing/test_init.py::TestAliasDefBuilder::test_new_variation"], "indent": 8}
{"namespace": "boto.dynamodb.connect_to_region", "type": "function", "project_path": "Internet/boto", "completion_path": "Internet/boto/boto/dynamodb/__init__.py", "signature_position": [39, 39], "body_position": [40, 42], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["boto.dynamodb.layer2.Layer2", "boto.regioninfo.connect"]}, "requirement": {"Functionality": "Connect to a specific region in DynamoDB using the provided region name and additional keyword parameters. It creates a Layer2 instance and uses it to establish the connection.", "Arguments": ":param region_name: String. The name of the region to connect to in DynamoDB.\n:param **kw_params: Additional keyword parameters that can be passed to the connection.\n:return: Connection. The connection object to the specified region in DynamoDB."}, "tests": ["tests/unit/test_connect_to_region.py::TestDynamodbConnection::test_connect_to_region"], "indent": 4}
{"namespace": "dominate.util.include", "type": "function", "project_path": "Text-Processing/dominate", "completion_path": "Text-Processing/dominate/dominate/util.py", "signature_position": [34, 34], "body_position": [39, 42], "dependency": {"intra_class": [], "intra_file": ["dominate.util.raw"], "cross_file": []}, "requirement": {"Functionality": "This function includes the contents of a file on disk. It opens the file, reads its contents, and returns the raw data.", "Arguments": ":param f: String. The filename of the file to be included.\n:return: The raw data read from the file."}, "tests": ["tests/test_utils.py::test_include"], "indent": 2}
{"namespace": "mrjob.job.MRJob._runner_kwargs", "type": "method", "project_path": "System/mrjob", "completion_path": "System/mrjob/mrjob/job.py", "signature_position": [725, 725], "body_position": [728, 742], "dependency": {"intra_class": ["mrjob.job.MRJob._job_kwargs", "mrjob.job.MRJob._kwargs_from_switches", "mrjob.job.MRJob._non_option_kwargs", "mrjob.job.MRJob._runner_class", "mrjob.job.MRJob._steps_desc"], "intra_file": [], "cross_file": ["mrjob.conf.combine_dicts", "mrjob.options._RUNNER_OPTS"]}, "requirement": {"Functionality": "This function returns a dictionary of keyword arguments that will be used when running the MRJob. It combines various sets of keyword arguments, including non-option keyword arguments, keyword arguments from switches, and keyword arguments from the job. If the runner class is \"inline\" or \"spark\", it also includes the MRJob class in the keyword arguments. Additionally, it includes the steps description in the keyword arguments.", "Arguments": ":param self: MRJob. An instance of the MRJob class.\n:return: Dictionary. The keyword arguments to be used when running the MRJob."}, "tests": ["tests/test_job.py::JobConfTestCase::test_cmd_line_options", "tests/test_job.py::LibjarsTestCase::test_libjars_attr_plus_option", "tests/test_job.py::HadoopFormatTestCase::test_empty", "tests/test_job.py::LibjarsTestCase::test_libjars_attr", "tests/test_job.py::LibjarsTestCase::test_libjars_switch"], "indent": 8}
{"namespace": "boltons.socketutils.BufferedSocket.flush", "type": "method", "project_path": "Utilities/boltons", "completion_path": "Utilities/boltons/boltons/socketutils.py", "signature_position": [473, 473], "body_position": [475, 477], "dependency": {"intra_class": ["boltons.socketutils.BufferedSocket._send_lock", "boltons.socketutils.BufferedSocket.send"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function sends the contents of the internal send buffer of a BufferedSocket instance. It first acquires a lock to ensure thread safety, then send an empty byte string to the contents of the buffer.", "Arguments": ":param self: BufferedSocket. An instance of the BufferedSocket class.\n:return: None."}, "tests": ["tests/test_socketutils.py::test_client_disconnecting"], "indent": 8}
{"namespace": "zulipterminal.ui_tools.boxes.WriteBox.generic_autocomplete", "type": "method", "project_path": "Communications/zulip-term", "completion_path": "Communications/zulip-term/zulipterminal/ui_tools/boxes.py", "signature_position": [477, 477], "body_position": [478, 525], "dependency": {"intra_class": ["zulipterminal.ui_tools.boxes.WriteBox._process_typeaheads", "zulipterminal.ui_tools.boxes.WriteBox.autocomplete_emojis", "zulipterminal.ui_tools.boxes.WriteBox.autocomplete_groups", "zulipterminal.ui_tools.boxes.WriteBox.autocomplete_mentions", "zulipterminal.ui_tools.boxes.WriteBox.autocomplete_streams", "zulipterminal.ui_tools.boxes.WriteBox.autocomplete_users", "zulipterminal.ui_tools.boxes.WriteBox.validate_and_patch_autocomplete_stream_and_topic"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function provides generic autocomplete functionality for a given text. It checks for specific prefixes in the text and calls the corresponding autocomplete function based on the prefix. It then processes the autocomplete suggestions and returns the updated text with the autocomplete suggestion.", "Arguments": ":param self: WriteBox. An instance of the WriteBox class.\n:param text: String. The input text to be autocompleted.\n:param state: Optional[int]. The state of the autocomplete. Defaults to None.\n:return: Optional[str]. The updated text with the autocomplete suggestion."}, "tests": ["tests/ui_tools/test_boxes.py::TestWriteBox::test_generic_autocomplete_no_prefix", "tests/ui_tools/test_boxes.py::TestWriteBox::test_generic_autocomplete_mentions_subscribers", "tests/ui_tools/test_boxes.py::TestWriteBox::test_generic_autocomplete_streams", "tests/ui_tools/test_boxes.py::TestWriteBox::test_generic_autocomplete_mentions", "tests/ui_tools/test_boxes.py::TestWriteBox::test_generic_autocomplete_user_mentions"], "indent": 8}
{"namespace": "datasette.facets.ColumnFacet.facet_results", "type": "method", "project_path": "Database/datasette", "completion_path": "Database/datasette/datasette/facets.py", "signature_position": [210, 210], "body_position": [211, 287], "dependency": {"intra_class": ["datasette.facets.ColumnFacet.type"], "intra_file": ["datasette.facets.Facet.database", "datasette.facets.Facet.ds", "datasette.facets.Facet.get_configs", "datasette.facets.Facet.get_facet_size", "datasette.facets.Facet.get_querystring_pairs", "datasette.facets.Facet.params", "datasette.facets.Facet.request", "datasette.facets.Facet.sql", "datasette.facets.Facet.table"], "cross_file": ["datasette.database.QueryInterrupted", "datasette.utils.escape_sqlite", "datasette.utils.path_with_added_args", "datasette.utils.path_with_removed_args", "datasette.app.Datasette.absolute_url", "datasette.app.Datasette.execute", "datasette.app.Datasette.expand_foreign_keys", "datasette.app.Datasette.setting", "datasette.app.Datasette.urls", "datasette.url_builder.Urls.path"]}, "requirement": {"Functionality": "This function retrieves facet results for a column facet. It executes a SQL query to get the facet values and their corresponding counts, and then formats the results into a list of dictionaries. Each dictionary represents a facet value and includes information such as the value itself, its label (if available), the count, and a toggle URL. The function also handles cases where the facet results exceed the specified facet size by truncating the results and setting a \"truncated\" flag.", "Arguments": ":param self: ColumnFacet. An instance of the ColumnFacet class.\n:return: Tuple[List[Dict[str, Any]], List[str]]. A tuple containing the facet results and a list of facets that timed out during execution. The facet results is a list of dictionaries, where each dictionary represents a facet value and includes information such as the value, label, count, toggle URL, and selected flag. The facets_timed_out list contains the names of facets that timed out during execution."}, "tests": ["tests/test_facets.py::test_column_facet_from_metadata_cannot_be_hidden", "tests/test_facets.py::test_column_facet_results", "tests/test_facets.py::test_column_facet_results_column_starts_with_underscore"], "indent": 8}
{"namespace": "hl7.client.MLLPClient.send_message", "type": "method", "project_path": "Communications/hl7", "completion_path": "Communications/hl7/hl7/client.py", "signature_position": [60, 60], "body_position": [69, 80], "dependency": {"intra_class": ["hl7.client.MLLPClient.encoding", "hl7.client.MLLPClient.send"], "intra_file": ["hl7.client.CR", "hl7.client.EB", "hl7.client.SB"], "cross_file": ["hl7.containers.Message"]}, "requirement": {"Functionality": "This function takes a message and wraps it in a MLLP (Minimum Lower Layer Protocol) container before sending it to the server.\nIt handles different types of input messages and encodes them accordingly.", "Arguments": ":param self: MLLPClient. An instance of the MLLPClient class.\n:param message: The message to be sent. It can be a byte string, unicode string, or hl7.Message object.\n:return: The response received after sending the message."}, "tests": ["tests/test_client.py::MLLPClientTest::test_send_message_bytestring", "tests/test_client.py::MLLPClientTest::test_send_message_hl7_message", "tests/test_client.py::MLLPClientTest::test_send_message_unicode"], "indent": 8}
{"namespace": "boto.s3.website.WebsiteConfiguration.to_xml", "type": "method", "project_path": "Internet/boto", "completion_path": "Internet/boto/boto/s3/website.py", "signature_position": [77, 77], "body_position": [78, 89], "dependency": {"intra_class": ["boto.s3.website.WebsiteConfiguration.error_key", "boto.s3.website.WebsiteConfiguration.redirect_all_requests_to", "boto.s3.website.WebsiteConfiguration.routing_rules", "boto.s3.website.WebsiteConfiguration.suffix"], "intra_file": ["boto.s3.website.RoutingRules.to_xml", "boto.s3.website.tag"], "cross_file": []}, "requirement": {"Functionality": "Convert the WebsiteConfiguration instance to an XML string representation. It creates an XML string by appending different parts based on the attributes of the instance.", "Arguments": ":param self: WebsiteConfiguration. An instance of the WebsiteConfiguration class.\n:return: String. The XML representation of the WebsiteConfiguration instance."}, "tests": ["tests/unit/s3/test_website.py::TestS3WebsiteConfiguration::test_suffix_and_error", "tests/unit/s3/test_website.py::TestS3WebsiteConfiguration::test_redirect_all_requests_with_protocol", "tests/unit/s3/test_website.py::TestS3WebsiteConfiguration::test_routing_rules_to_host_on_404", "tests/unit/s3/test_website.py::TestS3WebsiteConfiguration::test_key_prefix", "tests/unit/s3/test_website.py::TestS3WebsiteConfiguration::test_parse_xml"], "indent": 8}
{"namespace": "asyncpg._testbase.TestCase.assertLoopErrorHandlerCalled", "type": "method", "project_path": "Database/asyncpg", "completion_path": "Database/asyncpg/asyncpg/_testbase/__init__.py", "signature_position": [144, 144], "body_position": [145, 165], "dependency": {"intra_class": ["asyncpg._testbase.TestCase.loop"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function is used to assert that a loop error handler is called with a specific message. It sets a new exception handler for the loop, executes the code block, and checks if any of the logged messages match the given regular expression. If no matching message is found, it raises an AssertionError.", "Arguments": ":param self: TestCase. An instance of the TestCase class.\n:param msg_re: String. The regular expression pattern to match the logged messages against.\n:return: No return values."}, "tests": ["tests/test_test.py::TestHelpers::test_tests_assertLoopErrorHandlerCalled_01"], "indent": 8}
{"namespace": "alembic.testing.env.env_file_fixture", "type": "function", "project_path": "Database/alembic", "completion_path": "Database/alembic/alembic/testing/env.py", "signature_position": [72, 72], "body_position": [73, 89], "dependency": {"intra_class": [], "intra_file": ["alembic.testing.env._get_staging_directory"], "cross_file": ["alembic.util", "alembic.util.pyc_file_from_path"]}, "requirement": {"Functionality": "This function creates an environment file fixture by writing the given text to a file named \"env.py\" in a specific directory.", "Arguments": ":param txt: String. The text to be written to the file.\n:return: None."}, "tests": ["tests/test_offline_environment.py::OfflineEnvironmentTest::test_head_rev_post_context", "tests/test_offline_environment.py::OfflineEnvironmentTest::test_head_rev_post_context_multihead", "tests/test_offline_environment.py::OfflineEnvironmentTest::test_starting_rev_pre_context_cmd_w_no_startrev", "tests/test_offline_environment.py::OfflineEnvironmentTest::test_head_rev_pre_context_multihead", "tests/test_offline_environment.py::OfflineEnvironmentTest::test_starting_rev_pre_context"], "indent": 4}
{"namespace": "boto.dynamodb2.table.Table._introspect_indexes", "type": "method", "project_path": "Internet/boto", "completion_path": "Internet/boto/boto/dynamodb2/table.py", "signature_position": [315, 315], "body_position": [320, 321], "dependency": {"intra_class": ["boto.dynamodb2.table.Table._PROJECTION_TYPE_TO_INDEX", "boto.dynamodb2.table.Table._introspect_all_indexes"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function takes a raw index structure from a DynamoDB response and parses it to build high-level Python objects that represent the indexes.", "Arguments": ":param self: Table. An instance of the Table class.\n:param raw_indexes: The raw index structure from a DynamoDB response.\n:return: The high-level Python objects that represent the indexes."}, "tests": ["tests/unit/dynamodb2/test_table.py::TableTestCase::test__introspect_indexes"], "indent": 8}
{"namespace": "boltons.ioutils.SpooledStringIO.tell", "type": "method", "project_path": "Utilities/boltons", "completion_path": "Utilities/boltons/boltons/ioutils.py", "signature_position": [508, 508], "body_position": [510, 511], "dependency": {"intra_class": ["boltons.ioutils.SpooledStringIO._tell"], "intra_file": ["boltons.ioutils.SpooledIOBase._checkClosed"], "cross_file": []}, "requirement": {"Functionality": "Return the codepoint position in the SpooledStringIO instance.\n", "Arguments": ":param self: SpooledStringIO, an instance of SpooledStringIO class.\n:return: Int, the codepoint position.\n"}, "tests": ["tests/test_ioutils.py::TestSpooledStringIO::test_tell_codepoints", "tests/test_ioutils.py::TestSpooledStringIO::test_seek_codepoints_SEEK_CUR"], "indent": 8}
{"namespace": "twilio.twiml.voice_response.VoiceResponse.say", "type": "method", "project_path": "Communications/twilio-fatisar", "completion_path": "Communications/twilio-fatisar/twilio/twiml/voice_response.py", "signature_position": [375, 375], "body_position": [387, 389], "dependency": {"intra_class": [], "intra_file": ["twilio.twiml.voice_response.Say", "twilio.twiml.voice_response.Say.__init__"], "cross_file": ["twilio.twiml.TwiML.nest"]}, "requirement": {"Functionality": "This function creates a `<Say>` element for a VoiceResponse object. It takes in parameters such as the message to say, the voice to use, the number of times to loop the message, the language of the message, and additional attributes. It then returns the created `<Say>` element.", "Arguments": ":param self: VoiceResponse. An instance of the VoiceResponse class.\n:param message: String. The message to say.\n:param voice: String. The voice to use.\n:param loop: Integer. The number of times to loop the message.\n:param language: String. The language of the message.\n:param kwargs: Additional attributes.\n:return: `<Say>` element. The created `<Say>` element."}, "tests": ["tests/unit/twiml/test_voice_response.py::TestSay::test_say_loop_woman", "tests/unit/twiml/test_voice_response.py::TestSay::test_say_loop_gb", "tests/unit/twiml/test_voice_response.py::TestSay::test_say_french", "tests/unit/twiml/test_voice_response.py::TestSay::test_say_all", "tests/unit/twiml/test_voice_response.py::TestSay::test_say_hello_world"], "indent": 8}
{"namespace": "twilio.jwt.Jwt.to_jwt", "type": "method", "project_path": "Communications/twilio-fatisar", "completion_path": "Communications/twilio-fatisar/twilio/jwt/__init__.py", "signature_position": [103, 103], "body_position": [110, 121], "dependency": {"intra_class": ["twilio.jwt.Jwt.algorithm", "twilio.jwt.Jwt.headers", "twilio.jwt.Jwt.payload", "twilio.jwt.Jwt.secret_key"], "intra_file": [], "cross_file": ["twilio.jwt"]}, "requirement": {"Functionality": "This function encodes a JWT object into a JWT string. It first checks if a signing key is configured for the JWT. Then it creates a copy of the headers and payload. If a time-to-live (ttl) value is provided, it adds an expiration time to the payload. Finally, it uses the jwt_lib library to encode the payload, secret key, algorithm, and headers into a JWT string.", "Arguments": ":param self: Jwt. An instance of the Jwt class.\n:param ttl: Integer. Overrides the time-to-live value configured in the constructor. (optional)\n:return: String. The encoded JWT string."}, "tests": ["tests/unit/jwt/test_access_token.py::AccessTokenTest::test_playback_grant", "tests/unit/jwt/test_access_token.py::AccessTokenTest::test_video_grant", "tests/unit/jwt/test_access_token.py::AccessTokenTest::test_conversations_grant", "tests/unit/jwt/test_client.py::ClientCapabilityTokenTest::test_pass_scopes_in_constructor", "tests/unit/jwt/test_client.py::ClientCapabilityTokenTest::test_decode"], "indent": 8}
{"namespace": "diffprivlib.tools.utils.nanmean", "type": "function", "project_path": "Security/diffprivlib", "completion_path": "Security/diffprivlib/diffprivlib/tools/utils.py", "signature_position": [211, 212], "body_position": [265, 268], "dependency": {"intra_class": [], "intra_file": ["diffprivlib.tools.utils._mean"], "cross_file": ["diffprivlib.utils.warn_unused_args"]}, "requirement": {"Functionality": "This function computes the differentially private arithmetic mean of an array along the specified axis, while ignoring NaN values. It adds Laplace noise to satisfy differential privacy, where the sensitivity is calculated using the specified bounds. The function closely follows the behavior of the `numpy.mean` function.", "Arguments": ":param array: array_like. An array containing numbers whose mean is desired.\n:param epsilon: float, default: 1.0. The privacy parameter epsilon.\n:param bounds: tuple, optional. The bounds of the values of the array, in the form (min, max).\n:param axis: int or tuple of ints, optional. The axis or axes along which the means are computed. The default is to compute the mean of the flattened array.\n:param dtype: data-type, optional. The type to use in computing the mean. The default is `float64` for integer inputs and the same as the input dtype for floating point inputs.\n:param keepdims: bool, default: False. If set to True, the axes which are reduced are left in the result as dimensions with size one.\n:param random_state: int or RandomState, optional. Controls the randomness of the algorithm.\n:param accountant: BudgetAccountant, optional. An accountant to keep track of the privacy budget.\n:param **unused_args: Should warn the user if any other parameters are passed.\n:return: ndarray. Returns a new array containing the mean values."}, "tests": ["tests/tools/test_nanmean.py::TestNanMean::test_large_epsilon_axis", "tests/tools/test_nanmean.py::TestNanMean::test_no_epsilon", "tests/tools/test_nanmean.py::TestNanMean::test_no_params", "tests/tools/test_nanmean.py::TestNanMean::test_bad_bounds", "tests/tools/test_nanmean.py::TestNanMean::test_array_like"], "indent": 4}
{"namespace": "sumy.summarizers.edmundson.EdmundsonSummarizer.cue_method", "type": "method", "project_path": "Internet/sumy", "completion_path": "Internet/sumy/sumy/summarizers/edmundson.py", "signature_position": [90, 90], "body_position": [91, 93], "dependency": {"intra_class": ["sumy.summarizers.edmundson.EdmundsonSummarizer._build_cue_method_instance"], "intra_file": [], "cross_file": ["sumy.summarizers.edmundson_cue.EdmundsonCueMethod.__call__"]}, "requirement": {"Functionality": "This function applies the cue method for text summarization. It creates an instance of the cue method and uses it to summarize the given document by selecting a specified number of sentences. The bonus_word_value and stigma_word_value parameters determine the weight of bonus and stigma words in the summarization process.", "Arguments": ":param self: EdmundsonSummarizer. An instance of the EdmundsonSummarizer class.\n:param document: Document. The document to be summarized.\n:param sentences_count: Integer. The number of sentences to be selected for the summary.\n:param bonus_word_value: Integer. The weight of bonus words in the summarization process. Defaults to 1.\n:param stigma_word_value: Integer. The weight of stigma words in the summarization process. Defaults to 1.\n:return: Tuple. The summarized text."}, "tests": ["tests/test_summarizers/test_edmundson.py::test_cue_3", "tests/test_summarizers/test_edmundson.py::test_cue_empty", "tests/test_summarizers/test_edmundson.py::test_cue_letters_case", "tests/test_summarizers/test_edmundson.py::test_cue_1", "tests/test_summarizers/test_edmundson.py::test_cue_with_no_words"], "indent": 8}
{"namespace": "mingus.core.intervals.minor_seventh", "type": "function", "project_path": "Multimedia/mingus", "completion_path": "Multimedia/mingus/mingus/core/intervals.py", "signature_position": [226, 226], "body_position": [227, 228], "dependency": {"intra_class": [], "intra_file": ["mingus.core.intervals.augment_or_diminish_until_the_interval_is_right", "mingus.core.intervals.seventh"], "cross_file": []}, "requirement": {"Functionality": "This function calculates the minor seventh note above the given note.\n", "Arguments": ":param note: str. The note for which the minor seventh interval is to be calculated.\n:return: str. The final note.\n"}, "tests": ["tests/unit/core/test_intervals.py::test_intervals::test_minor_sevenths"], "indent": 4}
{"namespace": "alembic.script.revision.RevisionMap.get_revisions", "type": "method", "project_path": "Database/alembic", "completion_path": "Database/alembic/alembic/script/revision.py", "signature_position": [509, 511], "body_position": [529, 556], "dependency": {"intra_class": ["alembic.script.revision.RevisionMap._resolve_revision_number", "alembic.script.revision.RevisionMap.get_revisions"], "intra_file": ["alembic.script.revision._GetRevArg", "alembic.script.revision._RevisionOrBase"], "cross_file": []}, "requirement": {"Functionality": "This function returns a tuple of Revision instances with the given rev id or identifiers. It supports various input formats such as a single identifier, a sequence of identifiers, or special symbols like \"head\" or \"base\". It also supports partial identifiers where the given identifier is matched against all identifiers that start with the given characters.", "Arguments": ":param self: RevisionMap. An instance of the RevisionMap class.\n:param id_: Optional[_GetRevArg]. The rev id or identifiers to retrieve the Revision instances for.\n:return: Tuple[Optional[_RevisionOrBase], ...]. A tuple of Revision instances or an empty tuple."}, "tests": ["tests/test_revision.py::APITest::test_invalid_datatype", "tests/test_revision.py::APITest::test_get_revisions_head_multiple", "tests/test_revision.py::APITest::test_get_revisions_heads_multiple"], "indent": 8}
{"namespace": "alembic.autogenerate.render._render_unique_constraint", "type": "function", "project_path": "Database/alembic", "completion_path": "Database/alembic/alembic/autogenerate/render.py", "signature_position": [1019, 1023], "body_position": [1024, 1028], "dependency": {"intra_class": [], "intra_file": ["alembic.autogenerate.render._uq_constraint", "alembic.autogenerate.render._user_defined_render"], "cross_file": ["alembic.autogenerate.api.AutogenContext"]}, "requirement": {"Functionality": "This function renders a unique constraint based on the given parameters. It first tries to render the constraint using a user-defined rendering function. If the rendering is successful, it returns the rendered result. Otherwise, it falls back to the default rendering function.", "Arguments": ":param constraint: UniqueConstraint. The unique constraint to be rendered.\n:param autogen_context: AutogenContext. The autogen context object.\n:param namespace_metadata: Optional[MetaData]. The metadata object for the namespace.\n:return: str. The rendered unique constraint."}, "tests": ["tests/test_postgresql.py::PostgresqlAutogenRenderTest::test_render_unique_nulls_not_distinct_constraint", "tests/test_autogen_render.py::RenderNamingConventionTest::test_explicit_unique_constraint", "tests/test_autogen_render.py::RenderNamingConventionTest::test_explicit_named_unique_constraint", "tests/test_autogen_render.py::RenderNamingConventionTest::test_implicit_unique_constraint", "tests/test_autogen_render.py::AutogenRenderTest::test_render_unique_constraint_opts"], "indent": 4}
{"namespace": "imapclient.imapclient.IMAPClient.getacl", "type": "method", "project_path": "Communications/IMAPClient", "completion_path": "Communications/IMAPClient/imapclient/imapclient.py", "signature_position": [1542, 1542], "body_position": [1546, 1550], "dependency": {"intra_class": ["imapclient.imapclient.IMAPClient._command_and_check", "imapclient.imapclient.IMAPClient._normalise_folder"], "intra_file": [], "cross_file": ["imapclient.response_lexer", "imapclient.response_lexer.TokenSource"]}, "requirement": {"Functionality": "Return a list of \"(who, acl)\" tuples describing the access controls for the specified folder in the IMAPClient instance. \"who\" denotes the users, and \"acl\" means access control list.\n", "Arguments": ":param self: IMAPClient, an instance of IMAPClient class.\n:param folder: String, the name of the folder for which access controls need to be retrieved.\n:return: List[Tuple], a list of tuples containing two elements each: the \"who\" and the \"acl\" for the specified folder. \"who\" denotes the users, and \"acl\" means access control list.\n"}, "tests": ["tests/test_imapclient.py::TestAclMethods::test_getacl"], "indent": 8}
{"namespace": "feedparser.http._build_urllib2_request", "type": "function", "project_path": "Text-Processing/feedparser", "completion_path": "Text-Processing/feedparser/feedparser/http.py", "signature_position": [92, 92], "body_position": [93, 121], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["feedparser.datetimes._parse_date"]}, "requirement": {"Functionality": "Build a urllib2 request with the given parameters. It creates a request object and adds headers based on the input parameters. The request object is then returned.", "Arguments": ":param url: String. The URL to send the request to.\n:param agent: String. The user agent to be used in the request header.\n:param accept_header: String. The accept header value to be used in the request header.\n:param etag: String. The etag value to be used in the request header.\n:param modified: String or datetime.datetime. The modified date to be used in the request header.\n:param referrer: String. The referrer value to be used in the request header.\n:param auth: String. The authorization value to be used in the request header.\n:param request_headers: Dictionary. Additional headers to be added to the request.\n:return: urllib.request.Request. The created request object."}, "tests": ["tests/runtests.py::TestBuildRequest::test_extra_headers"], "indent": 4}
{"namespace": "zxcvbn.matching.repeat_match", "type": "function", "project_path": "Security/zxcvbn-python", "completion_path": "Security/zxcvbn-python/zxcvbn/matching.py", "signature_position": [250, 250], "body_position": [251, 299], "dependency": {"intra_class": [], "intra_file": ["zxcvbn.matching.RANKED_DICTIONARIES", "zxcvbn.matching.omnimatch"], "cross_file": ["zxcvbn.scoring.most_guessable_match_sequence"]}, "requirement": {"Functionality": "This function searches for repeated patterns in a given password and returns information about the matches found. It uses regular expressions to find both greedy and lazy matches of repeated substrings in the password. It then compares the lengths of the greedy and lazy matches to determine the base token and calculates the repeat count. Finally, it recursively matches and scores the base string to get additional information about the matches.", "Arguments": ":param password: String. The password to search for repeated patterns.\n:param _ranked_dictionaries: List of dictionaries. A list of ranked dictionaries used for matching. Defaults to RANKED_DICTIONARIES.\n:return: List of dictionaries. A list of dictionaries containing information about the repeated matches found in the password. Each dictionary includes the pattern type, start and end indices of the match, the matched token, the base token, the number of guesses required to guess the base token, the sequence of matches for the base token, and the repeat count."}, "tests": ["tests/matching_test.py::test_repeat_matching"], "indent": 4}
{"namespace": "imapclient.imapclient.IMAPClient.idle_check", "type": "method", "project_path": "Communications/IMAPClient", "completion_path": "Communications/IMAPClient/imapclient/imapclient.py", "signature_position": [930, 930], "body_position": [948, 981], "dependency": {"intra_class": ["imapclient.imapclient.IMAPClient.AbortError", "imapclient.imapclient.IMAPClient._imap", "imapclient.imapclient.IMAPClient._poll_socket", "imapclient.imapclient.IMAPClient._select_poll_socket", "imapclient.imapclient.IMAPClient._set_read_timeout", "imapclient.imapclient.IMAPClient.socket"], "intra_file": ["imapclient.imapclient.POLL_SUPPORT", "imapclient.imapclient._parse_untagged_response"], "cross_file": []}, "requirement": {"Functionality": "Check for any IDLE responses sent by the server. This method should only be called if the server is in IDLE mode. It blocks until an IDLE response is received, or until a timeout is reached.", "Arguments": ":param self: IMAPClient. An instance of the IMAPClient class.\n:param timeout: int or None. The maximum number of seconds to wait for an IDLE response. If None, the call will block indefinitely.\n:return: list. A list of received IDLE responses, parsed with values converted to appropriate types."}, "tests": ["tests/test_imapclient.py::TestIdleAndNoop::test_idle_check_timeout_poll", "tests/test_imapclient.py::TestIdleAndNoop::test_idle_check_timeout", "tests/test_imapclient.py::TestIdleAndNoop::test_idle_check_blocking_poll", "tests/test_imapclient.py::TestIdleAndNoop::test_idle_check_blocking", "tests/test_imapclient.py::TestIdleAndNoop::test_idle_check_with_data"], "indent": 8}
{"namespace": "zulipterminal.server_url.encode_stream", "type": "function", "project_path": "Communications/zulip-term", "completion_path": "Communications/zulip-term/zulipterminal/server_url.py", "signature_position": [16, 16], "body_position": [22, 23], "dependency": {"intra_class": [], "intra_file": ["zulipterminal.server_url.hash_util_encode"], "cross_file": []}, "requirement": {"Functionality": "This function replaces any occurrence of whitespace with a hyphen and encode the stream name. It returns the encoded string prefixed with the stream name", "Arguments": ":param stream_id: int.\n:param stream_name: str.\n:return: str. The encoded string representing the message."}, "tests": ["tests/server_url/test_server_url.py::test_encode_stream"], "indent": 4}
{"namespace": "boto.glacier.job.Job.download_to_fileobj", "type": "method", "project_path": "Internet/boto", "completion_path": "Internet/boto/boto/glacier/job.py", "signature_position": [125, 127], "body_position": [143, 145], "dependency": {"intra_class": ["boto.glacier.job.Job.DefaultPartSize", "boto.glacier.job.Job._calc_num_chunks", "boto.glacier.job.Job._download_to_fileob"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function downloads an archive and saves its contents to a file object. It divides the download into chunks and verifies the tree hashes for each downloaded chunk.", "Arguments": ":param self: Job. An instance of the Job class.\n:param output_file: file. The file object where the archive contents will be saved.\n:param chunk_size: int. The chunk size to use when downloading the archive.\n:param verify_hashes: bool. Indicates whether or not to verify the tree hashes for each downloaded chunk. It defaults to True.\n:param retry_exceptions: tuple. A tuple of exceptions that should be retried if they occur during the download. It defaults to (socket.error,).\n:return: No return values."}, "tests": ["tests/unit/glacier/test_job.py::TestJob::test_download_to_fileobj"], "indent": 8}
{"namespace": "boto.cloudsearch.connect_to_region", "type": "function", "project_path": "Internet/boto", "completion_path": "Internet/boto/boto/cloudsearch/__init__.py", "signature_position": [39, 39], "body_position": [40, 43], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["boto.cloudsearch.layer1.Layer1", "boto.regioninfo.connect"]}, "requirement": {"Functionality": "Connect to a specific region in the cloudsearch service. It creates a connection to the cloudsearch service in the specified region.", "Arguments": ":param region_name: String. The name of the region to connect to.\n:param **kw_params: Additional keyword arguments that can be passed to the connect function.\n:return: Connection. The connection object to the cloudsearch service in the specified region."}, "tests": ["tests/unit/test_connect_to_region.py::TestCloudsearchConnection::test_connect_to_region"], "indent": 4}
{"namespace": "sumy.summarizers.sum_basic.SumBasicSummarizer._get_content_words_in_sentence", "type": "method", "project_path": "Internet/sumy", "completion_path": "Internet/sumy/sumy/summarizers/sum_basic.py", "signature_position": [33, 33], "body_position": [34, 37], "dependency": {"intra_class": ["sumy.summarizers.sum_basic.SumBasicSummarizer._filter_out_stop_words", "sumy.summarizers.sum_basic.SumBasicSummarizer._normalize_words", "sumy.summarizers.sum_basic.SumBasicSummarizer._stem_words"], "intra_file": [], "cross_file": ["sumy.models.dom._sentence.Sentence.words"]}, "requirement": {"Functionality": "This function takes a sentence as input and returns the content words in that sentence. It performs several operations on the sentence, including normalizing the words, filtering out stop words, and stemming the content words.", "Arguments": ":param self: SumBasicSummarizer. An instance of the SumBasicSummarizer class.\n:param sentence: The input sentence.\n:return: A list of content words in the sentence after performing normalization, stop word filtering, and stemming."}, "tests": ["tests/test_summarizers/test_sum_basic.py::test_stemmer"], "indent": 8}
{"namespace": "boltons.ioutils.SpooledBytesIO.len", "type": "method", "project_path": "Utilities/boltons", "completion_path": "Utilities/boltons/boltons/ioutils.py", "signature_position": [366, 366], "body_position": [368, 376], "dependency": {"intra_class": ["boltons.ioutils.SpooledBytesIO._rolled", "boltons.ioutils.SpooledBytesIO.seek", "boltons.ioutils.SpooledBytesIO.tell"], "intra_file": ["boltons.ioutils.SpooledIOBase.fileno"], "cross_file": []}, "requirement": {"Functionality": "This function determines the length of the file. It first checks the current position of the file, then based on whether the file has been rolled or not, it calculates the length of the file using different methods. Finally, it returns the length of the file.", "Arguments": ":param self: SpooledBytesIO. An instance of the SpooledBytesIO class.\n:return: int. The length of the file."}, "tests": ["tests/test_ioutils.py::TestSpooledBytesIO::test_len_no_rollover", "tests/test_ioutils.py::TestSpooledBytesIO::test_len_rollover"], "indent": 8}
{"namespace": "exodus_bundler.input_parsing.extract_paths", "type": "function", "project_path": "System/exodus-bundler", "completion_path": "System/exodus-bundler/src/exodus_bundler/input_parsing.py", "signature_position": [70, 70], "body_position": [80, 102], "dependency": {"intra_class": [], "intra_file": ["exodus_bundler.input_parsing.blacklisted_directories", "exodus_bundler.input_parsing.extract_exec_path", "exodus_bundler.input_parsing.extract_open_path", "exodus_bundler.input_parsing.extract_stat_path"], "cross_file": []}, "requirement": {"Functionality": "This function parses paths from a piped input. It takes the raw input, which can be either a list of files or the output of the strace command, and extracts the paths from it. It also has an option to only include paths that actually exist and are not directories.", "Arguments": ":param content: str. The raw input, can be either a list of files or the output of the strace command.\n:param existing_only: bool, optional. Requires that files actually exist and aren't directories. Defaults to True.\n:return: list. A list of paths extracted from the input."}, "tests": ["tests/test_input_parsing.py::test_extract_no_paths", "tests/test_input_parsing.py::test_extract_raw_paths", "tests/test_input_parsing.py::test_extract_strace_paths"], "indent": 4}
{"namespace": "boto.s3.bucket.Bucket.get_key", "type": "method", "project_path": "Internet/boto", "completion_path": "Internet/boto/boto/s3/bucket.py", "signature_position": [145, 146], "body_position": [175, 195], "dependency": {"intra_class": ["boto.s3.bucket.Bucket._get_key_internal", "boto.s3.bucket.Bucket.new_key"], "intra_file": [], "cross_file": ["boto.exception.BotoClientError", "boto.vendored.six.iteritems", "boto.jsonresponse.XmlHandler.parse"]}, "requirement": {"Functionality": "This function checks if a specific key exists within a bucket. It sends a HEAD request to check for the existence of the key. If the key exists, it returns an instance of the Key object. Otherwise, it returns None.", "Arguments": ":param self: Bucket. An instance of the Bucket class.\n:param key_name: String. The name of the key to retrieve.\n:param headers: Dictionary. The headers to send when retrieving the key.\n:param version_id: String. The version ID of the key.\n:param response_headers: Dictionary. A dictionary containing HTTP headers/values that will override any headers associated with the stored object in the response.\n:param validate: Bool. Verifies whether the key exists. If False, this will not hit the service, constructing an in-memory object. Default is True.\n:return: Key. An instance of a Key object or None"}, "tests": ["tests/unit/s3/test_key.py::TestS3Key::test_restore_completed", "tests/unit/s3/test_key.py::TestS3Key::test_when_no_restore_header_present", "tests/unit/s3/test_key.py::TestS3Key::test_change_storage_class_new_bucket", "tests/unit/s3/test_key.py::TestS3Key::test_restore_header_with_ongoing_restore", "tests/unit/s3/test_key.py::TestS3Key::test_storage_class"], "indent": 8}
{"namespace": "zulipterminal.ui_tools.buttons.MessageLinkButton._validate_narrow_link", "type": "method", "project_path": "Communications/zulip-term", "completion_path": "Communications/zulip-term/zulipterminal/ui_tools/buttons.py", "signature_position": [551, 551], "body_position": [556, 580], "dependency": {"intra_class": [], "intra_file": ["zulipterminal.ui_tools.buttons.ParsedNarrowLink", "zulipterminal.model.Model.topics_in_stream"], "cross_file": []}, "requirement": {"Functionality": "This function validates a narrow link and returns either an empty string if the validation is successful or an appropriate validation error message if the validation fails. It checks various conditions related to the parsed link and returns the corresponding error message if any condition is not met.", "Arguments": ":param self: MessageLinkButton. An instance of the MessageLinkButton class.\n:param parsed_link: ParsedNarrowLink. The parsed narrow link to be validated.\n:return: str. Either an empty string for successful validation or an appropriate validation error message."}, "tests": ["tests/ui_tools/test_buttons.py::TestMessageLinkButton::test__validate_narrow_link"], "indent": 8}
{"namespace": "mrjob.job.MRJob.set_up_logging", "type": "method", "project_path": "System/mrjob", "completion_path": "System/mrjob/mrjob/job.py", "signature_position": [652, 652], "body_position": [661, 668], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["mrjob.util.log_to_null", "mrjob.util.log_to_stream"]}, "requirement": {"Functionality": "This function sets up logging when running from the command line. It should log to the 'mrjob' logger and '__main__' logger.", "Arguments": ":param cls: type. The MRJob class.\n:param quiet: bool. If True, logging is disabled. Overrides the value of `verbose`.\n:param verbose: bool. If True, the log level is set to \"DEBUG\". The default log level is \"INFO\".\n:param stream: Stream. The stream to log to. The default stream is `sys.stderr`.\n:return: No return values."}, "tests": ["tests/test_job.py::TestToolLogging::test_default_options", "tests/test_job.py::TestToolLogging::test_verbose"], "indent": 8}
{"namespace": "mingus.core.chords.augmented_triad", "type": "function", "project_path": "Multimedia/mingus", "completion_path": "Multimedia/mingus/mingus/core/chords.py", "signature_position": [222, 222], "body_position": [229, 233], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["mingus.core.intervals", "mingus.core.intervals.major_fifth", "mingus.core.intervals.major_third", "mingus.core.notes", "mingus.core.notes.augment"]}, "requirement": {"Functionality": "Build an augmented triad based on the given note.\nBuild a major third interval on the given note. Then build a major fifth interval on the given note and augment it.\n", "Arguments": ":param note: string. The root note of the triad.\n:return: list of strings. The notes that make up the augmented triad.\n"}, "tests": ["tests/unit/core/test_chords.py::test_chords::test_augmented_triad"], "indent": 4}
{"namespace": "twtxt.config.Config.discover", "type": "method", "project_path": "Communications/twtxt", "completion_path": "Communications/twtxt/twtxt/config.py", "signature_position": [57, 57], "body_position": [59, 60], "dependency": {"intra_class": ["twtxt.config.Config.config_dir", "twtxt.config.Config.config_name", "twtxt.config.Config.from_file"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function is a class method that discovers the location of the config file and tries to load it. It constructs the file path by joining the config directory and the config name of and then load the config from the constructed file path.", "Arguments": ":param cls: The class object itself.\n:return: The loaded config object."}, "tests": ["tests/test_config.py::test_create_config"], "indent": 8}
{"namespace": "alembic.operations.ops.DropTableOp.to_table", "type": "method", "project_path": "Database/alembic", "completion_path": "Database/alembic/alembic/operations/ops.py", "signature_position": [1350, 1352], "body_position": [1353, 1371], "dependency": {"intra_class": ["alembic.operations.ops.DropTableOp._reverse", "alembic.operations.ops.DropTableOp.comment", "alembic.operations.ops.DropTableOp.info", "alembic.operations.ops.DropTableOp.prefixes", "alembic.operations.ops.DropTableOp.schema", "alembic.operations.ops.DropTableOp.table_kw", "alembic.operations.ops.DropTableOp.table_name"], "intra_file": ["alembic.operations.ops.CreateTableOp._constraints_included", "alembic.operations.ops.CreateTableOp.columns"], "cross_file": ["alembic.operations.schemaobj", "alembic.operations.schemaobj.SchemaObjects", "alembic.operations.schemaobj.SchemaObjects.table", "alembic.runtime.migration.MigrationContext"]}, "requirement": {"Functionality": "This function converts a DropTableOp instance into a Table instance. It creates a Table object with the specified table name, columns, constraints, comment, info, prefixes, schema, and other parameters.", "Arguments": ":param self: DropTableOp. An instance of the DropTableOp class.\n:param migration_context: Optional. An instance of the MigrationContext class. Defaults to None.\n:return: Table. The created Table instance."}, "tests": ["tests/test_op.py::ObjectFromToTest::test_create_table_add_kw", "tests/test_op.py::ObjectFromToTest::test_drop_table_add_kw", "tests/test_autogen_diffs.py::OrigObjectTest::test_add_table", "tests/test_op.py::ObjectFromToTest::test_drop_table", "tests/test_autogen_diffs.py::OrigObjectTest::test_drop_table"], "indent": 8}
{"namespace": "boto.ec2.connection.EC2Connection.get_all_instance_status", "type": "method", "project_path": "Internet/boto", "completion_path": "Internet/boto/boto/ec2/connection.py", "signature_position": [683, 686], "body_position": [722, 737], "dependency": {"intra_class": ["boto.ec2.connection.EC2Connection.build_filter_params"], "intra_file": [], "cross_file": ["boto.connection.AWSQueryConnection.build_list_params", "boto.connection.AWSQueryConnection.get_object", "boto.ec2.instancestatus.InstanceStatusSet"]}, "requirement": {"Functionality": "This function retrieves all the instances in the user's account that are scheduled for maintenance. It allows for filtering and pagination of the results.", "Arguments": ":param self: EC2Connection. An instance of the EC2Connection class.\n:param instance_ids: List of strings. A list of instance IDs to filter the results by.\n:param max_results: Integer. The maximum number of instances to include in each response.\n:param next_token: String. A token to specify the next set of results to return.\n:param filters: Dictionary. Optional filters to limit the results. The filter names and values depend on the request being performed.\n:param dry_run: Bool. Set to True if the operation should not actually run.\n:param include_all_instances: Bool. Set to True if all instances should be returned, including non-running instances.\n:return: List. A list of instances that have maintenance scheduled."}, "tests": ["tests/unit/ec2/test_instancestatus.py::TestInstanceStatusResponseParsing::test_include_all_instances", "tests/unit/ec2/test_instancestatus.py::TestInstanceStatusResponseParsing::test_next_token"], "indent": 8}
{"namespace": "pyramid.csrf.CookieCSRFStoragePolicy.check_csrf_token", "type": "method", "project_path": "Internet/pyramid", "completion_path": "Internet/pyramid/src/pyramid/csrf.py", "signature_position": [156, 156], "body_position": [158, 161], "dependency": {"intra_class": ["pyramid.csrf.CookieCSRFStoragePolicy.get_csrf_token"], "intra_file": [], "cross_file": ["pyramid.util.bytes_", "pyramid.util.strings_differ"]}, "requirement": {"Functionality": "Check if the supplied CSRF token is valid by comparing it with the expected token. It converts both tokens to bytes and checks if they are equal.", "Arguments": ":param self: CookieCSRFStoragePolicy. An instance of the CookieCSRFStoragePolicy class.\n:param request: The HTTP request object.\n:param supplied_token: The CSRF token supplied by the client.\n:return: Bool. True if the supplied token is valid, False otherwise."}, "tests": ["tests/test_csrf.py::TestCookieCSRFStoragePolicy::test_check_csrf_token"], "indent": 8}
{"namespace": "mopidy.config.types.List.serialize", "type": "method", "project_path": "Multimedia/Mopidy", "completion_path": "Multimedia/Mopidy/mopidy/config/types.py", "signature_position": [321, 321], "body_position": [322, 335], "dependency": {"intra_class": [], "intra_file": ["mopidy.config.types.String", "mopidy.config.types.String.__init__", "mopidy.config.types.String.serialize"], "cross_file": []}, "requirement": {"Functionality": "Serialize a list of values into a string representation. It iterates through each item in the list and serializes each item. The serialized values are then joined together with newlines and returned as a string.", "Arguments": ":param self: List. An instance of the List class.\n:param value: The list of values to be serialized.\n:param display: Bool. Whether to include additional display information in the serialization. Defaults to False.\n:return: String. The serialized representation of the list."}, "tests": ["tests/config/test_types.py::TestList::test_serialize_ignores_blanks", "tests/config/test_types.py::TestList::test_serialize_none", "tests/config/test_types.py::TestList::test_serialize_ignores_blanks_sets", "tests/config/test_types.py::TestList::test_serialize_tuples", "tests/config/test_types.py::TestList::test_serialize_sets"], "indent": 8}
{"namespace": "gunicorn.instrument.statsd.Statsd.critical", "type": "method", "project_path": "Utilities/gunicorn", "completion_path": "Utilities/gunicorn/gunicorn/instrument/statsd.py", "signature_position": [44, 44], "body_position": [45, 46], "dependency": {"intra_class": ["gunicorn.instrument.statsd.Statsd.increment"], "intra_file": [], "cross_file": ["gunicorn.glogging.Logger", "gunicorn.glogging.Logger.critical"]}, "requirement": {"Functionality": "This function logs a critical message using the Logger class and then increments a counter for \"gunicorn.log.critical\" in the Statsd instance.", "Arguments": ":param self: Statsd. An instance of the Statsd class.\n:param msg: String. The message to be logged.\n:param *args: Variable length argument list. Additional arguments to be passed to the Logger.critical() method.\n:param **kwargs: Arbitrary keyword arguments. Additional keyword arguments to be passed to the Logger.critical() method.\n:return: No return values."}, "tests": ["tests/test_statsd.py::test_instrument"], "indent": 8}
{"namespace": "mrjob.local.LocalMRJobRunner._spark_master", "type": "method", "project_path": "System/mrjob", "completion_path": "System/mrjob/mrjob/local.py", "signature_position": [233, 233], "body_position": [236, 248], "dependency": {"intra_class": [], "intra_file": ["mrjob.local._DEFAULT_EXECUTOR_MEMORY", "mrjob.local._to_num_bytes"], "cross_file": ["mrjob.sim.SimMRJobRunner._num_cores"]}, "requirement": {"Functionality": "This function returns the Spark master information for running a job locally using the local-cluster mode. It calculates the number of executors, cores per executor, and executor memory based on the provided options and returns 'local-cluster[{number of executors},{cores per executor},{executor memory in MB (rounded up)}]'.", "Arguments": ":param self: LocalMRJobRunner. An instance of the LocalMRJobRunner class.\n:return: str. The Spark master URL for running a job locally using the local-cluster mode."}, "tests": ["tests/test_local.py::SparkMasterTestCase::test_default_spark_master", "tests/test_local.py::SparkMasterTestCase::test_num_cores"], "indent": 8}
{"namespace": "sqlitedict.SqliteDict.iteritems", "type": "method", "project_path": "Database/sqlitedict", "completion_path": "Database/sqlitedict/sqlitedict.py", "signature_position": [283, 283], "body_position": [284, 286], "dependency": {"intra_class": ["sqlitedict.SqliteDict.conn", "sqlitedict.SqliteDict.decode", "sqlitedict.SqliteDict.decode_key", "sqlitedict.SqliteDict.tablename"], "intra_file": ["sqlitedict.SqliteMultithread.select"], "cross_file": []}, "requirement": {"Functionality": "Iterate over all key-value pairs in the SqliteDict instance. It executes a SQL query to retrieve all key-value pairs from the table and yields each pair after decoding the key and value.", "Arguments": ":param self: SqliteDict. An instance of the SqliteDict class.\n:return: Iterator. An iterator that yields key-value pairs from the SqliteDict instance."}, "tests": ["tests/test_temp_db.py::TempSqliteDictTest::test_manage_few_records"], "indent": 8}
{"namespace": "mopidy.ext.Extension.get_config_dir", "type": "method", "project_path": "Multimedia/Mopidy", "completion_path": "Multimedia/Mopidy/mopidy/ext.py", "signature_position": [94, 94], "body_position": [100, 106], "dependency": {"intra_class": ["mopidy.ext.Extension.ext_name"], "intra_file": ["mopidy.ext.Config"], "cross_file": ["mopidy.internal.path.expand_path", "mopidy.internal.path.get_or_create_dir", "mopidy.internal.path"]}, "requirement": {"Functionality": "This function is a class method that gets or creates a configuration directory for the extension. It first checks if the extension name is None, and if so, raises an AssertionError. Then, it constructs the path to the configuration directory based on the Mopidy config object and the extension name. Finally, it calls a helper function to get or create the directory and returns the path.", "Arguments": ":param cls: Class. The Extension class.\n:param config: Config. The Mopidy config object.\n:return: Path. The path to the configuration directory for the extension."}, "tests": ["tests/test_ext.py::TestExtension::test_get_config_dir_raises_error"], "indent": 8}
{"namespace": "boto.dynamodb2.table.Table.create_global_secondary_index", "type": "method", "project_path": "Internet/boto", "completion_path": "Internet/boto/boto/dynamodb2/table.py", "signature_position": [460, 460], "body_position": [490, 513], "dependency": {"intra_class": ["boto.dynamodb2.table.Table.connection", "boto.dynamodb2.table.Table.table_name"], "intra_file": [], "cross_file": ["boto.dynamodb2.layer1.DynamoDBConnection.update_table", "boto.log", "boto.dynamodb2.fields.GlobalBaseIndexField.definition", "boto.dynamodb2.fields.GlobalBaseIndexField.schema", "boto"]}, "requirement": {"Functionality": "This function creates a global secondary index in DynamoDB after the table has been created. It takes a `global_index` parameter, which should be a subclass of `GlobalBaseIndexField` representing the desired index. It updates the `global_indexes` information on the `Table` by calling `Table.describe`. It returns `True` on success.", "Arguments": ":param self: Table. An instance of the Table class.\n:param global_index: GlobalBaseIndexField subclass. The desired global index to be created.\n:return: Bool. Returns `True` if the global index is created successfully, otherwise `False`."}, "tests": ["tests/unit/dynamodb2/test_table.py::TableTestCase::test_create_global_secondary_index"], "indent": 8}
{"namespace": "boto.utils.retry_url", "type": "function", "project_path": "Internet/boto", "completion_path": "Internet/boto/boto/utils.py", "signature_position": [205, 205], "body_position": [212, 237], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["boto.config", "boto.log"]}, "requirement": {"Functionality": "This function retries a URL request for accessing the metadata service on an instance. It tries to open the URL using a proxy handler and returns the result after reading it.", "Arguments": ":param url: String. The URL to be accessed.\n:param retry_on_404: Bool. Whether to retry the request if a 404 error is encountered. Defaults to True.\n:param num_retries: Integer. The number of times to retry the request. Defaults to 10.\n:param timeout: Float. The timeout value for the request. Defaults to None.\n:return: String. The result of the URL request."}, "tests": ["tests/unit/utils/test_utils.py::TestRetryURL::test_retry_url_using_bytes_and_string_response", "tests/unit/utils/test_utils.py::TestRetryURL::test_retry_url_uses_proxy"], "indent": 4}
{"namespace": "boltons.formatutils.split_format_str", "type": "function", "project_path": "Utilities/boltons", "completion_path": "Utilities/boltons/boltons/formatutils.py", "signature_position": [107, 107], "body_position": [112, 120], "dependency": {"intra_class": [], "intra_file": ["boltons.formatutils.construct_format_field_str"], "cross_file": []}, "requirement": {"Functionality": "This function performs basic splitting of a format string and returns a list of strings. It parse the format string and constructs a format field string for each parsed field. The resulting list contains tuples of literal strings and format field strings.", "Arguments": ":param fstr: String. The format string to be split.\n:return: List of tuples. Each tuple contains a literal string and a format field string."}, "tests": ["tests/test_formatutils.py::test_split_fstr"], "indent": 4}
{"namespace": "asyncssh.public_key.SSHKey.convert_to_public", "type": "method", "project_path": "Security/asyncssh", "completion_path": "Security/asyncssh/asyncssh/public_key.py", "signature_position": [624, 624], "body_position": [634, 637], "dependency": {"intra_class": ["asyncssh.public_key.SSHKey._comment", "asyncssh.public_key.SSHKey._filename", "asyncssh.public_key.SSHKey.public_data", "asyncssh.public_key.SSHKey.set_comment", "asyncssh.public_key.SSHKey.set_filename"], "intra_file": ["asyncssh.public_key.decode_ssh_public_key"], "cross_file": []}, "requirement": {"Functionality": "This method converts an SSHKey object that contains a private key into one that contains only the corresponding public key. It first decodes asymmetric encryption. Once decrypted, it proceeds to assign a relevant comment and filename to the associated key. Upon completion of these steps, the method returns the processed data as its final output.", "Arguments": ":param self: SSHKey. An instance of the SSHKey class.\n:return: SSHKey. The SSHKey object that contains only the corresponding public key."}, "tests": ["tests/test_agent.py::_TestAgent::test_lock", "tests/test_public_key.py::_TestPublicKeyTopLevel::test_rsa_encrypt_error", "tests/test_public_key.py::_TestPublicKeyTopLevel::test_generate_errors", "tests/test_agent.py::_TestAgent::test_reconnect", "tests/test_agent.py::_TestAgent::test_sign"], "indent": 8}
{"namespace": "boto.dynamodb2.items.Item.prepare_partial", "type": "method", "project_path": "Internet/boto", "completion_path": "Internet/boto/boto/dynamodb2/items.py", "signature_position": [333, 333], "body_position": [343, 367], "dependency": {"intra_class": ["boto.dynamodb2.items.Item._data", "boto.dynamodb2.items.Item._determine_alterations", "boto.dynamodb2.items.Item._dynamizer"], "intra_file": [], "cross_file": ["boto.dynamodb.types.Dynamizer.encode"]}, "requirement": {"Functionality": "This function prepares the changed or deleted fields of an Item instance to be encoded and handed off to DynamoDB for an update operation. It determines the alterations made to the fields, encodes the values, and creates a data structure with the necessary actions and values for each field.", "Arguments": ":param self: Item. An instance of the Item class.\n:return: Tuple. A tuple containing the final data structure with actions and values for each field, and a set of fields that were altered."}, "tests": ["tests/unit/dynamodb2/test_table.py::ItemTestCase::test_prepare_partial", "tests/unit/dynamodb2/test_table.py::ItemTestCase::test_prepare_partial_empty_set"], "indent": 8}
{"namespace": "ydata_profiling.model.pandas.correlations_pandas.pandas_auto_compute", "type": "function", "project_path": "Software-Development/pandas-profiling", "completion_path": "Software-Development/pandas-profiling/src/ydata_profiling/model/pandas/correlations_pandas.py", "signature_position": [161, 163], "body_position": [164, 214], "dependency": {"intra_class": [], "intra_file": ["ydata_profiling.model.pandas.correlations_pandas._pairwise_cramers", "ydata_profiling.model.pandas.correlations_pandas._pairwise_spearman", "ydata_profiling.model.pandas.discretize_pandas.DiscretizationType.UNIFORM"], "cross_file": ["ydata_profiling.config.Settings", "ydata_profiling.config.Settings.categorical_maximum_correlation_distinct", "ydata_profiling.config.Settings.correlations", "ydata_profiling.model.pandas.discretize_pandas.DiscretizationType", "ydata_profiling.model.pandas.discretize_pandas.Discretizer", "ydata_profiling.model.pandas.discretize_pandas.Discretizer.discretize_dataframe"]}, "requirement": {"Functionality": "This function performs automatic computation of correlations between columns in a pandas DataFrame. It first identifies the numerical and categorical columns based on the summary dictionary. Then, it discretizes the DataFrame using a uniform discretization method. Next, it calculates the correlation scores between each pair of columns using either the pairwise Spearman correlation or the pairwise Cramers' V, depending on the column types. Finally, it returns a correlation matrix.", "Arguments": ":param config: Settings. An instance of the Settings class that contains configuration parameters.\n:param df: pd.DataFrame. The input DataFrame.\n:param summary: dict. A dictionary that summarizes the properties of each column in the DataFrame.\n:return: Optional[pd.DataFrame]. The correlation matrix if there are more than one numerical or categorical columns, otherwise None."}, "tests": ["tests/unit/test_pandas/test_correlations.py::test_numeric_auto_equals_spearman", "tests/unit/test_pandas/test_correlations.py::test_categorical_auto_equals_equals_cramers"], "indent": 4}
{"namespace": "boto.cloudhsm.connect_to_region", "type": "function", "project_path": "Internet/boto", "completion_path": "Internet/boto/boto/cloudhsm/__init__.py", "signature_position": [38, 38], "body_position": [39, 42], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["boto.cloudhsm.layer1.CloudHSMConnection", "boto.regioninfo.connect"]}, "requirement": {"Functionality": "Connect to a specific region using the CloudHSMConnection class. It creates a connection with the specified parameters and returns the CloudHSMConnection object.", "Arguments": ":param region_name: String. The name of the region to connect to.\n:param **kw_params: Additional keyword arguments that can be passed to the connect function.\n:return: CloudHSMConnection. The connection object for the specified region."}, "tests": ["tests/unit/test_connect_to_region.py::TestConnectCloudHsm::test_connect_to_region"], "indent": 4}
{"namespace": "mssqlcli.packages.prioritization.PrevalenceCounter.update", "type": "method", "project_path": "Database/mssql-cli", "completion_path": "Database/mssql-cli/mssqlcli/packages/prioritization.py", "signature_position": [29, 29], "body_position": [30, 31], "dependency": {"intra_class": ["mssqlcli.packages.prioritization.PrevalenceCounter.update_keywords", "mssqlcli.packages.prioritization.PrevalenceCounter.update_names"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Update the PrevalenceCounter instance by updating the keywords and names based on the input text.", "Arguments": ":param self: PrevalenceCounter. An instance of the PrevalenceCounter class.\n:param text: String. The input text used to update the keywords and names.\n:return: No return values."}, "tests": ["tests/test_prioritization.py::PrioritizationTests::test_prevalence_counter"], "indent": 8}
{"namespace": "googleapiclient.channel.notification_from_headers", "type": "function", "project_path": "Internet/google-api-python-client", "completion_path": "Internet/google-api-python-client/googleapiclient/channel.py", "signature_position": [251, 251], "body_position": [267, 279], "dependency": {"intra_class": [], "intra_file": ["googleapiclient.errors", "googleapiclient.channel.Channel.id", "googleapiclient.channel.Notification", "googleapiclient.channel.Notification.__init__", "googleapiclient.channel.X_GOOG_CHANNEL_ID", "googleapiclient.channel.X_GOOG_MESSAGE_NUMBER", "googleapiclient.channel.X_GOOG_RESOURCE_ID", "googleapiclient.channel.X_GOOG_RESOURCE_STATE", "googleapiclient.channel.X_GOOG_RESOURCE_URI", "googleapiclient.channel._upper_header_keys"], "cross_file": ["googleapiclient.errors.InvalidNotificationError"]}, "requirement": {"Functionality": "This function parses a notification from the webhook request headers, validates the notification, and returns a Notification object. It will raise invalid notification error if the notification is invalid.", "Arguments": ":param channel: Channel. The channel that the notification is associated with.\n:param headers: dict. A dictionary-like object that contains the request headers from the webhook HTTP request.\n:return: Notification. A Notification object."}, "tests": ["tests/test_channel.py::TestNotification::test_notification_from_headers"], "indent": 4}
{"namespace": "boto.beanstalk.connect_to_region", "type": "function", "project_path": "Internet/boto", "completion_path": "Internet/boto/boto/beanstalk/__init__.py", "signature_position": [41, 41], "body_position": [42, 45], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["boto.beanstalk.layer1.Layer1", "boto.regioninfo.connect"]}, "requirement": {"Functionality": "Connect to a specific region in the Elastic Beanstalk service using the provided region name and additional keyword parameters. It creates a Layer1 instance and establishes a connection to the specified region.", "Arguments": ":param region_name: String. The name of the region to connect to.\n:param **kw_params: Additional keyword parameters that can be passed to the connect function.\n:return: Connection. The connection object established with the specified region."}, "tests": ["tests/unit/test_connect_to_region.py::TestConnectBeanstalk::test_connect_to_region"], "indent": 4}
{"namespace": "alembic.autogenerate.render._render_check_constraint", "type": "function", "project_path": "Database/alembic", "completion_path": "Database/alembic/alembic/autogenerate/render.py", "signature_position": [1032, 1036], "body_position": [1037, 1069], "dependency": {"intra_class": [], "intra_file": ["alembic.autogenerate.render._render_gen_name", "alembic.autogenerate.render._render_potential_expr", "alembic.autogenerate.render._sqlalchemy_autogenerate_prefix", "alembic.autogenerate.render._user_defined_render"], "cross_file": ["alembic.autogenerate.api.AutogenContext"]}, "requirement": {"Functionality": "This function renders a check constraint in a specific format. It first tries to render the constraint using a user-defined rendering function. If that fails, it checks if the constraint is part of a parent type already present in the table. If it is, it returns None. Otherwise, it constructs a string representation of the check constraint with optional parameters.", "Arguments": ":param constraint: CheckConstraint. The check constraint to render.\n:param autogen_context: AutogenContext. The autogen context.\n:param namespace_metadata: Optional[MetaData]. The metadata of the namespace.\n:return: Optional[str]. The rendered check constraint string, or None if the constraint is part of a parent type."}, "tests": ["tests/test_autogen_render.py::AutogenRenderTest::test_render_check_constraint_literal", "tests/test_autogen_render.py::RenderNamingConventionTest::test_render_check_constraint_renamed", "tests/test_autogen_render.py::AutogenRenderTest::test_render_check_constraint_literal_binds", "tests/test_autogen_render.py::AutogenRenderTest::test_render_check_constraint_sqlexpr"], "indent": 4}
{"namespace": "rows.fields.DateField.deserialize", "type": "method", "project_path": "Text-Processing/rows", "completion_path": "Text-Processing/rows/rows/fields.py", "signature_position": [367, 367], "body_position": [368, 375], "dependency": {"intra_class": ["rows.fields.DateField.INPUT_FORMAT", "rows.fields.DateField.TYPE"], "intra_file": ["rows.fields.Field", "rows.fields.Field.deserialize", "rows.fields.as_string"], "cross_file": []}, "requirement": {"Functionality": "Deserialize a value into a date instance. It first calls the parent class's deserialize method to convert the value into a date object. Then, it checks if the value is already None or an instance of allowed type in DateField class. If so, it returns the value as is. Otherwise, it converts the value into a string, and parse the string value into a datetime object and creates a new date object using the year, month, and day attributes of the datetime object.", "Arguments": ":param cls: Class. The DateField class.\n:param value: Object. The value to be deserialized into a DateField instance.\n:param args: Object. Additional positional arguments.\n:param kwargs: Object. Additional keyword arguments.\n:return: date. The deserialized date instance."}, "tests": ["tests/tests_fields.py::FieldsTestCase::test_DateField"], "indent": 8}
{"namespace": "sacred.utils.rel_path", "type": "function", "project_path": "Utilities/sacred", "completion_path": "Utilities/sacred/sacred/utils.py", "signature_position": [529, 529], "body_position": [531, 534], "dependency": {"intra_class": [], "intra_file": ["sacred.utils.is_prefix"], "cross_file": []}, "requirement": {"Functionality": "This function returns the relative path of a given path with respect to a base path. It checks if the base path is a prefix of the given path and returns the relative path by removing the base path from the given path. Otherwise, it raises a assert error message - \"{base} not a prefix of {path}\".", "Arguments": ":param base: String. The base path.\n:param path: String. The path for which the relative path needs to be calculated.\n:return: String. The relative path of the given path with respect to the base path."}, "tests": ["tests/test_utils.py::test_rel_path"], "indent": 4}
{"namespace": "mopidy.config.types.Hostname.deserialize", "type": "method", "project_path": "Multimedia/Mopidy", "completion_path": "Multimedia/Mopidy/mopidy/config/types.py", "signature_position": [385, 385], "body_position": [386, 401], "dependency": {"intra_class": ["mopidy.config.types.Hostname._required"], "intra_file": ["mopidy.config.types.Path", "mopidy.config.types.Path.__init__", "mopidy.config.types.Path.deserialize", "mopidy.config.types.decode"], "cross_file": ["mopidy.config.validators.validate_required", "mopidy.internal.path.get_unix_socket_path", "mopidy.config.validators", "mopidy.internal.path"]}, "requirement": {"Functionality": "This function deserializes a value and validates it to ensure it is a valid hostname or IP address. It first decodes the value and removes any leading or trailing whitespace. Then, it checks if the value is required and validates it accordingly. If the value is empty, it returns None. If the value is a valid Unix socket path, it converts it to a string representation and returns it. If the value is a valid hostname or IP address, it returns the value as is. Otherwise, it raises a ValueError.", "Arguments": ":param self: Hostname. An instance of the Hostname class.\n:param value: The value to deserialize and validate.\n:param display: Bool. Whether to display the value. Defaults to False.\n:return: The deserialized and validated value."}, "tests": ["tests/config/test_types.py::TestHostname::test_deserialize_with_unix_socket", "tests/config/test_types.py::TestHostname::test_deserialize_enforces_required", "tests/config/test_types.py::TestHostname::test_deserialize_conversion_failure", "tests/config/test_types.py::TestHostname::test_deserialize_conversion_success"], "indent": 8}
{"namespace": "bentoml._internal.runner.container.NdarrayContainer.to_payload", "type": "method", "project_path": "Scientific-Engineering/bentoml", "completion_path": "Scientific-Engineering/bentoml/src/bentoml/_internal/runner/container.py", "signature_position": [275, 280], "body_position": [281, 306], "dependency": {"intra_class": [], "intra_file": ["bentoml._internal.runner.container.Payload", "bentoml._internal.runner.container.np"], "cross_file": ["bentoml._internal.external_typing.NpNDArray", "bentoml._internal.utils.pickle.pep574_dumps", "bentoml._internal.external_typing", "bentoml._internal.runner.container.DataContainer.create_payload"]}, "requirement": {"Functionality": "This function converts a numpy ndarray into a Payload object. It first checks if the ndarray is not 0-dimensional. If it is not, it ensures that the ndarray is either C-contiguous or F-contiguous. Then, it converts the ndarray into a byte string using the dump function with PEP 574 support. The byte string is then encoded using base64 and stored in the \"pickle_bytes_str\" field of the Payload object. If the ndarray is 0-dimensional, it directly converts the ndarray into a byte string using the pickle.dumps function and stores it in the \"pickle_bytes_str\" field of the Payload object.", "Arguments": ":param cls: Class. The class itself.\n:param batch: NpNDArray. The numpy ndarray to be converted into a Payload object.\n:param batch_dim: Int. The dimension along which the ndarray will be split.\n:return: Payload. The created Payload object."}, "tests": ["tests/unit/_internal/runner/test_container.py::test_ndarray_container"], "indent": 8}
{"namespace": "bplustree.memory.FileMemory.get_metadata", "type": "method", "project_path": "Database/bplustree", "completion_path": "Database/bplustree/bplustree/memory.py", "signature_position": [205, 205], "body_position": [206, 233], "dependency": {"intra_class": ["bplustree.memory.FileMemory._read_page", "bplustree.memory.FileMemory._tree_conf"], "intra_file": ["bplustree.memory.ReachedEndOfFile"], "cross_file": ["bplustree.serializer", "bplustree.const.ENDIAN", "bplustree.const.OTHERS_BYTES", "bplustree.const.PAGE_REFERENCE_BYTES", "bplustree.const.TreeConf"]}, "requirement": {"Functionality": "This function retrieves the metadata of a FileMemory instance. It reads the first page of the file and extracts the root node page, page size, order, key size, and value size. It then creates a TreeConf object with the extracted values and returns the root node page and the TreeConf object.", "Arguments": ":param self: FileMemory. An instance of the FileMemory class.\n:return: tuple. A tuple containing the root node page and the TreeConf object."}, "tests": ["tests/test_memory.py::test_file_memory_metadata"], "indent": 8}
{"namespace": "wikipediaapi.WikipediaPage.sections", "type": "method", "project_path": "Communications/Wikipedia-API", "completion_path": "Communications/Wikipedia-API/wikipediaapi/__init__.py", "signature_position": [924, 924], "body_position": [930, 932], "dependency": {"intra_class": ["wikipediaapi.WikipediaPage._called", "wikipediaapi.WikipediaPage._fetch", "wikipediaapi.WikipediaPage._section"], "intra_file": ["wikipediaapi.WikipediaPageSection"], "cross_file": []}, "requirement": {"Functionality": "This function returns all sections of the current Wikipedia page. It first checks if the sections have been fetched. If not, it fetches that. Then, it returns the list of WikipediaPageSection objects representing each section.", "Arguments": ":param self: WikipediaPage. An instance of the WikipediaPage class.\n:return: List of WikipediaPageSection. The list of all sections of the current Wikipedia page."}, "tests": ["tests/extract_html_format_test.py::TestHtmlFormatExtracts::test_section_count", "tests/extract_wiki_format_test.py::TestWikiFormatExtracts::test_top_level_section_titles", "tests/extract_wiki_format_test.py::TestWikiFormatExtracts::test_section_count", "tests/extract_html_format_test.py::TestHtmlFormatExtracts::test_top_level_section_titles"], "indent": 8}
{"namespace": "msticpy.analysis.anomalous_sequence.utils.cmds_only.rarest_window_session", "type": "function", "project_path": "Security/msticpy", "completion_path": "Security/msticpy/msticpy/analysis/anomalous_sequence/utils/cmds_only.py", "signature_position": [281, 290], "body_position": [324, 339], "dependency": {"intra_class": [], "intra_file": ["msticpy.analysis.anomalous_sequence.utils.cmds_only.compute_likelihood_windows_in_session"], "cross_file": ["msticpy.analysis.anomalous_sequence.utils.data_structures.StateMatrix"]}, "requirement": {"Functionality": "This function finds the rarest window in a given session and computes the likelihood of that window. It calculates the likelihoods of all sliding windows in the session.", "Arguments": ":param session: List[str]. A list of commands (strings) representing a session.\n:param prior_probs: Union[StateMatrix, dict]. Computed probabilities of individual commands.\n:param trans_probs: Union[StateMatrix, dict]. Computed probabilities of sequences of commands (length 2).\n:param window_len: int. The length of the sliding window for likelihood calculations.\n:param use_start_end_tokens: bool. If True, the `start_token` and `end_token` will be added to the beginning and end of the session respectively before the calculations are done.\n:param start_token: str. A dummy command to signify the start of the session.\n:param end_token: str. A dummy command to signify the end of the session.\n:param use_geo_mean: bool. If True, each of the likelihoods of the sliding windows will be raised to the power of (1/`window_len`).\n:return: Tuple[List[str], float]. The rarest window part of the session and the likelihood of that window."}, "tests": ["tests/analysis/test_anom_seq_cmds_only.py::TestCmdsOnly::test_rarest_window_session"], "indent": 4}
{"namespace": "imapclient.imapclient.IMAPClient.select_folder", "type": "method", "project_path": "Communications/IMAPClient", "completion_path": "Communications/IMAPClient/imapclient/imapclient.py", "signature_position": [802, 802], "body_position": [820, 821], "dependency": {"intra_class": ["imapclient.imapclient.IMAPClient._command_and_check", "imapclient.imapclient.IMAPClient._imap", "imapclient.imapclient.IMAPClient._normalise_folder", "imapclient.imapclient.IMAPClient._process_select_response"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function sets the current folder on the server for the IMAPClient instance. It allows future calls to methods such as search and fetch to act on the selected folder.", "Arguments": ":param self: IMAPClient. An instance of the IMAPClient class.\n:param folder: String. The name of the folder to select on the server.\n:param readonly: Bool. Whether to open the folder in read-only mode. Defaults to False.\n:return: Dictionary. A dictionary containing the response from the server after selecting the folder. The keys \"EXISTS\", \"FLAGS\", and \"RECENT\" are guaranteed to exist in the dictionary."}, "tests": ["tests/test_imapclient.py::TestSelectFolder::test_normal"], "indent": 8}
{"namespace": "capirca.aclgen.EntryPoint", "type": "function", "project_path": "Security/capirca", "completion_path": "Security/capirca/capirca/aclgen.py", "signature_position": [694, 694], "body_position": [696, 697], "dependency": {"intra_class": [], "intra_file": ["capirca.aclgen.SetupFlags", "capirca.aclgen.main"], "cross_file": []}, "requirement": {"Functionality": "This function serves as the entry point of the program. It reads in the flags and calls the main function to start the program.", "Arguments": ":param: No input parameters.\n:return: No return values."}, "tests": ["tests/integration/aclgen_test.py::TestAclGenDemo::test_entry_point"], "indent": 2}
{"namespace": "sumy.parsers.plaintext.PlaintextParser.document", "type": "method", "project_path": "Internet/sumy", "completion_path": "Internet/sumy/sumy/parsers/plaintext.py", "signature_position": [60, 60], "body_position": [61, 78], "dependency": {"intra_class": ["sumy.parsers.plaintext.PlaintextParser._text", "sumy.parsers.plaintext.PlaintextParser._to_sentences"], "intra_file": [], "cross_file": ["sumy.parsers.parser.DocumentParser._tokenizer", "sumy.models.dom._document.ObjectDocumentModel", "sumy.models.dom._paragraph.Paragraph", "sumy.models.dom._sentence.Sentence"]}, "requirement": {"Functionality": "This function parses the plaintext document saves in this instance and creates a document model object. It iterates through each line of the input text, identifies sentences and paragraphs, and creates corresponding objects. The final document model is returned.", "Arguments": ":param self: PlaintextParser. An instance of the PlaintextParser class.\n:return: ObjectDocumentModel. The created document model object."}, "tests": ["tests/test_evaluation/test_evaluation_rouge.py::test_rouge_l_summary_level", "tests/test_evaluation/test_evaluation_rouge.py::test_ngrams_for_more_sentences_should_not_return_words_at_boundaries", "tests/test_evaluation/test_evaluation_rouge.py::test_rouge_l_sentence_level", "tests/test_plaintext_parser.py::test_parse_plaintext_long", "tests/test_plaintext_parser.py::test_parse_plaintext"], "indent": 8}
{"namespace": "falcon.request.Request.uri", "type": "method", "project_path": "Internet/falcon", "completion_path": "Internet/falcon/falcon/request.py", "signature_position": [775, 775], "body_position": [776, 784], "dependency": {"intra_class": ["falcon.request.Request._cached_uri", "falcon.request.Request.netloc", "falcon.request.Request.relative_uri", "falcon.request.Request.scheme"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function returns the URI of a Request instance. If the URI is not cached, it concatenates the scheme, netloc, and relative uri to form the URI and caches it for future use. The output format is \"{scheme}://{netloc}{relative uri}\".", "Arguments": ":param self: Request. An instance of the Request class.\n:return: String. The URI of the Request instance."}, "tests": ["tests/test_request_forwarded.py::test_no_forwarded_headers_with_port", "tests/test_request_forwarded.py::test_no_forwarded_headers", "tests/test_request_attrs.py::TestRequestAttributes::test_reconstruct_url", "tests/test_request_attrs.py::TestRequestAttributes::test_uri_https", "tests/test_request_attrs.py::TestRequestAttributes::test_uri"], "indent": 8}
{"namespace": "mrjob.parse.is_s3_uri", "type": "function", "project_path": "System/mrjob", "completion_path": "System/mrjob/mrjob/parse.py", "signature_position": [43, 43], "body_position": [45, 49], "dependency": {"intra_class": [], "intra_file": ["mrjob.parse.parse_s3_uri"], "cross_file": []}, "requirement": {"Functionality": "This function checks whether a given URI can be parsed into an S3 URI and returns True if it can, otherwise it returns False.\nThis function uses a try-except block to handle any ValueError that may occur when trying to parse the URI.\n", "Arguments": ":param uri: String. The URI to be checked if it can be parsed into an S3 URI.\n:return: Boolean. True if the URI can be parsed into an S3 URI, False otherwise.\n"}, "tests": ["tests/test_parse.py::URITestCase::test_is_s3_uri"], "indent": 4}
{"namespace": "rest_framework.fields.ChoiceField.iter_options", "type": "method", "project_path": "Internet/djangorestframework", "completion_path": "Internet/djangorestframework/rest_framework/fields.py", "signature_position": [1390, 1390], "body_position": [1394, 1398], "dependency": {"intra_class": ["rest_framework.fields.ChoiceField.grouped_choices", "rest_framework.fields.ChoiceField.html_cutoff", "rest_framework.fields.ChoiceField.html_cutoff_text", "rest_framework.fields.ChoiceField.iter_options"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function is a helper method used for rendering select widgets in templates. It returns an iterator of options based on the grouped choices, cutoff value, and cutoff text.", "Arguments": ":param self: ChoiceField. An instance of the ChoiceField class.\n:return: Iterator. An iterator of options for rendering select widgets."}, "tests": ["tests/test_fields.py::TestChoiceField::test_iter_options"], "indent": 8}
{"namespace": "trailscraper.iam.parse_policy_document", "type": "function", "project_path": "Security/trailscraper", "completion_path": "Security/trailscraper/trailscraper/iam.py", "signature_position": [163, 163], "body_position": [165, 170], "dependency": {"intra_class": [], "intra_file": ["trailscraper.iam.PolicyDocument", "trailscraper.iam.PolicyDocument.__init__", "trailscraper.iam._parse_statements"], "cross_file": []}, "requirement": {"Functionality": "This function takes a stream of JSON data and parses it into a PolicyDocument object. It first checks if the stream is a string, and if so, it loads the JSON data into a dictionary. Otherwise, it loads the JSON data as file stream. Finally, it creates a PolicyDocument object using the parsed statements and version from the JSON dictionary.", "Arguments": ":param stream: The input stream of JSON data.\n:return: PolicyDocument. The parsed PolicyDocument object."}, "tests": ["tests/integration/cli_guess_test.py::test_should_guess_all_matching_statements", "tests/iam/policy_document_test.py::test_json_parses_to_policy_document", "tests/integration/cli_guess_test.py::test_should_guess_only_specific_actions_and_fix_upper_lowercase"], "indent": 4}
{"namespace": "sacred.config.config_files.load_config_file", "type": "function", "project_path": "Utilities/sacred", "completion_path": "Utilities/sacred/sacred/config/config_files.py", "signature_position": [59, 59], "body_position": [60, 62], "dependency": {"intra_class": [], "intra_file": ["sacred.config.config_files.Handler.load", "sacred.config.config_files.Handler.mode", "sacred.config.config_files.get_handler"], "cross_file": []}, "requirement": {"Functionality": "Load a configuration file by getting the appropriate handler based on the file extension, opening the file, and using the handler to load the configuration data.", "Arguments": ":param filename: str. The name of the configuration file to load.\n:return: The loaded configuration data."}, "tests": ["tests/test_config/test_config_files.py::test_load_config_file_exception_msg_invalid_ext", "tests/test_config/test_config_files.py::test_load_config_file"], "indent": 4}
{"namespace": "mopidy.config.types.Boolean.deserialize", "type": "method", "project_path": "Multimedia/Mopidy", "completion_path": "Multimedia/Mopidy/mopidy/config/types.py", "signature_position": [202, 202], "body_position": [203, 211], "dependency": {"intra_class": ["mopidy.config.types.Boolean._required", "mopidy.config.types.Boolean.false_values", "mopidy.config.types.Boolean.true_values"], "intra_file": ["mopidy.config.types.decode"], "cross_file": ["mopidy.config.validators.validate_required", "mopidy.config.validators"]}, "requirement": {"Functionality": "Deserialize a boolean value from a serialized string representation. It decodes the input value, validates if it is required, and then checks if it matches any of the true or false values. If it doesn't match any, it raises a ValueError.", "Arguments": ":param self: Boolean. An instance of the Boolean class.\n:param value: String. The serialized string representation of the boolean value.\n:return: Bool. The deserialized boolean value."}, "tests": ["tests/config/test_types.py::TestBoolean::test_deserialize_conversion_failure", "tests/config/test_types.py::TestBoolean::test_deserialize_conversion_success", "tests/config/test_types.py::TestBoolean::test_deserialize_enforces_required"], "indent": 8}
{"namespace": "kinto.core.resource.Resource.timestamp", "type": "method", "project_path": "Internet/kinto", "completion_path": "Internet/kinto/kinto/core/resource/__init__.py", "signature_position": [233, 233], "body_position": [238, 250], "dependency": {"intra_class": ["kinto.core.resource.Resource.model"], "intra_file": ["kinto.core.resource.logger"], "cross_file": ["kinto.core.resource.model.Model.timestamp", "kinto.core.errors.ERRORS", "kinto.core.errors.ERRORS.BACKEND", "kinto.core.errors.http_error", "kinto.core.storage.exceptions", "kinto.core.storage.exceptions.ReadonlyError"]}, "requirement": {"Functionality": "This function returns the current timestamp of a resource. It first tries to get the timestamp from the model associated with the resource. If fails it raises an read only error exception and save the error information into http error, raise a JSON formated response matching the error HTTP API.", "Arguments": ":param self: Resource. An instance of the Resource class.\n:return: int. The current timestamp of the resource."}, "tests": ["tests/core/resource/test_preconditions.py::NotModifiedTest::test_single_object_last_modified_is_returned"], "indent": 8}
{"namespace": "gunicorn.config.Config.address", "type": "method", "project_path": "Utilities/gunicorn", "completion_path": "Utilities/gunicorn/gunicorn/config.py", "signature_position": [127, 127], "body_position": [128, 129], "dependency": {"intra_class": ["gunicorn.config.Config.settings"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function retrieves the bind address from settings and returns a list of parsed addresses.", "Arguments": ":param self: Config. An instance of the Config class.\n:return: List of addresses. The parsed addresses from settings."}, "tests": ["tests/test_config.py::test_property_access"], "indent": 8}
{"namespace": "diffprivlib.models.linear_regression.LinearRegression.fit", "type": "method", "project_path": "Security/diffprivlib", "completion_path": "Security/diffprivlib/diffprivlib/models/linear_regression.py", "signature_position": [240, 240], "body_position": [260, 317], "dependency": {"intra_class": ["diffprivlib.models.linear_regression.LinearRegression._obj_coefs", "diffprivlib.models.linear_regression.LinearRegression._preprocess_data", "diffprivlib.models.linear_regression.LinearRegression.accountant", "diffprivlib.models.linear_regression.LinearRegression.bounds_X", "diffprivlib.models.linear_regression.LinearRegression.bounds_y", "diffprivlib.models.linear_regression.LinearRegression.coef_", "diffprivlib.models.linear_regression.LinearRegression.epsilon", "diffprivlib.models.linear_regression.LinearRegression.random_state"], "intra_file": ["diffprivlib.models.linear_regression._construct_regression_obj"], "cross_file": ["diffprivlib.accountant.BudgetAccountant.check", "diffprivlib.accountant.BudgetAccountant.spend", "diffprivlib.utils.PrivacyLeakWarning", "diffprivlib.utils.check_random_state", "diffprivlib.validation.DiffprivlibMixin._check_bounds", "diffprivlib.validation.DiffprivlibMixin._validate_params", "diffprivlib.validation.DiffprivlibMixin._warn_unused_args"]}, "requirement": {"Functionality": "This function fits a linear regression model to the given training data. It preprocesses the data, determines the bounds, constructs regression objects, and optimizes the coefficients using the minimize function. It also sets the intercept and updates the accountant's spending.", "Arguments": ":param self: LinearRegression. An instance of the LinearRegression class.\n:param X: array-like or sparse matrix. The training data with shape (n_samples, n_features).\n:param y: array_like. The target values with shape (n_samples, n_targets).\n:param sample_weight: ignored. Ignored by diffprivlib. Present for consistency with sklearn API.\n:return: self. An instance of the LinearRegression class."}, "tests": ["tests/models/test_LinearRegression.py::TestLinearRegression::test_large_data", "tests/models/test_LinearRegression.py::TestLinearRegression::test_simple", "tests/models/test_LinearRegression.py::TestLinearRegression::test_accountant", "tests/models/test_LinearRegression.py::TestLinearRegression::test_multiple_targets", "tests/models/test_LinearRegression.py::TestLinearRegression::test_sample_weight_warning"], "indent": 8}
{"namespace": "sacred.dependencies.is_local_source", "type": "function", "project_path": "Utilities/sacred", "completion_path": "Utilities/sacred/sacred/dependencies.py", "signature_position": [552, 552], "body_position": [576, 589], "dependency": {"intra_class": [], "intra_file": ["sacred.dependencies.convert_path_to_module_parts"], "cross_file": []}, "requirement": {"Functionality": "This function checks if a module comes from a specific experiment path. It compares the absolute filename and the experiment path to determine if the module is a local source file or a package dependency.", "Arguments": ":param filename: str. The absolute filename of the module in question.\n:param modname: str. The full name of the module including parent namespaces.\n:param experiment_path: str. The base path of the experiment.\n:return: bool. True if the module was imported locally from (a subdir of) the experiment_path, and False otherwise."}, "tests": ["tests/test_dependencies.py::test_is_local_source"], "indent": 4}
{"namespace": "asyncssh.public_key.SSHKey.verify", "type": "method", "project_path": "Security/asyncssh", "completion_path": "Security/asyncssh/asyncssh/public_key.py", "signature_position": [569, 569], "body_position": [572, 581], "dependency": {"intra_class": ["asyncssh.public_key.SSHKey.all_sig_algorithms", "asyncssh.public_key.SSHKey.verify_ssh"], "intra_file": [], "cross_file": ["asyncssh.packet.PacketDecodeError", "asyncssh.packet.SSHPacket", "asyncssh.packet.SSHPacket.get_string"]}, "requirement": {"Functionality": "This function verifies an SSH signature of the specified data using the SSHKey instance. It decodes the signature packet, checks if the signature algorithm is supported, and performs the actual verification.", "Arguments": ":param self: SSHKey. An instance of the SSHKey class.\n:param data: bytes. The data to be verified.\n:param sig: bytes. The SSH signature to be verified.\n:return: bool. True if the signature is valid, False otherwise."}, "tests": ["tests/test_agent.py::_TestAgent::test_reconnect", "tests/test_agent.py::_TestAgent::test_lock", "tests/test_agent.py::_TestAgent::test_confirm", "tests/test_agent.py::_TestAgent::test_sign"], "indent": 8}
{"namespace": "fs._url_tools.url_quote", "type": "function", "project_path": "System/fs", "completion_path": "System/fs/fs/_url_tools.py", "signature_position": [13, 14], "body_position": [25, 35], "dependency": {"intra_class": [], "intra_file": ["fs._url_tools._WINDOWS_PLATFORM", "fs._url_tools._has_drive_letter"], "cross_file": []}, "requirement": {"Functionality": "This function quotes a URL, excluding the Windows drive letter if present. On Windows, it separates the drive letter and quotes the Windows path separately. On Unix-like systems, it uses the `~urllib.request.pathname2url` function.", "Arguments": ":param path_snippet: Text. A file path, either relative or absolute.\n:return: Text. The quoted URL."}, "tests": ["tests/test_url_tools.py::TestBase::test_quote"], "indent": 4}
{"namespace": "bentoml._internal.resource.system_resources", "type": "function", "project_path": "Scientific-Engineering/bentoml", "completion_path": "Scientific-Engineering/bentoml/src/bentoml/_internal/resource.py", "signature_position": [43, 43], "body_position": [44, 47], "dependency": {"intra_class": [], "intra_file": ["bentoml._internal.resource._RESOURCE_REGISTRY"], "cross_file": []}, "requirement": {"Functionality": "This function retrieves system resources and returns them as a dictionary. It iterates over the items in the resource registry dictionary, retrieves the corresponding resource for each resource kind, and adds it to the result dictionary.", "Arguments": ":param: No input parameters.\n:return: dict[str, t.Any]. A dictionary containing the system resources, where the keys are the resource kinds and the values are the corresponding resources."}, "tests": ["tests/unit/_internal/test_resource.py::test_system_resources"], "indent": 4}
{"namespace": "zulipterminal.ui_tools.boxes.WriteBox._stream_box_autocomplete", "type": "method", "project_path": "Communications/zulip-term", "completion_path": "Communications/zulip-term/zulipterminal/ui_tools/boxes.py", "signature_position": [462, 464], "body_position": [465, 475], "dependency": {"intra_class": ["zulipterminal.ui_tools.boxes.WriteBox._process_typeaheads", "zulipterminal.ui_tools.boxes.WriteBox.view"], "intra_file": [], "cross_file": ["zulipterminal.helper.match_stream"]}, "requirement": {"Functionality": "This function is a private method that is used for stream box autocomplete. It takes a text and a state as input parameters and returns a string or None. It retrieves a list of stream names from the view's corresponding attributes. Then, it matches the input text with the stream names. Finally, it processes the matched streams and returns the result.", "Arguments": ":param self: WriteBox. An instance of the WriteBox class.\n:param text: String. The input text to match with stream names.\n:param state: Optional integer. The state of the autocomplete. Defaults to None.\n:return: Optional string. The processed typeaheads or None."}, "tests": ["tests/ui_tools/test_boxes.py::TestWriteBox::test__stream_box_autocomplete"], "indent": 8}
{"namespace": "playhouse.sqlite_changelog.ChangeLog.install", "type": "method", "project_path": "Software-Development/peewee", "completion_path": "Software-Development/peewee/playhouse/sqlite_changelog.py", "signature_position": [114, 115], "body_position": [116, 128], "dependency": {"intra_class": ["playhouse.sqlite_changelog.ChangeLog._actions", "playhouse.sqlite_changelog.ChangeLog.db", "playhouse.sqlite_changelog.ChangeLog.drop_trigger_sql", "playhouse.sqlite_changelog.ChangeLog.model", "playhouse.sqlite_changelog.ChangeLog.trigger_sql"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function is used to install a change log for a model. It creates a table for the change log if the \"create_table\" parameter is set to True. It then generates and executes SQL statements to create triggers for insert, update, and delete actions on the model.", "Arguments": ":param self: ChangeLog. An instance of the ChangeLog class.\n:param model: The model for which the change log is being installed.\n:param skip_fields: List of strings. The fields to skip when generating triggers. Defaults to None.\n:param drop: Bool. Whether to drop existing triggers before installing new ones. Defaults to True.\n:param insert: Bool. Whether to create triggers for insert actions. Defaults to True.\n:param update: Bool. Whether to create triggers for update actions. Defaults to True.\n:param delete: Bool. Whether to create triggers for delete actions. Defaults to True.\n:param create_table: Bool. Whether to create a table for the change log. Defaults to True.\n:return: No return values."}, "tests": ["tests/sqlite_changelog.py::TestChangeLog::test_changelog_details", "tests/sqlite_changelog.py::TestChangeLog::test_changelog_jsonfield"], "indent": 8}
{"namespace": "wikipediaapi.Wikipedia.article", "type": "method", "project_path": "Communications/Wikipedia-API", "completion_path": "Communications/Wikipedia-API/wikipediaapi/__init__.py", "signature_position": [237, 239], "body_position": [250, 254], "dependency": {"intra_class": ["wikipediaapi.Wikipedia.page"], "intra_file": ["wikipediaapi.Namespace", "wikipediaapi.Namespace.MAIN", "wikipediaapi.WikiNamespace"], "cross_file": []}, "requirement": {"Functionality": "This function constructs a Wikipedia page with the given title.", "Arguments": ":param self: Wikipedia. An instance of the Wikipedia class.\n:param title: String. The title of the Wikipedia page as used in the URL.\n:param ns: WikiNamespace. The namespace of the Wikipedia page. It defaults to Namespace.MAIN if not specified.\n:param unquote: Bool. Whether to unquote the title. It defaults to False if not specified.\n:return: WikipediaPage. An object representing the Wikipedia page."}, "tests": ["tests/wikipedia_page_test.py::TestWikipediaPage::test_article_title_unquote", "tests/wikipedia_page_test.py::TestWikipediaPage::test_article_method"], "indent": 8}
{"namespace": "rows.fields.EmailField.deserialize", "type": "method", "project_path": "Text-Processing/rows", "completion_path": "Text-Processing/rows/rows/fields.py", "signature_position": [445, 445], "body_position": [446, 454], "dependency": {"intra_class": ["rows.fields.EmailField.EMAIL_REGEXP"], "intra_file": ["rows.fields.TextField", "rows.fields.TextField.deserialize", "rows.fields.value_error"], "cross_file": []}, "requirement": {"Functionality": "Deserialize the input value and validate it as an email field. It first calls the superclass's deserialize method to perform the initial deserialization. Then, it checks if the deserialized value is None or empty. If it is, it returns None. Otherwise, it uses a regular expression to validate the email format. If the email is valid, it returns the first match. If not, it raises a value error.", "Arguments": ":param cls: Class. The class object itself.\n:param value: Any. The value to be deserialized and validated as an email field.\n:param *args: Any. Additional positional arguments.\n:param **kwargs: Any. Additional keyword arguments.\n:return: Object. The deserialized and validated email value, or None if the input value is None or empty."}, "tests": ["tests/tests_fields.py::FieldsTestCase::test_EmailField"], "indent": 8}
{"namespace": "mopidy.config.schemas.ConfigSchema.deserialize", "type": "method", "project_path": "Multimedia/Mopidy", "completion_path": "Multimedia/Mopidy/mopidy/config/schemas.py", "signature_position": [54, 54], "body_position": [59, 82], "dependency": {"intra_class": ["mopidy.config.schemas.ConfigSchema.deserialize"], "intra_file": ["mopidy.config.schemas._did_you_mean"], "cross_file": ["mopidy.config.types.Deprecated", "mopidy.config.types"]}, "requirement": {"Functionality": "This function validates the given `values` using the config schema. It iterates through each key-value pair in the `values` dictionary and tries to deserialize the value using the corresponding schema in the config. If the key is not found in the schema, it adds an error message to the `errors` dictionary. If the deserialization fails, it adds the error message to the `errors` dictionary and sets the value to None in the `result` dictionary. After iterating through all the keys in the schema, it checks for any deprecated keys and removes them from the `result` dictionary. Finally, it returns a tuple containing the cleaned values in the `result` dictionary and the errors in the `errors` dictionary.", "Arguments": ":param self: ConfigSchema. An instance of the ConfigSchema class.\n:param values: dict. A dictionary containing the values to be validated against the config schema.\n:return: tuple. A tuple containing the cleaned values in the `result` dictionary and the errors in the `errors` dictionary."}, "tests": ["tests/config/test_schemas.py::ConfigSchemaTest::test_deserialize_deserialization_unknown_and_missing_errors", "tests/config/test_config.py::ValidateTest::test_config_single_schema_config_error", "tests/config/test_schemas.py::ConfigSchemaTest::test_deserialize_with_missing_value", "tests/config/test_schemas.py::ConfigSchemaTest::test_deserialize_deprecated_value", "tests/config/test_schemas.py::ConfigSchemaTest::test_deserialize_with_deserialization_error"], "indent": 8}
{"namespace": "pyramid.request.RequestLocalCache.get_or_create", "type": "method", "project_path": "Internet/pyramid", "completion_path": "Internet/pyramid/src/pyramid/request.py", "signature_position": [403, 403], "body_position": [414, 425], "dependency": {"intra_class": ["pyramid.request.RequestLocalCache.NO_VALUE", "pyramid.request.RequestLocalCache._creator", "pyramid.request.RequestLocalCache._store", "pyramid.request.RequestLocalCache.set"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function retrieves a value from the cache based on the given request. If the value is not found in the cache, it executes the creator function to compute the value, caches the result, and returns it.", "Arguments": ":param self: RequestLocalCache. An instance of the RequestLocalCache class.\n:param request: The request object used as the key to retrieve the value from the cache.\n:param creator: Function. The function used to compute the value if it is not found in the cache. If not provided, it defaults to the creator function bound to the cache.\n:return: The value retrieved from the cache or computed by the creator function."}, "tests": ["tests/test_request.py::TestRequestLocalCache::test_get_or_create_overrides_creator", "tests/test_request.py::TestRequestLocalCache::test_creator_in_constructor", "tests/test_request.py::TestRequestLocalCache::test_get_or_create_with_no_creator", "tests/test_request.py::TestRequestLocalCache::test_decorator_overrides_creator"], "indent": 8}
{"namespace": "boltons.iterutils.remap", "type": "function", "project_path": "Utilities/boltons", "completion_path": "Utilities/boltons/boltons/iterutils.py", "signature_position": [1035, 1036], "body_position": [1135, 1199], "dependency": {"intra_class": [], "intra_file": ["boltons.iterutils._REMAP_EXIT", "boltons.iterutils._orig_default_visit", "boltons.iterutils.default_enter", "boltons.iterutils.default_exit", "boltons.iterutils.default_visit"], "cross_file": []}, "requirement": {"Functionality": "This function recursively transform nested structures and returns the transformed object.\n", "Arguments": ":param root: The target object to traverse. By default, support iterables like list, tuple, dict, and set. Any object traversable by \"enter\" will work.\n:param visit: callable. This function is called on every item in \"root\". It accepts three positional arguments: path, key, and value, where \"path\" is a tuple of parents' keys, key is the key or index in parent, and value is the element itself. \"visit\" returns the new key-value pair. It may also return \"True\" as shorthand to keep the old item unmodified, or \"False\" to drop the item from the new structure. \"visit\" is called after \"enter\", on the new parent. It is called for every item in root, including duplicate items. For traversable values, it is called on the new parent object, after all its children have been visited. Defaults to default_visit.\n:param enter: callable. This function controls which items in \"root\" are traversed. It accepts the same arguments as \"visit\". It returns a pair of the blank new parent and an iterator over the items which should be visited. If \"False\" is returned instead of an iterator, the value will not be traversed. It is only called once per unique value. Defaults to default_enter.\n:param exit: callable. This function determines how to handle items once they have been visited. It gets the same three arguments as the other functions: path, key, value, plus two more: the blank new parent object returned from \"enter\" and a list of the new items, as remapped by \"visit\". It returns the new parent object. It is only called once per unique value. Defaults to default_exit.\n:param reraise_visit: bool. A pragmatic convenience for the \"visit\" callable. When set to \"False\", ignore any errors raised by the \"visit\" callback. Items causing exceptions are kept. Defaults to True.\n"}, "tests": ["tests/test_iterutils.py::TestRemap::test_drop_nones", "tests/test_iterutils.py::TestRemap::test_dict_to_omd", "tests/test_iterutils.py::TestRemap::test_sort_all_lists", "tests/test_iterutils.py::TestRemap::test_duperef", "tests/test_iterutils.py::TestRemap::test_prepop"], "indent": 4}
{"namespace": "boto.dynamodb2.table.BatchTable.flush", "type": "method", "project_path": "Internet/boto", "completion_path": "Internet/boto/boto/dynamodb2/table.py", "signature_position": [1663, 1663], "body_position": [1664, 1690], "dependency": {"intra_class": ["boto.dynamodb2.table.BatchTable._to_delete", "boto.dynamodb2.table.BatchTable._to_put", "boto.dynamodb2.table.BatchTable.handle_unprocessed", "boto.dynamodb2.table.BatchTable.table"], "intra_file": ["boto.dynamodb2.table.Table._encode_keys", "boto.dynamodb2.table.Table.connection"], "cross_file": ["boto.dynamodb2.items.Item", "boto.dynamodb2.items.Item.prepare_full", "boto.dynamodb2.layer1.DynamoDBConnection.batch_write_item"]}, "requirement": {"Functionality": "This function flushes the batch data by preparing the data to be inserted or deleted. It also handles any unprocessed items.", "Arguments": ":param self: BatchTable. An instance of the BatchTable class.\n:return: bool. Returns True after flushing the batch data."}, "tests": ["tests/unit/dynamodb2/test_table.py::TableTestCase::test_batch_write_unprocessed_items"], "indent": 8}
{"namespace": "pycoin.contrib.bech32m.decode", "type": "function", "project_path": "Security/pycoin", "completion_path": "Security/pycoin/pycoin/contrib/bech32m.py", "signature_position": [115, 115], "body_position": [117, 129], "dependency": {"intra_class": [], "intra_file": ["pycoin.contrib.bech32m.Encoding", "pycoin.contrib.bech32m.bech32_decode", "pycoin.contrib.bech32m.convertbits"], "cross_file": ["pycoin.contrib.bech32m.Encoding.BECH32", "pycoin.contrib.bech32m.Encoding.BECH32M"]}, "requirement": {"Functionality": "This function decodes a segwit address. It takes a human-readable part (hrp) and an address as input. It decodes the address and performs various checks on the decoded data. If any of the checks fail, it returns (None, None). Otherwise, it returns the version byte and the decoded data.", "Arguments": ":param hrp: String. The human-readable part of the address.\n:param addr: String. The address to decode.\n:return: Tuple. The version byte and the decoded data."}, "tests": ["tests/bech32_test.py::Bech32Test::test_bip350_vectors"], "indent": 4}
{"namespace": "pyramid.csrf.SessionCSRFStoragePolicy.get_csrf_token", "type": "method", "project_path": "Internet/pyramid", "completion_path": "Internet/pyramid/src/pyramid/csrf.py", "signature_position": [78, 78], "body_position": [81, 84], "dependency": {"intra_class": ["pyramid.csrf.SessionCSRFStoragePolicy.key", "pyramid.csrf.SessionCSRFStoragePolicy.new_csrf_token"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function retrieves the currently active CSRF token from the session. If the token is not found in the session, a new one is generated and returned.", "Arguments": ":param self: SessionCSRFStoragePolicy. An instance of the SessionCSRFStoragePolicy class.\n:param request: The request object.\n:return: The CSRF token from the session."}, "tests": ["tests/test_csrf.py::TestSessionCSRFStoragePolicy::test_it_creates_a_new_token", "tests/test_csrf.py::TestSessionCSRFStoragePolicy::test_get_csrf_token_returns_the_new_token"], "indent": 8}
{"namespace": "principalmapper.querying.local_policy_simulation._statement_matches_resource", "type": "function", "project_path": "Security/principalmapper", "completion_path": "Security/principalmapper/principalmapper/querying/local_policy_simulation.py", "signature_position": [873, 873], "body_position": [875, 888], "dependency": {"intra_class": [], "intra_file": ["principalmapper.querying.local_policy_simulation._listify_string", "principalmapper.querying.local_policy_simulation._matches_after_expansion"], "cross_file": ["principalmapper.util.case_insensitive_dict.CaseInsensitiveDict"]}, "requirement": {"Functionality": "This function is a helper function that checks if a given resource is present in a policy statement. It checks if the resource matches any of the resources listed in the 'Resource' field of the statement. If it does, it returns True. If 'Resource' not in statement and the 'NotResource' field is present, it checks if the resource matches any of the resources listed in that field. If it does, it returns False. If neither 'Resource' nor 'NotResource' fields are present, it returns True.", "Arguments": ":param statement: dict. The policy statement to check.\n:param resource: str. The resource to check for.\n:param condition_keys: Optional[CaseInsensitiveDict]. A dictionary of condition keys. Defaults to None.\n:return: bool. True if the resource is in the policy statement, False otherwise."}, "tests": ["tests/test_local_policy_sim.py::TestLocalPolicyStatementMatching::test_resource_matching"], "indent": 4}
{"namespace": "msticpy.analysis.anomalous_sequence.utils.cmds_params_only.compute_likelihood_window", "type": "function", "project_path": "Security/msticpy", "completion_path": "Security/msticpy/msticpy/analysis/anomalous_sequence/utils/cmds_params_only.py", "signature_position": [224, 233], "body_position": [268, 315], "dependency": {"intra_class": [], "intra_file": ["msticpy.analysis.anomalous_sequence.utils.cmds_params_only.compute_prob_setofparams_given_cmd"], "cross_file": ["msticpy.analysis.anomalous_sequence.utils.data_structures.Cmd", "msticpy.analysis.anomalous_sequence.utils.data_structures.StateMatrix", "msticpy.common.exceptions.MsticpyException"]}, "requirement": {"Functionality": "This function computes the likelihood of a given window of commands. It calculates the probability of the window based on prior probabilities, transition probabilities, and parameter conditional command probabilities.", "Arguments": ":param window: List[Cmd]. A list of commands representing a session.\n:param prior_probs: Union[StateMatrix, dict]. Computed probabilities of individual commands.\n:param trans_probs: Union[StateMatrix, dict]. Computed probabilities of sequences of commands.\n:param param_cond_cmd_probs: Union[StateMatrix, dict]. Computed probabilities of the parameters conditional on the commands.\n:param use_start_token: Bool. Whether to prepend the start_token to the window before calculating the likelihood.\n:param use_end_token: Bool. Whether to append the end_token to the window before calculating the likelihood.\n:param start_token: Str. A dummy command to signify the start of the session. Defaults to None.\n:param end_token: Str. A dummy command to signify the end of the session. Defaults to None.\n:return: Float. The likelihood of the window."}, "tests": ["tests/analysis/test_anom_seq_cmds_params_only.py::TestCmdsParamsOnly::test_compute_likelihood_window"], "indent": 4}
{"namespace": "boltons.ioutils.SpooledStringIO.seek", "type": "method", "project_path": "Utilities/boltons", "completion_path": "Utilities/boltons/boltons/ioutils.py", "signature_position": [450, 450], "body_position": [452, 472], "dependency": {"intra_class": ["boltons.ioutils.SpooledStringIO._tell", "boltons.ioutils.SpooledStringIO._traverse_codepoints", "boltons.ioutils.SpooledStringIO.buffer", "boltons.ioutils.SpooledStringIO.len", "boltons.ioutils.SpooledStringIO.tell"], "intra_file": ["boltons.ioutils.SpooledIOBase._checkClosed"], "cross_file": []}, "requirement": {"Functionality": "This function is used to traverse to a specified codepoint in the SpooledStringIO instance. It updates the current position based on the given offset and mode. If the mode is not valid, it raise a ValueError: 'Invalid whence ({mode}, should be 0, 1, or 2)'. It returns the updated current position.", "Arguments": ":param self: SpooledStringIO. An instance of the SpooledStringIO class.\n:param pos: int. The offset or position to traverse to.\n:param mode: int. The mode of seeking. It can be os.SEEK_SET (0) to seek from the start of the file, os.SEEK_CUR (1) to seek relative to the current position, or os.SEEK_END (2) to seek from the end of the file. Defaults to 0.\n:return: int. The updated current position after seeking."}, "tests": ["tests/test_ioutils.py::TestSpooledStringIO::test_seek_codepoints_large_SEEK_END", "tests/test_ioutils.py::TestSpooledStringIO::test_seek_codepoints_SEEK_CUR", "tests/test_ioutils.py::TestSpooledStringIO::test_seek_codepoints_large_SEEK_CUR", "tests/test_ioutils.py::TestSpooledStringIO::test_seek_codepoints_SEEK_END", "tests/test_ioutils.py::TestSpooledStringIO::test_iter"], "indent": 8}
{"namespace": "mopidy.config.format_initial", "type": "function", "project_path": "Multimedia/Mopidy", "completion_path": "Multimedia/Mopidy/mopidy/config/__init__.py", "signature_position": [125, 125], "body_position": [126, 148], "dependency": {"intra_class": [], "intra_file": ["mopidy.config._INITIAL_HELP", "mopidy.config._format", "mopidy.config._load", "mopidy.config._schemas", "mopidy.config._validate", "mopidy.config.read"], "cross_file": ["mopidy.internal.versioning", "mopidy.internal.versioning.get_version", "mopidy.ext.ExtensionData.extension", "mopidy.ext.ExtensionData.extension.version", "mopidy.ext.ExtensionData.extension.dist_name"]}, "requirement": {"Functionality": "This function formats the initial configuration for a set of extensions. It reads the default configuration file, gets the default configuration for each extension, and loads the raw configuration. It then validates the configuration against the schemas. After that, it creates a header with version information for each extension and formats the configuration. Finally, it returns the formatted initial configuration.", "Arguments": ":param extensions_data: The data of the extensions. It is a list of extension data objects.\n:return: String. The formatted initial configuration."}, "tests": ["tests/config/test_config.py::test_format_initial"], "indent": 4}
{"namespace": "sslyze.plugins.certificate_info._symantec.SymantecDistructTester.get_distrust_timeline", "type": "method", "project_path": "System/sslyze", "completion_path": "System/sslyze/sslyze/plugins/certificate_info/_symantec.py", "signature_position": [102, 104], "body_position": [105, 124], "dependency": {"intra_class": ["sslyze.plugins.certificate_info._symantec.SymantecDistructTester._CA_KEYS_BLACKLIST", "sslyze.plugins.certificate_info._symantec.SymantecDistructTester._CA_KEYS_WHITELIST"], "intra_file": ["sslyze.plugins.certificate_info._symantec.SymantecDistrustTimelineEnum", "sslyze.plugins.certificate_info._symantec.SymantecDistrustTimelineEnum.MARCH_2018", "sslyze.plugins.certificate_info._symantec.SymantecDistrustTimelineEnum.SEPTEMBER_2018"], "cross_file": ["sslyze.plugins.certificate_info._certificate_utils.get_public_key_sha256"]}, "requirement": {"Functionality": "This function checks the given list of verified certificates for the presence of Symantec root certificates. It determines the distrust timeline based on the presence of blacklisted and whitelisted certificates in the chain.", "Arguments": ":param cls: The class object of SymantecDistructTester.\n:param verified_certificate_chain: List of Certificate. A list of verified certificates.\n:return: Optional[SymantecDistrustTimelineEnum]. The distrust timeline enum value, which can be either \"MARCH_2018\" or \"SEPTEMBER_2018\", or None if no distrust is detected."}, "tests": ["tests/plugins_tests/certificate_info/test_symantec.py::TestSymantecDistrust::test_march_2018", "tests/plugins_tests/certificate_info/test_symantec.py::TestSymantecDistrust::test_september_2018"], "indent": 8}
{"namespace": "playhouse.db_url.connect", "type": "function", "project_path": "Software-Development/peewee", "completion_path": "Software-Development/peewee/playhouse/db_url.py", "signature_position": [91, 91], "body_position": [92, 105], "dependency": {"intra_class": [], "intra_file": ["playhouse.db_url.parseresult_to_dict", "playhouse.db_url.schemes"], "cross_file": []}, "requirement": {"Functionality": "Connect to a database using the given URL and connection parameters. It parses the URL, converts it to a dictionary of connection parameters, updates it with additional parameters, and then creates an instance of the appropriate database class using the connection parameters.", "Arguments": ":param url: String. The URL of the database to connect to.\n:param unquote_password: Bool. Whether to unquote the password in the URL. Defaults to False.\n:param **connect_params: Additional connection parameters as keyword arguments.\n:return: The instance of the database class created using the connection parameters."}, "tests": ["tests/db_url.py::TestDBUrl::test_db_url"], "indent": 4}
{"namespace": "alembic.operations.ops.DropColumnOp.reverse", "type": "method", "project_path": "Database/alembic", "completion_path": "Database/alembic/alembic/operations/ops.py", "signature_position": [2190, 2190], "body_position": [2191, 2199], "dependency": {"intra_class": ["alembic.operations.ops.DropColumnOp._reverse"], "intra_file": ["alembic.operations.ops.AddColumnOp", "alembic.operations.ops.AddColumnOp.from_column_and_tablename", "alembic.operations.ops.AlterTableOp.schema", "alembic.operations.ops.AlterTableOp.table_name"], "cross_file": ["alembic.operations.ops.AddColumnOp.column"]}, "requirement": {"Functionality": "This function reverses the operation performed by the DropColumnOp. It checks if the reverse operation is available and raises a ValueError if it is not.", "Arguments": ":param self: DropColumnOp. An instance of the DropColumnOp class.\n:return: AddColumnOp."}, "tests": ["tests/test_autogen_diffs.py::OrigObjectTest::test_drop_column"], "indent": 8}
{"namespace": "boltons.iterutils.research", "type": "function", "project_path": "Utilities/boltons", "completion_path": "Utilities/boltons/boltons/iterutils.py", "signature_position": [1281, 1281], "body_position": [1323, 1338], "dependency": {"intra_class": [], "intra_file": ["boltons.iterutils.remap"], "cross_file": []}, "requirement": {"Functionality": "The function recursively searches for values in any data nested in `root` that match a given criterion specified by the `query` callable. The results are returned as a list of `(path, value)` pairs.\n", "Arguments": ":param root: The target object to search. Supports the same types of objects as `remap`, including list, tuple, dict, and set.\n:param query: Callable. The function called on every object to determine whether to include it in the search results. The callable must accept three arguments: `path`, `key`, and `value`, commonly abbreviated as `p`, `k`, and `v`. Defaults to `lambda p, k, v: True`.\n:param reraise: bool. Whether to reraise exceptions raised by the `query` callable or to simply drop the result that caused the error. Defaults to False.\n:return: List of `(path, value)` pairs. The pairs represent the paths to matching values and the values themselves in the nested data structure.\n"}, "tests": ["tests/test_iterutils.py::test_research"], "indent": 4}
{"namespace": "playhouse.dataset.DataSet.freeze", "type": "method", "project_path": "Software-Development/peewee", "completion_path": "Software-Development/peewee/playhouse/dataset.py", "signature_position": [162, 163], "body_position": [164, 172], "dependency": {"intra_class": ["playhouse.dataset.DataSet._check_arguments", "playhouse.dataset.DataSet._export_formats"], "intra_file": ["playhouse.dataset.TSVExporter.export", "playhouse.dataset.open_file"], "cross_file": []}, "requirement": {"Functionality": "Freeze the dataset by exporting it to a file in the specified format. It checks the arguments, opens the file if a filename is provided, creates an exporter instance based on the format, and exports the dataset to the file. Finally, it closes the file if it was opened.", "Arguments": ":param self: DataSet. An instance of the DataSet class.\n:param query: The query to export.\n:param format: String. The format in which to export the dataset. Defaults to 'csv'.\n:param filename: String. The name of the file to export to. If provided, the file will be opened and closed automatically.\n:param file_obj: File object. The file object to export to. If provided, the file will not be opened or closed automatically.\n:param encoding: String. The encoding to use when opening the file. Defaults to 'utf8'.\n:param kwargs: Additional keyword arguments to pass to the exporter's export method.\n:return: No return values."}, "tests": ["tests/dataset.py::TestDataSet::test_export", "tests/dataset.py::TestDataSet::test_freeze_thaw"], "indent": 8}
{"namespace": "sacred.arg_parser._convert_value", "type": "function", "project_path": "Utilities/sacred", "completion_path": "Utilities/sacred/sacred/arg_parser.py", "signature_position": [206, 206], "body_position": [208, 216], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["sacred.serializer.restore", "sacred.settings.SETTINGS"]}, "requirement": {"Functionality": "This function takes a string as input and tries to parse it as a Python literal. If successful, it returns the parsed value. If parsing fails, if the exception is a ValueError or Syntaxerror and strict parsing setting is not enabled, it returns the input string as is. Otherwise, the exception is raised.", "Arguments": ":param value: The input string to be parsed.\n:return: The parsed value if successful, or the input string if parsing fails."}, "tests": ["tests/test_arg_parser.py::test_convert_value"], "indent": 4}
{"namespace": "chatette.parsing.ChoiceBuilder.create_concrete", "type": "method", "project_path": "Communications/chatette", "completion_path": "Communications/chatette/chatette/parsing/__init__.py", "signature_position": [80, 80], "body_position": [81, 86], "dependency": {"intra_class": ["chatette.parsing.ChoiceBuilder.leading_space", "chatette.parsing.ChoiceBuilder.rules"], "intra_file": ["chatette.parsing.ItemBuilder._build_modifiers_repr", "chatette.parsing.ItemBuilder._check_information"], "cross_file": ["chatette.units.modifiable.choice.Choice"]}, "requirement": {"Functionality": "The function creates a concrete Choice instance based on the current state of the ChoiceBuilder object. It first checks if all the necessary information is provided, and then constructs a Choice object using the leading space, modifiers representation, and rules of the ChoiceBuilder object.", "Arguments": ":param self: ChoiceBuilder. An instance of the ChoiceBuilder class.\n:return: Choice. The created Choice instance."}, "tests": ["tests/unit-testing/parsing/test_init.py::TestChoiceBuilder::test_create_concrete"], "indent": 8}
{"namespace": "pyramid.config.Configurator.make_wsgi_app", "type": "method", "project_path": "Internet/pyramid", "completion_path": "Internet/pyramid/src/pyramid/config/__init__.py", "signature_position": [881, 881], "body_position": [888, 906], "dependency": {"intra_class": ["pyramid.config.Configurator.begin", "pyramid.config.Configurator.end", "pyramid.config.Configurator.registry"], "intra_file": ["pyramid.config.global_registries"], "cross_file": ["pyramid.events.ApplicationCreated", "pyramid.registry.Registry.notify", "pyramid.router.Router", "pyramid.config.actions.ActionConfiguratorMixin.commit", "pyramid.util.WeakOrderedSet.add"]}, "requirement": {"Functionality": "This function is a method of the Configurator class. It commits any pending configuration statements, sends an ApplicationCreated event to all listeners, adds this configuration's registry to global, and returns a Pyramid WSGI application representing the committed configuration state.", "Arguments": ":param self: Configurator. An instance of the Configurator class.\n:return: Router. The WSGI application representing the committed configuration state."}, "tests": ["tests/test_integration.py::TestConflictApp::test_overridden_authorization_policy", "tests/test_config/test_init.py::ConfiguratorTests::test_make_wsgi_app", "tests/test_integration.py::TestConflictApp::test_autoresolved_view", "tests/test_integration.py::TestConflictApp::test_overridden_route_view", "tests/test_config/test_init.py::TestGlobalRegistriesIntegration::test_global_registries"], "indent": 8}
{"namespace": "mrjob.conf.combine_cmds", "type": "function", "project_path": "System/mrjob", "completion_path": "System/mrjob/mrjob/conf.py", "signature_position": [416, 416], "body_position": [425, 432], "dependency": {"intra_class": [], "intra_file": ["mrjob.conf.combine_values"], "cross_file": ["mrjob.py2.string_types", "mrjob.util.shlex_split"]}, "requirement": {"Functionality": "This function takes zero or more commands to run on the command line and returns the last one that is not None. Each command can be a list containing the command plus switches or a string, which will be parsed with shlex.split. The string must be a byte string or a Unicode string containing no non-ASCII characters.\nGet the last command. If the command is None, returns None. If the command is a string, it is splited using shell-like syntax. Otherwise, the command is converted to a list and returned.\n", "Arguments": ":param cmds: Variable number of arguments. Each argument can be a list or string representing a command.\n:return: List or None. Either a list containing the last non-None command or None.\n"}, "tests": ["tests/test_conf.py::CombineCmdsTestCase::test_unicode", "tests/test_conf.py::CombineCmdsTestCase::test_convert_to_list", "tests/test_conf.py::CombineCmdsTestCase::test_parse_string", "tests/test_conf.py::CombineCmdsTestCase::test_picks_last_value", "tests/test_conf.py::CombineCmdsTestCase::test_parse_empty_string"], "indent": 4}
{"namespace": "googleapiclient._helpers._add_query_parameter", "type": "function", "project_path": "Internet/google-api-python-client", "completion_path": "Internet/google-api-python-client/googleapiclient/_helpers.py", "signature_position": [191, 191], "body_position": [204, 207], "dependency": {"intra_class": [], "intra_file": ["googleapiclient._helpers.update_query_params"], "cross_file": []}, "requirement": {"Functionality": "This function adds a query parameter to a URL. If the query parameter already exists in the URL, it replaces the current value with the new value. If the value is None, the URL remains unchanged.", "Arguments": ":param url: string. The URL to add the query parameter to.\n:param name: string. The name of the query parameter.\n:param value: string. The value of the query parameter.\n:return: string. The updated URL with the added query parameter. If the value is None, the original URL is returned."}, "tests": ["tests/test__helpers.py::AddQueryParameterTests::test__add_query_parameter"], "indent": 4}
{"namespace": "mrjob.job.MRJob.parse_output", "type": "method", "project_path": "System/mrjob", "completion_path": "System/mrjob/mrjob/job.py", "signature_position": [1299, 1299], "body_position": [1303, 1306], "dependency": {"intra_class": ["mrjob.job.MRJob.output_protocol"], "intra_file": [], "cross_file": ["mrjob.protocol.BytesValueProtocol.read", "mrjob.util.to_lines"]}, "requirement": {"Functionality": "This function takes a stream of byte chunks as input and parses it into a stream of (key, value) pairs. It uses the output protocol to read each line of the input and yields the result.", "Arguments": ":param self: MRJob. An instance of the MRJob class.\n:param chunks: List of byte chunks. The input stream of byte chunks to be parsed.\n:return: Generator. A generator that yields (key, value) pairs from the parsed output."}, "tests": ["tests/test_local.py::SortBinTestCase::test_empty_sort_bin_means_default", "tests/test_sim.py::NoMRJobConfTestCase::test_no_mrjob_confs", "tests/test_inline.py::InlineRunnerStepsTestCase::test_adding_2", "tests/test_sim.py::SimRunnerJobConfTestCase::test_jobconf_simulated_by_runner", "tests/test_sim.py::FileURIsAsInputTestCase::test_file_uris_as_input"], "indent": 8}
{"namespace": "ydata_profiling.report.presentation.flavours.html.frequency_table.HTMLFrequencyTable.render", "type": "method", "project_path": "Software-Development/pandas-profiling", "completion_path": "Software-Development/pandas-profiling/src/ydata_profiling/report/presentation/flavours/html/frequency_table.py", "signature_position": [6, 6], "body_position": [7, 21], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["ydata_profiling.report.presentation.flavours.html.templates", "ydata_profiling.report.presentation.flavours.html.templates.template"]}, "requirement": {"Functionality": "This function renders an HTML frequency table based on the content provided. It checks if the content is a list of rows or a single row, and then uses a template to generate the HTML code for the frequency table.", "Arguments": ":param self: HTMLFrequencyTable. An instance of the HTMLFrequencyTable class.\n:return: str. The rendered HTML code for the frequency table."}, "tests": ["tests/unit/test_renderable.py::test_html_frequency_table"], "indent": 8}
{"namespace": "trailscraper.iam.known_iam_actions", "type": "function", "project_path": "Security/trailscraper", "completion_path": "Security/trailscraper/trailscraper/iam.py", "signature_position": [179, 179], "body_position": [182, 186], "dependency": {"intra_class": [], "intra_file": ["trailscraper.iam._parse_action", "trailscraper.iam.all_known_iam_permissions"], "cross_file": []}, "requirement": {"Functionality": "This function returns a list of known IAM actions for a given prefix. It retrieves all known IAM permissions, parses the actions, and groups them by prefix. It then returns the list of actions corresponding to the given prefix.", "Arguments": ":param prefix: String. The prefix for which known IAM actions are to be retrieved.\n:return: List of String. The list of known IAM actions for the given prefix."}, "tests": ["tests/iam/known_iam_actions_test.py::test_known_iam_action_for_prefix", "tests/iam/known_iam_actions_test.py::test_known_iam_action_for_prefix_does_not_fail_if_action_not_found"], "indent": 4}
{"namespace": "asyncssh.asn1.der_decode", "type": "function", "project_path": "Security/asyncssh", "completion_path": "Security/asyncssh/asyncssh/asn1.py", "signature_position": [752, 752], "body_position": [781, 786], "dependency": {"intra_class": [], "intra_file": ["asyncssh.asn1.ASN1DecodeError", "asyncssh.asn1.der_decode_partial"], "cross_file": []}, "requirement": {"Functionality": "This function decodes a byte string in DER format and converts it into a corresponding set of Python objects.\nIt first decodes a value in DER format partially to get the consumed value and the end which is the byte length of the content that has been decoded, plus the offset at which the content begins. If the end index is less than the total length of the value in DER format, the function raise error in format \"Data contains unexpected bytes at end\". Otherwise, the decoded value is returned.", "Arguments": ":param data: bytes. The byte string in DER format to be decoded.\n:return: object. The decoded value from the DER format."}, "tests": ["tests/test_asn1.py::_TestASN1::test_asn1"], "indent": 4}
{"namespace": "pycoin.contrib.bech32m.bech32_encode", "type": "function", "project_path": "Security/pycoin", "completion_path": "Security/pycoin/pycoin/contrib/bech32m.py", "signature_position": [69, 69], "body_position": [71, 72], "dependency": {"intra_class": [], "intra_file": ["pycoin.contrib.bech32m.bech32_create_checksum"], "cross_file": []}, "requirement": {"Functionality": "This function takes an HRP (Human Readable Part), data, and a specification as input and computes a Bech32 string. It combines the data with a checksum generated and returns the Bech32 string.", "Arguments": ":param hrp: String. The Human Readable Part of the Bech32 string.\n:param data: List of integers. The data values to be encoded.\n:param spec: String. The specification to be used for encoding.\n:return: String. The computed Bech32 string."}, "tests": ["tests/bech32_test.py::Bech32Test::test_bip350_vectors"], "indent": 4}
{"namespace": "pythonforandroid.bootstrap.expand_dependencies", "type": "function", "project_path": "Utilities/python-for-android", "completion_path": "Utilities/python-for-android/pythonforandroid/bootstrap.py", "signature_position": [403, 403], "body_position": [412, 439], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["pythonforandroid.recipe.Recipe", "pythonforandroid.recipe.Recipe.get_recipe"]}, "requirement": {"Functionality": "This function expands the lists of all different available alternative recipe combinations. It adds the dependencies for the recipes that do not have alternatives. It split up lists by available alternatives. This function is used for basic bootstrap compatibility checks.", "Arguments": ":param recipes: List. The list of recipes to expand.\n:param ctx: Context. The context object.\n:return: List of lists. The expanded recipe combinations with added dependencies."}, "tests": ["tests/test_bootstrap.py::TestBootstrapBasic::test_expand_dependencies", "tests/test_bootstrap.py::TestBootstrapBasic::test_expand_dependencies_with_pure_python_package"], "indent": 4}
{"namespace": "sslyze.cli.server_string_parser.CommandLineServerStringParser.parse_server_string", "type": "method", "project_path": "System/sslyze", "completion_path": "System/sslyze/sslyze/cli/server_string_parser.py", "signature_position": [22, 23], "body_position": [24, 45], "dependency": {"intra_class": ["sslyze.cli.server_string_parser.CommandLineServerStringParser._parse_ipv4_server_string", "sslyze.cli.server_string_parser.CommandLineServerStringParser._parse_ipv6_server_string"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function parses a server string and extracts the host, ip, and port information from it. It first checks if the server string contains curly braces, indicating the presence of an ip address. If so, it extracts the ip address and removes it from the server string. Then, it checks if the server string contains square brackets, indicating the presence of an ipv6 hint. If so, it calls a helper function to parse the ipv6 server string. If not, it checks if the extracted ip address contains square brackets, indicating the presence of an ipv6 hint. If so, it calls the helper function to parse the ipv6 ip address. Finally, if none of the above conditions are met, it calls the helper function to parse the ipv4 server string. The function returns the host, ip, and port extracted from the server string.", "Arguments": ":param cls: The class object.\n:param server_str: String. The server string to be parsed.\n:return: Tuple. The host, ip, and port extracted from the server string."}, "tests": ["tests/cli_tests/test_server_string_parser.py::TestCommandLineServerStringParser::test_ipv6_as_hint", "tests/cli_tests/test_server_string_parser.py::TestCommandLineServerStringParser::test_with_port", "tests/cli_tests/test_server_string_parser.py::TestCommandLineServerStringParser::test_ipv6_with_port", "tests/cli_tests/test_server_string_parser.py::TestCommandLineServerStringParser::test_ipv4_as_hint_with_port", "tests/cli_tests/test_server_string_parser.py::TestCommandLineServerStringParser::test_ipv4_as_hint"], "indent": 8}
{"namespace": "kinto.plugins.accounts.utils.get_cached_validation_key", "type": "function", "project_path": "Internet/kinto", "completion_path": "Internet/kinto/kinto/plugins/accounts/utils.py", "signature_position": [93, 93], "body_position": [95, 99], "dependency": {"intra_class": [], "intra_file": ["kinto.plugins.accounts.utils.ACCOUNT_VALIDATION_CACHE_KEY"], "cross_file": ["kinto.core.utils.hmac_digest", "kinto.core.cache", "kinto.core.utils"]}, "requirement": {"Functionality": "This function retrieves the validation key for a given username from the cache. It first generates a cache key using the username and a secret key. Then, it retrieves the validation key from the cache using the cache key.", "Arguments": ":param username: String. The username for which the validation key is to be retrieved.\n:param registry: Dictionary. The registry containing the settings and cache.\n:return: The validation key for the given username."}, "tests": ["tests/plugins/test_accounts.py::AccountValidationCreationTest::test_validation_fail_bad_activation_key", "tests/plugins/test_accounts.py::AccountValidationCreationTest::test_validation_validates_user", "tests/plugins/test_accounts.py::AccountValidationCreationTest::test_create_account_stores_activated_field"], "indent": 4}
{"namespace": "sacred.config.signature.Signature.construct_arguments", "type": "method", "project_path": "Utilities/sacred", "completion_path": "Utilities/sacred/sacred/config/signature.py", "signature_position": [70, 70], "body_position": [83, 91], "dependency": {"intra_class": ["sacred.config.signature.Signature._assert_no_duplicate_args", "sacred.config.signature.Signature._assert_no_missing_args", "sacred.config.signature.Signature._assert_no_unexpected_args", "sacred.config.signature.Signature._assert_no_unexpected_kwargs", "sacred.config.signature.Signature._fill_in_options", "sacred.config.signature.Signature._get_expected_args"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function constructs the arguments list and keyword arguments dictionary for a Signature instance. It ensures that the original explicit call arguments are preserved, missing arguments are filled in by name using options (if possible), default arguments are overridden by options, and it ensures that there are no unexpected arguments, conflicting values for a parameter in both args and kwargs, or unfilled parameters at the end of the process.", "Arguments": ":param self: Signature. An instance of the Signature class.\n:param args: list. The original explicit call arguments.\n:param kwargs: dict. The original explicit call keyword arguments.\n:param options: dict. The options to fill in missing arguments and override default arguments.\n:param bound: bool. Whether the Signature instance is bound to an object.\n:return: Tuple[list, dict]. The constructed args list and kwargs dictionary."}, "tests": ["tests/test_config/test_signature.py::test_construct_arguments_with_duplicate_args_raises_typeerror", "tests/test_config/test_signature.py::test_construct_arguments_with_unexpected_args_raises_typeerror", "tests/test_config/test_signature.py::test_construct_arguments_for_bound_method", "tests/test_config/test_signature.py::test_construct_arguments_does_not_overwrite_args_and_kwargs", "tests/test_config/test_signature.py::test_construct_arguments_overwrites_defaults"], "indent": 8}
{"namespace": "boto.dynamodb2.fields.GlobalIncludeIndex.schema", "type": "method", "project_path": "Internet/boto", "completion_path": "Internet/boto/boto/dynamodb2/fields.py", "signature_position": [332, 333], "body_position": [334, 337], "dependency": {"intra_class": [], "intra_file": ["boto.dynamodb2.fields.GlobalBaseIndexField", "boto.dynamodb2.fields.GlobalBaseIndexField.schema", "boto.dynamodb2.fields.IncludeIndex", "boto.dynamodb2.fields.IncludeIndex.schema"], "cross_file": []}, "requirement": {"Functionality": "This function returns the schema data for the GlobalIncludeIndex class. It first retrieves the schema data from the its superclass and then updates it with the schema data from the GlobalBaseIndexField superclass.", "Arguments": ":param self: GlobalIncludeIndex. An instance of the GlobalIncludeIndex class.\n:return: Dictionary. The schema data for the GlobalIncludeIndex class."}, "tests": ["tests/unit/dynamodb2/test_table.py::IndexFieldTestCase::test_global_include_index_throughput", "tests/unit/dynamodb2/test_table.py::IndexFieldTestCase::test_global_include_index"], "indent": 8}
{"namespace": "datasette.utils.check_connection", "type": "function", "project_path": "Database/datasette", "completion_path": "Database/datasette/datasette/utils/__init__.py", "signature_position": [953, 953], "body_position": [954, 969], "dependency": {"intra_class": [], "intra_file": ["datasette.utils.ConnectionProblem", "datasette.utils.SpatialiteConnectionProblem", "datasette.utils.escape_sqlite"], "cross_file": []}, "requirement": {"Functionality": "Check the connection to a SQLite database by executing a query to retrieve the names of all tables in the database. Then, for each table, it executes another query to retrieve the table information using the `PRAGMA` statement. If any error occurs during the execution of these queries, it raises specific exceptions based on the error message.", "Arguments": ":param conn: SQLite connection object. The connection to the SQLite database.\n:return: None."}, "tests": ["tests/test_utils.py::test_check_connection_spatialite_raises"], "indent": 4}
{"namespace": "wikipediaapi.WikipediaPage.langlinks", "type": "method", "project_path": "Communications/Wikipedia-API", "completion_path": "Communications/Wikipedia-API/wikipediaapi/__init__.py", "signature_position": [983, 983], "body_position": [994, 996], "dependency": {"intra_class": ["wikipediaapi.WikipediaPage._called", "wikipediaapi.WikipediaPage._fetch", "wikipediaapi.WikipediaPage._langlinks"], "intra_file": ["wikipediaapi.PagesDict"], "cross_file": []}, "requirement": {"Functionality": "This function returns all language links to pages in other languages. It is a wrapper for the MediaWiki API's query+langlinks module and the API:Langlinks page.", "Arguments": ":param self: WikipediaPage. An instance of the WikipediaPage class.\n:return: PagesDict. A dictionary containing language links to pages in other languages."}, "tests": ["tests/langlinks_test.py::TestLangLinks::test_langlinks_urls", "tests/langlinks_test.py::TestLangLinks::test_langlinks_count", "tests/langlinks_test.py::TestLangLinks::test_langlinks_lang_keys", "tests/langlinks_test.py::TestLangLinks::test_jump_between_languages", "tests/langlinks_test.py::TestLangLinks::test_langlinks_no_langlink_count"], "indent": 8}
{"namespace": "litecli.packages.parseutils.extract_tables", "type": "function", "project_path": "Database/litecli", "completion_path": "Database/litecli/litecli/packages/parseutils.py", "signature_position": [149, 149], "body_position": [155, 165], "dependency": {"intra_class": [], "intra_file": ["litecli.packages.parseutils.extract_from_part", "litecli.packages.parseutils.extract_table_identifiers"], "cross_file": []}, "requirement": {"Functionality": "This function extracts the table names from an SQL statement. It uses the sqlparse library to parse the SQL statement and then extracts the table names from the parsed result.", "Arguments": ":param sql: String. The SQL statement to extract table names from.\n:return: List of tuples. Each tuple contains the schema, table, and alias of a table mentioned in the SQL statement."}, "tests": ["tests/test_parseutils.py::test_simple_select_multiple_tables", "tests/test_parseutils.py::test_select_with_hanging_comma_multiple_tables", "tests/test_parseutils.py::test_simple_update_table_with_schema", "tests/test_parseutils.py::test_simple_update_table", "tests/test_parseutils.py::test_simple_select_with_cols_multiple_tables"], "indent": 4}
{"namespace": "datasette.app.DatasetteClient.get", "type": "method", "project_path": "Database/datasette", "completion_path": "Database/datasette/datasette/app.py", "signature_position": [1556, 1556], "body_position": [1557, 1558], "dependency": {"intra_class": ["datasette.app.DatasetteClient._fix", "datasette.app.DatasetteClient.app"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function sends an HTTP GET request to the specified path using the DatasetteClient instance. It uses the httpx library to make the asynchronous request.", "Arguments": ":param self: DatasetteClient. An instance of the DatasetteClient class.\n:param path: String. The path to send the GET request to.\n:param kwargs: Additional keyword arguments that can be passed to the httpx client.\n:return: The response from the GET request."}, "tests": ["tests/test_facets.py::test_facet_size", "tests/test_api.py::test_hidden_sqlite_stat1_table", "tests/test_internals_datasette.py::test_datasette_constructor", "tests/test_facets.py::test_json_array_with_blanks_and_nulls", "tests/test_internals_datasette.py::test_num_sql_threads_zero"], "indent": 8}
{"namespace": "pymorphy2.opencorpora_dict.compile._to_paradigm", "type": "function", "project_path": "Text-Processing/pymorphy2", "completion_path": "Text-Processing/pymorphy2/pymorphy2/opencorpora_dict/compile.py", "signature_position": [241, 241], "body_position": [247, 270], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["pymorphy2.utils.longest_common_substring"]}, "requirement": {"Functionality": "This function extracts a stem and paradigm pair from a given lexeme. The lexeme is a list of tuples, where each tuple contains a word form and its corresponding tag. The paradigm is a list of suffixes with associated tags and prefixes. It also extracts prefixes from each word form and checks if they are in the list of paradigm prefixes. If any prefix is not in the paradigm prefixes, the function sets the stem to an empty string and assigns empty prefixes to all word forms. Finally, the function extracts suffixes from each word form and creates a tuple of suffixes, tags, and prefixes.", "Arguments": ":param lexeme: List of tuples. A list of (word_form, tag) tuples representing a lexeme.\n:param paradigm_prefixes: List of strings. A list of prefixes that are allowed in the paradigm.\n:return: Tuple. A tuple containing the stem and a tuple of suffixes, tags, and prefixes."}, "tests": ["tests/test_opencorpora_dict.py::TestToParadigm::test_simple", "tests/test_opencorpora_dict.py::TestToParadigm::test_platina", "tests/test_opencorpora_dict.py::TestToParadigm::test_single_prefix", "tests/test_opencorpora_dict.py::TestToParadigm::test_multiple_prefixes_2", "tests/test_opencorpora_dict.py::TestToParadigm::test_no_prefix"], "indent": 4}
{"namespace": "sqlite_utils.utils.suggest_column_types", "type": "function", "project_path": "Database/sqlite-utils", "completion_path": "Database/sqlite-utils/sqlite_utils/utils.py", "signature_position": [88, 88], "body_position": [89, 93], "dependency": {"intra_class": [], "intra_file": ["sqlite_utils.utils.types_for_column_types"], "cross_file": []}, "requirement": {"Functionality": "This function suggests the column types for a given set of records. It iterates over each record and its key-value pairs, and creates a dictionary of column types. It then calls another function to determine the suggested types for each column.", "Arguments": ":param records: List of dictionaries. The set of records for which column types need to be suggested.\n:return: The suggested column types for the given records."}, "tests": ["tests/test_suggest_column_types.py::test_suggest_column_types"], "indent": 4}
{"namespace": "sacred.utils.get_package_version", "type": "function", "project_path": "Utilities/sacred", "completion_path": "Utilities/sacred/sacred/utils.py", "signature_position": [698, 698], "body_position": [700, 701], "dependency": {"intra_class": [], "intra_file": ["sacred.utils.parse_version"], "cross_file": []}, "requirement": {"Functionality": "This function retrieves the version string of a package and parses it into a version object.", "Arguments": ":param name: String. The name of the package.\n:return: Version. The parsed version object of the package."}, "tests": ["tests/test_utils.py::test_get_package_version", "tests/test_utils.py::test_get_package_version_comparison"], "indent": 4}
{"namespace": "oletools.ooxml.get_type", "type": "function", "project_path": "Security/oletools", "completion_path": "Security/oletools/oletools/ooxml.py", "signature_position": [172, 172], "body_position": [174, 217], "dependency": {"intra_class": [], "intra_file": ["oletools.ooxml.BadOOXML", "oletools.ooxml.CONTENT_TYPES_EXCEL", "oletools.ooxml.CONTENT_TYPES_PPT", "oletools.ooxml.CONTENT_TYPES_WORD", "oletools.ooxml.DOCTYPE_EXCEL", "oletools.ooxml.DOCTYPE_EXCEL_XML", "oletools.ooxml.DOCTYPE_MIXED", "oletools.ooxml.DOCTYPE_NONE", "oletools.ooxml.DOCTYPE_POWERPOINT", "oletools.ooxml.DOCTYPE_WORD", "oletools.ooxml.DOCTYPE_WORD_XML", "oletools.ooxml.EXCEL_XML_PROG_ID", "oletools.ooxml.FILE_CONTENT_TYPES", "oletools.ooxml.OFFICE_XML_PROGID_REGEX", "oletools.ooxml.WORD_XML_PROG_ID", "oletools.ooxml.XmlParser", "oletools.ooxml.XmlParser.__init__", "oletools.ooxml.XmlParser.is_single_xml", "oletools.ooxml.XmlParser.iter_xml", "oletools.ooxml.debug_str", "oletools.ooxml.logger"], "cross_file": ["oletools.common.io_encoding.uopen"]}, "requirement": {"Functionality": "This function determines the type of a file based on its content. It checks the file's XML structure and content types to identify if it is a Word document, Excel spreadsheet, PowerPoint presentation, or none of these.", "Arguments": ":param filename: String. The name of the file to be checked.\n:return: Integer. One of the DOCTYPE_* constants indicating the type of the file."}, "tests": ["tests/ooxml/test_basic.py::TestOOXML::test_rough_doctype"], "indent": 4}
{"namespace": "flower.command.apply_options", "type": "function", "project_path": "System/flower", "completion_path": "System/flower/flower/command.py", "signature_position": [82, 82], "body_position": [84, 93], "dependency": {"intra_class": [], "intra_file": ["flower.command.is_flower_option"], "cross_file": ["flower.options.DEFAULT_CONFIG_FILE"]}, "requirement": {"Functionality": "This function applies options passed through the configuration file. It filters the options that are specific to the application and parses the command line to get the \"--conf\" option. It then parses the configuration file and the command line again to update the options. It will stop IOError during parsing if the configuration file's name is the same as the default configuration file's name.", "Arguments": ":param prog_name: String. The name of the program.\n:param argv: List of strings. The command line arguments passed to the program.\n:return: No return values."}, "tests": ["tests/unit/test_command.py::TestFlowerCommand::test_port", "tests/unit/test_command.py::TestConfOption::test_empty_conf", "tests/unit/test_command.py::TestFlowerCommand::test_task_runtime_metric_buckets_read_from_cmd_line", "tests/unit/test_command.py::TestConfOption::test_conf_abs", "tests/unit/test_command.py::TestFlowerCommand::test_address"], "indent": 4}
{"namespace": "msticpy.analysis.anomalous_sequence.model.Model.compute_rarest_windows", "type": "method", "project_path": "Security/msticpy", "completion_path": "Security/msticpy/msticpy/analysis/anomalous_sequence/model.py", "signature_position": [517, 522], "body_position": [558, 617], "dependency": {"intra_class": ["msticpy.analysis.anomalous_sequence.model.Model.prior_probs", "msticpy.analysis.anomalous_sequence.model.Model.rare_window_likelihoods", "msticpy.analysis.anomalous_sequence.model.Model.rare_window_likelihoods_geo", "msticpy.analysis.anomalous_sequence.model.Model.rare_windows", "msticpy.analysis.anomalous_sequence.model.Model.rare_windows_geo", "msticpy.analysis.anomalous_sequence.model.Model.session_type", "msticpy.analysis.anomalous_sequence.model.Model.sessions"], "intra_file": ["msticpy.analysis.anomalous_sequence.model.SessionType", "msticpy.analysis.anomalous_sequence.model.SessionType.cmds_only", "msticpy.analysis.anomalous_sequence.model.SessionType.cmds_params_only"], "cross_file": ["msticpy.common.exceptions.MsticpyException"]}, "requirement": {"Functionality": "This function computes the rarest windows and corresponding likelihood for each session. It uses a sliding window approach to identify the rarest window and its likelihood in each session. The function takes into account the length of the sliding window, whether to use start and end tokens, and whether to use the geometric mean for likelihood calculations.", "Arguments": ":param self: Model. An instance of the Model class.\n:param window_len: int. The length of the sliding window for likelihood calculations.\n:param use_start_end_tokens: bool. If True, start and end tokens will be added to each session before calculations.\n:param use_geo_mean: bool. If True, the likelihoods of the sliding windows will be raised to the power of (1/window_len).\n:return: None. The function updates the rarest windows and corresponding likelihoods in the Model instance."}, "tests": ["tests/analysis/test_anom_seq_model.py::TestModel::test_compute_rarest_windows"], "indent": 8}
{"namespace": "alembic.testing.env.three_rev_fixture", "type": "function", "project_path": "Database/alembic", "completion_path": "Database/alembic/alembic/testing/env.py", "signature_position": [305, 305], "body_position": [306, 379], "dependency": {"intra_class": [], "intra_file": ["alembic.testing.env.write_script"], "cross_file": ["alembic.script.ScriptDirectory.from_config", "alembic.script.ScriptDirectory.generate_revision", "alembic.util", "alembic.util.rev_id"]}, "requirement": {"Functionality": "This function generates three revision fixtures for a given configuration. It creates three revision IDs and generates corresponding revision scripts using the `ScriptDirectory` class. Each revision script contains an upgrade and downgrade function that execute SQL statements. The generated revision scripts are written to files.", "Arguments": ":param cfg: The configuration object used by the `ScriptDirectory` class.\n:return: Tuple of three revision IDs (a, b, c)"}, "tests": ["tests/test_command.py::RevisionEnvironmentTest::test_merge_cmd_revision_environment"], "indent": 4}
{"namespace": "boto.dynamodb2.table.Table.has_item", "type": "method", "project_path": "Internet/boto", "completion_path": "Internet/boto/boto/dynamodb2/table.py", "signature_position": [713, 713], "body_position": [745, 751], "dependency": {"intra_class": ["boto.dynamodb2.table.Table.get_item"], "intra_file": [], "cross_file": ["boto.dynamodb2.exceptions.ItemNotFound", "boto.exception.JSONResponseError", "boto.dynamodb2.exceptions"]}, "requirement": {"Functionality": "This function checks whether an item (record) exists within a table in DynamoDB. It takes the key attributes as keyword arguments and optionally accepts a \"consistent\" parameter to perform a consistent read from DynamoDB. It also accepts an \"attributes\" parameter to specify the fields to fetch. It returns True if the item is present and False if not.", "Arguments": ":param self: Table. An instance of the Table class.\n:param kwargs: Key attributes of the item to check. (1) consistent [Optional]: Bool. Whether to perform a consistent read from DynamoDB. Defaults to False. (2) attributes [Optional]: List of strings. The fields to fetch. Defaults to None, which means all fields should be fetched.\n:return: Bool. True if the item is present, False if not."}, "tests": ["tests/unit/dynamodb2/test_table.py::TableTestCase::test_has_item"], "indent": 8}
{"namespace": "mopidy.internal.playlists.parse", "type": "function", "project_path": "Multimedia/Mopidy", "completion_path": "Multimedia/Mopidy/mopidy/internal/playlists.py", "signature_position": [8, 8], "body_position": [9, 18], "dependency": {"intra_class": [], "intra_file": ["mopidy.internal.playlists.detect_asx_header", "mopidy.internal.playlists.detect_extm3u_header", "mopidy.internal.playlists.detect_pls_header", "mopidy.internal.playlists.detect_xspf_header", "mopidy.internal.playlists.parse_asx", "mopidy.internal.playlists.parse_extm3u", "mopidy.internal.playlists.parse_pls", "mopidy.internal.playlists.parse_urilist", "mopidy.internal.playlists.parse_xspf"], "cross_file": []}, "requirement": {"Functionality": "This function parses the given data and returns a list of parsed items. It uses a dictionary of handlers, where each handler is associated with a specific detector function. It iterates through the handlers and checks if the detector function returns True for the given data. If a match is found, it calls the corresponding parser function and returns the parsed items as a list. If no match is found, it parses the result as uris and returns the parsed items as a list.", "Arguments": ":param data: The data to be parsed.\n:return: List. The list of parsed items."}, "tests": ["tests/internal/test_playlists.py::test_parse_any_format_from_valid_data", "tests/internal/test_playlists.py::test_parse_from_invalid_data"], "indent": 4}
{"namespace": "boltons.funcutils.FunctionBuilder.from_func", "type": "method", "project_path": "Utilities/boltons", "completion_path": "Utilities/boltons/boltons/funcutils.py", "signature_position": [868, 868], "body_position": [875, 898], "dependency": {"intra_class": ["boltons.funcutils.FunctionBuilder.__init__", "boltons.funcutils.FunctionBuilder._argspec_to_dict"], "intra_file": ["boltons.funcutils._IS_PY2", "boltons.funcutils._inspect_iscoroutinefunction"], "cross_file": []}, "requirement": {"Functionality": "This function creates a new instance of the FunctionBuilder class based on an existing function. The original function is not modified or stored. It also takes into account whether the function is a partial object or not.", "Arguments": ":param cls: type. The FunctionBuilder class.\n:param func: Callable object. The existing function to base the new instance on.\n:return: FunctionBuilder. The newly created instance of the FunctionBuilder class."}, "tests": ["tests/test_funcutils_fb.py::test_get_arg_names", "tests/test_funcutils_fb.py::test_defaults_dict", "tests/test_funcutils_fb_py3.py::test_remove_kwonly_arg", "tests/test_funcutils_fb_py3.py::test_get_arg_names", "tests/test_funcutils_fb_py3.py::test_defaults_dict"], "indent": 8}
{"namespace": "sumy.summarizers.kl.KLSummarizer.compute_tf", "type": "method", "project_path": "Internet/sumy", "completion_path": "Internet/sumy/sumy/summarizers/kl.py", "signature_position": [54, 54], "body_position": [60, 64], "dependency": {"intra_class": ["sumy.summarizers.kl.KLSummarizer._compute_word_freq", "sumy.summarizers.kl.KLSummarizer._get_all_content_words_in_doc"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function computes the normalized term frequency for a given list of sentences. It first extracts the content words from the sentences, then calculates the frequency of each content word. Finally, it normalizes the term frequency by dividing the frequency of each content word by the total number of content words in the document.", "Arguments": ":param self: KLSummarizer. An instance of the KLSummarizer class.\n:param sentences: List of Sentence objects. The sentences from which to compute the term frequency.\n:return: Dictionary. A dictionary mapping each content word to its normalized term frequency."}, "tests": ["tests/test_summarizers/test_kl.py::test_tf_idf_metric_should_be_real_number"], "indent": 8}
{"namespace": "bentoml._internal.resource.CpuResource.validate", "type": "method", "project_path": "Scientific-Engineering/bentoml", "completion_path": "Scientific-Engineering/bentoml/src/bentoml/_internal/resource.py", "signature_position": [112, 112], "body_position": [113, 120], "dependency": {"intra_class": ["bentoml._internal.resource.CpuResource.from_system"], "intra_file": [], "cross_file": ["bentoml.exceptions.BentoMLConfigException"]}, "requirement": {"Functionality": "This function validates a CPU resource limit value. It checks if the value is negative and raises an exception if it is. It also compares the value with the system's available CPU resources and raises an exception if the value is greater than the system's available resources.", "Arguments": ":param cls: Class. The class itself.\n:param val: Float. The CPU resource limit value to validate.\n:return: No return values."}, "tests": ["tests/unit/_internal/test_resource.py::test_CpuResource"], "indent": 8}
{"namespace": "passpie.database.PasspieStorage.delete", "type": "method", "project_path": "Security/passpie", "completion_path": "Security/passpie/passpie/database.py", "signature_position": [26, 26], "body_position": [27, 31], "dependency": {"intra_class": ["passpie.database.PasspieStorage.make_credpath"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Delete the credentials from the PasspieStorage instance. It iterates over the list of credentials and deletes the corresponding files from the storage. If the directory containing the file becomes empty after deletion, it is also removed.", "Arguments": ":param self: PasspieStorage. An instance of the PasspieStorage class.\n:param credentials: List of dictionaries. A list of credentials, where each credential is represented as a dictionary with \"name\" and \"login\" keys.\n:return: No return values."}, "tests": ["tests/test_database.py::StorageTests::test_delete_removes_empty_directories", "tests/test_database.py::StorageTests::test_delete_removes_credentials_files"], "indent": 8}
{"namespace": "sumy.summarizers.reduction.ReductionSummarizer._to_words_set", "type": "method", "project_path": "Internet/sumy", "completion_path": "Internet/sumy/sumy/summarizers/reduction.py", "signature_position": [41, 41], "body_position": [42, 43], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["sumy.summarizers._summarizer.AbstractSummarizer.normalize_word", "sumy.summarizers._summarizer.AbstractSummarizer.stem_word", "sumy.models.dom._sentence.Sentence.words"]}, "requirement": {"Functionality": "This function takes a sentence as input and converts it into a set of words. It normalizes each word in the sentence and removes any stop words. The resulting set of words is returned.", "Arguments": ":param self: ReductionSummarizer. An instance of the ReductionSummarizer class.\n:param sentence: Sentence. The sentence to be converted into a set of words.\n:return: List. The set of words after normalization and removal of stop words."}, "tests": ["tests/test_summarizers/test_reduction.py::test_stop_words_correctly_removed"], "indent": 8}
{"namespace": "jwt.algorithms.HMACAlgorithm.prepare_key", "type": "method", "project_path": "Utilities/PyJWT", "completion_path": "Utilities/PyJWT/jwt/algorithms.py", "signature_position": [254, 254], "body_position": [255, 265], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["jwt.exceptions.InvalidKeyError", "jwt.utils.force_bytes", "jwt.utils.is_pem_format", "jwt.utils.is_ssh_key"]}, "requirement": {"Functionality": "This function prepares the key for use in HMAC algorithm. It converts the key to bytes and checks if it is in PEM or SSH format. If it is, it raises an invalid key error \"The specified key is an asymmetric key or x509 certificate and should not be used as an HMAC secret.\" Otherwise, the key is returned as bytes.", "Arguments": ":param self: HMACAlgorithm. An instance of the HMACAlgorithm class.\n:param key: str or bytes. The key to be prepared for HMAC algorithm.\n:return: bytes. The prepared key for HMAC algorithm."}, "tests": ["tests/test_algorithms.py::TestAlgorithms::test_hmac_should_reject_nonstring_key", "tests/test_algorithms.py::TestAlgorithmsRFC7520::test_hmac_verify_should_return_true_for_test_vector", "tests/test_algorithms.py::TestAlgorithms::test_hmac_should_throw_exception"], "indent": 8}
{"namespace": "mrjob.fs.local.LocalFilesystem.du", "type": "method", "project_path": "System/mrjob", "completion_path": "System/mrjob/mrjob/fs/local.py", "signature_position": [36, 36], "body_position": [37, 38], "dependency": {"intra_class": ["mrjob.fs.local.LocalFilesystem.ls"], "intra_file": ["mrjob.fs.local._from_file_uri"], "cross_file": []}, "requirement": {"Functionality": "This function calculates the total size of files in a given path.\nFirst converts the input path to a local file path format. Then, it iterate through all the files in the given path and get the file size. Finally, it sums up all the file sizes.\n", "Arguments": ":param self: LocalFilesystem, an instance of the LocalFilesystem class.\n:param path_glob: String. The file path or path pattern for which the total size needs to be calculated.\n:return: Integer. The total size of files in the given path.\n"}, "tests": ["tests/fs/test_local.py::LocalFSTestCase::test_du"], "indent": 8}
{"namespace": "fs.path.isbase", "type": "function", "project_path": "System/fs", "completion_path": "System/fs/fs/path.py", "signature_position": [443, 444], "body_position": [459, 461], "dependency": {"intra_class": [], "intra_file": ["fs.path.abspath", "fs.path.forcedir"], "cross_file": []}, "requirement": {"Functionality": "Take two paths - `path1` and `path2` as input. Check if `path1` is a base of `path2` by comparing their absolute paths. \n", "Arguments": ":param path1: String, a PyFilesytem path, e.g., ``'a/b/c'``.\n:param path2: String, a PyFilesytem path, e.g., ``'a/b/c'``.\n:return: Bool, True if path2 starts with path1. False otherwise.\n"}, "tests": ["tests/test_path.py::TestPathFunctions::test_isbase"], "indent": 4}
{"namespace": "boto.dynamodb2.table.Table.delete_global_secondary_index", "type": "method", "project_path": "Internet/boto", "completion_path": "Internet/boto/boto/dynamodb2/table.py", "signature_position": [515, 515], "body_position": [535, 555], "dependency": {"intra_class": ["boto.dynamodb2.table.Table.connection", "boto.dynamodb2.table.Table.table_name"], "intra_file": [], "cross_file": ["boto.dynamodb2.layer1.DynamoDBConnection.update_table", "boto.log", "boto"]}, "requirement": {"Functionality": "This function deletes a global secondary index in DynamoDB for a Table instance. It takes the name of the global secondary index as input and uses it to delete the index from a Table instance. If the global_index_name is not provided, this function logs a error message - \"You need to provide the global index name to delete_global_secondary_index method\" and return False.", "Arguments": ":param self: Table. An instance of the Table class.\n:param global_index_name: String. The name of the global secondary index to be deleted.\n:return: Bool. Returns True if the index is successfully deleted, False otherwise."}, "tests": ["tests/unit/dynamodb2/test_table.py::TableTestCase::test_delete_global_secondary_index"], "indent": 8}
{"namespace": "diffprivlib.tools.histograms.histogram", "type": "function", "project_path": "Security/diffprivlib", "completion_path": "Security/diffprivlib/diffprivlib/tools/histograms.py", "signature_position": [57, 58], "body_position": [129, 158], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["diffprivlib.accountant.BudgetAccountant", "diffprivlib.accountant.BudgetAccountant.check", "diffprivlib.accountant.BudgetAccountant.load_default", "diffprivlib.accountant.BudgetAccountant.spend", "diffprivlib.utils.PrivacyLeakWarning", "diffprivlib.utils.check_random_state", "diffprivlib.utils.warn_unused_args", "diffprivlib.mechanisms.geometric.GeometricTruncated.randomise"]}, "requirement": {"Functionality": "This function computes the differentially private histogram of a set of data. It computes the histogram and adds noise to satisfy differential privacy. It also handles various parameters such as epsilon, bins, range, weights, density, random_state, and accountant.", "Arguments": ":param sample: array_like. The input data for which the histogram needs to be computed.\n:param epsilon: float, default: 1.0. The privacy parameter epsilon to be applied.\n:param bins: int or sequence of scalars or str, default: 10. The number of equal-width bins in the given range. It can also be a sequence defining a monotonically increasing array of bin edges.\n:param range: (float, float), optional. The lower and upper range of the bins. Values outside the range are ignored.\n:param weights: array_like, optional. An array of weights, of the same shape as the input data. Each value in the input data contributes its associated weight towards the bin count.\n:param density: bool, optional. If False, the result will contain the number of samples in each bin. If True, the result is the value of the probability density function at the bin, normalized such that the integral over the range is 1.\n:param random_state: int or RandomState, optional. Controls the randomness of the algorithm.\n:param accountant: BudgetAccountant, optional. Accountant to keep track of privacy budget.\n:param **unused_args: Should warn the user if any other parameters are passed.\n:return: hist: array. The values of the histogram. bin_edges: array of dtype float. The bin edges."}, "tests": ["tests/tools/test_histogram.py::TestHistogram::test_no_params", "tests/tools/test_histogram.py::TestHistogram::test_different_result", "tests/tools/test_histogram.py::TestHistogram::test_accountant", "tests/tools/test_histogram.py::TestHistogram::test_default_accountant", "tests/tools/test_histogram.py::TestHistogram::test_density"], "indent": 4}
{"namespace": "fs.info.Info.suffixes", "type": "method", "project_path": "System/fs", "completion_path": "System/fs/fs/info.py", "signature_position": [229, 230], "body_position": [239, 242], "dependency": {"intra_class": ["fs.info.Info.get"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function returns a list of any suffixes in the name of an instance of the Info class. It checks if the name starts with a dot and only contains one dot, in which case it returns an empty list. Otherwise, it splits the name by dots and returns a list of the suffixes.", "Arguments": ":param self: Info. An instance of the Info class.\n:return: List[Text]. A list of any suffixes in the name."}, "tests": ["tests/test_info.py::TestInfo::test_suffix"], "indent": 8}
{"namespace": "mssqlcli.mssqlbuffer._is_query_executable", "type": "function", "project_path": "Database/mssql-cli", "completion_path": "Database/mssql-cli/mssqlcli/mssqlbuffer.py", "signature_position": [24, 27], "body_position": [28, 50], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["mssqlcli.packages.parseutils.utils.is_open_quote"]}, "requirement": {"Functionality": "Check if an SQL statement is executable. It checks if the statement is a complete command by verifying if it ends with 'GO' (unless it is surrounded by an open quote). It also removes comments and checks for open comments in the statement.", "Arguments": ":param sql: String. The SQL statement to be checked.\n:return: Bool. True if the SQL statement is executable, False otherwise."}, "tests": ["tests/test_multiline.py::TestMssqlCliMultiline::test_multiline_completeness"], "indent": 4}
{"namespace": "boltons.ioutils.SpooledStringIO.len", "type": "method", "project_path": "Utilities/boltons", "completion_path": "Utilities/boltons/boltons/ioutils.py", "signature_position": [514, 514], "body_position": [516, 525], "dependency": {"intra_class": ["boltons.ioutils.SpooledStringIO.buffer", "boltons.ioutils.SpooledStringIO.len", "boltons.ioutils.SpooledStringIO.read"], "intra_file": ["boltons.ioutils.READ_CHUNK_SIZE"], "cross_file": []}, "requirement": {"Functionality": "This function calculates the number of codepoints in the file by reading the file in chunks and counting the length of each chunk.", "Arguments": ":param self: SpooledStringIO. An instance of the SpooledStringIO class.\n:return: int. The number of codepoints in the file."}, "tests": ["tests/test_ioutils.py::TestSpooledStringIO::test_len_rollover", "tests/test_ioutils.py::TestSpooledStringIO::test_len_no_rollover"], "indent": 8}
{"namespace": "prometheus_client.multiprocess.MultiProcessCollector.collect", "type": "method", "project_path": "System/prometheus-client", "completion_path": "System/prometheus-client/prometheus_client/multiprocess.py", "signature_position": [156, 156], "body_position": [157, 158], "dependency": {"intra_class": ["prometheus_client.multiprocess.MultiProcessCollector._path", "prometheus_client.multiprocess.MultiProcessCollector.merge"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Collect data from multiple files and merge them into a single result. It first retrieves a list of file paths that match the pattern \"*.db\" in the specified directory. Then, it merge files in accumulate mode.", "Arguments": ":param self: MultiProcessCollector. An instance of the MultiProcessCollector class.\n:return: The merged result of the collected data."}, "tests": ["tests/test_multiprocess.py::TestMultiProcess::test_collect_preserves_help", "tests/test_multiprocess.py::TestMultiProcess::test_collect"], "indent": 8}
{"namespace": "boltons.tableutils.Table.to_text", "type": "method", "project_path": "Utilities/boltons", "completion_path": "Utilities/boltons/boltons/tableutils.py", "signature_position": [575, 575], "body_position": [583, 600], "dependency": {"intra_class": ["boltons.tableutils.Table._data", "boltons.tableutils.Table._width", "boltons.tableutils.Table.headers", "boltons.tableutils.Table.to_text"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function returns the textual representation of a Table object. It includes the header row at the top and formats the data in a table-like structure. Each cell is first tried to be converted to a string. If that fails, it is converted to a repr string. If it exceeds the maximum length, it is truncated and an ellipsis is added. The text is padded with spaces to be centered in the cell. Each column is separated by ' | '. The header row is separated from the data by a line of dashes, where the intersection of each column and the header row is '-|-'.", "Arguments": ":param self: Table. An instance of the Table class.\n:param with_headers: bool. Whether to include a header row at the top. It defaults to True if not specified.\n:param maxlen: int. The maximum length of data in each cell. It defaults to None if not specified.\n:return: str. The textual representation of the Table object."}, "tests": ["tests/test_tableutils.py::test_table_dicts"], "indent": 8}
{"namespace": "mrjob.setup.UploadDirManager.uri", "type": "method", "project_path": "System/mrjob", "completion_path": "System/mrjob/mrjob/setup.py", "signature_position": [332, 332], "body_position": [335, 341], "dependency": {"intra_class": ["mrjob.setup.UploadDirManager._path_to_name", "mrjob.setup.UploadDirManager.prefix"], "intra_file": [], "cross_file": ["mrjob.parse.is_uri"]}, "requirement": {"Functionality": "This function returns the URI for a given path. If the path is already a URI, it is returned as is. If the path is a known local file, the URI is constructed using the prefix and the corresponding name. If the path is neither a URI nor a known local file, a ValueError is raised with the error message '%r is not a URI or a known local file'.", "Arguments": ":param self: UploadDirManager. An instance of the UploadDirManager class.\n:param path: str. The path for which the URI is to be obtained.\n:return: str. The URI corresponding to the given path."}, "tests": ["tests/test_setup.py::UploadDirManagerTestCase::test_unknown_uri", "tests/test_setup.py::UploadDirManagerTestCase::test_uri"], "indent": 8}
{"namespace": "boto.dynamodb2.table.Table._put_item", "type": "method", "project_path": "Internet/boto", "completion_path": "Internet/boto/boto/dynamodb2/table.py", "signature_position": [824, 824], "body_position": [831, 837], "dependency": {"intra_class": ["boto.dynamodb2.table.Table.connection", "boto.dynamodb2.table.Table.table_name"], "intra_file": [], "cross_file": ["boto.dynamodb2.layer1.DynamoDBConnection.put_item"]}, "requirement": {"Functionality": "This function is used by the Item instances to save themselves to a Table instance.", "Arguments": ":param self: Table. An instance of the Table class.\n:param item_data: Item. Several Item instances to be saved.\n:param expects: Optional. The expected conditions for the save operation.\n:return: Bool. Returns True after saving the item to the table."}, "tests": ["tests/unit/dynamodb2/test_table.py::TableTestCase::test_private_put_item"], "indent": 8}
{"namespace": "mingus.core.intervals.measure", "type": "function", "project_path": "Multimedia/mingus", "completion_path": "Multimedia/mingus/mingus/core/intervals.py", "signature_position": [253, 253], "body_position": [263, 267], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["mingus.core.notes", "mingus.core.notes.note_to_int"]}, "requirement": {"Functionality": "This function takes two musical notes as input and returns an integer representing the number of half-note steps (0 - 11) between them.\n", "Arguments": ":param note1: str. The first musical note.\n:param note2: str. The second musical note.\n:return: int. The number of half-note steps between note1 and note2.\n"}, "tests": ["tests/unit/core/test_intervals.py::test_intervals::test_valid_measure"], "indent": 4}
{"namespace": "boto.ec2containerservice.connect_to_region", "type": "function", "project_path": "Internet/boto", "completion_path": "Internet/boto/boto/ec2containerservice/__init__.py", "signature_position": [39, 39], "body_position": [40, 43], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["boto.ec2containerservice.layer1.EC2ContainerServiceConnection", "boto.regioninfo.connect"]}, "requirement": {"Functionality": "Connect to a specific region using the EC2ContainerServiceConnection class from the boto library. It creates an instance of the EC2ContainerServiceConnection class with the specified region name and additional keyword parameters.", "Arguments": ":param region_name: String. The name of the region to connect to.\n:param **kw_params: Additional keyword parameters that can be passed to the EC2ContainerServiceConnection class.\n:return: EC2ContainerServiceConnection. An instance of the EC2ContainerServiceConnection class connected to the specified region."}, "tests": ["tests/unit/test_connect_to_region.py::TestEc2ContainerserviceConnection::test_connect_to_region"], "indent": 4}
{"namespace": "mopidy.config.types.Integer.deserialize", "type": "method", "project_path": "Multimedia/Mopidy", "completion_path": "Multimedia/Mopidy/mopidy/config/types.py", "signature_position": [155, 155], "body_position": [156, 164], "dependency": {"intra_class": ["mopidy.config.types.Integer._choices", "mopidy.config.types.Integer._maximum", "mopidy.config.types.Integer._minimum", "mopidy.config.types.Integer._required"], "intra_file": ["mopidy.config.types.decode"], "cross_file": ["mopidy.config.validators", "mopidy.config.validators.validate_choice", "mopidy.config.validators.validate_maximum", "mopidy.config.validators.validate_minimum", "mopidy.config.validators.validate_required"]}, "requirement": {"Functionality": "Deserialize a value into an Integer object. It decodes the input value, validates it based on the specified constraints, and returns the deserialized integer value.", "Arguments": ":param self: Integer. An instance of the Integer class.\n:param value: The value to be deserialized.\n:return: int. The deserialized integer value."}, "tests": ["tests/config/test_types.py::TestInteger::test_deserialize_enforces_choices", "tests/config/test_types.py::TestInteger::test_deserialize_enforces_maximum", "tests/config/test_types.py::TestInteger::test_deserialize_enforces_minimum", "tests/config/test_types.py::TestPort::test_invalid_ports", "tests/config/test_types.py::TestPort::test_valid_ports"], "indent": 8}
{"namespace": "pycoin.satoshi.stackops.do_OP_HASH160", "type": "function", "project_path": "Security/pycoin", "completion_path": "Security/pycoin/pycoin/satoshi/stackops.py", "signature_position": [126, 126], "body_position": [127, 128], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["pycoin.encoding.hash.hash160"]}, "requirement": {"Functionality": "Pop the top item from the stack, calculate its hash160 value, and append the result back to the stack.\n", "Arguments": ":param stack: List, a stack containing items on which to perform the operation.\n:return: No return values.\n"}, "tests": ["tests/script/stackops_test.py::StackOpsTest::test_do_OP_HASH160"], "indent": 4}
{"namespace": "kinto.core.authorization.RouteFactory.fetch_shared_objects", "type": "method", "project_path": "Internet/kinto", "completion_path": "Internet/kinto/kinto/core/authorization.py", "signature_position": [213, 213], "body_position": [226, 234], "dependency": {"intra_class": ["kinto.core.authorization.RouteFactory._get_accessible_objects", "kinto.core.authorization.RouteFactory._object_id_match", "kinto.core.authorization.RouteFactory.shared_ids"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function fetches objects that are readable or writable for the current principals based on the given permissions. It sets shared ids to the context with the fetched object IDs. If no object is shared, it returns None.", "Arguments": ":param self: RouteFactory. An instance of the RouteFactory class.\n:param perm: The permission to check for the objects.\n:param principals: The current principals.\n:param get_bound_permissions: Bool. Whether to get bound permissions for the object ID match.\n:return: List of object IDs that are readable or writable for the current principals."}, "tests": ["tests/core/test_authorization.py::RouteFactoryTest::test_fetch_shared_objects_uses_pattern_if_on_plural_endpoint", "tests/core/test_authorization.py::RouteFactoryTest::test_fetch_shared_objects_uses_get_bound_permission_callback", "tests/core/test_authorization.py::RouteFactoryTest::test_fetch_shared_objects_sets_shared_ids_from_results", "tests/core/test_authorization.py::RouteFactoryTest::test_fetch_shared_objects_sets_shared_ids_if_empty"], "indent": 8}
{"namespace": "diffprivlib.models.naive_bayes.GaussianNB._noisy_class_counts", "type": "method", "project_path": "Security/diffprivlib", "completion_path": "Security/diffprivlib/diffprivlib/models/naive_bayes.py", "signature_position": [280, 280], "body_position": [281, 299], "dependency": {"intra_class": ["diffprivlib.models.naive_bayes.GaussianNB.epsilon"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function calculates the noisy class counts for each unique class label in the given target variable. It uses a privacy mechanism to add noise to the actual class counts in order to protect privacy.", "Arguments": ":param self: GaussianNB. An instance of the GaussianNB class.\n:param y: numpy array. The target variable containing class labels.\n:param random_state: int or RandomState instance. The random state used for generating noise.\n:return: numpy array. The noisy class counts for each unique class label."}, "tests": ["tests/models/test_GaussianNB.py::TestGaussianNB::test_noisy_count"], "indent": 8}
{"namespace": "sumy.utils.get_stop_words", "type": "function", "project_path": "Internet/sumy", "completion_path": "Internet/sumy/sumy/utils.py", "signature_position": [66, 66], "body_position": [67, 72], "dependency": {"intra_class": [], "intra_file": ["sumy.utils.normalize_language", "sumy.utils.parse_stop_words"], "cross_file": []}, "requirement": {"Functionality": "This function retrieves the stop words for a given language. The language name is normalized before retrieval. If the data is not available, it raises a LookupError. The data is converted before being returned.", "Arguments": ":param language: str. The language for which stop words are needed.\n:return: frozenset. The stop words for the given language."}, "tests": ["tests/test_summarizers/test_luhn.py::test_real_example", "tests/test_utils/test_utils.py::test_missing_stop_words_language", "tests/test_utils/test_utils.py::test_ok_stop_words_language"], "indent": 4}
{"namespace": "gunicorn.http.unreader.Unreader.read", "type": "method", "project_path": "Utilities/gunicorn", "completion_path": "Utilities/gunicorn/gunicorn/http/unreader.py", "signature_position": [20, 20], "body_position": [21, 50], "dependency": {"intra_class": ["gunicorn.http.unreader.Unreader.buf", "gunicorn.http.unreader.Unreader.chunk"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function is used to read a specific size of data from a buffer. The function first checks if the size parameter is an integer or long. If it is not, it raises a TypeError \"size parameter must be an int or long.\". Then it checks if the size is zero, in which case it returns an empty byte string. If the size is negative, it sets the size to None.\nNext, the function seeks to the end of the buffer. If the size is None and there is data in the buffer, it reads the data from the buffer, resets the buffer, and returns the data. If the size is None and there is no data in the buffer, it get chunk data and returns it.\nIf the size is not None, the function enters a loop that continues until the amount of data in the buffer is more than the specified size. In each iteration, it get chunk data and writes it to the buffer if there is any data. If there is no data in the chunk, it reads the data from the buffer, resets the buffer, and returns the data. Finally, it reads the data from the buffer, writes the remaining data to a new buffer, and returns the desired amount of data.", "Arguments": ":param self: Unreader. An instance of the Unreader class.\n:param size: Integer. The number of bytes to read from the buffer. If not provided, it reads all the remaining bytes.\n:return: Bytes. The read bytes from the buffer."}, "tests": ["tests/test_http.py::test_unreader_read_zero_size", "tests/test_http.py::test_unreader_read_when_size_is_none", "tests/test_http.py::test_unreader_raises_excpetion_on_invalid_size", "tests/test_http.py::test_unreader_unread", "tests/test_http.py::test_unreader_read_with_nonzero_size"], "indent": 8}
{"namespace": "boltons.urlutils.URL.navigate", "type": "method", "project_path": "Utilities/boltons", "completion_path": "Utilities/boltons/boltons/urlutils.py", "signature_position": [657, 657], "body_position": [675, 704], "dependency": {"intra_class": ["boltons.urlutils.URL.__init__", "boltons.urlutils.URL.fragment", "boltons.urlutils.URL.from_parts", "boltons.urlutils.URL.host", "boltons.urlutils.URL.normalize", "boltons.urlutils.URL.password", "boltons.urlutils.URL.path", "boltons.urlutils.URL.path_parts", "boltons.urlutils.URL.port", "boltons.urlutils.URL.query_params", "boltons.urlutils.URL.scheme", "boltons.urlutils.URL.username"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function is a factory method that returns a new URL object based on a given destination. It is used to navigate relative links easily. The newly created URL is normalized before being returned.", "Arguments": ":param self: URL. An instance of the URL class.\n:param dest: str or URL. The destination to navigate to. It can be a string or a URL object.\n:return: URL. The newly created URL object."}, "tests": ["tests/test_urlutils.py::test_chained_navigate", "tests/test_urlutils.py::test_navigate", "tests/test_urlutils.py::test_rel_navigate"], "indent": 8}
{"namespace": "threatingestor.Ingestor.run", "type": "method", "project_path": "Security/threatingestor", "completion_path": "Security/threatingestor/threatingestor/__init__.py", "signature_position": [99, 99], "body_position": [101, 107], "dependency": {"intra_class": ["threatingestor.Ingestor.config", "threatingestor.Ingestor.run_forever", "threatingestor.Ingestor.run_once", "threatingestor.Ingestor.statsd"], "intra_file": [], "cross_file": ["threatingestor.config.Config.daemon"]}, "requirement": {"Functionality": "This function runs the Ingestor instance either once or forever, depending on the configuration. If the configuration specifies to run as a daemon, it runs the instance in a loop. Otherwise, it runs the instance once to completion.", "Arguments": ":param self: Ingestor. An instance of the Ingestor class.\n:return: No return values."}, "tests": ["tests/test_ingestor.py::TestIngestor::test_run_checks_config_daemon"], "indent": 8}
{"namespace": "jinja2.idtracking.symbols_for_node", "type": "function", "project_path": "Internet/Jinja2", "completion_path": "Internet/Jinja2/src/jinja2/idtracking.py", "signature_position": [22, 24], "body_position": [25, 27], "dependency": {"intra_class": [], "intra_file": ["jinja2.idtracking.Symbols", "jinja2.idtracking.Symbols.__init__", "jinja2.idtracking.Symbols.analyze_node"], "cross_file": []}, "requirement": {"Functionality": "This function creates a Symbols instance for a given node and parent symbols.", "Arguments": ":param node: nodes.Node. The node for which symbols need to be created.\n:param parent_symbols: Optional[Symbols]. The parent symbols to be used as the parent of the created Symbols instance. Defaults to None.\n:return: Symbols. The created Symbols instance."}, "tests": ["tests/test_idtracking.py::test_if_branching_multi_scope", "tests/test_idtracking.py::test_basics", "tests/test_idtracking.py::test_if_branching_stores_undefined", "tests/test_idtracking.py::test_complex", "tests/test_idtracking.py::test_if_branching_stores"], "indent": 4}
{"namespace": "jinja2.bccache.MemcachedBytecodeCache.dump_bytecode", "type": "method", "project_path": "Internet/Jinja2", "completion_path": "Internet/Jinja2/src/jinja2/bccache.py", "signature_position": [395, 395], "body_position": [396, 406], "dependency": {"intra_class": ["jinja2.bccache.MemcachedBytecodeCache.client", "jinja2.bccache.MemcachedBytecodeCache.ignore_memcache_errors", "jinja2.bccache.MemcachedBytecodeCache.prefix", "jinja2.bccache.MemcachedBytecodeCache.timeout"], "intra_file": ["jinja2.bccache.Bucket.bytecode_to_string", "jinja2.bccache.Bucket.key", "jinja2.bccache._MemcachedClient.set"], "cross_file": []}, "requirement": {"Functionality": "This function is used to dump the bytecode of a bucket into the Memcached cache. The key is generated by concatenating the prefix and the bucket key, and the bytecode is converted into a string. If the timeout is specified, it is used to set the timeout for the key-value pair. If an exception occurs during the process and the flag to ignore errors is not set, the exception is re-raised.", "Arguments": ":param self: MemcachedBytecodeCache. An instance of the MemcachedBytecodeCache class.\n:param bucket: Bucket. The bucket containing the bytecode to be dumped into the cache.\n:return: None."}, "tests": ["tests/test_bytecode_cache.py::TestMemcachedBytecodeCache::test_exception", "tests/test_bytecode_cache.py::TestMemcachedBytecodeCache::test_dump_load"], "indent": 8}
{"namespace": "mrjob.fs.hadoop.HadoopFilesystem.touchz", "type": "method", "project_path": "System/mrjob", "completion_path": "System/mrjob/mrjob/fs/hadoop.py", "signature_position": [340, 340], "body_position": [341, 344], "dependency": {"intra_class": ["mrjob.fs.hadoop.HadoopFilesystem.invoke_hadoop"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Create an empty file at the specified path in the Hadoop filesystem. It invokes the Hadoop command to perform the operation and raises an IOError \"Could not touchz path\" if the operation fails.", "Arguments": ":param self: HadoopFilesystem. An instance of the HadoopFilesystem class.\n:param path: String. The path where the empty file should be created.\n:return: No return values."}, "tests": ["tests/fs/test_hadoop.py::HadoopFSTestCase::test_touchz"], "indent": 8}
{"namespace": "authlib.common.encoding.json_b64encode", "type": "function", "project_path": "Internet/Authlib", "completion_path": "Internet/Authlib/authlib/common/encoding.py", "signature_position": [63, 63], "body_position": [64, 66], "dependency": {"intra_class": [], "intra_file": ["authlib.common.encoding.json_dumps", "authlib.common.encoding.to_bytes", "authlib.common.encoding.urlsafe_b64encode"], "cross_file": []}, "requirement": {"Functionality": "Encode the given text as JSON and then base64 encode it. If the input text is already a dictionary, it is first converted to JSON format. Then, the resulting JSON string is encoded.", "Arguments": ":param text: The text to be encoded. It can be either a string or a dictionary.\n:return: The base64 encoded string."}, "tests": ["tests/jose/test_ecdh_1pu.py::ECDH1PUTest::test_ecdh_1pu_key_agreement_computation_appx_b", "tests/jose/test_jwe.py::JWETest::test_deserialize_json_fails_if_protected_header_contains_unknown_field_while_private_fields_restricted"], "indent": 4}
{"namespace": "boto.dynamodb2.items.Item.save", "type": "method", "project_path": "Internet/boto", "completion_path": "Internet/boto/boto/dynamodb2/items.py", "signature_position": [415, 415], "body_position": [445, 458], "dependency": {"intra_class": ["boto.dynamodb2.items.Item.build_expects", "boto.dynamodb2.items.Item.mark_clean", "boto.dynamodb2.items.Item.needs_save", "boto.dynamodb2.items.Item.prepare_full", "boto.dynamodb2.items.Item.table"], "intra_file": [], "cross_file": ["boto.dynamodb2.table.Table._put_item"]}, "requirement": {"Functionality": "This function saves all data of an Item instance to DynamoDB. By default, it checks if any fields have changed since the Item was constructed, and if so, it fails to save in order to prevent data loss. If the overwrite parameter is set to True, the item will be forcibly overwritten in DynamoDB, even if the data has changed.", "Arguments": ":param self: Item. An instance of the Item class.\n:param overwrite: Bool. Whether to forcibly overwrite the item in DynamoDB, even if the data has changed. Defaults to False.\n:return: Bool. True if the save is successful, False if no save was performed."}, "tests": ["tests/unit/dynamodb2/test_table.py::ItemTestCase::test_save_with_changes_overwrite", "tests/unit/dynamodb2/test_table.py::ItemTestCase::test_save_with_changes"], "indent": 8}
{"namespace": "twilio.jwt.client.ClientCapabilityToken.allow_client_outgoing", "type": "method", "project_path": "Communications/twilio-fatisar", "completion_path": "Communications/twilio-fatisar/twilio/jwt/client/__init__.py", "signature_position": [52, 52], "body_position": [59, 63], "dependency": {"intra_class": ["twilio.jwt.client.ClientCapabilityToken.capabilities"], "intra_file": ["twilio.jwt.client.ScopeURI", "twilio.jwt.client.ScopeURI.__init__", "twilio.jwt.client.ScopeURI.add_param"], "cross_file": []}, "requirement": {"Functionality": "This function allows the user of the ClientCapabilityToken to make outgoing connections. It creates a scope URI with the given application SID and any additional keyword arguments provided. If there are additional keyword arguments, they are added as parameters to the scope URI. Finally, the scope URI is added to the capabilities dictionary of the ClientCapabilityToken instance.", "Arguments": ":param self: ClientCapabilityToken. An instance of the ClientCapabilityToken class.\n:param application_sid: str. The application SID to contact.\n:param kwargs: Additional keyword arguments to be passed to the application.\n:return: No return values."}, "tests": ["tests/unit/jwt/test_client.py::ClientCapabilityTokenTest::test_outbound_permissions", "tests/unit/jwt/test_client.py::ClientCapabilityTokenTest::test_outbound_permissions_params", "tests/unit/jwt/test_client.py::ClientCapabilityTokenTest::test_decode"], "indent": 8}
{"namespace": "bplustree.memory.FileMemory.set_metadata", "type": "method", "project_path": "Database/bplustree", "completion_path": "Database/bplustree/bplustree/memory.py", "signature_position": [235, 235], "body_position": [236, 246], "dependency": {"intra_class": ["bplustree.memory.FileMemory._tree_conf", "bplustree.memory.FileMemory._write_page_in_tree"], "intra_file": [], "cross_file": ["bplustree.const.ENDIAN", "bplustree.const.OTHERS_BYTES", "bplustree.const.PAGE_REFERENCE_BYTES", "bplustree.const.TreeConf"]}, "requirement": {"Functionality": "Set the metadata of the FileMemory instance. It sets the root node page and tree configuration parameters in the instance.", "Arguments": ":param self: FileMemory. An instance of the FileMemory class.\n:param root_node_page: Integer. The page number of the root node.\n:param tree_conf: TreeConf. The tree configuration object containing page size, order, key size, and value size.\n:return: No return values."}, "tests": ["tests/test_memory.py::test_file_memory_metadata"], "indent": 8}
{"namespace": "mrjob.conf.load_opts_from_mrjob_conf", "type": "function", "project_path": "System/mrjob", "completion_path": "System/mrjob/mrjob/conf.py", "signature_position": [233, 234], "body_position": [256, 260], "dependency": {"intra_class": [], "intra_file": ["mrjob.conf._expanded_mrjob_conf_path", "mrjob.conf._load_opts_from_mrjob_conf"], "cross_file": []}, "requirement": {"Functionality": "This function loads a list of dictionaries representing the options in the mrjob.conf file for a specific runner. It resolves includes and returns [(path, values)]. If the conf_path is not found, it returns [(None, {})].\nFirst checks if already_loaded is None and assigns an empty list to it if it is. Then it expands the conf path. Finally, it load options.\n", "Arguments": ":param runner_alias: str. String identifier of the runner type, e.g. \"emr\", \"local\", etc.\n:param conf_path: str. Location of the file to load.\n:param already_loaded: list. List of real (according to os.path.realpath()) conf paths that have already been loaded. (used by load_opts_from_mrjob_confs() function).\n:return: list. A list of dictionaries representing the options in the mrjob.conf file for a specific runner. [(path, values)]\n"}, "tests": ["tests/test_conf.py::MRJobBasicConfTestCase::test_include_order_beats_include", "tests/test_conf.py::MRJobBasicConfTestCase::test_relative_include", "tests/test_conf.py::MRJobBasicConfTestCase::test_include_relative_to_real_path", "tests/test_conf.py::MRJobBasicConfTestCase::test_doubly_recursive_include", "tests/test_conf.py::MRJobBasicConfTestCase::test_load_mrjob_conf_and_load_opts"], "indent": 4}
{"namespace": "pyramid.renderers.render_to_response", "type": "function", "project_path": "Internet/pyramid", "completion_path": "Internet/pyramid/src/pyramid/renderers.py", "signature_position": [72, 74], "body_position": [117, 132], "dependency": {"intra_class": [], "intra_file": ["pyramid.renderers.RendererHelper", "pyramid.renderers.RendererHelper.__init__", "pyramid.renderers.RendererHelper.render_to_response"], "cross_file": ["pyramid.path.caller_package", "pyramid.util.hide_attrs", "pyramid.request.Request.response", "pyramid.request.Request.registry"]}, "requirement": {"Functionality": "This function uses a renderer to render the value (or set of values), and uses the result of the renderer's ``__call__`` method (usually a string or Unicode) as the response body.", "Arguments": ":param renderer_name: String. The name of the renderer to be used. It can be a template or a static renderer.\n:param value: Any. For template renderings, this should be a dictionary.  For other renderers, this will need to be whatever sort of value the renderer expects.\n:param request: Request. The request object that provides system values to the renderer. It is used to provide the most correct 'system' values such as `request` and `context`.\n:param package: String. The name of the package to be used for resolving relative asset specifications. If not provided, the package name of the caller of this function will be used as the package.\n:param response: Response. The response object to be used for rendering. If not provided, a new response object will be created for each call.\n:return: String. The result of the renderer's ``__call__`` method (usually a string or Unicode)."}, "tests": ["tests/test_config/test_testing.py::TestingConfiguratorMixinTests::test_testing_add_renderer", "tests/test_config/test_testing.py::TestingConfiguratorMixinTests::test_testing_add_template", "tests/test_config/test_testing.py::TestingConfiguratorMixinTests::test_testing_add_renderer_explicitrenderer", "tests/test_config/test_testing.py::TestingConfiguratorMixinTests::test_testing_add_renderer_twice"], "indent": 4}
{"namespace": "mopidy.config.types.Pair.serialize", "type": "method", "project_path": "Multimedia/Mopidy", "completion_path": "Multimedia/Mopidy/mopidy/config/types.py", "signature_position": [261, 261], "body_position": [262, 280], "dependency": {"intra_class": ["mopidy.config.types.Pair._optional_pair", "mopidy.config.types.Pair._separator", "mopidy.config.types.Pair._subtypes"], "intra_file": ["mopidy.config.types.String.serialize"], "cross_file": []}, "requirement": {"Functionality": "Serialize a pair of values into a string representation. It first serializes the first value using the appropriate subtype's serialization, then serializes the second value using the appropriate subtype's serialization. If the display flag is False and the pair is optional and the serialized values are the same, it returns only the serialized first value. Otherwise, it returns a string representation of the pair with the separator between the serialized values.", "Arguments": ":param self: Pair. An instance of the Pair class.\n:param value: The pair of values to be serialized.\n:param display: Bool. Whether to display the serialized values. Defaults to False.\n:return: String. The serialized representation of the pair."}, "tests": ["tests/config/test_types.py::TestPair::test_serialize_with_custom_separator", "tests/config/test_types.py::TestPair::test_serialize_nested_pair", "tests/config/test_types.py::TestPair::test_serialize_returns_single_value_with_optional_pair", "tests/config/test_types.py::TestPair::test_serialize"], "indent": 8}
{"namespace": "boto.s3.key.Key.get_contents_to_filename", "type": "method", "project_path": "Internet/boto", "completion_path": "Internet/boto/boto/s3/key.py", "signature_position": [1668, 1673], "body_position": [1722, 1739], "dependency": {"intra_class": ["boto.s3.key.Key.get_contents_to_file", "boto.s3.key.Key.last_modified", "boto.s3.key.Key.open"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function retrieves an object from S3 using the name of the Key object as the key in S3 and stores the contents of the object to a file specified by 'filename'. It provides various options for customization such as specifying additional headers, using a callback function to report progress, setting the granularity of the callback, retrieving a torrent file, using a resumable download handler, overriding response headers, and specifying a particular version of the object.", "Arguments": ":param self: Key. An instance of the Key class.\n:param filename: String. The filename of where to put the file contents.\n:param headers: Dict. Any additional headers to send in the request.\n:param cb: Function. A callback function that will be called to report progress on the upload.\n:param num_cb: Int. If a callback is specified with the cb parameter, this parameter determines the granularity of the callback by defining the maximum number of times the callback will be called during the file transfer.\n:param torrent: Bool. If True, returns the contents of a torrent file as a string.\n:param res_download_handler: ResumableDownloadHandler. If provided, this handler will perform the download.\n:param response_headers: Dict. A dictionary containing HTTP headers/values that will override any headers associated with the stored object in the response.\n:param version_id: Str. The ID of a particular version of the object. If this parameter is not supplied but the Key object has a \"version_id\" attribute, that value will be used when retrieving the object. You can set the Key object's \"version_id\" attribute to None to always grab the latest version from a version-enabled bucket.\n:return: No return values."}, "tests": ["tests/unit/s3/test_key.py::TestFileError::test_file_error"], "indent": 8}
{"namespace": "mrjob.fs.local.LocalFilesystem._cat_file", "type": "method", "project_path": "System/mrjob", "completion_path": "System/mrjob/mrjob/fs/local.py", "signature_position": [52, 52], "body_position": [53, 57], "dependency": {"intra_class": [], "intra_file": ["mrjob.fs.local._from_file_uri"], "cross_file": ["mrjob.cat.decompress"]}, "requirement": {"Functionality": "Reads a file from the local filesystem and yields its content in chunks of bytes.\nFirst converts the file path from a file URI format to a local file path format. Then, it iterates over the file content in chunks.\n", "Arguments": ":param self: LocalFilesystem, an instance of the LocalFilesystem class.\n:param path: String, the URI or path of the file to be read.\n:return: bytes. Yields chunks of content from the file.\n"}, "tests": ["tests/fs/test_local.py::CatTestCase::test_cat_gz", "tests/fs/test_local.py::CatTestCase::test_yields_lines", "tests/fs/test_local.py::CatTestCase::test_cat_uncompressed", "tests/fs/test_local.py::CatTestCase::test_cat_file_uri", "tests/fs/test_local.py::CatTestCase::test_cat_bz2"], "indent": 8}
{"namespace": "falcon.asgi.reader.BufferedReader.peek", "type": "method", "project_path": "Internet/falcon", "completion_path": "Internet/falcon/falcon/asgi/reader.py", "signature_position": [242, 242], "body_position": [243, 256], "dependency": {"intra_class": ["falcon.asgi.reader.BufferedReader._buffer", "falcon.asgi.reader.BufferedReader._buffer_len", "falcon.asgi.reader.BufferedReader._buffer_pos", "falcon.asgi.reader.BufferedReader._chunk_size", "falcon.asgi.reader.BufferedReader._source", "falcon.asgi.reader.BufferedReader._trim_buffer"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function peeks into the buffered data and returns the specified number of bytes. It first checks if the specified size is valid, and then trims the buffer if necessary. If the buffer does not have enough data, it reads from the source asynchronously and adds the chunks to the buffer until the desired size is reached. Finally, it returns the requested number of bytes from the buffer.", "Arguments": ":param self: BufferedReader. An instance of the BufferedReader class.\n:param size: Integer. The number of bytes to peek into the buffer. Defaults to -1, which means peeking the entire buffer.\n:return: Bytes. The peeked bytes from the buffer."}, "tests": ["tests/asgi/test_buffered_reader.py::test_read_until_shared_boundary", "tests/asgi/test_buffered_reader.py::test_peek_at_eof"], "indent": 8}
{"namespace": "pythonforandroid.prerequisites.CmakePrerequisite.darwin_checker", "type": "method", "project_path": "Utilities/python-for-android", "completion_path": "Utilities/python-for-android/pythonforandroid/prerequisites.py", "signature_position": [357, 357], "body_position": [358, 361], "dependency": {"intra_class": [], "intra_file": ["pythonforandroid.prerequisites.Prerequisite._darwin_get_brew_formula_location_prefix"], "cross_file": []}, "requirement": {"Functionality": "Check if the prerequisite for CMake on macOS is met. It checks if the brew formula for CMake is installed on the system.", "Arguments": ":param self: CmakePrerequisite. An instance of the CmakePrerequisite class.\n:return: Bool. True if the brew formula for CMake is installed, False otherwise."}, "tests": ["tests/test_prerequisites.py::TestCmakePrerequisite::test_darwin_checker"], "indent": 8}
{"namespace": "hbmqtt.codecs.encode_string", "type": "function", "project_path": "Communications/hbmqtt", "completion_path": "Communications/hbmqtt/hbmqtt/codecs.py", "signature_position": [90, 90], "body_position": [91, 93], "dependency": {"intra_class": [], "intra_file": ["hbmqtt.codecs.int_to_bytes"], "cross_file": []}, "requirement": {"Functionality": "Encode the given string into bytes using utf-8 encoding. Add the length of the encoded data as a prefix of 2 bytes before the actual data.\n", "Arguments": ":param string: String, a string to be encoded.\n:return: Bytes, the encoded string as bytes.\n"}, "tests": ["tests/test_codecs.py::TestCodecs::test_encode_string"], "indent": 4}
{"namespace": "pycorrector.en_spell.EnSpell.candidates", "type": "method", "project_path": "Text-Processing/pycorrector", "completion_path": "Text-Processing/pycorrector/pycorrector/en_spell.py", "signature_position": [90, 90], "body_position": [96, 97], "dependency": {"intra_class": ["pycorrector.en_spell.EnSpell.check_init", "pycorrector.en_spell.EnSpell.edits1", "pycorrector.en_spell.EnSpell.edits2", "pycorrector.en_spell.EnSpell.known"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function generates possible spelling corrections for a given word. It checks whether zero, one, or two edits are needed to correct the word. If zero edit is needed, it returns the set of the given words. If one edit is needed, it returns the set of known words by applying one edit. If two edits are needed, it returns the set of known words by applying two edits. If no corrections are found, it returns the original word. It checks if the EnSpell instance has been initialized before performing the operation.", "Arguments": ":param self: EnSpell. An instance of the EnSpell class.\n:param word: String. The word for which spelling corrections need to be generated.\n:return: Set of strings. The set of possible spelling corrections for the word."}, "tests": ["tests/en_spell_bug_fix_test.py::EnBugTestCase::test_en_bug_correct2", "tests/en_spell_dict_test.py::TestEnSpell::test_candidates"], "indent": 8}
{"namespace": "ehforwarderbot.chat.PrivateChat.verify", "type": "method", "project_path": "Communications/ehforwarderbot", "completion_path": "Communications/ehforwarderbot/ehforwarderbot/chat.py", "signature_position": [675, 675], "body_position": [676, 678], "dependency": {"intra_class": [], "intra_file": ["ehforwarderbot.chat.Chat", "ehforwarderbot.chat.ChatMember", "ehforwarderbot.chat.Chat.members", "ehforwarderbot.chat.BaseChat.verify"], "cross_file": []}, "requirement": {"Functionality": "This function verifies the validity of a PrivateChat instance. It first calls the same method of the superclass, and then checks if all members of the chat are valid chat member. If any member is not valid, an assertion error is raised.", "Arguments": ":param self: PrivateChat. An instance of the PrivateChat class.\n:return: No return values."}, "tests": ["tests/test_chat.py::test_verify_missing_uid"], "indent": 8}
{"namespace": "twilio.jwt.client.ClientCapabilityToken.allow_event_stream", "type": "method", "project_path": "Communications/twilio-fatisar", "completion_path": "Communications/twilio-fatisar/twilio/jwt/client/__init__.py", "signature_position": [76, 76], "body_position": [80, 84], "dependency": {"intra_class": ["twilio.jwt.client.ClientCapabilityToken.capabilities"], "intra_file": ["twilio.jwt.client.ScopeURI", "twilio.jwt.client.ScopeURI.__init__", "twilio.jwt.client.ScopeURI.add_param"], "cross_file": []}, "requirement": {"Functionality": "This function allows the user of the ClientCapabilityToken instance to access their event stream. It creates a scope URI with the necessary parameters and adds it to the capabilities dictionary of the instance.", "Arguments": ":param self: ClientCapabilityToken. An instance of the ClientCapabilityToken class.\n:param kwargs: Keyword arguments that can be used to specify additional parameters for the event stream.\n:return: No return values."}, "tests": ["tests/unit/jwt/test_client.py::ClientCapabilityTokenTest::test_encode_full_payload", "tests/unit/jwt/test_client.py::ClientCapabilityTokenTest::test_events", "tests/unit/jwt/test_client.py::ClientCapabilityTokenTest::test_events_with_filters", "tests/unit/jwt/test_client.py::ClientCapabilityTokenTest::test_decode"], "indent": 8}
{"namespace": "alembic.operations.ops.CreatePrimaryKeyOp.to_constraint", "type": "method", "project_path": "Database/alembic", "completion_path": "Database/alembic/alembic/operations/ops.py", "signature_position": [281, 283], "body_position": [284, 292], "dependency": {"intra_class": ["alembic.operations.ops.CreatePrimaryKeyOp.columns", "alembic.operations.ops.CreatePrimaryKeyOp.constraint_name", "alembic.operations.ops.CreatePrimaryKeyOp.kw", "alembic.operations.ops.CreatePrimaryKeyOp.schema", "alembic.operations.ops.CreatePrimaryKeyOp.table_name"], "intra_file": [], "cross_file": ["alembic.operations.schemaobj", "alembic.operations.schemaobj.SchemaObjects", "alembic.operations.schemaobj.SchemaObjects.primary_key_constraint", "alembic.runtime.migration.MigrationContext"]}, "requirement": {"Functionality": "This function converts the CreatePrimaryKeyOp object into a PrimaryKeyConstraint object. It creates a schema object based on the given migration context and uses it to create the primary key constraint.", "Arguments": ":param self: CreatePrimaryKeyOp. An instance of the CreatePrimaryKeyOp class.\n:param migration_context: Optional. The migration context to be used. Defaults to None.\n:return: PrimaryKeyConstraint. The created PrimaryKeyConstraint object."}, "tests": ["tests/test_autogen_diffs.py::OrigObjectTest::test_add_pk_no_orig"], "indent": 8}
{"namespace": "kinto.core.authorization.RouteFactory.get_permission_object_id", "type": "method", "project_path": "Internet/kinto", "completion_path": "Internet/kinto/kinto/core/authorization.py", "signature_position": [236, 236], "body_position": [245, 261], "dependency": {"intra_class": ["kinto.core.authorization.RouteFactory.on_plural_endpoint", "kinto.core.authorization.RouteFactory.resource_name"], "intra_file": [], "cross_file": ["kinto.core.utils", "kinto.core.utils.instance_uri", "kinto.core.utils.strip_uri_prefix"]}, "requirement": {"Functionality": "This function returns the permission object id for the current request. It determines the object URI based on the request path and the specified object_id. If the request is on a plural endpoint and object_id is provided, it finds the object URI by inspecting the \"plural\" service and its sibling \"object\" service.", "Arguments": ":param self: RouteFactory. An instance of the RouteFactory class.\n:param request: The current request object.\n:param object_id: The object id to be used in the object URI. Defaults to None.\n:return: The permission object id for the current request."}, "tests": ["tests/core/test_authorization.py::GuestAuthorizationPolicyTest::test_perm_object_id_is_naive_if_no_object_path_exists"], "indent": 8}
{"namespace": "mopidy.config._load", "type": "function", "project_path": "Multimedia/Mopidy", "completion_path": "Multimedia/Mopidy/mopidy/config/__init__.py", "signature_position": [151, 151], "body_position": [152, 181], "dependency": {"intra_class": [], "intra_file": ["mopidy.config._load_file", "mopidy.config.logger"], "cross_file": ["mopidy.internal.path", "mopidy.internal.path.expand_path"]}, "requirement": {"Functionality": "This function loads configuration settings from multiple sources and returns a dictionary containing the loaded configuration. It first creates a `configparser.RawConfigParser` instance and sets the inline comment prefixes. Then, it loads the configuration from the builtin defaults by reading the strings in the `defaults` list. Next, it iterates over the `files` list and loads the configuration from each file. If a file is a directory, it iterates over the files in the directory and loads the configuration from each file with the \".conf\" suffix. After loading the configuration from all sources, it creates a dictionary `raw_config` where each section is a key and the corresponding value is a dictionary of key-value pairs for that section. Finally, it updates the `raw_config` dictionary with any command line overrides specified in the `overrides` list.", "Arguments": ":param files: List of strings. A list of file paths or directories containing configuration files.\n:param defaults: List of strings. A list of default configuration strings.\n:param overrides: List of tuples. A list of tuples where each tuple contains the section, key, and value for a command line override.\n:return: Dictionary. A dictionary containing the loaded configuration settings."}, "tests": ["tests/config/test_config.py::LoadConfigTest::test_load_directory_only_conf_files", "tests/config/test_config.py::LoadConfigTest::test_load_single_default", "tests/config/test_config.py::LoadConfigTest::test_load_single_file", "tests/config/test_config.py::LoadConfigTest::test_load_ignore_inline_comment", "tests/config/test_config.py::LoadConfigTest::test_load_missing_file"], "indent": 4}
{"namespace": "diffprivlib.mechanisms.base.bernoulli_neg_exp", "type": "function", "project_path": "Security/diffprivlib", "completion_path": "Security/diffprivlib/diffprivlib/mechanisms/base.py", "signature_position": [234, 234], "body_position": [254, 269], "dependency": {"intra_class": [], "intra_file": ["diffprivlib.mechanisms.base.bernoulli_neg_exp"], "cross_file": ["diffprivlib.utils.check_random_state"]}, "requirement": {"Functionality": "This function samples from the Bernoulli distribution with parameter exp(-gamma). It generates a random number based on the given gamma value and returns either 0 or 1.", "Arguments": ":param gamma: Float. The parameter to sample from Bernoulli(exp(-gamma)). Must be non-negative.\n:param random_state: Int or RandomState, optional. Controls the randomness of the mechanism. To obtain a deterministic behavior during randomization, \"random_state\" has to be fixed to an integer.\n:return: Int. One sample from the Bernoulli(exp(-gamma)) distribution."}, "tests": ["tests/mechanisms/test_BernoulliNegExp.py::TestBernoulliNegExp::test_output_domain", "tests/mechanisms/test_BernoulliNegExp.py::TestBernoulliNegExp::test_bad_rng", "tests/mechanisms/test_BernoulliNegExp.py::TestBernoulliNegExp::test_zero_gamma", "tests/mechanisms/test_BernoulliNegExp.py::TestBernoulliNegExp::test_bad_gamma", "tests/mechanisms/test_BernoulliNegExp.py::TestBernoulliNegExp::test_infinite_gamma"], "indent": 4}
{"namespace": "boltons.statsutils.Stats.get_histogram_counts", "type": "method", "project_path": "Utilities/boltons", "completion_path": "Utilities/boltons/boltons/statsutils.py", "signature_position": [557, 557], "body_position": [575, 610], "dependency": {"intra_class": ["boltons.statsutils.Stats._get_bin_bounds", "boltons.statsutils.Stats.data", "boltons.statsutils.Stats.min"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function produces a list of (bin, count) pairs that represents a histogram of the Stats object's data using fixed-width bins.\n", "Arguments": ":param self: Stats. An instance of the Stats class.\n:param bins: int or list of float. The maximum number of bins or the list of floating-point bin boundaries. Defaults to the output of Freedman's algorithm.\n:param bin_digits: int. Number of digits used to round down the bin boundaries. Defaults to 1.\n:return: list of (bin, count) pairs. The histogram counts of the Stats object's data.\n"}, "tests": ["tests/test_statsutils_histogram.py::test_check_sum"], "indent": 8}
{"namespace": "boto.dynamodb.types.Dynamizer.encode", "type": "method", "project_path": "Internet/boto", "completion_path": "Internet/boto/boto/dynamodb/types.py", "signature_position": [267, 267], "body_position": [273, 279], "dependency": {"intra_class": ["boto.dynamodb.types.Dynamizer._get_dynamodb_type"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function encodes a Python type to the format expected by DynamoDB. It determines the DynamoDB type of the input attribute and uses the corresponding encoder method to encode the attribute.", "Arguments": ":param self: Dynamizer. An instance of the Dynamizer class.\n:param attr: The attribute to be encoded.\n:return: Dictionary. The encoded attribute in the format expected by DynamoDB."}, "tests": ["tests/unit/dynamodb/test_types.py::TestDynamizer::test_float_conversion_errors", "tests/unit/dynamodb/test_types.py::TestDynamizer::test_non_boolean_conversions", "tests/unit/dynamodb/test_types.py::TestDynamizer::test_encoding_to_dynamodb", "tests/unit/dynamodb/test_types.py::TestDynamizer::test_lossy_float_conversions"], "indent": 8}
{"namespace": "mingus.containers.instrument.Guitar.can_play_notes", "type": "method", "project_path": "Multimedia/mingus", "completion_path": "Multimedia/mingus/mingus/containers/instrument.py", "signature_position": [119, 119], "body_position": [120, 122], "dependency": {"intra_class": [], "intra_file": ["mingus.containers.instrument.Instrument", "mingus.containers.instrument.Instrument.can_play_notes"], "cross_file": []}, "requirement": {"Functionality": "Check if the guitar can play the given notes. It checks if the number of notes is greater than 6, and if so, returns False. Otherwise, it just returns the parent method.", "Arguments": ":param self: Guitar. An instance of the Guitar class.\n:param notes: List of strings. The notes to be played.\n:return: Bool. True if the guitar can play the notes, False otherwise."}, "tests": ["tests/unit/containers/test_instrument.py::test_Instrument::test_can_play_notes"], "indent": 8}
{"namespace": "pyramid.util.InstancePropertyMixin.set_property", "type": "method", "project_path": "Internet/pyramid", "completion_path": "Internet/pyramid/src/pyramid/util.py", "signature_position": [196, 196], "body_position": [248, 250], "dependency": {"intra_class": [], "intra_file": ["pyramid.util.InstancePropertyHelper", "pyramid.util.InstancePropertyHelper.set_property"], "cross_file": []}, "requirement": {"Functionality": "This function adds a callable or a property descriptor to an instance.", "Arguments": ":param self: InstancePropertyMixin. An instance of the InstancePropertyMixin class.\n:param callable: Callable or property descriptor. The callable or property descriptor to be added to the instance.\n:param name: String. The name of the property. If None, the name will be computed from the name of the callable. Defaults to None.\n:param reify: Bool. Whether the property should be reified. If True, the value of the property is cached and computed only once. Defaults to False.\n:return: No return values."}, "tests": ["tests/test_util.py::Test_InstancePropertyMixin::test_callable_with_name", "tests/test_util.py::Test_InstancePropertyMixin::test_reset_reify", "tests/test_util.py::Test_InstancePropertyMixin::test_property_with_name", "tests/test_util.py::Test_InstancePropertyMixin::test_callable", "tests/test_util.py::Test_InstancePropertyMixin::test_property_with_reify"], "indent": 8}
{"namespace": "diffprivlib.tools.utils.nansum", "type": "function", "project_path": "Security/diffprivlib", "completion_path": "Security/diffprivlib/diffprivlib/tools/utils.py", "signature_position": [657, 658], "body_position": [709, 712], "dependency": {"intra_class": [], "intra_file": ["diffprivlib.tools.utils._sum"], "cross_file": ["diffprivlib.utils.warn_unused_args"]}, "requirement": {"Functionality": "This function calculates the sum of array elements over a given axis with differential privacy, while ignoring NaN values.", "Arguments": ":param array: array_like. The elements to be summed.\n:param epsilon: float, default: 1.0. The privacy parameter epsilon.\n:param bounds: tuple, optional. The bounds of the values of the array, in the form (min, max).\n:param axis: None or int or tuple of ints, optional. The axis or axes along which the sum is performed. If None, the sum is performed on all elements. If negative, it counts from the last to the first axis. If a tuple of ints, the sum is performed on the specified axes.\n:param dtype: dtype, optional. The type of the returned array and accumulator. If not specified, the dtype of the input array is used.\n:param keepdims: bool, default: False. If True, the reduced axes are left in the result as dimensions with size one.\n:param random_state: int or RandomState, optional. Controls the randomness of the algorithm.\n:param accountant: BudgetAccountant, optional. Accountant to keep track of privacy budget.\n:param **unused_args: Should warn the user if any other parameters are passed.\n:return: ndarray. An array with the same shape as the input array, with the specified axis removed. If the input array is 0-d or if axis is None, a scalar is returned."}, "tests": ["tests/tools/test_nansum.py::TestNansum::test_clipped_output", "tests/tools/test_nansum.py::TestNansum::test_int_output", "tests/tools/test_nansum.py::TestNansum::test_missing_bounds", "tests/tools/test_nansum.py::TestNansum::test_array_like", "tests/tools/test_nansum.py::TestNansum::test_no_bounds"], "indent": 4}
{"namespace": "alembic.autogenerate.render._render_constraint", "type": "function", "project_path": "Database/alembic", "completion_path": "Database/alembic/alembic/autogenerate/render.py", "signature_position": [884, 888], "body_position": [889, 895], "dependency": {"intra_class": [], "intra_file": ["alembic.autogenerate.render._constraint_renderers"], "cross_file": ["alembic.autogenerate.api.AutogenContext", "alembic.langhelpers.Dispatcher.dispatch", "alembic.util", "alembic.util.warn"]}, "requirement": {"Functionality": "This function renders a constraint object based on its type. It first tries to find a renderer for the constraint object using dispatch. If a renderer is found, it calls the renderer function with the constraint object, autogen_context, and namespace_metadata as arguments and returns the result. If no renderer is found, it returns a string indicating that the Python object is unknown.", "Arguments": ":param constraint: Constraint. The constraint object to be rendered.\n:param autogen_context: AutogenContext. The autogen context object.\n:param namespace_metadata: Optional MetaData. The metadata associated with the namespace.\n:return: Optional string. The rendered constraint string or a string indicating that the Python object is unknown."}, "tests": ["tests/test_autogen_render.py::AutogenRenderTest::test_render_fk_constraint_link_to_name", "tests/test_autogen_render.py::AutogenRenderTest::test_render_fk_constraint_resolve_key", "tests/test_autogen_render.py::AutogenRenderTest::test_render_fk_constraint_use_alter", "tests/test_autogen_render.py::AutogenRenderTest::test_render_fk_constraint_kwarg", "tests/test_autogen_render.py::AutogenRenderTest::test_render_fk_constraint_bad_table_resolve_dont_get_confused"], "indent": 4}
{"namespace": "boltons.listutils.BarrelList.insert", "type": "method", "project_path": "Utilities/boltons", "completion_path": "Utilities/boltons/boltons/listutils.py", "signature_position": [144, 144], "body_position": [145, 154], "dependency": {"intra_class": ["boltons.listutils.BarrelList._balance_list", "boltons.listutils.BarrelList._translate_index", "boltons.listutils.BarrelList.lists"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Insert an item at the specified index in the BarrelList instance.\n", "Arguments": ":param self: BarrelList, an instance of BarrelList class.\n:param index: Int, the index at which the item will be inserted.\n:param item: The item to be inserted.\n:return: No return values.\n"}, "tests": ["tests/test_listutils.py::test_barrel_list"], "indent": 8}
{"namespace": "alembic.script.revision.RevisionMap.add_revision", "type": "method", "project_path": "Database/alembic", "completion_path": "Database/alembic/alembic/script/revision.py", "signature_position": [414, 414], "body_position": [421, 468], "dependency": {"intra_class": ["alembic.script.revision.RevisionMap._add_branches", "alembic.script.revision.RevisionMap._add_depends_on", "alembic.script.revision.RevisionMap._map_branch_labels", "alembic.script.revision.RevisionMap._normalize_depends_on", "alembic.script.revision.RevisionMap._real_bases", "alembic.script.revision.RevisionMap._real_heads", "alembic.script.revision.RevisionMap._revision_map", "alembic.script.revision.RevisionMap.bases", "alembic.script.revision.RevisionMap.heads"], "intra_file": ["alembic.script.revision.Revision", "alembic.script.revision.Revision._all_down_revisions", "alembic.script.revision.Revision._is_real_base", "alembic.script.revision.Revision._is_real_head", "alembic.script.revision.Revision.is_base", "alembic.script.revision.Revision.is_head", "alembic.script.revision.Revision.revision"], "cross_file": ["alembic.util", "alembic.util.not_none.add_nextrev", "alembic.util.warn"]}, "requirement": {"Functionality": "This function adds a single revision to an existing revision map. It performs various operations such as adding the revision to the map, adding branches, mapping branch labels, adding dependencies, updating bases and real bases, checking and adding referenced revisions, normalizing dependencies, and updating real heads and heads.", "Arguments": ":param self: RevisionMap. An instance of the RevisionMap class.\n:param revision: Revision. The revision to be added to the map.\n:param _replace: Bool. Whether to replace an existing revision with the same key. Defaults to False.\n:return: No return values."}, "tests": ["tests/test_revision.py::APITest::test_add_revision_two_head", "tests/test_revision.py::APITest::test_add_revision_one_head"], "indent": 8}
{"namespace": "imapclient.datetime_util.parse_to_datetime", "type": "function", "project_path": "Communications/IMAPClient", "completion_path": "Communications/IMAPClient/imapclient/datetime_util.py", "signature_position": [14, 14], "body_position": [23, 36], "dependency": {"intra_class": [], "intra_file": ["imapclient.datetime_util._munge", "imapclient.datetime_util.datetime_to_native"], "cross_file": ["imapclient.fixed_offset.FixedOffset"]}, "requirement": {"Functionality": "Convert an IMAP datetime string to a datetime object. \n", "Arguments": ":param timestamp: String, the IMAP datetime string to be converted.\n:param normalise: Bool, whether to adjust the converted datetime to the local time. If `normalise` is True (default), the returned datetime object will be timezone-naive but adjusted to the local time. If `normalise` is False, the returned datetime object will be unadjusted but will contain timezone information as per the input.\n:return: datetime, the converted datetime object from the IMAP datetime string.\n"}, "tests": ["tests/test_datetime_util.py::TestParsing::test_invalid"], "indent": 4}
{"namespace": "rest_framework.parsers.JSONParser.parse", "type": "method", "project_path": "Internet/djangorestframework", "completion_path": "Internet/djangorestframework/rest_framework/parsers.py", "signature_position": [54, 54], "body_position": [58, 67], "dependency": {"intra_class": ["rest_framework.parsers.JSONParser.strict"], "intra_file": [], "cross_file": ["rest_framework.exceptions.ParseError", "rest_framework.utils.json.load", "rest_framework.utils.json.strict_constant", "rest_framework.settings", "rest_framework.utils.json"]}, "requirement": {"Functionality": "This function parses an incoming bytestream as JSON and returns the resulting data. It decodes the stream using the specified encoding and parses the decoded stream into a Python object.", "Arguments": ":param self: JSONParser. An instance of the JSONParser class.\n:param stream: The bytestream to be parsed as JSON.\n:param media_type: [optional] The media type of the stream. Defaults to None.\n:param parser_context: [optional] Additional context for the parser. Defaults to None.\n:return: The parsed data as a Python object."}, "tests": ["tests/test_parsers.py::TestJSONParser::test_float_strictness"], "indent": 8}
{"namespace": "jwt.utils.base64url_decode", "type": "function", "project_path": "Utilities/PyJWT", "completion_path": "Utilities/PyJWT/jwt/utils.py", "signature_position": [25, 25], "body_position": [26, 33], "dependency": {"intra_class": [], "intra_file": ["jwt.utils.force_bytes"], "cross_file": []}, "requirement": {"Functionality": "Decode a base64url-encoded input string or bytes and return the decoded bytes. It first converts the input to bytes if it is a string, then pads the input with \"=\" characters if necessary, and finally decodes the input using the base64.urlsafe_b64decode() function.", "Arguments": ":param input: Union[bytes, str]. The base64url-encoded input string or bytes to be decoded.\n:return: bytes. The decoded bytes."}, "tests": ["tests/test_api_jws.py::TestJWS::test_custom_json_encoder", "tests/test_api_jws.py::TestJWS::test_encode_with_typ_without_keywords", "tests/test_api_jws.py::TestJWS::test_encode_with_typ_empty_string", "tests/test_algorithms.py::TestAlgorithmsRFC7520::test_hmac_verify_should_return_true_for_test_vector", "tests/test_api_jws.py::TestJWS::test_encode_with_typ"], "indent": 4}
{"namespace": "alembic.script.revision.RevisionMap.iterate_revisions", "type": "method", "project_path": "Database/alembic", "completion_path": "Database/alembic/alembic/script/revision.py", "signature_position": [774, 782], "body_position": [794, 809], "dependency": {"intra_class": ["alembic.script.revision.RevisionMap._collect_downgrade_revisions", "alembic.script.revision.RevisionMap._collect_upgrade_revisions", "alembic.script.revision.RevisionMap._topological_sort", "alembic.script.revision.RevisionMap.get_revision"], "intra_file": ["alembic.script.revision.Revision", "alembic.script.revision._RevisionIdentifierType"], "cross_file": []}, "requirement": {"Functionality": "This function iterates through script revisions starting from the upper revision identifier and ending at the lower revision identifier. It uses the `down_revision` marker inside each migration script to determine the traversal order.", "Arguments": ":param self: RevisionMap. An instance of the RevisionMap class.\n:param upper: _RevisionIdentifierType. The upper revision identifier to start the iteration from.\n:param lower: _RevisionIdentifierType. The lower revision identifier to end the iteration at.\n:param implicit_base: Bool. Whether to include the implicit base revision in the iteration. Defaults to False.\n:param inclusive: Bool. Whether to include the upper revision in the iteration. Defaults to False.\n:param assert_relative_length: Bool. Whether to assert that the number of revisions between the upper and lower is the same as the number of revisions returned. Defaults to True.\n:param select_for_downgrade: Bool. Whether to select revisions for downgrade instead of upgrade. Defaults to False.\n:return: Iterator[Revision]. An iterator that yields `Revision` objects."}, "tests": ["tests/test_revision.py::MultipleBaseCrossDependencyTestOne::test_different_branch_not_wrong_direction", "tests/test_revision.py::MultipleBranchTest::test_wrong_direction_to_base_as_none", "tests/test_revision.py::MultipleBranchTest::test_wrong_direction_to_base_as_empty", "tests/test_revision.py::MultipleBranchTest::test_same_branch_wrong_direction", "tests/test_revision.py::BranchTravellingTest::test_detect_invalid_head_selection"], "indent": 8}
{"namespace": "zulipterminal.ui_tools.boxes.WriteBox.update_recipients", "type": "method", "project_path": "Communications/zulip-term", "completion_path": "Communications/zulip-term/zulipterminal/ui_tools/boxes.py", "signature_position": [273, 273], "body_position": [274, 278], "dependency": {"intra_class": ["zulipterminal.ui_tools.boxes.WriteBox._set_regular_and_typing_recipient_user_ids", "zulipterminal.ui_tools.boxes.WriteBox.recipient_emails"], "intra_file": [], "cross_file": ["zulipterminal.config.regexes.REGEX_RECIPIENT_EMAIL"]}, "requirement": {"Functionality": "Update the recipients of the WriteBox instance based on the input from the ReadlineEdit instance. It extracts the recipient emails from the input text and sets the corresponding user IDs in the WriteBox instance.", "Arguments": ":param self: WriteBox. An instance of the WriteBox class.\n:param write_box: ReadlineEdit. An instance of the ReadlineEdit class that contains the input text.\n:return: No return values."}, "tests": ["tests/ui_tools/test_boxes.py::TestWriteBox::test_update_recipients"], "indent": 8}
{"namespace": "mrjob.fs.local.LocalFilesystem.touchz", "type": "method", "project_path": "System/mrjob", "completion_path": "System/mrjob/mrjob/fs/local.py", "signature_position": [83, 83], "body_position": [84, 90], "dependency": {"intra_class": [], "intra_file": ["mrjob.fs.local._from_file_uri"], "cross_file": []}, "requirement": {"Functionality": "Create an empty file at the specified path. If the file already exists and is not empty, raise an OSError.", "Arguments": ":param self: LocalFilesystem. An instance of the LocalFilesystem class.\n:param path: String. The path where the empty file should be created.\n:return: No return values."}, "tests": ["tests/fs/test_local.py::LocalFSTestCase::test_touchz_file_uri", "tests/fs/test_local.py::LocalFSTestCase::test_touchz"], "indent": 8}
{"namespace": "sacred.dependencies.Source.create", "type": "method", "project_path": "Utilities/sacred", "completion_path": "Utilities/sacred/sacred/dependencies.py", "signature_position": [455, 455], "body_position": [456, 461], "dependency": {"intra_class": ["sacred.dependencies.Source.__init__"], "intra_file": ["sacred.dependencies.get_commit_if_possible", "sacred.dependencies.get_digest", "sacred.dependencies.get_py_file_if_possible"], "cross_file": []}, "requirement": {"Functionality": "Create a Source instance based on the given filename. It first checks if the filename is valid and exists. Otherwise, it raises a error message - \"invalid filename or file not found {filename}\". Then it retrieves the main file, repository information, commit information, and dirty status using helper functions. Finally, it creates a Source instance with the obtained information.", "Arguments": ":param filename: String. The name of the file to create the Source instance from.\n:param save_git_info: Bool. Whether to save the git information in the Source instance. Defaults to True.\n:return: Source. The created Source instance."}, "tests": ["tests/test_ingredients.py::test_create_ingredient", "tests/test_dependencies.py::test_source_create_py", "tests/test_dependencies.py::test_custom_base_dir", "tests/test_dependencies.py::test_source_to_json", "tests/test_dependencies.py::test_source_create_empty"], "indent": 8}
{"namespace": "mssqlcli.jsonrpc.jsonrpcclient.JsonRpcClient.start", "type": "method", "project_path": "Database/mssql-cli", "completion_path": "Database/mssql-cli/mssqlcli/jsonrpc/jsonrpcclient.py", "signature_position": [31, 31], "body_position": [37, 48], "dependency": {"intra_class": ["mssqlcli.jsonrpc.jsonrpcclient.JsonRpcClient.REQUEST_THREAD_NAME", "mssqlcli.jsonrpc.jsonrpcclient.JsonRpcClient.RESPONSE_THREAD_NAME", "mssqlcli.jsonrpc.jsonrpcclient.JsonRpcClient._listen_for_request", "mssqlcli.jsonrpc.jsonrpcclient.JsonRpcClient._listen_for_response", "mssqlcli.jsonrpc.jsonrpcclient.JsonRpcClient.request_thread", "mssqlcli.jsonrpc.jsonrpcclient.JsonRpcClient.response_thread"], "intra_file": ["mssqlcli.jsonrpc.jsonrpcclient.logger"], "cross_file": []}, "requirement": {"Functionality": "This function starts the background threads to listen for responses and requests from the underlying streams. It creates two threads, one for listening to requests and one for listening to responses.", "Arguments": ":param self: JsonRpcClient. An instance of the JsonRpcClient class.\n:return: No return values."}, "tests": ["tests/jsonrpc/test_json_rpc_contracts.py::JSONRPCContractsTests::test_query_retrieve_correct_response", "tests/jsonrpc/test_json_rpc_contracts.py::JSONRPCContractsTests::test_query_subset_response_AdventureWorks2014", "tests/jsonrpc/test_json_rpc_contracts.py::JSONRPCContractsTests::test_query_execute_response_AdventureWorks2014", "tests/jsonrpc/test_jsonrpcclient.py::JsonRpcClientTests::test_submit_simple_request", "tests/jsonrpc/test_jsonrpcclient.py::JsonRpcClientTests::test_response_dequeued"], "indent": 8}
{"namespace": "alembic.command.downgrade", "type": "function", "project_path": "Database/alembic", "completion_path": "Database/alembic/alembic/command.py", "signature_position": [401, 406], "body_position": [421, 444], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["alembic.config.Config", "alembic.runtime.environment.EnvironmentContext", "alembic.script.ScriptDirectory.from_config", "alembic.script.ScriptDirectory.run_env", "alembic.util", "alembic.util.CommandError"]}, "requirement": {"Functionality": "This function is used to revert to a previous version of a database schema. It takes in a configuration object, a revision string, a boolean flag indicating whether to use SQL mode, and an optional tag. It creates a script directory based on the configuration, determines the starting revision if a range is specified, and performs the downgrade operation using the script directory. The downgrade operation is executed within an environment context, which handles the execution of the downgrade script.", "Arguments": ":param config: Config. An instance of the Config class.\n:param revision: str. The target revision or range for --sql mode.\n:param sql: bool. If True, use --sql mode.\n:param tag: Optional[str]. An arbitrary tag that can be intercepted by custom env.py scripts.\n:return: None."}, "tests": ["tests/test_command.py::UpgradeDowngradeStampTest::test_version_to_middle", "tests/test_postgresql.py::PGOfflineEnumTest::test_offline_inline_enum_drop", "tests/test_postgresql.py::PGOfflineEnumTest::test_offline_distinct_enum_drop", "tests/test_batch.py::OfflineTest::test_downgrade_batch_no_reflection", "tests/test_command.py::UpgradeDowngradeStampTest::test_version_to_none"], "indent": 4}
{"namespace": "authlib.oauth2.rfc6749.parameters.prepare_grant_uri", "type": "function", "project_path": "Internet/Authlib", "completion_path": "Internet/Authlib/authlib/oauth2/rfc6749/parameters.py", "signature_position": [7, 8], "body_position": [41, 58], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["authlib.common.encoding.to_unicode", "authlib.common.urls.add_params_to_uri", "authlib.oauth2.rfc6749.util.list_to_scope"]}, "requirement": {"Functionality": "This function prepares the authorization grant request URI by adding the necessary parameters to the query component of the authorization endpoint URI. It constructs the URI using the \"application/x-www-form-urlencoded\" format.", "Arguments": ":param uri: String. The authorization endpoint URI to fetch \"code\" or \"token\".\n:param client_id: String. The client identifier.\n:param response_type: String. The type of OAuth 2 grant/flow required (\"code\" or \"token\").\n:param redirect_uri: String. The client provided URI to redirect back to after authorization.\n:param scope: String or List. The scope of the access request.\n:param state: String. An opaque value used by the client to maintain state between the request and callback.\n:param kwargs: Extra arguments to embed in the grant/authorization URL.\n:return: String. The prepared authorization grant request URI."}, "tests": ["tests/core/test_oauth2/test_rfc6749_misc.py::OAuth2ParametersTest::test_prepare_grant_uri"], "indent": 4}
{"namespace": "diffprivlib.tools.histograms.histogram2d", "type": "function", "project_path": "Security/diffprivlib", "completion_path": "Security/diffprivlib/diffprivlib/tools/histograms.py", "signature_position": [279, 280], "body_position": [352, 365], "dependency": {"intra_class": [], "intra_file": ["diffprivlib.tools.histograms.histogramdd"], "cross_file": ["diffprivlib.utils.warn_unused_args"]}, "requirement": {"Functionality": "This function computes the differentially private bi-dimensional histogram of two data samples. It takes in two arrays containing the x and y coordinates of the points to be histogrammed, along with other optional parameters such as privacy parameter, bin specification, range, density, weights, random state, and accountant. It returns the bi-dimensional histogram, along with the bin edges along the x and y dimensions.", "Arguments": ":param array_x: array_like. An array containing the x coordinates of the points to be histogrammed.\n:param array_y: array_like. An array containing the y coordinates of the points to be histogrammed.\n:param epsilon: float. Privacy parameter  to be applied. Defaults to 1.0.\n:param bins: int or array_like or [int, int] or [array, array]. The bin specification. Defaults to 10.\n:param range: array_like, shape(2,2), optional. The leftmost and rightmost edges of the bins along each dimension. Defaults to None.\n:param density: bool, optional. If False, returns the number of samples in each bin. If True, returns the probability density function at the bin. Defaults to None.\n:param weights: array_like, shape(N,), optional. An array of values weighing each sample. Defaults to None.\n:param random_state: int or RandomState, optional. Controls the randomness of the algorithm. Defaults to None.\n:param accountant: BudgetAccountant, optional. Accountant to keep track of privacy budget. Defaults to None.\n:param **unused_args: Should warn the user if any other parameters are passed.\n:return: H: ndarray, shape(nx, ny). The bi-dimensional histogram of samples x and y. xedges: ndarray, shape(nx+1,). The bin edges along the first dimension. yedges: ndarray, shape(ny+1,). The bin edges along the second dimension."}, "tests": ["tests/tools/test_histogram2d.py::TestHistogram2d::test_different_result", "tests/tools/test_histogram2d.py::TestHistogram2d::test_no_params", "tests/tools/test_histogram2d.py::TestHistogram2d::test_custom_bins", "tests/tools/test_histogram2d.py::TestHistogram2d::test_accountant", "tests/tools/test_histogram2d.py::TestHistogram2d::test_missing_range"], "indent": 4}
{"namespace": "sumy.nlp.tokenizers.Tokenizer.to_sentences", "type": "method", "project_path": "Internet/sumy", "completion_path": "Internet/sumy/sumy/nlp/tokenizers.py", "signature_position": [186, 186], "body_position": [187, 192], "dependency": {"intra_class": ["sumy.nlp.tokenizers.Tokenizer.LANGUAGE_EXTRA_ABREVS", "sumy.nlp.tokenizers.Tokenizer._language", "sumy.nlp.tokenizers.Tokenizer._sentence_tokenizer"], "intra_file": ["sumy.nlp.tokenizers.ArabicSentencesTokenizer.tokenize"], "cross_file": ["sumy._compat.to_unicode", "sumy._compat.unicode"]}, "requirement": {"Functionality": "This function takes a paragraph as input and tokenizes it into sentences using a sentence tokenizer. It first updates the abbreviations used by the tokenizer based on the language. The function returns a tuple of the tokenized sentences.", "Arguments": ":param self: Tokenizer. An instance of the Tokenizer class.\n:param paragraph: String. The paragraph to be tokenized into sentences.\n:return: Tuple of strings. The tokenized sentences."}, "tests": ["tests/test_tokenizers.py::test_tokenize_paragraph", "tests/test_tokenizers.py::test_tokenize_sentences_with_abbreviations", "tests/test_tokenizers.py::test_tokenize_japanese_paragraph", "tests/test_tokenizers.py::test_slovak_alias_into_czech_tokenizer", "tests/test_tokenizers.py::test_ensure_czech_tokenizer_available"], "indent": 8}
{"namespace": "asyncssh.public_key.SSHKey.generate_x509_user_certificate", "type": "method", "project_path": "Security/asyncssh", "completion_path": "Security/asyncssh/asyncssh/public_key.py", "signature_position": [823, 830], "body_position": [888, 892], "dependency": {"intra_class": ["asyncssh.public_key.SSHKey._generate_x509_certificate"], "intra_file": ["asyncssh.public_key.X509CertPurposes", "asyncssh.public_key._CertPrincipals", "asyncssh.public_key._Comment", "asyncssh.public_key._Time"], "cross_file": ["asyncssh.misc.DefTuple"]}, "requirement": {"Functionality": "This function generates a new X.509 user certificate based on the given parameters. It uses the private key of the SSHKey instance to sign the certificate.", "Arguments": ":param self: SSHKey. An instance of the SSHKey class.\n:param user_key: SSHKey. The user's public key.\n:param subject: String. The subject name in the certificate, expressed as a comma-separated list of X.509 `name=value` pairs.\n:param issuer: String (optional). The issuer name in the certificate, expressed as a comma-separated list of X.509 `name=value` pairs. If not specified, the subject name will be used, creating a self-signed certificate.\n:param serial: Integer (optional). The serial number of the certificate, defaulting to a random 64-bit value.\n:param principals: List of strings (optional). The user names this certificate is valid for. By default, it can be used with any user name.\n:param valid_after: Integer (optional). The earliest time the certificate is valid for, defaulting to no restriction on when the certificate starts being valid.\n:param valid_before: Integer (optional). The latest time the certificate is valid for, defaulting to no restriction on when the certificate stops being valid.\n:param purposes: X509CertPurposes (optional). The allowed purposes for this certificate or `None` to not restrict the certificate's purpose, defaulting to 'secureShellClient'.\n:param hash_alg: Tuple of strings (optional). The hash algorithm to use when signing the new certificate, defaulting to SHA256.\n:param comment: Tuple of _Comment (optional). The comment to associate with this certificate. By default, the comment will be set to the comment currently set on user_key.\n:return: SSHX509Certificate. The generated X.509 user certificate."}, "tests": ["tests/test_public_key.py::_TestPublicKeyTopLevel::test_generate_errors"], "indent": 8}
{"namespace": "kinto.authorization._relative_object_uri", "type": "function", "project_path": "Internet/kinto", "completion_path": "Internet/kinto/kinto/authorization.py", "signature_position": [81, 81], "body_position": [83, 91], "dependency": {"intra_class": [], "intra_file": ["kinto.authorization._resource_endpoint"], "cross_file": []}, "requirement": {"Functionality": "This function takes a resource name and an object URI as input and returns the object URI. It splits the object URI into parts and iterates through each part to find the parent URI. It then checks if the resource name matches the parent resource name. If a match is found, it returns the parent URI. If no match is found, it raises a ValueError with an error message.", "Arguments": ":param resource_name: String. The name of the resource.\n:param object_uri: String. The URI of the object.\n:return: String. The object URI."}, "tests": ["tests/test_authorization.py::RelativeObjectUri::test_related_object_uri_can_construct_parents_set_uris", "tests/test_authorization.py::PermissionInheritanceTest::test_relative_object_uri_fail_on_wrong_type", "tests/test_authorization.py::RelativeObjectUri::test_relative_object_uri_fail_construct_children_set_uris"], "indent": 4}
{"namespace": "mrjob.util.to_lines", "type": "function", "project_path": "System/mrjob", "completion_path": "System/mrjob/mrjob/util.py", "signature_position": [257, 257], "body_position": [266, 269], "dependency": {"intra_class": [], "intra_file": ["mrjob.util._to_lines"], "cross_file": []}, "requirement": {"Functionality": "This function takes in data as a sequence of bytes and yields it one line at a time. It breaks lines only on \"\\n\" and does not add a trailing newline. If the input has a \"readline\" attribute, it is returned as is.", "Arguments": ":param chunks: The input data as a sequence of bytes.\n:return: The processed data, one line at a time."}, "tests": ["tests/test_local.py::FilterTestCase::test_pre_filter_failure", "tests/test_util.py::ToLinesTestCase::test_buffered_lines", "tests/test_util.py::ToLinesTestCase::test_long_lines", "tests/test_util.py::ToLinesTestCase::test_no_trailing_newline", "tests/test_local.py::FilterTestCase::test_pre_filter_on_compressed_data"], "indent": 4}
{"namespace": "msticpy.analysis.anomalous_sequence.utils.cmds_params_only.rarest_window_session", "type": "function", "project_path": "Security/msticpy", "completion_path": "Security/msticpy/msticpy/analysis/anomalous_sequence/utils/cmds_params_only.py", "signature_position": [408, 418], "body_position": [457, 473], "dependency": {"intra_class": [], "intra_file": ["msticpy.analysis.anomalous_sequence.utils.cmds_params_only.compute_likelihood_windows_in_session"], "cross_file": ["msticpy.analysis.anomalous_sequence.utils.data_structures.Cmd", "msticpy.analysis.anomalous_sequence.utils.data_structures.StateMatrix"]}, "requirement": {"Functionality": "This function finds and computes the likelihood of the rarest window of a given length in a session. It calculates the likelihoods of all sliding windows in the session and returns the rarest window and its likelihood.", "Arguments": ":param session: List[Cmd]. A list of Cmd objects representing a session.\n:param prior_probs: Union[StateMatrix, dict]. Computed probabilities of individual commands.\n:param trans_probs: Union[StateMatrix, dict]. Computed probabilities of sequences of commands (length 2).\n:param param_cond_cmd_probs: Union[StateMatrix, dict]. Computed probabilities of the params conditional on the command.\n:param window_len: int. The length of the sliding window for likelihood calculations.\n:param use_start_end_tokens: bool. If True, the `start_token` and `end_token` will be added to the session before calculations.\n:param start_token: str. A dummy command to signify the start of the session.\n:param end_token: str. A dummy command to signify the end of the session.\n:param use_geo_mean: bool. If True, each likelihood of the sliding windows will be raised to the power of (1/`window_len`).\n:return: Tuple[List[Cmd], float]. The rarest window part of the session and the likelihood of the rarest window."}, "tests": ["tests/analysis/test_anom_seq_cmds_params_only.py::TestCmdsParamsOnly::test_rarest_window_session"], "indent": 4}
{"namespace": "rows.fields.BoolField.deserialize", "type": "method", "project_path": "Text-Processing/rows", "completion_path": "Text-Processing/rows/rows/fields.py", "signature_position": [159, 159], "body_position": [160, 170], "dependency": {"intra_class": ["rows.fields.BoolField.FALSE_VALUES", "rows.fields.BoolField.TRUE_VALUES", "rows.fields.BoolField.TYPE"], "intra_file": ["rows.fields.Field", "rows.fields.Field.deserialize", "rows.fields.as_string"], "cross_file": []}, "requirement": {"Functionality": "Deserialize a value into a boolean field. It first calls the parent class's deserialize method to convert the value into a boolean. Then if the value is already None or an instance of the boolean field's type, it is returned as is. Otherwise, the value is converted to a string and checked against the true and false values defined in the class. If it matches a true value, True is returned. If it matches a false value, False is returned. If it doesn't match any of the defined values, a ValueError is raised with the error message \"Value is not boolean\".", "Arguments": ":param cls: Class. The class object of the boolean field.\n:param value: Any. The value to be deserialized into a boolean.\n:param *args: Any. Additional positional arguments.\n:param **kwargs: Any. Additional keyword arguments.\n:return: Bool. The deserialized boolean value."}, "tests": ["tests/tests_fields.py::FieldsTestCase::test_BoolField"], "indent": 8}
{"namespace": "mopidy.config.types.String.deserialize", "type": "method", "project_path": "Multimedia/Mopidy", "completion_path": "Multimedia/Mopidy/mopidy/config/types.py", "signature_position": [98, 98], "body_position": [99, 112], "dependency": {"intra_class": ["mopidy.config.types.String._choices", "mopidy.config.types.String._required"], "intra_file": ["mopidy.config.types._TransformedValue", "mopidy.config.types._TransformedValue.__init__", "mopidy.config.types.decode"], "cross_file": ["mopidy.config.validators.validate_choice", "mopidy.config.validators.validate_required", "mopidy.config.validators"]}, "requirement": {"Functionality": "Deserialize a string value based on the given conditions. It first decodes the value and removes any leading or trailing whitespace. Then, it validates the value based on whether it is required or not. If the value is empty, it returns None. If a transformer is defined, it applies the transformer to the value. Finally, it validates the value based on a list of choices and returns the deserialized value.", "Arguments": ":param self: String. An instance of the String class.\n:param value: The string value to be deserialized.\n:return: The deserialized value."}, "tests": ["tests/config/test_types.py::TestString::test_deserialize_does_not_double_encode_unicode", "tests/config/test_types.py::TestString::test_deserialize_enforces_choices", "tests/config/test_types.py::TestString::test_deserialize_invalid_encoding", "tests/config/test_types.py::TestString::test_deserialize_utilises_transformer", "tests/config/test_types.py::TestString::test_deserialize_decodes_utf8"], "indent": 8}
{"namespace": "backtrader.trade.Trade.update", "type": "method", "project_path": "Software-Development/backtrader", "completion_path": "Software-Development/backtrader/backtrader/trade.py", "signature_position": [213, 214], "body_position": [244, 304], "dependency": {"intra_class": ["backtrader.trade.Trade.Closed", "backtrader.trade.Trade.Open", "backtrader.trade.Trade.barclose", "backtrader.trade.Trade.barlen", "backtrader.trade.Trade.baropen", "backtrader.trade.Trade.commission", "backtrader.trade.Trade.data", "backtrader.trade.Trade.dtclose", "backtrader.trade.Trade.dtopen", "backtrader.trade.Trade.history", "backtrader.trade.Trade.historyon", "backtrader.trade.Trade.isclosed", "backtrader.trade.Trade.isopen", "backtrader.trade.Trade.justopened", "backtrader.trade.Trade.long", "backtrader.trade.Trade.pnl", "backtrader.trade.Trade.pnlcomm", "backtrader.trade.Trade.price", "backtrader.trade.Trade.size", "backtrader.trade.Trade.status", "backtrader.trade.Trade.value"], "intra_file": ["backtrader.trade.TradeHistory", "backtrader.trade.TradeHistory.__init__", "backtrader.trade.TradeHistory.doupdate"], "cross_file": []}, "requirement": {"Functionality": "This function updates the current trade based on the given parameters. It increases the commissions, updates the size. The size will carry the opposite sign if reducing. It checks if it has been currently opened. Any size means the trade was opened. It updatas current trade length and record if the position was closed (set to null), then it records last bar for the trade, updates the average price if the absolute size is bigger than the absolute old size or reduces or closes position if that condition is not met. Finally, it updates the attributes of the trade object and history if needed.", "Arguments": ":param self: Trade. An instance of the Trade class.\n:param order: The order object that generated this update.\n:param size: Integer. The amount to update the order. If the size has the same sign as the current trade, it will increase the position. If the size has the opposite sign, it will reduce/close the position.\n:param price: Float. The price of the trade. Always positive to ensure consistency.\n:param value: Float. Unused. The cost incurred in the new size/price operation.\n:param commission: Float. The incurred commission in the new size/price operation.\n:param pnl: Float. Unused. The profit and loss generated by the executed part.\n:return: No return values."}, "tests": ["tests/test_trade.py::test_run"], "indent": 8}
{"namespace": "ehforwarderbot.chat.Chat.add_system_member", "type": "method", "project_path": "Communications/ehforwarderbot", "completion_path": "Communications/ehforwarderbot/ehforwarderbot/chat.py", "signature_position": [567, 570], "body_position": [592, 596], "dependency": {"intra_class": ["ehforwarderbot.chat.Chat.make_system_member", "ehforwarderbot.chat.Chat.members"], "intra_file": ["ehforwarderbot.chat.SystemChatMember"], "cross_file": ["ehforwarderbot.middleware.Middleware", "ehforwarderbot.types.ChatID"]}, "requirement": {"Functionality": "This function adds a system member to the chat. It creates a system member with the given parameters and adds it to the list of members in the chat.", "Arguments": ":param self: Chat. An instance of the Chat class.\n:param name: String. The name of the system member.\n:param alias: Optional string. The alias of the system member.\n:param id: ChatID. The ID of the system member.\n:param uid: ChatID. The UID of the system member.\n:param vendor_specific: Dictionary. Any vendor specific attributes.\n:param description: String. A text description of the chat.\n:param middleware: Optional Middleware. Initialize this chat as a part of a middleware.\n:return: SystemChatMember. The created system member."}, "tests": ["tests/test_chat.py::test_add_system_member"], "indent": 8}
{"namespace": "sacred.ingredient.Ingredient.command", "type": "method", "project_path": "Utilities/sacred", "completion_path": "Utilities/sacred/sacred/ingredient.py", "signature_position": [130, 130], "body_position": [145, 148], "dependency": {"intra_class": ["sacred.ingredient.Ingredient.capture", "sacred.ingredient.Ingredient.commands"], "intra_file": ["sacred.ingredient.Ingredient.capture.unobserved"], "cross_file": []}, "requirement": {"Functionality": "This function is a decorator used to define a new command for an Ingredient or Experiment. It captures the function and adds it to the commands dictionary of the Ingredient instance. The name of the command will be the name of the function. It can be called from the command-line or by using the run_command function.", "Arguments": ":param self: Ingredient. An instance of the Ingredient class.\n:param function: Function. The function to be decorated and added as a command.\n:param prefix: String. The prefix to restrict the configuration space of the command. Defaults to None.\n:param unobserved: Bool. Whether the command should be unobserved, i.e., ignoring all observers. Defaults to False.\n:return: The captured function."}, "tests": ["tests/test_ingredients.py::test_gather_commands"], "indent": 8}
{"namespace": "boto.cloudformation.connect_to_region", "type": "function", "project_path": "Internet/boto", "completion_path": "Internet/boto/boto/cloudformation/__init__.py", "signature_position": [43, 43], "body_position": [54, 56], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["boto.cloudformation.connection.CloudFormationConnection", "boto.regioninfo.connect"]}, "requirement": {"Functionality": "This function connects to a specific region and returns a CloudFormationConnection object. It uses the connect function from the boto library to establish the connection.", "Arguments": ":param region_name: str. The name of the region to connect to.\n:param kw_params: keyword arguments. Additional parameters that can be passed to the connect function.\n:return: CloudFormationConnection or None. A connection to the given region, or None if an invalid region name is given."}, "tests": ["tests/unit/test_connect_to_region.py::TestConnectCloudformation::test_connect_to_region"], "indent": 4}
{"namespace": "onlinejudge_command.pretty_printers._render_tokens", "type": "function", "project_path": "Text-Processing/online-judge-tools", "completion_path": "Text-Processing/online-judge-tools/onlinejudge_command/pretty_printers.py", "signature_position": [163, 171], "body_position": [175, 207], "dependency": {"intra_class": [], "intra_file": ["onlinejudge_command.pretty_printers._PrettyTokenType", "onlinejudge_command.pretty_printers._PrettyTokenType.BODY", "onlinejudge_command.pretty_printers._PrettyTokenType.BODY_HIGHLIGHT_LEFT", "onlinejudge_command.pretty_printers._PrettyTokenType.BODY_HIGHLIGHT_RIGHT", "onlinejudge_command.pretty_printers._PrettyTokenType.HINT", "onlinejudge_command.pretty_printers._PrettyTokenType.LINENO", "onlinejudge_command.pretty_printers._PrettyTokenType.NEWLINE", "onlinejudge_command.pretty_printers._PrettyTokenType.OTHERS", "onlinejudge_command.pretty_printers._PrettyTokenType.WHITESPACE", "onlinejudge_command.pretty_printers._replace_whitespace"], "cross_file": []}, "requirement": {"Functionality": "This function takes a list of tokens and applies different formatting styles to each token based on its type. It then concatenates all the formatted tokens into a single string and returns it.", "Arguments": ":param tokens: List of _PrettyToken. A list of tokens to be formatted.\n:param font_bold: Optional Callable. A function that applies bold font style to a string. Defaults to None.\n:param font_dim: Optional Callable. A function that applies dim font style to a string. Defaults to None.\n:param font_red: Optional Callable. A function that applies red font color to a string. Defaults to None.\n:param font_blue: Optional Callable. A function that applies blue font color to a string. Defaults to None.\n:param font_normal: Optional Callable. A function that applies normal font style to a string. Defaults to None.\n:return: String. The formatted string generated from the tokens."}, "tests": ["tests/pretty_printers.py::MakePrettyDiffTest::test_file_difflib", "tests/pretty_printers.py::MakePrettyDiffTest::test_line_difflib", "tests/pretty_printers.py::MakePrettyDiffLimitTest::test_with_limit", "tests/pretty_printers.py::RenderTokensTest::test_simple", "tests/pretty_printers.py::RenderTokensTest::test_complicated"], "indent": 4}
{"namespace": "boto.dynamodb2.table.BatchTable.put_item", "type": "method", "project_path": "Internet/boto", "completion_path": "Internet/boto/boto/dynamodb2/table.py", "signature_position": [1645, 1645], "body_position": [1646, 1649], "dependency": {"intra_class": ["boto.dynamodb2.table.BatchTable._to_put", "boto.dynamodb2.table.BatchTable.flush", "boto.dynamodb2.table.BatchTable.should_flush"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function adds an item to the BatchTable instance. It appends the input data to the list of items to be put in the BatchTable. It also can flush the items.", "Arguments": ":param self: BatchTable. An instance of the BatchTable class.\n:param data: The data to be added to the BatchTable.\n:param overwrite: Bool. Whether to overwrite existing data with the same key. Defaults to False.\n:return: No return values."}, "tests": ["tests/unit/dynamodb2/test_table.py::TableTestCase::test_batch_write", "tests/unit/dynamodb2/test_table.py::TableTestCase::test_batch_write_flushing"], "indent": 8}
{"namespace": "pycoin.message.PeerAddress.PeerAddress.host", "type": "method", "project_path": "Security/pycoin", "completion_path": "Security/pycoin/pycoin/message/PeerAddress.py", "signature_position": [35, 35], "body_position": [36, 38], "dependency": {"intra_class": ["pycoin.message.PeerAddress.IP4_HEADER", "pycoin.message.PeerAddress.PeerAddress.ip_bin"], "intra_file": ["pycoin.message.PeerAddress.ip_bin_to_ip4_addr", "pycoin.message.PeerAddress.ip_bin_to_ip6_addr"], "cross_file": []}, "requirement": {"Functionality": "This function determines the host address based on the IP binary string. If the IP binary string starts with the IP4 header, it converts the last 4 characters of the IP binary string to an IP4 address. Otherwise, it converts the entire IP binary string to an IP6 address.", "Arguments": ":param self: PeerAddress. An instance of the PeerAddress class.\n:return: The host address based on the IP binary string."}, "tests": ["tests/message_test.py::MessageTest::test_PeerAddress"], "indent": 8}
{"namespace": "diffprivlib.tools.utils.sum", "type": "function", "project_path": "Security/diffprivlib", "completion_path": "Security/diffprivlib/diffprivlib/tools/utils.py", "signature_position": [599, 600], "body_position": [651, 654], "dependency": {"intra_class": [], "intra_file": ["diffprivlib.tools.utils._sum"], "cross_file": ["diffprivlib.utils.warn_unused_args"]}, "requirement": {"Functionality": "This function calculates the sum of array elements over a given axis with differential privacy.", "Arguments": ":param array: array_like. The elements to be summed.\n:param epsilon: float, default: 1.0. The privacy parameter epsilon.\n:param bounds: tuple, optional. The bounds of the values of the array, in the form (min, max).\n:param axis: None or int or tuple of ints, optional. The axis or axes along which the sum is performed. If None, it sums all elements of the input array. If negative, it counts from the last to the first axis. If a tuple of ints, it performs the sum on all specified axes.\n:param dtype: dtype, optional. The type of the returned array and accumulator in which the elements are summed. If not specified, the dtype of the input array is used.\n:param keepdims: bool, default: False. If True, the reduced axes are left in the result as dimensions with size one.\n:param random_state: int or RandomState, optional. Controls the randomness of the algorithm. To obtain deterministic behavior, fix the random_state to an integer.\n:param accountant: BudgetAccountant, optional. Accountant to keep track of privacy budget.\n:param **unused_args: Should warn the user if any other parameters are passed.\n:return: sum_along_axis : ndarray. An array with the same shape as the input array, with the specified axis removed. If the input array is 0-d or if axis is None, a scalar is returned."}, "tests": ["tests/tools/test_sum.py::TestSum::test_large_epsilon", "tests/tools/test_sum.py::TestSum::test_missing_bounds", "tests/tools/test_sum.py::TestSum::test_no_params", "tests/tools/test_sum.py::TestSum::test_nan", "tests/tools/test_sum.py::TestSum::test_no_bounds"], "indent": 4}
{"namespace": "pyramid.authentication.RepozeWho1AuthenticationPolicy.unauthenticated_userid", "type": "method", "project_path": "Internet/pyramid", "completion_path": "Internet/pyramid/src/pyramid/authentication.py", "signature_position": [267, 267], "body_position": [269, 272], "dependency": {"intra_class": ["pyramid.authentication.RepozeWho1AuthenticationPolicy._get_identity"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function retrieves the user ID from the detected identity in the request. It first gets the identity dictionary and then returns the value of the 'repoze.who.userid' key from the identity dictionary.", "Arguments": ":param self: RepozeWho1AuthenticationPolicy. An instance of the RepozeWho1AuthenticationPolicy class.\n:param request: The request object.\n:return: The value of the 'repoze.who.userid' key from the identity dictionary."}, "tests": ["tests/test_authentication.py::TestRepozeWho1AuthenticationPolicy::test_unauthenticated_userid"], "indent": 8}
{"namespace": "mackup.utils.copy", "type": "function", "project_path": "Utilities/mackup", "completion_path": "Utilities/mackup/mackup/utils.py", "signature_position": [71, 71], "body_position": [89, 112], "dependency": {"intra_class": [], "intra_file": ["mackup.utils.chmod"], "cross_file": []}, "requirement": {"Functionality": "This function copies a file or a folder (recursively) from the source path to the destination path. It first checks if the source and destination paths are valid and absolute paths. Then, it creates the necessary directories in the destination path if they do not exist. If the source is a file, it copies the file to the destination. If the source is a folder, it copies the entire folder to the destination. If the source is neither a file nor a folder, it raises a ValueError. Finally, it sets the appropriate file permissions for the copied file or folder.", "Arguments": ":param src: str. The source file or folder path.\n:param dst: str. The destination file or folder path.\n:return: No return values."}, "tests": ["tests/utils_test.py::TestMackup::test_copy_file", "tests/utils_test.py::TestMackup::test_copy_fail", "tests/utils_test.py::TestMackup::test_copy_file_to_dir", "tests/utils_test.py::TestMackup::test_copy_dir"], "indent": 4}
{"namespace": "bentoml._internal.runner.container.DefaultContainer.batch_to_payloads", "type": "method", "project_path": "Scientific-Engineering/bentoml", "completion_path": "Scientific-Engineering/bentoml/src/bentoml/_internal/runner/container.py", "signature_position": [538, 543], "body_position": [544, 547], "dependency": {"intra_class": ["bentoml._internal.runner.container.DefaultContainer.batch_to_batches"], "intra_file": ["bentoml._internal.runner.container.Payload"], "cross_file": []}, "requirement": {"Functionality": "This function converts a batch of data into a list of payloads. It first converts the batch into a list of batches based on the given indices and batch dimension. Then, it iterates over each subbatch and converts it into a payload.", "Arguments": ":param cls: DefaultContainer. The class itself.\n:param batch: List of any type. The input batch of data.\n:param indices: Sequence of integers. The indices to select from the batch for each subbatch.\n:param batch_dim: Integer. The dimension along which the batch is split. Defaults to 0.\n:return: List of Payload. The list of payloads created from the batch."}, "tests": ["tests/unit/_internal/runner/test_container.py::test_default_container"], "indent": 8}
{"namespace": "boto.codedeploy.connect_to_region", "type": "function", "project_path": "Internet/boto", "completion_path": "Internet/boto/boto/codedeploy/__init__.py", "signature_position": [37, 37], "body_position": [38, 41], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["boto.codedeploy.layer1.CodeDeployConnection", "boto.regioninfo.connect"]}, "requirement": {"Functionality": "Connect to a specific region using the CodeDeployConnection class from the boto library. It creates a connection to the specified region using the provided parameters.", "Arguments": ":param region_name: String. The name of the region to connect to.\n:param **kw_params: Additional keyword arguments that can be passed to the connection.\n:return: CodeDeployConnection. The connection object to the specified region."}, "tests": ["tests/unit/test_connect_to_region.py::TestCodeDeployConnection::test_connect_to_region"], "indent": 4}
{"namespace": "pyramid.csrf.LegacySessionCSRFStoragePolicy.check_csrf_token", "type": "method", "project_path": "Internet/pyramid", "completion_path": "Internet/pyramid/src/pyramid/csrf.py", "signature_position": [43, 43], "body_position": [45, 48], "dependency": {"intra_class": ["pyramid.csrf.LegacySessionCSRFStoragePolicy.get_csrf_token"], "intra_file": [], "cross_file": ["pyramid.util.bytes_", "pyramid.util.strings_differ"]}, "requirement": {"Functionality": "Check if the supplied CSRF token is valid by comparing it with the expected token. It converts both tokens to bytes and checks if they are equal.", "Arguments": ":param self: LegacySessionCSRFStoragePolicy. An instance of the LegacySessionCSRFStoragePolicy class.\n:param request: The request object.\n:param supplied_token: The CSRF token supplied by the client.\n:return: Bool. Returns True if the supplied token is valid, False otherwise."}, "tests": ["tests/test_csrf.py::TestLegacySessionCSRFStoragePolicy::test_check_csrf_token"], "indent": 8}
{"namespace": "authlib.jose.util.extract_header", "type": "function", "project_path": "Internet/Authlib", "completion_path": "Internet/Authlib/authlib/jose/util.py", "signature_position": [6, 6], "body_position": [7, 16], "dependency": {"intra_class": [], "intra_file": ["authlib.jose.util.extract_segment"], "cross_file": ["authlib.common.encoding.json_loads", "authlib.common.encoding.urlsafe_b64decode.decode"]}, "requirement": {"Functionality": "This function extracts the header from a given header segment. It first extracts the header segment. Then, it decodes the extracted header data using UTF-8 encoding and loads it as a JSON object. If the loaded header is not a dictionary, it raises an error. Finally, it returns the extracted header.", "Arguments": ":param header_segment: The header segment to extract the header from.\n:param error_cls: The error class to raise if there is an error during the extraction process.\n:return: The extracted header as a dictionary."}, "tests": ["tests/jose/test_jwe.py::JWETest::test_deserialize_json_fails_if_protected_header_contains_unknown_field_while_private_fields_restricted"], "indent": 4}
{"namespace": "imapclient.datetime_util.datetime_to_INTERNALDATE", "type": "function", "project_path": "Communications/IMAPClient", "completion_path": "Communications/IMAPClient/imapclient/datetime_util.py", "signature_position": [43, 43], "body_position": [49, 52], "dependency": {"intra_class": [], "intra_file": ["imapclient.datetime_util._SHORT_MONTHS"], "cross_file": ["imapclient.fixed_offset.FixedOffset", "imapclient.fixed_offset.FixedOffset.for_system"]}, "requirement": {"Functionality": "This function converts a datetime instance like \"-%Y %H:%M:%S %z\" to a string representation in the format required by IMAP INTERNALDATE. If the datetime instance does not have timezone information, the current system timezone is used.", "Arguments": ":param dt: datetime. The datetime instance to be converted.\n:return: str. The string representation of the datetime instance in the IMAP INTERNALDATE format."}, "tests": ["tests/test_datetime_util.py::TestDatetimeToINTERNALDATE::test_without_timezone", "tests/test_datetime_util.py::TestDatetimeToINTERNALDATE::test_with_timezone"], "indent": 4}
{"namespace": "twilio.twiml.voice_response.VoiceResponse.sms", "type": "method", "project_path": "Communications/twilio-fatisar", "completion_path": "Communications/twilio-fatisar/twilio/twiml/voice_response.py", "signature_position": [391, 400], "body_position": [414, 424], "dependency": {"intra_class": [], "intra_file": ["twilio.twiml.voice_response.Sms", "twilio.twiml.voice_response.Sms.__init__"], "cross_file": ["twilio.twiml.TwiML.nest"]}, "requirement": {"Functionality": "This function creates a <Sms> element for a VoiceResponse instance. It takes in various parameters such as the message body, recipient number, sender number, action URL, method, status callback URL, and additional attributes. It then creates the <Sms> element with these parameters and returns it.", "Arguments": ":param self: VoiceResponse. An instance of the VoiceResponse class.\n:param message: String. The body of the SMS message.\n:param to: String. The number to send the message to.\n:param from_: String. The number to send the message from.\n:param action: String. The action URL.\n:param method: String. The method for the action URL.\n:param status_callback: String. The status callback URL.\n:param kwargs: Additional attributes.\n:return: <Sms> element. The created <Sms> element."}, "tests": ["tests/unit/twiml/test_voice_response.py::TestSms::test_body", "tests/unit/twiml/test_voice_response.py::TestSms::test_to_from_action", "tests/unit/twiml/test_voice_response.py::TestResponse::test_response_chain", "tests/unit/twiml/test_voice_response.py::TestResponse::test_response", "tests/unit/twiml/test_voice_response.py::TestSms::test_empty"], "indent": 8}
{"namespace": "diffprivlib.tools.utils.nanvar", "type": "function", "project_path": "Security/diffprivlib", "completion_path": "Security/diffprivlib/diffprivlib/tools/utils.py", "signature_position": [364, 365], "body_position": [421, 424], "dependency": {"intra_class": [], "intra_file": ["diffprivlib.tools.utils._var"], "cross_file": ["diffprivlib.utils.warn_unused_args"]}, "requirement": {"Functionality": "This function computes the differentially private variance of an array along a specified axis, while ignoring NaN values. It adds noise to the variance calculation to satisfy differential privacy. The function closely follows the behavior of the `numpy.var` function.", "Arguments": ":param array: array_like. The array containing numbers whose variance is desired.\n:param epsilon: float, default: 1.0. The privacy parameter epsilon.\n:param bounds: tuple, optional. The bounds of the values of the array, in the form (min, max).\n:param axis: int or tuple of ints, optional. The axis or axes along which the variance is computed. The default is to compute the variance of the flattened array. If a tuple of ints is provided, the variance is performed over multiple axes.\n:param dtype: data-type, optional. The type to use in computing the variance. The default is `float32` for arrays of integer type, and the same as the array type for arrays of float types.\n:param keepdims: bool, default: False. If set to True, the axes which are reduced are left in the result as dimensions with size one.\n:param random_state: int or RandomState, optional. Controls the randomness of the algorithm. To obtain deterministic behavior, `random_state` should be fixed to an integer.\n:param accountant: BudgetAccountant, optional. An accountant to keep track of privacy budget.\n:param **unused_args: Should warn the user if any other parameters are passed.\n:return: variance : ndarray, see dtype parameter above. If `out=None`, returns a new array containing the variance; otherwise, a reference to the output array is returned."}, "tests": ["tests/tools/test_nanvar.py::TestNanVar::test_no_params", "tests/tools/test_nanvar.py::TestNanVar::test_no_bounds", "tests/tools/test_nanvar.py::TestNanVar::test_bad_bounds", "tests/tools/test_nanvar.py::TestNanVar::test_array_like", "tests/tools/test_nanvar.py::TestNanVar::test_large_epsilon_axis"], "indent": 4}
{"namespace": "oletools.oleobj.get_sane_embedded_filenames", "type": "function", "project_path": "Security/oletools", "completion_path": "Security/oletools/oletools/oleobj.py", "signature_position": [550, 551], "body_position": [566, 610], "dependency": {"intra_class": [], "intra_file": ["oletools.oleobj.MAX_FILENAME_ATTEMPTS", "oletools.oleobj.sanitize_filename"], "cross_file": []}, "requirement": {"Functionality": "This function generates a list of sane filenames based on the given input parameters. It extracts the filename from the input paths, sanitizes it, and preserves the file suffix. It returns multiple candidates, first with suffix, then without, then random with suffix, and finally one last attempt ignoring the maximum length using the `noname_index` argument.", "Arguments": ":param filename: String. The original filename.\n:param src_path: String. The source path containing the filename.\n:param tmp_path: String. The temporary path containing the filename.\n:param max_len: Integer. The maximum length of the filename.\n:param noname_index: Integer. The index used to generate a name when all other attempts fail.\n:return: List of Strings. The generated sane filenames."}, "tests": ["tests/oleobj/test_basic.py::TestSaneFilenameCreation::test_with_empty_inputs", "tests/oleobj/test_basic.py::TestSaneFilenameCreation::test_realworld_lnk_example", "tests/oleobj/test_basic.py::TestSaneFilenameCreation::test_with_hardly_any_length", "tests/oleobj/test_basic.py::TestSaneFilenameCreation::test_that_first_has_priority", "tests/oleobj/test_basic.py::TestSaneFilenameCreation::test_with_mean_unicode"], "indent": 4}
{"namespace": "chatette.parsing.UnitRefBuilder.create_concrete", "type": "method", "project_path": "Communications/chatette", "completion_path": "Communications/chatette/chatette/parsing/__init__.py", "signature_position": [110, 110], "body_position": [111, 116], "dependency": {"intra_class": ["chatette.parsing.UnitRefBuilder._build_modifiers_repr", "chatette.parsing.UnitRefBuilder._check_information", "chatette.parsing.UnitRefBuilder.identifier", "chatette.parsing.UnitRefBuilder.leading_space", "chatette.parsing.UnitRefBuilder.type"], "intra_file": [], "cross_file": ["chatette.units.modifiable.unit_reference.UnitReference"]}, "requirement": {"Functionality": "Create a concrete UnitReference object based on the information stored in the UnitRefBuilder instance. It first checks if all the necessary information is available, and then uses that information to create the UnitReference object.", "Arguments": ":param self: UnitRefBuilder. An instance of the UnitRefBuilder class.\n:return: UnitReference. The created UnitReference object."}, "tests": ["tests/unit-testing/parsing/test_init.py::TestUnitRefBuilder::test_create_concrete"], "indent": 8}
{"namespace": "pyramid.request.CallbackMethodsMixin._process_response_callbacks", "type": "method", "project_path": "Internet/pyramid", "completion_path": "Internet/pyramid/src/pyramid/request.py", "signature_position": [76, 76], "body_position": [77, 80], "dependency": {"intra_class": ["pyramid.request.CallbackMethodsMixin.response_callbacks"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function processes the response callbacks for a given response. It iterates through the response callbacks and calls each callback function with the given response and self as arguments.", "Arguments": ":param self: CallbackMethodsMixin. An instance of the CallbackMethodsMixin class.\n:param response: The response object to be passed to the callback functions.\n:return: No return values."}, "tests": ["tests/test_request.py::TestRequest::test__process_response_callbacks", "tests/test_request.py::TestRequest::test__process_response_callback_adding_response_callback"], "indent": 8}
{"namespace": "fs.path.join", "type": "function", "project_path": "System/fs", "completion_path": "System/fs/fs/path.py", "signature_position": [210, 211], "body_position": [229, 241], "dependency": {"intra_class": [], "intra_file": ["fs.path.abspath", "fs.path.normpath"], "cross_file": []}, "requirement": {"Functionality": "This function joins any number of paths together. It takes multiple paths as input and returns a single joined path.", "Arguments": ":param *paths: Variable number of strings. Paths to join, given as positional arguments.\n:return: str. The joined path."}, "tests": ["tests/test_path.py::TestPathFunctions::test_pathjoin"], "indent": 4}
{"namespace": "rest_framework.fields.MultipleChoiceField.get_value", "type": "method", "project_path": "Internet/djangorestframework", "completion_path": "Internet/djangorestframework/rest_framework/fields.py", "signature_position": [1429, 1429], "body_position": [1430, 1437], "dependency": {"intra_class": [], "intra_file": ["rest_framework.fields.Field.root", "rest_framework.fields.empty"], "cross_file": ["rest_framework.fields.ChoiceField.field_name", "rest_framework.utils.html", "rest_framework.utils.html.is_html_input"]}, "requirement": {"Functionality": "This function retrieves the value of a field from a dictionary. It first checks if the field name is present in the dictionary. If not, it checks if the form is partial and returns an empty value. Then, it checks if the input is in HTML form and returns a list of values if it is. Otherwise, it returns the value corresponding to the field name in the dictionary.", "Arguments": ":param self: MultipleChoiceField. An instance of the MultipleChoiceField class.\n:param dictionary: Dictionary. The dictionary from which to retrieve the field value.\n:return: The value of the field from the dictionary."}, "tests": ["tests/test_fields.py::TestMultipleChoiceField::test_against_partial_and_full_updates"], "indent": 8}
{"namespace": "mopidy.config._validate", "type": "function", "project_path": "Multimedia/Mopidy", "completion_path": "Multimedia/Mopidy/mopidy/config/__init__.py", "signature_position": [219, 220], "body_position": [221, 239], "dependency": {"intra_class": [], "intra_file": ["mopidy.config.logger"], "cross_file": []}, "requirement": {"Functionality": "This function validates a raw configuration against a set of schemas. It iterates through each schema and checks if the corresponding section exists in the raw configuration. If it does, it deserializes the values and adds the result to the validated config. If there are any errors during deserialization, they are stored in the errors dictionary. Any sections in the raw configuration that do not have a matching schema are ignored and a warning message is logged. The function returns the validated config and any errors encountered during validation.", "Arguments": ":param raw_config: Dictionary. The raw configuration to be validated.\n:param schemas: List of Schema objects. The schemas to validate the raw configuration against.\n:return: Tuple. The validated config dictionary and the errors dictionary."}, "tests": ["tests/config/test_config.py::ValidateTest::test_config_no_schemas", "tests/config/test_config.py::ValidateTest::test_config_single_schema_config_error", "tests/config/test_config.py::ValidateTest::test_config_single_schema", "tests/config/test_config.py::ValidateTest::test_empty_config_no_schemas", "tests/config/test_config.py::ValidateTest::test_empty_config_single_schema"], "indent": 4}
{"namespace": "trailscraper.cloudtrail.Record.to_statement", "type": "method", "project_path": "Security/trailscraper", "completion_path": "Security/trailscraper/trailscraper/cloudtrail.py", "signature_position": [155, 155], "body_position": [157, 167], "dependency": {"intra_class": ["trailscraper.cloudtrail.Record._event_name_to_iam_action", "trailscraper.cloudtrail.Record._source_to_iam_prefix", "trailscraper.cloudtrail.Record._to_api_gateway_statement", "trailscraper.cloudtrail.Record.event_name", "trailscraper.cloudtrail.Record.event_source", "trailscraper.cloudtrail.Record.resource_arns"], "intra_file": [], "cross_file": ["trailscraper.iam.Action", "trailscraper.iam.Statement"]}, "requirement": {"Functionality": "This function converts a record into a matching IAM Policy Statement. It checks the event source and event name of the record and returns the corresponding IAM Policy Statement.", "Arguments": ":param self: Record. An instance of the Record class.\n:return: Statement or None. The IAM Policy Statement that matches the record, or None if the event source is \"sts.amazonaws.com\" and the event name is \"GetCallerIdentity\"."}, "tests": ["tests/cloudtrail/record_test.py::test_should_convert_special_event_sources_properly", "tests/cloudtrail/record_test.py::test_should_convert_special_actions_properly", "tests/cloudtrail/record_test.py::test_should_convert_api_gateway_events_properly", "tests/cloudtrail/record_test.py::test_should_convert_into_iam_statement", "tests/cloudtrail/record_test.py::test_should_convert_api_gateway_events_with_parameters_properly"], "indent": 8}
{"namespace": "boto.dynamodb2.table.Table.get_key_fields", "type": "method", "project_path": "Internet/boto", "completion_path": "Internet/boto/boto/dynamodb2/table.py", "signature_position": [919, 919], "body_position": [939, 944], "dependency": {"intra_class": ["boto.dynamodb2.table.Table.describe", "boto.dynamodb2.table.Table.schema"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function returns the fields necessary to make a key for a table. If the table does not already have a populated schema, it requests it. It returns a list of field names.", "Arguments": ":param self: Table. An instance of the Table class.\n:return: List of field names (strings) that are necessary to make a key for the table."}, "tests": ["tests/unit/dynamodb2/test_table.py::TableTestCase::test_get_key_fields_no_schema_populated"], "indent": 8}
{"namespace": "sacred.dependencies.gather_sources_and_dependencies", "type": "function", "project_path": "Utilities/sacred", "completion_path": "Utilities/sacred/sacred/dependencies.py", "signature_position": [726, 726], "body_position": [728, 747], "dependency": {"intra_class": [], "intra_file": ["sacred.dependencies.PackageDependency", "sacred.dependencies.PackageDependency.create", "sacred.dependencies.dependency_discovery_strategies", "sacred.dependencies.get_main_file", "sacred.dependencies.source_discovery_strategies"], "cross_file": ["sacred.optional.has_numpy", "sacred.optional.np", "sacred.settings.SETTINGS"]}, "requirement": {"Functionality": "This function scans the given globals for modules and returns them as dependencies. It gather the soruces and dependencies based on the source discovery strategy and dependency discovery strategy. The main file is added to the sources set if it is not None. If numpy is available, it is added as a dependency. Finally, it returns the main file, sources set, and dependencies set.", "Arguments": ":param globs: dict. The globals to scan for modules.\n:param save_git_info: bool. Whether to save git information.\n:param base_dir: str. The base directory to use for gathering sources and dependencies. Defaults to None. If None, the experiment path is used.\n:return: The main file, sources set, and dependencies set."}, "tests": ["tests/test_dependencies.py::test_gather_sources_and_dependencies", "tests/test_dependencies.py::test_custom_base_dir"], "indent": 4}
{"namespace": "boto.ec2.elb.connect_to_region", "type": "function", "project_path": "Internet/boto", "completion_path": "Internet/boto/boto/ec2/elb/__init__.py", "signature_position": [51, 51], "body_position": [62, 64], "dependency": {"intra_class": [], "intra_file": ["boto.ec2.elb.ELBConnection"], "cross_file": ["boto.regioninfo.connect"]}, "requirement": {"Functionality": "This function connects to a specific region and returns an instance of the ELBConnection class.", "Arguments": ":param region_name: str. The name of the region to connect to.\n:param **kw_params: Additional keyword arguments that can be passed to the connect function.\n:return: boto.ec2.ELBConnection or None. A connection to the specified region, or None if an invalid region name is given."}, "tests": ["tests/unit/test_connect_to_region.py::TestElbConnection::test_connect_to_region"], "indent": 4}
{"namespace": "pyramid.renderers.RendererHelper.render", "type": "method", "project_path": "Internet/pyramid", "completion_path": "Internet/pyramid/src/pyramid/renderers.py", "signature_position": [445, 445], "body_position": [446, 464], "dependency": {"intra_class": ["pyramid.renderers.RendererHelper.name", "pyramid.renderers.RendererHelper.registry", "pyramid.renderers.RendererHelper.renderer"], "intra_file": [], "cross_file": ["pyramid.csrf.get_csrf_token", "pyramid.events.BeforeRender", "pyramid.registry.Registry.notify"]}, "requirement": {"Functionality": "This function renders a given value using the specified renderer. It first sets up the system values dictionary, which includes information about the view, renderer name, renderer info, context, request, and CSRF token. Then, it notifies the registry about the system values and calls the renderer function to process the value. The render result is returned.", "Arguments": ":param self: RendererHelper. An instance of the RendererHelper class.\n:param value: The value to be rendered.\n:param system_values: Dictionary. A dictionary containing system values such as view, renderer name, renderer info, context, request, and CSRF token.\n:param request: Optional. The request object.\n:return: The rendered result."}, "tests": ["tests/test_renderers.py::TestRendererHelper::test_render_explicit_registry", "tests/test_renderers.py::TestRendererHelper::test_render_system_values_is_None"], "indent": 8}
{"namespace": "falcon.request.Request.get_cookie_values", "type": "method", "project_path": "Internet/falcon", "completion_path": "Internet/falcon/falcon/request.py", "signature_position": [1207, 1207], "body_position": [1223, 1236], "dependency": {"intra_class": ["falcon.request.Request._cookies", "falcon.request.Request.get_header"], "intra_file": [], "cross_file": ["falcon.request_helpers.parse_cookie_header", "falcon.request_helpers"]}, "requirement": {"Functionality": "This function returns all values provided in the Cookie header for the named cookie. It first checks if the cookies are None, and if so, it parses the Cookie header and stores the result. Then, it retrieves the value for the specified cookie name and returns it.", "Arguments": ":param self: Request. An instance of the Request class.\n:param name: str. The name of the cookie to retrieve the values for.\n:return: list. An ordered list of all values specified in the Cookie header for the named cookie, or None if the cookie was not included in the request. If the cookie is specified more than once in the header, the returned list of values will preserve the ordering of the individual `cookie-pair`'s in the header."}, "tests": ["tests/test_cookies.py::test_request_cookie_parsing", "tests/test_cookies.py::test_duplicate_cookie"], "indent": 8}
{"namespace": "mrjob.logs.spark._parse_spark_log", "type": "function", "project_path": "System/mrjob", "completion_path": "System/mrjob/mrjob/logs/spark.py", "signature_position": [30, 30], "body_position": [32, 38], "dependency": {"intra_class": [], "intra_file": ["mrjob.logs.spark._parse_spark_log_from_log4j_records"], "cross_file": []}, "requirement": {"Functionality": "Parses a Spark log, extracting errors and application ID. \n", "Arguments": ""}, "tests": ["tests/logs/test_spark.py::ParseSparkLogTestCase::test_multi_line_error", "tests/logs/test_spark.py::ParseSparkLogTestCase::test_multiple_errors", "tests/logs/test_spark.py::ParseSparkLogTestCase::test_application_id", "tests/logs/test_spark.py::ParseSparkLogTestCase::test_multi_line_warning", "tests/logs/test_spark.py::ParseSparkLogTestCase::test_empty"], "indent": 4}
{"namespace": "boltons.cacheutils.MinIDMap.get", "type": "method", "project_path": "Utilities/boltons", "completion_path": "Utilities/boltons/boltons/cacheutils.py", "signature_position": [839, 839], "body_position": [840, 852], "dependency": {"intra_class": ["boltons.cacheutils.MinIDMap._clean", "boltons.cacheutils.MinIDMap.free", "boltons.cacheutils.MinIDMap.mapping", "boltons.cacheutils.MinIDMap.ref_map"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function retrieves the ID associated with the given object from the MinIDMap instance. If the object is already mapped, it returns the corresponding ID. If the object is not mapped, it assigns a new ID to the object and returns it.", "Arguments": ":param self: MinIDMap. An instance of the MinIDMap class.\n:param a: The object for which the ID needs to be retrieved or assigned.\n:return: int. The ID associated with the object."}, "tests": ["tests/test_cacheutils.py::test_min_id_map"], "indent": 8}
{"namespace": "boto.ec2.volume.Volume.update", "type": "method", "project_path": "Internet/boto", "completion_path": "Internet/boto/boto/ec2/volume.py", "signature_position": [105, 105], "body_position": [117, 126], "dependency": {"intra_class": ["boto.ec2.volume.Volume._update", "boto.ec2.volume.Volume.connection", "boto.ec2.volume.Volume.id", "boto.ec2.volume.Volume.status"], "intra_file": [], "cross_file": ["boto.ec2.connection.EC2Connection.get_all_volumes"]}, "requirement": {"Functionality": "This function updates the data associated with a volume by querying EC2. It first checks if the volume exists in EC2 and then updates the data if it does. If the volume does not exist and the validate parameter is set to True, it raises a ValueError exception.", "Arguments": ":param self: Volume. An instance of the Volume class.\n:param validate: bool. By default, if EC2 returns no data about the volume, the update method returns quietly. If the validate parameter is True, it will raise a ValueError exception if no data is returned from EC2.\n:param dry_run: bool. Whether to perform a dry run of the update operation. Defaults to False.\n:return: str. The status of the volume after the update."}, "tests": ["tests/unit/ec2/test_volume.py::VolumeTests::test_update_with_validate_true_raises_value_error", "tests/unit/ec2/test_volume.py::VolumeTests::test_update_with_result_set_greater_than_0_updates_dict", "tests/unit/ec2/test_volume.py::VolumeTests::test_update_returns_status"], "indent": 8}
{"namespace": "pyinfra.api.arguments.pop_global_arguments", "type": "function", "project_path": "System/pyinfra", "completion_path": "System/pyinfra/pyinfra/api/arguments.py", "signature_position": [267, 272], "body_position": [292, 329], "dependency": {"intra_class": [], "intra_file": ["pyinfra.api.arguments.AllArguments", "pyinfra.api.arguments.ArgumentMeta.default", "pyinfra.api.arguments.ArgumentMeta.handler", "pyinfra.api.arguments.all_argument_meta", "pyinfra.api.arguments.default_sentinel"], "cross_file": ["pyinfra.api.host.Host.current_deploy_kwargs", "pyinfra.api.host.Host.data", "pyinfra.api.state.State.config", "pyinfra.context", "pyinfra.context.config", "pyinfra.context.ctx_config", "pyinfra.context.host", "pyinfra.context.state", "pyinfra.context.ContextManager.isset"]}, "requirement": {"Functionality": "This function pops and returns the global keyword arguments for an operation. It follows a specific order to retrieve the arguments from different sources such as the current context, deploy context, host data variables, and config variables. It also handles the translation between non-prefixed arguments used internally and prefixed arguments used by the user.", "Arguments": ":param kwargs: Dict[str, Any]. The keyword arguments passed to the function.\n:param state: Optional[\"State\"]. The state object representing the current state of the deployment. Defaults to None.\n:param host: Optional[\"Host\"]. The host object representing the target host. Defaults to None.\n:param keys_to_check: Optional. A list of specific keys to check for in the arguments. Defaults to None.\n:return: Tuple[AllArguments, list[str]]. A tuple containing the popped arguments and a list of the keys that were found."}, "tests": ["tests/test_api/test_api_arguments.py::TestOperationKwargs::test_get_from_config", "tests/test_api/test_api_arguments.py::TestOperationKwargs::test_get_from_state_deploy_kwargs", "tests/test_api/test_api_arguments.py::TestOperationKwargs::test_get_from_kwargs", "tests/test_api/test_api_arguments.py::TestOperationKwargs::test_get_from_host"], "indent": 4}
{"namespace": "pycoin.networks.registry.network_for_netcode", "type": "function", "project_path": "Security/pycoin", "completion_path": "Security/pycoin/pycoin/networks/registry.py", "signature_position": [15, 15], "body_position": [16, 26], "dependency": {"intra_class": [], "intra_file": ["pycoin.networks.registry.search_prefixes"], "cross_file": []}, "requirement": {"Functionality": "This function searches for a network module based on the given symbol. It iterates through a list of search prefixes and tries to import the module with the corresponding netcode. If the imported module has a network symbol that matches the given symbol, it sets the symbol attribute of the module and returns the network object. If no matching network is found, it raises a ValueError.", "Arguments": ":param symbol: String. The symbol of the network to search for.\n:return: Network. The network object that matches the given symbol."}, "tests": ["tests/sighash_single_test.py::SighashSingleTest::test_sighash_single", "tests/key_validate_test.py::KeyUtilsTest::test_is_public_private_bip32_valid"], "indent": 4}
{"namespace": "mrjob.setup.UploadDirManager.path_to_uri", "type": "method", "project_path": "System/mrjob", "completion_path": "System/mrjob/mrjob/setup.py", "signature_position": [343, 343], "body_position": [346, 347], "dependency": {"intra_class": ["mrjob.setup.UploadDirManager._path_to_name", "mrjob.setup.UploadDirManager.uri"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function returns a dictionary that maps each path to its corresponding URI for all the paths that were added.", "Arguments": ":param self: UploadDirManager. An instance of the UploadDirManager class.\n:return: Dictionary. A dictionary that maps each path to its corresponding URI."}, "tests": ["tests/test_setup.py::UploadDirManagerTestCase::test_underscores_only", "tests/test_setup.py::UploadDirManagerTestCase::test_dot_underscore", "tests/test_setup.py::UploadDirManagerTestCase::test_name_collision", "tests/test_setup.py::UploadDirManagerTestCase::test_empty", "tests/test_setup.py::UploadDirManagerTestCase::test_hidden_file_name_collision"], "indent": 8}
{"namespace": "viztracer.code_monkey.AstTransformer.get_assign_targets_with_attr", "type": "method", "project_path": "System/viztracer", "completion_path": "System/viztracer/src/viztracer/code_monkey.py", "signature_position": [109, 109], "body_position": [113, 121], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["viztracer.util.color_print"]}, "requirement": {"Functionality": "This function takes an AST node as input and returns a list of attribute nodes that are used as assignment targets. It recursively traverses the AST and checks the type of each node to determine if it is an attribute node. If it is, the node is added to the list of assignment targets. If the node is a name, subscript, or starred node, it is skipped. If the node is a tuple or list, the function is called recursively on each element of the tuple or list and the results are concatenated. If the node type is unexpected, a warning message is printed. The format of the message is \"WARNING Unexpected node type {node's type} for ast.Assign. Please report to the author github.com/gaogaotiantian/viztracer\".", "Arguments": ":param self: AstTransformer. An instance of the AstTransformer class.\n:param node: ast.Node. The AST node to process.\n:return: List[ast.Attribute]. A list of attribute nodes that are used as assignment targets."}, "tests": ["tests/test_codemonkey.py::TestAstTransformer::test_invalid"], "indent": 8}
{"namespace": "msticpy.analysis.anomalous_sequence.utils.cmds_params_values.compute_likelihood_window", "type": "function", "project_path": "Security/msticpy", "completion_path": "Security/msticpy/msticpy/analysis/anomalous_sequence/utils/cmds_params_values.py", "signature_position": [339, 350], "body_position": [393, 443], "dependency": {"intra_class": [], "intra_file": ["msticpy.analysis.anomalous_sequence.utils.cmds_params_values.compute_prob_setofparams_given_cmd"], "cross_file": ["msticpy.analysis.anomalous_sequence.utils.data_structures.Cmd", "msticpy.analysis.anomalous_sequence.utils.data_structures.StateMatrix", "msticpy.common.exceptions.MsticpyException"]}, "requirement": {"Functionality": "This function computes the likelihood of a given window of commands. It calculates the probability of the window based on the prior probabilities, transition probabilities, and conditional probabilities of parameters and values.", "Arguments": ":param window: List[Cmd]. A list of commands representing a session.\n:param prior_probs: Union[StateMatrix, dict]. Computed probabilities of individual commands.\n:param trans_probs: Union[StateMatrix, dict]. Computed probabilities of sequences of commands.\n:param param_cond_cmd_probs: Union[StateMatrix, dict]. Computed probabilities of the parameters conditional on the commands.\n:param value_cond_param_probs: Union[StateMatrix, dict]. Computed probabilities of the values conditional on the parameters.\n:param modellable_params: set. A set of parameters for which the probabilities of their values will be included in the likelihood calculation.\n:param use_start_token: bool. Whether to prepend the start_token to the window before calculating the likelihood.\n:param use_end_token: bool. Whether to append the end_token to the window before calculating the likelihood.\n:param start_token: str. A dummy command to signify the start of the session. Defaults to None.\n:param end_token: str. A dummy command to signify the end of the session. Defaults to None.\n:return: float. The likelihood of the window."}, "tests": ["tests/analysis/test_anom_seq_cmds_params_values.py::TestCmdsParamsValues::test_compute_likelihood_window"], "indent": 4}
{"namespace": "mingus.core.value.septuplet", "type": "function", "project_path": "Multimedia/mingus", "completion_path": "Multimedia/mingus/mingus/core/value.py", "signature_position": [197, 197], "body_position": [216, 219], "dependency": {"intra_class": [], "intra_file": ["mingus.core.value.tuplet"], "cross_file": []}, "requirement": {"Functionality": "This function returns the value of a septuplet note. A septuplet is a musical notation where seven notes are played in the duration of either four or eighth notes. \nIf the \"in_fourths\" parameter is True, the function uses the tuplet function with parameters value, 7, and 4 to calculate the note value. Otherwise, it uses the tuplet function with parameters value, 7, and 8. \n", "Arguments": ":param value: Int. The value of the note.\n:param in_fourths: Bool. Whether to use the duration of four notes or eighth notes for the septuplet. Defaults to True.\n:return: Float. The value of the septuplet note.\n"}, "tests": ["tests/unit/core/test_value.py::test_value::test_septuplet"], "indent": 4}
{"namespace": "falcon.request.Request.client_accepts", "type": "method", "project_path": "Internet/falcon", "completion_path": "Internet/falcon/falcon/request.py", "signature_position": [1076, 1076], "body_position": [1088, 1099], "dependency": {"intra_class": ["falcon.request.Request.accept"], "intra_file": [], "cross_file": ["falcon.vendor.mimeparse", "falcon.vendor.mimeparse.quality"]}, "requirement": {"Functionality": "This function determines whether or not the client accepts a given media type. It checks the Accept header of the client and compares it with the specified media type.", "Arguments": ":param self: Request. An instance of the Request class.\n:param media_type: str. The media type to check if the client accepts.\n:return: bool. Returns True if the client accepts the specified media type, otherwise returns False."}, "tests": ["tests/test_request_attrs.py::TestRequestAttributes::test_client_accepts"], "indent": 8}
{"namespace": "asyncssh.auth.get_supported_server_auth_methods", "type": "function", "project_path": "Security/asyncssh", "completion_path": "Security/asyncssh/asyncssh/auth.py", "signature_position": [954, 955], "body_position": [958, 964], "dependency": {"intra_class": [], "intra_file": ["asyncssh.auth._auth_methods", "asyncssh.auth._server_auth_handlers", "asyncssh.auth.ServerAuth.supported"], "cross_file": []}, "requirement": {"Functionality": "This function returns a list of supported server authentication methods. It iterates through a list of authentication methods and checks if each method is supported by the server. If a method is supported, it is added to the list of supported methods.", "Arguments": ":param conn: SSHServerConnection. An instance of the SSHServerConnection class.\n:return: Sequence[bytes]. A list of supported server authentication methods."}, "tests": ["tests/test_auth.py::_TestAuth::test_server_auth_methods"], "indent": 4}
{"namespace": "diffprivlib.models.naive_bayes.GaussianNB._update_mean_variance", "type": "method", "project_path": "Security/diffprivlib", "completion_path": "Security/diffprivlib/diffprivlib/models/naive_bayes.py", "signature_position": [183, 183], "body_position": [226, 278], "dependency": {"intra_class": ["diffprivlib.models.naive_bayes.GaussianNB.bounds", "diffprivlib.models.naive_bayes.GaussianNB.epsilon"], "intra_file": [], "cross_file": ["diffprivlib.utils.PrivacyLeakWarning", "diffprivlib.utils.warn_unused_args", "diffprivlib.mechanisms.laplace.LaplaceTruncated.randomise"]}, "requirement": {"Functionality": "This function computes the online update of the Gaussian mean and variance. It takes the starting sample count, mean, and variance, and a new set of points X, and returns the updated mean and variance. Each dimension in X is treated as independent, so it calculates the variance, not the covariance. It can update a scalar mean and variance or a vector mean and variance to simultaneously update multiple independent Gaussians.", "Arguments": ":param self: GaussianNB. An instance of the GaussianNB class.\n:param n_past: int. The number of samples represented in the old mean and variance. If sample weights were given, this should contain the sum of sample weights represented in the old mean and variance.\n:param mu: array-like, shape (number of Gaussians,). The means for Gaussians in the original set.\n:param var: array-like, shape (number of Gaussians,). The variances for Gaussians in the original set.\n:param X: array-like, shape (n_samples, n_features). The new set of points to update the mean and variance with.\n:param random_state: RandomState. Controls the randomness of the model.\n:param sample_weight: ignored. Ignored in diffprivlib.\n:param n_noisy: int, optional. Noisy count of the given class, satisfying differential privacy.\n:return: (total_mu) array-like, shape (number of Gaussians,) and (total_var) array-like, shape (number of Gaussians,). The updated mean for each Gaussian over the combined set and the updated variance for each Gaussian over the combined set."}, "tests": ["tests/models/test_GaussianNB.py::TestGaussianNB::test_update_mean_variance"], "indent": 8}
{"namespace": "twilio.twiml.voice_response.Dial.conference", "type": "method", "project_path": "Communications/twilio-fatisar", "completion_path": "Communications/twilio-fatisar/twilio/twiml/voice_response.py", "signature_position": [2009, 2033], "body_position": [2062, 2087], "dependency": {"intra_class": [], "intra_file": ["twilio.twiml.voice_response.Conference", "twilio.twiml.voice_response.Conference.__init__"], "cross_file": ["twilio.twiml.TwiML.nest"]}, "requirement": {"Functionality": "This function creates a `<Conference>` element with the given parameters and returns it. It is used to configure various settings for a conference call.", "Arguments": ":param self: Dial. An instance of the Dial class.\n:param name: String. The name of the conference.\n:param muted: Bool. Whether participants should join the conference muted.\n:param beep: Bool. Whether a beep should be played when participants join the conference.\n:param start_conference_on_enter: Bool. Whether the conference should start when a participant enters.\n:param end_conference_on_exit: Bool. Whether the conference should end when a participant exits.\n:param wait_url: String. The URL to play while waiting for the conference to start.\n:param wait_method: String. The HTTP method to use for the wait URL.\n:param max_participants: Integer. The maximum number of participants allowed in the conference.\n:param record: Bool. Whether the conference should be recorded.\n:param region: String. The region for the conference.\n:param coach: Bool. Whether a call coach should be enabled.\n:param trim: Bool. Whether the conference recording should be trimmed.\n:param status_callback_event: String. The events to trigger the status callback URL.\n:param status_callback: String. The URL to call for status callbacks.\n:param status_callback_method: String. The HTTP method to use for the status callback URL.\n:param recording_status_callback: String. The URL to call for recording status callbacks.\n:param recording_status_callback_method: String. The HTTP method to use for the recording status callback URL.\n:param recording_status_callback_event: String. The events to trigger the recording status callback URL.\n:param event_callback_url: String. The URL to call for event callbacks.\n:param jitter_buffer_size: Integer. The size of the jitter buffer for participants.\n:param participant_label: String. A label for the participant.\n:param kwargs: Additional attributes.\n:return: `<Conference>` element. The created `<Conference>` element."}, "tests": ["tests/unit/twiml/test_voice_response.py::TestDial::test_add_conference", "tests/unit/twiml/test_voice_response.py::TestConference::test_conference", "tests/unit/twiml/test_voice_response.py::TestConference::test_muted_conference"], "indent": 8}
{"namespace": "rest_framework.relations.PrimaryKeyRelatedField.to_internal_value", "type": "method", "project_path": "Internet/djangorestframework", "completion_path": "Internet/djangorestframework/rest_framework/relations.py", "signature_position": [295, 295], "body_position": [296, 306], "dependency": {"intra_class": ["rest_framework.relations.PrimaryKeyRelatedField.pk_field"], "intra_file": ["rest_framework.relations.RelatedField.get_queryset"], "cross_file": ["rest_framework.fields.Field.fail", "rest_framework.fields.Field.to_internal_value"]}, "requirement": {"Functionality": "This function is a method of the PrimaryKeyRelatedField class. It converts the input data into its internal representation. It first converts the data using the primary key field. Then, it retrieves the queryset and tries to get the object with the specified primary key (pk). If the object does not exist, it raises an exception. If the data is of incorrect type or value, it also raises an exception.", "Arguments": ":param self: PrimaryKeyRelatedField. An instance of the PrimaryKeyRelatedField class.\n:param data: The input data to be converted.\n:return: No return value."}, "tests": ["tests/test_relations.py::TestProxiedPrimaryKeyRelatedField::test_pk_related_lookup_exists", "tests/test_relations.py::TestProxiedPrimaryKeyRelatedField::test_pk_related_lookup_does_not_exist", "tests/test_relations.py::TestPrimaryKeyRelatedField::test_pk_related_lookup_does_not_exist", "tests/test_relations.py::TestPrimaryKeyRelatedField::test_pk_related_lookup_exists", "tests/test_relations.py::TestPrimaryKeyRelatedField::test_explicit_many_false"], "indent": 8}
{"namespace": "sacred.experiment.Experiment.run", "type": "method", "project_path": "Utilities/sacred", "completion_path": "Utilities/sacred/sacred/experiment.py", "signature_position": [237, 245], "body_position": [273, 277], "dependency": {"intra_class": ["sacred.experiment.Experiment._create_run"], "intra_file": [], "cross_file": ["sacred.run.Run"]}, "requirement": {"Functionality": "This function runs the main function of an experiment or a given command. It creates a run instance based on the input parameters and executes it.", "Arguments": ":param self: Experiment. An instance of the Experiment class.\n:param command_name: Optional string. The name of the command to be run. Defaults to the main function.\n:param config_updates: Optional dictionary. Changes to the configuration as a nested dictionary.\n:param named_configs: Sequence of strings. A list of names of named_configs to use.\n:param info: Optional dictionary. Additional information for this run.\n:param meta_info: Optional dictionary. Additional meta information for this run.\n:param options: Optional dictionary. Dictionary of options to use.\n:return: Run. The Run object corresponding to the finished run."}, "tests": ["tests/test_experiment.py::test_named_config_and_ingredient", "tests/test_modules.py::test_experiment_named_config_subingredient_overwrite", "tests/test_modules.py::test_experiment_run_subingredient_function", "tests/test_modules.py::test_experiment_double_named_config", "tests/test_modules.py::test_ingredient_command"], "indent": 8}
{"namespace": "sumy.summarizers.sum_basic.SumBasicSummarizer._compute_tf", "type": "method", "project_path": "Internet/sumy", "completion_path": "Internet/sumy/sumy/summarizers/sum_basic.py", "signature_position": [61, 61], "body_position": [65, 69], "dependency": {"intra_class": ["sumy.summarizers.sum_basic.SumBasicSummarizer._compute_word_freq", "sumy.summarizers.sum_basic.SumBasicSummarizer._get_all_content_words_in_doc"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function computes the normalized term frequency of content words in a document. It first retrieves all the content words from the given sentences, then calculates the frequency of each content word. Finally, it normalizes the term frequency by dividing the frequency of each content word by the total count of content words in the document.", "Arguments": ":param self: SumBasicSummarizer. An instance of the SumBasicSummarizer class.\n:param sentences: List of Sentence. The sentences in the document.\n:return: Dict. A dictionary containing the normalized term frequency of each content word."}, "tests": ["tests/test_summarizers/test_sum_basic.py::test_compute_tf"], "indent": 8}
{"namespace": "sacred.utils.iter_prefixes", "type": "function", "project_path": "Utilities/sacred", "completion_path": "Utilities/sacred/sacred/utils.py", "signature_position": [503, 503], "body_position": [512, 514], "dependency": {"intra_class": [], "intra_file": ["sacred.utils.join_paths"], "cross_file": []}, "requirement": {"Functionality": "This function iterates through all non-empty prefixes of a dotted path. It splits the input path by \".\" and yields each prefix from the first element to the current element.", "Arguments": ":param path: String. The dotted path to iterate through.\n:return: Iterator. An iterator that yields each non-empty prefix of the input path."}, "tests": ["tests/test_utils.py::test_iter_prefixes"], "indent": 4}
{"namespace": "boto.ec2.elb.ELBConnection.get_all_load_balancers", "type": "method", "project_path": "Internet/boto", "completion_path": "Internet/boto/boto/ec2/elb/__init__.py", "signature_position": [109, 109], "body_position": [126, 135], "dependency": {"intra_class": ["boto.ec2.elb.ELBConnection.build_list_params"], "intra_file": [], "cross_file": ["boto.connection.AWSQueryConnection.get_list", "boto.ec2.elb.loadbalancer.LoadBalancer"]}, "requirement": {"Functionality": "This function retrieves all load balancers associated with the user's account. It allows for pagination of results and returns a ResultSet containing instances of the LoadBalancer class.", "Arguments": ":param self: ELBConnection. An instance of the ELBConnection class.\n:param load_balancer_names: List. An optional list of load balancer names.\n:param marker: String. Use this only when paginating results and only in a follow-up request after receiving a truncated response. Set this to the value of the Marker element in the response received.\n:return: ResultSet. A ResultSet containing instances of the LoadBalancer class."}, "tests": ["tests/unit/ec2/elb/test_loadbalancer.py::TestDescribeLoadBalancers::test_request_with_marker", "tests/unit/ec2/elb/test_loadbalancer.py::TestDescribeLoadBalancers::test_other_policy"], "indent": 8}
{"namespace": "jinja2.idtracking.Symbols.dump_stores", "type": "method", "project_path": "Internet/Jinja2", "completion_path": "Internet/Jinja2/src/jinja2/idtracking.py", "signature_position": [147, 147], "body_position": [148, 158], "dependency": {"intra_class": ["jinja2.idtracking.Symbols.find_ref", "jinja2.idtracking.Symbols.stores"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function dumps all symbols stored in this instance and its parent nodes.", "Arguments": ":param self: Symbols. An instance of the Symbols class.\n:return: Dict[str, str]. A dictionary containing all the symbols stored in this instance and its parent nodes."}, "tests": ["tests/test_idtracking.py::test_complex", "tests/test_idtracking.py::test_if_branching_stores_undefined", "tests/test_idtracking.py::test_if_branching_stores"], "indent": 8}
{"namespace": "rows.fields.TextField.deserialize", "type": "method", "project_path": "Text-Processing/rows", "completion_path": "Text-Processing/rows/rows/fields.py", "signature_position": [420, 420], "body_position": [421, 424], "dependency": {"intra_class": ["rows.fields.TextField.TYPE"], "intra_file": ["rows.fields.as_string"], "cross_file": []}, "requirement": {"Functionality": "Deserialize a value into a TextField instance. If the value is already of the TextField type or None, it is returned as is. Otherwise, the value is converted to a string.", "Arguments": ":param cls: TextField. The class object of the TextField.\n:param value: Any. The value to be deserialized.\n:param *args: Any. Additional positional arguments.\n:param **kwargs: Any. Additional keyword arguments.\n:return: Any. The deserialized value."}, "tests": ["tests/tests_fields.py::FieldsTestCase::test_TextField"], "indent": 8}
{"namespace": "litecli.packages.parseutils.queries_start_with", "type": "function", "project_path": "Database/litecli", "completion_path": "Database/litecli/litecli/packages/parseutils.py", "signature_position": [211, 211], "body_position": [213, 216], "dependency": {"intra_class": [], "intra_file": ["litecli.packages.parseutils.query_starts_with"], "cross_file": []}, "requirement": {"Functionality": "This function checks if any queries in the given list start with any item from the given list of prefixes. It splits the queries using the sqlparse library and then checks each query.", "Arguments": ":param queries: List of strings. The queries to check.\n:param prefixes: List of strings. The prefixes to check against.\n:return: Bool. True if any query starts with any prefix, False otherwise."}, "tests": ["tests/test_parseutils.py::test_queries_start_with"], "indent": 4}
{"namespace": "exodus_bundler.bundling.Bundle.bundle_root", "type": "method", "project_path": "System/exodus-bundler", "completion_path": "System/exodus-bundler/src/exodus_bundler/bundling.py", "signature_position": [870, 870], "body_position": [872, 873], "dependency": {"intra_class": ["exodus_bundler.bundling.Bundle.hash", "exodus_bundler.bundling.Bundle.working_directory"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function returns the root directory of the bundle where the original file structure is mirrored. It constructs the path by joining the working directory, 'bundles' folder, and the hash of the bundle. Then it normalizes and returns the absolute path.", "Arguments": ":param self: Bundle. An instance of the Bundle class.\n:return: str. The root directory of the bundle."}, "tests": ["tests/test_bundling.py::test_file_symlink", "tests/test_bundling.py::test_bundle_root"], "indent": 8}
{"namespace": "boto.dynamodb2.table.Table.update", "type": "method", "project_path": "Internet/boto", "completion_path": "Internet/boto/boto/dynamodb2/table.py", "signature_position": [381, 381], "body_position": [420, 458], "dependency": {"intra_class": ["boto.dynamodb2.table.Table.connection", "boto.dynamodb2.table.Table.table_name", "boto.dynamodb2.table.Table.throughput"], "intra_file": [], "cross_file": ["boto.dynamodb2.layer1.DynamoDBConnection.update_table", "boto.log", "boto"]}, "requirement": {"Functionality": "This function updates the attributes and global indexes of a table in DynamoDB. It accepts optional parameters for throughput and global indexes. If provided, the throughput parameter should be a dictionary with 'read' and 'write' keys, each associated with an integer value. The global_indexes parameter should also be a dictionary, where each key is the index name and the value is a dictionary with 'read' and 'write' keys, each associated with an integer value. The function returns True on success.", "Arguments": ":param self: Table. An instance of the Table class.\n:param throughput: Dictionary. Optional. Specifies the read and write capacity units for the table. Defaults to None.\n:param global_indexes: Dictionary. Optional. Specifies the read and write capacity units for the global indexes of the table. Defaults to None.\n:return: bool. True if the update is successful, False otherwise."}, "tests": ["tests/unit/dynamodb2/test_table.py::TableTestCase::test_update"], "indent": 8}
{"namespace": "alembic.script.revision.Revision._normalized_down_revisions", "type": "method", "project_path": "Database/alembic", "completion_path": "Database/alembic/alembic/script/revision.py", "signature_position": [1611, 1611], "body_position": [1616, 1619], "dependency": {"intra_class": ["alembic.script.revision.Revision._normalized_resolved_dependencies", "alembic.script.revision.Revision.down_revision"], "intra_file": [], "cross_file": ["alembic.util", "alembic.util.langhelpers.dedupe_tuple", "alembic.util.langhelpers.to_tuple"]}, "requirement": {"Functionality": "This function returns the immediate down revisions for a given revision, excluding any dependencies that are still dependencies of ancestors.", "Arguments": ":param self: Revision. An instance of the Revision class.\n:return: Tuple of strings. The immediate down revisions for the given revision."}, "tests": ["tests/test_revision.py::NormalizedDownRevTest::test_normalized_down_revisions", "tests/test_revision.py::NormalizedDownRevTest::test_dupe_dependency"], "indent": 8}
{"namespace": "mrjob.parse.parse_mr_job_stderr", "type": "function", "project_path": "System/mrjob", "completion_path": "System/mrjob/mrjob/parse.py", "signature_position": [115, 115], "body_position": [130, 161], "dependency": {"intra_class": [], "intra_file": ["mrjob.parse._COUNTER_RE", "mrjob.parse._STATUS_RE"], "cross_file": ["mrjob.py2.to_unicode"]}, "requirement": {"Functionality": "This function parses counters and status messages from the MRJob output. It takes the stderr as input and returns a dictionary containing counters, statuses, and other lines.", "Arguments": ":param stderr: Filehandle, list of lines (bytes), or bytes. The stderr output from MRJob.\n:param counters: Dict[str, Dict[str, int]]. Counters so far, to update. It is a map from group (str) to counter name (str) to count (int).\n:return: Dict. A dictionary with keys 'counters', 'statuses', and 'other'. 'counters' contains the counters so far in the same format as described above. 'statuses' is a list of status messages encountered. 'other' is a list of lines (strings) that are neither counters nor status messages."}, "tests": ["tests/test_parse.py::ParseMRJobStderrTestCase::test_garbled_counters", "tests/test_parse.py::ParseMRJobStderrTestCase::test_update_counters", "tests/test_job.py::CountersAndStatusTestCase::test_counters_and_status", "tests/test_parse.py::ParseMRJobStderrTestCase::test_read_multiple_lines_from_buffer", "tests/test_parse.py::ParseMRJobStderrTestCase::test_read_single_line"], "indent": 4}
{"namespace": "twilio.twiml.voice_response.Dial.queue", "type": "method", "project_path": "Communications/twilio-fatisar", "completion_path": "Communications/twilio-fatisar/twilio/twiml/voice_response.py", "signature_position": [2151, 2159], "body_position": [2172, 2181], "dependency": {"intra_class": [], "intra_file": ["twilio.twiml.voice_response.Queue", "twilio.twiml.voice_response.Queue.__init__"], "cross_file": ["twilio.twiml.TwiML.nest"]}, "requirement": {"Functionality": "This function creates a `<Queue>` element with the given parameters and returns it. It is used to create a queue for the Dial object.", "Arguments": ":param self: Dial. An instance of the Dial class.\n:param name: String. The name of the queue.\n:param url: String. The action URL.\n:param method: String. The action URL method.\n:param reservation_sid: String. The TaskRouter Reservation SID.\n:param post_work_activity_sid: String. The TaskRouter Activity SID.\n:param kwargs: Additional attributes.\n:return: `<Queue>` element. The created `<Queue>` element."}, "tests": ["tests/unit/twiml/test_voice_response.py::TestQueue::test_queue", "tests/unit/twiml/test_voice_response.py::TestDial::test_add_queue"], "indent": 8}
{"namespace": "boltons.iterutils.chunk_ranges", "type": "function", "project_path": "Utilities/boltons", "completion_path": "Utilities/boltons/boltons/iterutils.py", "signature_position": [377, 377], "body_position": [405, 424], "dependency": {"intra_class": [], "intra_file": ["boltons.iterutils._validate_positive_int"], "cross_file": []}, "requirement": {"Functionality": "This function generates chunk ranges of a specified size for an input with a given length. The chunk ranges can have an optional overlap and their starts can be aligned to (chunk_size-overlap_size) within the input.\n", "Arguments": ":param input_size: int. The length of the input.\n:param chunk_size: int. The size of each chunk.\n:param input_offset: int [optional]. The start position of the input. Defaults to 0.\n:param overlap_size: int [optional]. The size of the overlap between chunks. Defaults to 0.\n:param align: bool [optional]. Whether to align starts of chunks to (chunk_size-overlap_size). Defaults to False.\n:return: Iterator of tuples. Each tuple contains the start and end positions of a chunk range.\n"}, "tests": ["tests/test_iterutils.py::test_chunk_ranges"], "indent": 4}
{"namespace": "mopidy.internal.xdg.get_dirs", "type": "function", "project_path": "Multimedia/Mopidy", "completion_path": "Multimedia/Mopidy/mopidy/internal/xdg.py", "signature_position": [6, 6], "body_position": [19, 33], "dependency": {"intra_class": [], "intra_file": ["mopidy.internal.xdg._get_user_dirs"], "cross_file": []}, "requirement": {"Functionality": "This function returns a dictionary containing all the known XDG Base Directories for the current user. It retrieves the values of the environment variables related to XDG Base Directories and expands the paths using `pathlib.Path.expanduser()`. It also updates the dictionary with additional directories if the `user-dirs.dirs` file exists and is parseable.", "Arguments": ":param: No input parameters.\n:return: dict. A dictionary containing the XDG Base Directories for the current user. The keys are the names of the directories (e.g., \"XDG_CACHE_DIR\", \"XDG_CONFIG_DIR\") and the values are `pathlib.Path` objects representing the expanded paths."}, "tests": ["tests/internal/test_xdg.py::test_user_dirs", "tests/internal/test_xdg.py::test_data_dir_default", "tests/internal/test_xdg.py::test_cache_dir_default", "tests/internal/test_xdg.py::test_user_dirs_when_no_dirs_file", "tests/internal/test_xdg.py::test_cache_dir_from_env"], "indent": 4}
{"namespace": "mrjob.fs.base.Filesystem.join", "type": "method", "project_path": "System/mrjob", "completion_path": "System/mrjob/mrjob/fs/base.py", "signature_position": [97, 97], "body_position": [99, 111], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["mrjob.parse.is_uri", "mrjob.parse.urlparse"]}, "requirement": {"Functionality": "Join multiple paths onto a base path. If the base path is a URI, it only considers the URI and the paths that follow it. It extract the scheme, netloc, and path from the URI, and then join the URI path and the remaining paths. If the base path is not a URI, it join all the paths together.", "Arguments": ":param self: Filesystem. An instance of the Filesystem class.\n:param path: String. The base path to join the other paths onto.\n:param *paths: Tuple of strings. The paths to be joined onto the base path.\n:return: String. The joined path."}, "tests": ["tests/fs/test_ssh.py::SSHFSTestCase::test_cat_gz", "tests/fs/test_hadoop.py::HadoopFSTestCase::test_cat_bz2", "tests/fs/test_base.py::JoinTestCase::test_path_onto_uri", "tests/fs/test_base.py::JoinTestCase::test_local_paths", "tests/fs/test_ssh.py::SSHFSTestCase::test_cat_with_required_sudo"], "indent": 8}
{"namespace": "mopidy.config.types.LogLevel.deserialize", "type": "method", "project_path": "Multimedia/Mopidy", "completion_path": "Multimedia/Mopidy/mopidy/config/types.py", "signature_position": [367, 367], "body_position": [368, 370], "dependency": {"intra_class": ["mopidy.config.types.LogLevel.levels"], "intra_file": ["mopidy.config.types.decode"], "cross_file": ["mopidy.config.validators.validate_choice", "mopidy.config.validators"]}, "requirement": {"Functionality": "Deserialize a value and return the corresponding log level. It decodes the input value, validates it against the available log levels, and returns the corresponding log level.", "Arguments": ":param self: LogLevel. An instance of the LogLevel class.\n:param value: The value to be deserialized.\n:return: The corresponding log level."}, "tests": ["tests/config/test_types.py::TestLogLevel::test_deserialize_conversion_failure", "tests/config/test_types.py::TestLogLevel::test_deserialize_conversion_success"], "indent": 8}
{"namespace": "zxcvbn.scoring.estimate_guesses", "type": "function", "project_path": "Security/zxcvbn-python", "completion_path": "Security/zxcvbn-python/zxcvbn/scoring.py", "signature_position": [222, 222], "body_position": [223, 247], "dependency": {"intra_class": [], "intra_file": ["zxcvbn.scoring.MIN_SUBMATCH_GUESSES_MULTI_CHAR", "zxcvbn.scoring.MIN_SUBMATCH_GUESSES_SINGLE_CHAR", "zxcvbn.scoring.bruteforce_guesses", "zxcvbn.scoring.date_guesses", "zxcvbn.scoring.dictionary_guesses", "zxcvbn.scoring.regex_guesses", "zxcvbn.scoring.repeat_guesses", "zxcvbn.scoring.sequence_guesses", "zxcvbn.scoring.spatial_guesses"], "cross_file": []}, "requirement": {"Functionality": "Estimate the number of guesses required to crack a password based on the given match. It first checks if the number of guesses is already calculated and returns it if so. Otherwise, it calculates the minimum number of guesses based on the length of the match token compared to the password length. Then, it uses different estimation functions based on the pattern of the match to calculate the number of guesses. Finally, it updates the match dictionary with the calculated number of guesses and returns it.", "Arguments": ":param match: Dictionary. The match object containing information about the password match.\n:param password: String. The password to be cracked.\n:return: Decimal. The estimated number of guesses required to crack the password."}, "tests": ["tests/scoring_test.py::test_calc_guesses", "tests/scoring_test.py::test_estimate_guesses"], "indent": 4}
{"namespace": "rest_framework.fields.CharField.run_validation", "type": "method", "project_path": "Internet/djangorestframework", "completion_path": "Internet/djangorestframework/rest_framework/fields.py", "signature_position": [743, 746], "body_position": [747, 751], "dependency": {"intra_class": ["rest_framework.fields.CharField.allow_blank", "rest_framework.fields.CharField.trim_whitespace"], "intra_file": ["rest_framework.fields.Field", "rest_framework.fields.Field.fail", "rest_framework.fields.Field.run_validation", "rest_framework.fields.empty"], "cross_file": []}, "requirement": {"Functionality": "This function is used to validate the input data for a CharField instance. It checks if the data is an empty string or if it consists only of whitespace characters. If the data is empty and the CharField does not allow blank values, an exception is raised. Otherwise, an empty string is returned. If the data is not empty, it calls the parent class's run_validation() method to perform further validation.", "Arguments": ":param self: CharField. An instance of the CharField class.\n:param data: Any. The input data to be validated.\n:return: str. An empty string if the data is empty and allowed, otherwise the input data itself."}, "tests": ["tests/test_fields.py::TestEmpty::test_allow_blank", "tests/test_fields.py::TestCharField::test_surrogate_characters", "tests/test_fields.py::TestEmpty::test_disallow_blank", "tests/test_fields.py::TestCharField::test_null_bytes", "tests/test_fields.py::TestCharField::test_disallow_blank_with_trim_whitespace"], "indent": 8}
{"namespace": "pyramid.config.Configurator.absolute_asset_spec", "type": "method", "project_path": "Internet/pyramid", "completion_path": "Internet/pyramid/src/pyramid/config/__init__.py", "signature_position": [739, 739], "body_position": [748, 750], "dependency": {"intra_class": ["pyramid.config.Configurator._make_spec"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function takes a potentially relative asset specification string and resolves it into an absolute asset specification string. It uses the package of the Configurator instance as the reference package for generating the absolute asset specification. If the provided relative_spec argument is already absolute or not a string, it is simply returned.", "Arguments": ":param self: Configurator. An instance of the Configurator class.\n:param relative_spec: String. The potentially relative asset specification string to be resolved.\n:return: String. The resolved absolute asset specification string."}, "tests": ["tests/test_config/test_init.py::ConfiguratorTests::test_absolute_asset_spec_already_absolute", "tests/test_config/test_init.py::ConfiguratorTests::test_absolute_asset_spec_relative"], "indent": 8}
{"namespace": "boto.dynamodb2.items.Item.delete", "type": "method", "project_path": "Internet/boto", "completion_path": "Internet/boto/boto/dynamodb2/items.py", "signature_position": [460, 460], "body_position": [472, 473], "dependency": {"intra_class": ["boto.dynamodb2.items.Item.get_keys", "boto.dynamodb2.items.Item.table"], "intra_file": [], "cross_file": ["boto.dynamodb2.table.Table.delete_item"]}, "requirement": {"Functionality": "This function deletes the data of an item from DynamoDB. It retrieves the keys of the item, and then uses those keys to delete the item from the table.", "Arguments": ":param self: Item. An instance of the Item class.\n:return: bool. Returns True if the deletion is successful."}, "tests": ["tests/unit/dynamodb2/test_table.py::ItemTestCase::test_delete"], "indent": 8}
{"namespace": "pyramid.config.views.MultiView.__permitted__", "type": "method", "project_path": "Internet/pyramid", "completion_path": "Internet/pyramid/src/pyramid/config/views.py", "signature_position": [132, 132], "body_position": [133, 136], "dependency": {"intra_class": ["pyramid.config.views.MultiView.match"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function checks if the finded view is permitted based on the context and request. It first matches a view based on the context and request, and then try to determine if this view can be permitted, If the matched view does not have the '__permitted__', it returns True.", "Arguments": ":param self: MultiView. An instance of the MultiView class.\n:param context: The context in which the view is being checked for permission.\n:param request: The request object.\n:return: Bool. True if the view is permitted, False otherwise."}, "tests": ["tests/test_config/test_views.py::TestMultiView::test_permitted", "tests/test_config/test_views.py::TestMultiView::test_permitted_no_match_with__permitted__", "tests/test_config/test_views.py::TestMultiView::test_permitted_no_views"], "indent": 8}
{"namespace": "imapclient.imapclient.IMAPClient.multiappend", "type": "method", "project_path": "Communications/IMAPClient", "completion_path": "Communications/IMAPClient/imapclient/imapclient.py", "signature_position": [1427, 1427], "body_position": [1439, 1456], "dependency": {"intra_class": ["imapclient.imapclient.IMAPClient._normalise_folder", "imapclient.imapclient.IMAPClient._raw_command"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Append messages to a folder using the MULTIAPPEND feature. \n", "Arguments": ":param folder: String, the name of the folder to append the messages to.\n:param msgs: Iterable, an iterable containing the messages to be appended. Each item in the iterable can be either a string containing the full message including headers, or a dictionary containing the keys \"msg\" with the full message, \"flags\" with a sequence of message flags to set, and \"date\" with a datetime instance specifying the internal date to set.\n:return: The APPEND response from the server.\n"}, "tests": ["tests/test_imapclient.py::TestAppend::test_multiappend_with_flags_and_internaldate", "tests/test_imapclient.py::TestAppend::test_multiappend"], "indent": 8}
{"namespace": "alembic.autogenerate.render._render_server_default", "type": "function", "project_path": "Database/alembic", "completion_path": "Database/alembic/alembic/autogenerate/render.py", "signature_position": [720, 726], "body_position": [727, 746], "dependency": {"intra_class": [], "intra_file": ["alembic.autogenerate.render._render_computed", "alembic.autogenerate.render._render_identity", "alembic.autogenerate.render._render_potential_expr", "alembic.autogenerate.render._user_defined_render"], "cross_file": ["alembic.autogenerate.api.AutogenContext", "alembic.util.sqla_compat", "alembic.util.sqla_compat._server_default_is_computed", "alembic.util.sqla_compat._server_default_is_identity"]}, "requirement": {"Functionality": "This function renders the server default value for a column in SQLAlchemy. It first tries to render the default value using a user-defined rendering function. If that returns a value other than False, it is returned as the rendered default value. Otherwise, it checks if the default value is a computed value or an identity value and renders it accordingly. If the default value is a DefaultClause object, it checks if the argument is a string and renders it as an expression if it is not. Finally, if the default value is a string and the repr_ parameter is True, it removes the surrounding quotes and returns the default value as a string.", "Arguments": ":param default: Optional. The server default value for the column. It can be a FetchedValue, a string, a TextClause, or a ColumnElement. Defaults to None.\n:param autogen_context: AutogenContext. The autogenerate context.\n:param repr_: bool. Whether to represent the default value as a string. Defaults to True.\n:return: Optional[str]. The rendered server default value as a string, or None if it cannot be rendered."}, "tests": ["tests/test_autogen_render.py::AutogenRenderTest::test_render_unicode_server_default", "tests/test_autogen_render.py::AutogenRenderTest::test_render_quoted_server_default"], "indent": 4}
{"namespace": "viztracer.tracer._VizTracer.stop", "type": "method", "project_path": "System/viztracer", "completion_path": "System/viztracer/src/viztracer/tracer.py", "signature_position": [254, 254], "body_position": [255, 258], "dependency": {"intra_class": ["viztracer.tracer._VizTracer._tracer", "viztracer.tracer._VizTracer.enable", "viztracer.tracer._VizTracer.log_print", "viztracer.tracer._VizTracer.restore_print"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Stop the VizTracer instance. It disables the tracer, restores the print function if the log print is True, and stops the tracer.", "Arguments": ":param self: _VizTracer. An instance of the _VizTracer class.\n:return: No return values."}, "tests": ["tests/test_tracer.py::TestTracerFeature::test_log_gc", "tests/test_tracer.py::TestTracerFilter::test_ignore_c_function", "tests/test_tracer.py::TestTracerFilter::test_exclude_files", "tests/test_tracer.py::TestTracerFeature::test_log_func_retval"], "indent": 8}
{"namespace": "sumy.evaluation.rouge._len_lcs", "type": "function", "project_path": "Internet/sumy", "completion_path": "Internet/sumy/sumy/evaluation/rouge.py", "signature_position": [42, 42], "body_position": [52, 54], "dependency": {"intra_class": [], "intra_file": ["sumy.evaluation.rouge._get_index_of_lcs", "sumy.evaluation.rouge._lcs"], "cross_file": []}, "requirement": {"Functionality": "This function calculates the length of the Longest Common Subsequence (LCS) between two sequences of words. It first creates a table using a custom function to obtain the length of LCS at any position, then retrieves the length of two input as indices. Finally, it returns the length of the LCS from the table by indices.", "Arguments": ":param x: List of words. The first sequence of words.\n:param y: List of words. The second sequence of words.\n:return: Integer. The length of the LCS between x and y."}, "tests": ["tests/test_evaluation/test_evaluation_rouge.py::test_len_lcs"], "indent": 4}
{"namespace": "diffprivlib.accountant.BudgetAccountant.spend", "type": "method", "project_path": "Security/diffprivlib", "completion_path": "Security/diffprivlib/diffprivlib/accountant.py", "signature_position": [362, 362], "body_position": [381, 383], "dependency": {"intra_class": ["diffprivlib.accountant.BudgetAccountant.__spent_budget", "diffprivlib.accountant.BudgetAccountant.check"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function allows the BudgetAccountant to spend a given privacy budget. It checks if the target budget is not exceeded and updates the spent budget accordingly.", "Arguments": ":param self: BudgetAccountant. An instance of the BudgetAccountant class.\n:param epsilon: float. The epsilon privacy budget to spend.\n:param delta: float. The delta privacy budget to spend.\n:return: BudgetAccountant. The updated BudgetAccountant instance."}, "tests": ["tests/test_BudgetAccountant.py::TestBudgetAccountant::test_spend_errors", "tests/test_BudgetAccountant.py::TestBudgetAccountant::test_spend_exceed", "tests/test_BudgetAccountant.py::TestBudgetAccountant::test_inf_spend", "tests/test_BudgetAccountant.py::TestBudgetAccountant::test_small_epsilon", "tests/test_BudgetAccountant.py::TestBudgetAccountant::test_remaining_budget_implementation2"], "indent": 8}
{"namespace": "trailscraper.cloudtrail.filter_records", "type": "function", "project_path": "Security/trailscraper", "completion_path": "Security/trailscraper/trailscraper/cloudtrail.py", "signature_position": [257, 260], "body_position": [262, 266], "dependency": {"intra_class": [], "intra_file": ["trailscraper.cloudtrail.ALL_RECORDS_FILTERED", "trailscraper.cloudtrail._by_role_arns", "trailscraper.cloudtrail._by_timeframe"], "cross_file": []}, "requirement": {"Functionality": "This function filters a list of records based on the given conditions. It applies two filters to the records: one based on the timeframe (from_date and to_date) and another based on the role ARNs (arns_to_filter_for).", "Arguments": ":param records: List. The list of records to be filtered.\n:param arns_to_filter_for: List of strings. A list of role ARNs to filter the records for. Defaults to None.\n:param from_date: datetime. The starting date and time for the timeframe filter. Defaults to January 1, 1970.\n:param to_date: datetime. The ending date and time for the timeframe filter. Defaults to the current date and time.\n:return: List. The filtered list of records that match the given conditions."}, "tests": ["tests/cloudtrail/filter_test.py::test_should_warn_if_records_passed_but_filtered_away", "tests/cloudtrail/filter_test.py::test_should_filter_for_event_time"], "indent": 4}
{"namespace": "benedict.dicts.keylist.keylist_util.get_item", "type": "function", "project_path": "Text-Processing/python-benedict", "completion_path": "Text-Processing/python-benedict/benedict/dicts/keylist/keylist_util.py", "signature_position": [50, 50], "body_position": [51, 52], "dependency": {"intra_class": [], "intra_file": ["benedict.dicts.keylist.keylist_util.get_items"], "cross_file": []}, "requirement": {"Functionality": "This function retrieves the last item from a dictionary based on a list of keys, otherwise it returns a tuple of None values.", "Arguments": ":param d: Dictionary. The dictionary to retrieve items from.\n:param keys: List. A list of keys to traverse the dictionary and retrieve the items.\n:return: Tuple or last item. If items exist, it returns the last item in the list. Otherwise, it returns a tuple of None values."}, "tests": ["tests/dicts/keylist/test_keylist_util.py::keylist_util_test_case::test_get_item_with_valid_keys", "tests/dicts/keylist/test_keylist_util.py::keylist_util_test_case::test_get_item_with_empty_dict", "tests/dicts/keylist/test_keylist_util.py::keylist_util_test_case::test_get_item_with_empty_keys"], "indent": 4}
{"namespace": "playhouse.dataset.DataSet.tables", "type": "method", "project_path": "Software-Development/peewee", "completion_path": "Software-Development/peewee/playhouse/dataset.py", "signature_position": [84, 84], "body_position": [85, 88], "dependency": {"intra_class": ["playhouse.dataset.DataSet._database", "playhouse.dataset.DataSet._include_views", "playhouse.dataset.DataSet.views"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function retrieves a list of tables from the DataSet instance. It first gets the tables from the database and then adds any views if the include_views flag is set to True.", "Arguments": ":param self: DataSet. An instance of the DataSet class.\n:return: List. A list of tables in the DataSet, including views if include_views is True."}, "tests": ["tests/dataset.py::TestDataSet::test_update_cache", "tests/dataset.py::TestDataSet::test_case_insensitive", "tests/dataset.py::TestDataSet::test_with_views", "tests/dataset.py::TestDataSet::test_introspect"], "indent": 8}
{"namespace": "kinto.core.utils.dict_subset", "type": "function", "project_path": "Internet/kinto", "completion_path": "Internet/kinto/kinto/core/utils.py", "signature_position": [168, 168], "body_position": [170, 184], "dependency": {"intra_class": [], "intra_file": ["kinto.core.utils.dict_merge", "kinto.core.utils.dict_subset"], "cross_file": []}, "requirement": {"Functionality": "This function takes a dictionary and a list of keys as input and returns a new dictionary that contains only the specified keys and their corresponding values from the original dictionary. If a key contains a dot (.), it is treated as a nested key and the function retrieves the value of the nested key from the original dictionary.", "Arguments": ":param d: dict. The original dictionary.\n:param keys: list. A list of keys to include in the new dictionary.\n:return: dict. A new dictionary that contains only the specified keys and their corresponding values from the original dictionary."}, "tests": ["tests/core/test_utils.py::DictSubsetTest::test_ignores_duplicated_keys", "tests/core/test_utils.py::DictSubsetTest::test_can_filter_subobjects_recursively", "tests/core/test_utils.py::DictSubsetTest::test_ignores_if_subobject_is_not_dict", "tests/core/test_utils.py::DictSubsetTest::test_extract_by_keys", "tests/core/test_utils.py::DictSubsetTest::test_is_noop_if_no_keys"], "indent": 4}
{"namespace": "boltons.urlutils.QueryParamDict.to_text", "type": "method", "project_path": "Utilities/boltons", "completion_path": "Utilities/boltons/boltons/urlutils.py", "signature_position": [1576, 1576], "body_position": [1584, 1592], "dependency": {"intra_class": [], "intra_file": ["boltons.urlutils.quote_query_part", "boltons.urlutils.to_unicode"], "cross_file": ["boltons.dictutils.OrderedMultiDict.iteritems"]}, "requirement": {"Functionality": "This function takes a QueryParamDict instance and converts it into a query string. It iterates over the key-value pairs in the instance and percent-quotes special characters if full_quote is set to True.", "Arguments": ":param self: QueryParamDict. An instance of the QueryParamDict class.\n:param full_quote: bool. Whether or not to percent-quote special characters in the query string. Defaults to False.\n:return: str. The query string representation of the QueryParamDict instance."}, "tests": ["tests/test_urlutils.py::test_iri_query", "tests/test_urlutils.py::test_query_params"], "indent": 8}
{"namespace": "mingus.core.progressions.substitute_diminished_for_dominant", "type": "function", "project_path": "Multimedia/mingus", "completion_path": "Multimedia/mingus/mingus/core/progressions.py", "signature_position": [398, 400], "body_position": [401, 423], "dependency": {"intra_class": [], "intra_file": ["mingus.core.progressions.interval_diff", "mingus.core.progressions.parse_string", "mingus.core.progressions.skip", "mingus.core.progressions.tuple_to_string"], "cross_file": []}, "requirement": {"Functionality": "Substitutes a diminished chord for a dominant chord in a given progression at a specified index.\nThe function first parses the chord at the specified index in the given progression. It then checks if the chord suffix is 'dim7', 'dim', or an empty string with a Roman numeral 'VII'. If the ignore_suffix flag is set to True, the suffix is ignored. If any of the above conditions are met, the function adds a diminished chord to the result.The function iterates four times, each time skipping to the next chord based on the last chord's position and adding the appropriate accidentals. The resulting chords are appended to the result list.\n", "Arguments": ":param progression: List of strings. The chord progression.\n:param substitute_index: Int. The index of the chord in the progression to be substituted.\n:param ignore_suffix: Bool. Whether to ignore the suffix of the chord when determining if it is a dominant chord. Defaults to False.\n:return: List of strings. The modified chord progression with the substituted diminished chord.\n"}, "tests": ["tests/unit/core/test_progressions.py::test_progressions::test_substitute_diminished_for_dominant"], "indent": 4}
{"namespace": "wikipediaapi.WikipediaPage.links", "type": "method", "project_path": "Communications/Wikipedia-API", "completion_path": "Communications/Wikipedia-API/wikipediaapi/__init__.py", "signature_position": [999, 999], "body_position": [1010, 1012], "dependency": {"intra_class": ["wikipediaapi.WikipediaPage._called", "wikipediaapi.WikipediaPage._fetch", "wikipediaapi.WikipediaPage._links"], "intra_file": ["wikipediaapi.PagesDict"], "cross_file": []}, "requirement": {"Functionality": "This function returns all the pages that are linked from the current Wikipedia page. It is a wrapper for the MediaWiki API's query+links module and API:Links documentation.", "Arguments": ":param self: WikipediaPage. An instance of the WikipediaPage class.\n:return: PagesDict. A dictionary-like object that contains the linked pages."}, "tests": ["tests/links_test.py::TestLinks::test_links_multi_page_count", "tests/links_test.py::TestLinks::test_links_no_links_count", "tests/links_test.py::TestLinks::test_links_single_page_count", "tests/links_test.py::TestLinks::test_links_single_page_titles", "tests/links_test.py::TestLinks::test_links_multi_page_titles"], "indent": 8}
{"namespace": "falcon.request.Request.client_accepts_msgpack", "type": "method", "project_path": "Internet/falcon", "completion_path": "Internet/falcon/falcon/request.py", "signature_position": [581, 581], "body_position": [582, 584], "dependency": {"intra_class": ["falcon.request.Request.client_accepts"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Check if the client accepts the message pack format. It checks the client's accepted content types and returns True if either 'application/x-msgpack' or 'application/msgpack' is present.", "Arguments": ":param self: Request. An instance of the Request class.\n:return: Bool. True if the client accepts message pack format, False otherwise."}, "tests": ["tests/test_request_attrs.py::TestRequestAttributes::test_client_accepts_props"], "indent": 8}
{"namespace": "boltons.urlutils.URL.to_text", "type": "method", "project_path": "Utilities/boltons", "completion_path": "Utilities/boltons/boltons/urlutils.py", "signature_position": [753, 753], "body_position": [769, 799], "dependency": {"intra_class": ["boltons.urlutils.URL.fragment", "boltons.urlutils.URL.get_authority", "boltons.urlutils.URL.path_parts", "boltons.urlutils.URL.query_params", "boltons.urlutils.URL.scheme", "boltons.urlutils.URL.uses_netloc"], "intra_file": ["boltons.urlutils.QueryParamDict.to_text", "boltons.urlutils.quote_fragment_part"], "cross_file": []}, "requirement": {"Functionality": "This function returns a string representation of the current state of the URL object. It constructs the URL string by combining the different components of the URL object, such as scheme, authority, path, query string, and fragment.", "Arguments": ":param self: URL. An instance of the URL class.\n:param full_quote: bool. Whether to fully quote the URL or use minimal quoting. Defaults to False.\n:return: str. The string representation of the URL object."}, "tests": ["tests/test_urlutils.py::test_roundtrip", "tests/test_urlutils.py::test_basic", "tests/test_urlutils.py::test_mailto", "tests/test_urlutils.py::test_parse_equals_in_qp_value", "tests/test_urlutils.py::test_navigate"], "indent": 8}
{"namespace": "pyramid.path.DottedNameResolver.maybe_resolve", "type": "method", "project_path": "Internet/pyramid", "completion_path": "Internet/pyramid/src/pyramid/path.py", "signature_position": [278, 278], "body_position": [292, 297], "dependency": {"intra_class": ["pyramid.path.DottedNameResolver._resolve"], "intra_file": ["pyramid.path.CALLER_PACKAGE", "pyramid.path.Resolver.package", "pyramid.path.caller_package"], "cross_file": []}, "requirement": {"Functionality": "This function is used to resolve a dotted name to its corresponding object. If the input is not a string, it is simply returned. It first checks if the input is a string, then it retrieves the package information and resolves the dotted name.", "Arguments": ":param self: DottedNameResolver. An instance of the DottedNameResolver class.\n:param dotted: The dotted name to be resolved.\n:return: The resolved object if the input is a string, otherwise the input itself."}, "tests": ["tests/test_path.py::TestDottedNameResolver::test_maybe_resolve_caller_package"], "indent": 8}
{"namespace": "zxcvbn.matching.reverse_dictionary_match", "type": "function", "project_path": "Security/zxcvbn-python", "completion_path": "Security/zxcvbn-python/zxcvbn/matching.py", "signature_position": [121, 122], "body_position": [123, 131], "dependency": {"intra_class": [], "intra_file": ["zxcvbn.matching.RANKED_DICTIONARIES", "zxcvbn.matching.dictionary_match"], "cross_file": []}, "requirement": {"Functionality": "This function takes a password as input and performs a reverse dictionary match on it. It reverses the password, performs a dictionary match on the reversed password, and then reverses the matched tokens back to their original order. Finally, it sorts the matches based on their positions in the original password.", "Arguments": ":param password: String. The password to perform reverse dictionary match on.\n:param _ranked_dictionaries: List of dictionaries. A list of ranked dictionaries to use for matching. Defaults to RANKED_DICTIONARIES.\n:return: List of matches. The matches found during the reverse dictionary match, sorted based on their positions in the original password."}, "tests": ["tests/matching_test.py::test_reverse_dictionary_matching"], "indent": 4}
{"namespace": "diffprivlib.models.k_means.KMeans.fit", "type": "method", "project_path": "Security/diffprivlib", "completion_path": "Security/diffprivlib/diffprivlib/models/k_means.py", "signature_position": [100, 100], "body_position": [119, 167], "dependency": {"intra_class": ["diffprivlib.models.k_means.KMeans._calc_iters", "diffprivlib.models.k_means.KMeans._distances_labels", "diffprivlib.models.k_means.KMeans._init_centers", "diffprivlib.models.k_means.KMeans._update_centers", "diffprivlib.models.k_means.KMeans.accountant", "diffprivlib.models.k_means.KMeans.bounds", "diffprivlib.models.k_means.KMeans.cluster_centers_", "diffprivlib.models.k_means.KMeans.epsilon", "diffprivlib.models.k_means.KMeans.inertia_", "diffprivlib.models.k_means.KMeans.labels_", "diffprivlib.models.k_means.KMeans.n_iter_"], "intra_file": [], "cross_file": ["diffprivlib.accountant.BudgetAccountant.check", "diffprivlib.accountant.BudgetAccountant.spend", "diffprivlib.utils.PrivacyLeakWarning", "diffprivlib.utils.check_random_state", "diffprivlib.validation.DiffprivlibMixin._check_bounds", "diffprivlib.validation.DiffprivlibMixin._clip_to_bounds", "diffprivlib.validation.DiffprivlibMixin._validate_params", "diffprivlib.validation.DiffprivlibMixin._warn_unused_args"]}, "requirement": {"Functionality": "This function performs k-means clustering with differential privacy. It takes the input data and clusters it into k clusters using the k-means algorithm. The function also ensures differential privacy by adding noise to the computation.", "Arguments": ":param self: KMeans. An instance of the KMeans class.\n:param X: array-like. The training instances to be clustered.\n:param y: Ignored. Not used in the function.\n:param sample_weight: Ignored. Not used in the function.\n:return: self. The class instance itself."}, "tests": ["tests/models/test_KMeans.py::TestKMeans::test_1d_array", "tests/models/test_KMeans.py::TestKMeans::test_no_bounds", "tests/models/test_KMeans.py::TestKMeans::test_too_many_clusters", "tests/models/test_KMeans.py::TestKMeans::test_sample_weights", "tests/models/test_KMeans.py::TestKMeans::test_simple"], "indent": 8}
{"namespace": "mrjob.fs.hadoop.HadoopFilesystem.exists", "type": "method", "project_path": "System/mrjob", "completion_path": "System/mrjob/mrjob/fs/hadoop.py", "signature_position": [300, 300], "body_position": [306, 314], "dependency": {"intra_class": ["mrjob.fs.hadoop.HadoopFilesystem.invoke_hadoop"], "intra_file": ["mrjob.fs.hadoop._HADOOP_LS_NO_SUCH_FILE"], "cross_file": []}, "requirement": {"Functionality": "Check if the given path exists in the Hadoop filesystem. If the path is a directory (ends with a '/'), it checks if there are any files starting with that path. It invokes Hadoop 'fs -ls' command to check if the path exists. If the command returns 0, it returns True. If the command returns -1 or 255, it returns False. If the command returns any other value or the stderr has any output except for 'No such file', it raises an IOError: 'Could not check path {path}'.", "Arguments": ":param self: HadoopFilesystem. An instance of the HadoopFilesystem class.\n:param path_glob: str. The path to check in the Hadoop filesystem.\n:return: bool. True if the path exists, False otherwise."}, "tests": ["tests/fs/test_hadoop.py::HadoopFSTestCase::test_exists_no", "tests/fs/test_hadoop.py::HadoopFSTestCase::test_exists_yes"], "indent": 8}
{"namespace": "hypertools.datageometry.DataGeometry.transform", "type": "method", "project_path": "Multimedia/hypertools", "completion_path": "Multimedia/hypertools/hypertools/datageometry.py", "signature_position": [111, 111], "body_position": [129, 146], "dependency": {"intra_class": ["hypertools.datageometry.DataGeometry.align", "hypertools.datageometry.DataGeometry.corpus", "hypertools.datageometry.DataGeometry.normalize", "hypertools.datageometry.DataGeometry.reduce", "hypertools.datageometry.DataGeometry.semantic", "hypertools.datageometry.DataGeometry.vectorizer", "hypertools.datageometry.DataGeometry.xform_data"], "intra_file": [], "cross_file": ["hypertools.tools.align.align", "hypertools.tools.format_data.format_data", "hypertools.tools.normalize.normalize", "hypertools.tools.reduce.reduce"]}, "requirement": {"Functionality": "This function transforms the input data using a specified model. If no data is passed, it returns the transformed data stored in the DataGeometry object.", "Arguments": ":param self: DataGeometry. An instance of the DataGeometry class.\n:param data: Optional. The data to be transformed. It can be a numpy array, pandas dataframe, or a list of arrays/dataframes. If no data is passed, the xform_data from the DataGeometry object will be returned.\n:return: list of numpy arrays. The transformed data."}, "tests": ["tests/test_geo.py::test_geo_transform_dims", "tests/test_geo.py::test_geo_transform"], "indent": 8}
{"namespace": "wal_e.worker.upload_pool.TarUploadPool.put", "type": "method", "project_path": "System/wal-e", "completion_path": "System/wal-e/wal_e/worker/upload_pool.py", "signature_position": [71, 71], "body_position": [78, 114], "dependency": {"intra_class": ["wal_e.worker.upload_pool.TarUploadPool._start", "wal_e.worker.upload_pool.TarUploadPool._wait", "wal_e.worker.upload_pool.TarUploadPool.closed", "wal_e.worker.upload_pool.TarUploadPool.concurrency_burden", "wal_e.worker.upload_pool.TarUploadPool.max_concurrency", "wal_e.worker.upload_pool.TarUploadPool.max_members", "wal_e.worker.upload_pool.TarUploadPool.member_burden"], "intra_file": [], "cross_file": ["wal_e.exception.UserCritical"]}, "requirement": {"Functionality": "This function is used to upload a tar volume. It checks if there is too much work outstanding already and raises errors of previously submitted greenlets that die unexpectedly. If there are not enough resources to start an upload, it raises an exception. Otherwise, it starts the upload.", "Arguments": ":param self: TarUploadPool. An instance of the TarUploadPool class.\n:param tpart: The tar volume to be uploaded.\n:return: No return values."}, "tests": ["tests/test_tar_upload_pool.py::test_pool_concurrent_failure", "tests/test_tar_upload_pool.py::test_fault_join", "tests/test_tar_upload_pool.py::test_not_enough_resources", "tests/test_tar_upload_pool.py::test_fault_midstream", "tests/test_tar_upload_pool.py::test_put_after_join"], "indent": 8}
{"namespace": "mingus.core.keys.get_notes", "type": "function", "project_path": "Multimedia/mingus", "completion_path": "Multimedia/mingus/mingus/core/keys.py", "signature_position": [109, 109], "body_position": [118, 142], "dependency": {"intra_class": [], "intra_file": ["mingus.core.keys._key_cache", "mingus.core.keys.base_scale", "mingus.core.keys.get_key_signature", "mingus.core.keys.get_key_signature_accidentals", "mingus.core.keys.is_valid_key"], "cross_file": ["mingus.core.mt_exceptions.NoteFormatError"]}, "requirement": {"Functionality": "This function returns an ordered list of notes in the specified natural key.\n", "Arguments": ":param key: str. The natural key for which the notes are to be retrieved. It defaults to \"C\" if not specified.\n:return: List of str. An ordered list of notes in the specified natural key.\n"}, "tests": ["tests/unit/core/test_keys.py::test_keys::test_get_notes"], "indent": 4}
{"namespace": "msticpy.auth.msal_auth.MSALDelegatedAuth.get_token", "type": "method", "project_path": "Security/msticpy", "completion_path": "Security/msticpy/msticpy/auth/msal_auth.py", "signature_position": [77, 77], "body_position": [79, 88], "dependency": {"intra_class": ["msticpy.auth.msal_auth.MSALDelegatedAuth._app_auth", "msticpy.auth.msal_auth.MSALDelegatedAuth.app", "msticpy.auth.msal_auth.MSALDelegatedAuth.auth_type", "msticpy.auth.msal_auth.MSALDelegatedAuth.refresh_token", "msticpy.auth.msal_auth.MSALDelegatedAuth.result", "msticpy.auth.msal_auth.MSALDelegatedAuth.scopes", "msticpy.auth.msal_auth.MSALDelegatedAuth.username"], "intra_file": [], "cross_file": ["tests.auth.test_msal_auth.MSALAppMock.acquire_token_silent_with_error", "tests.auth.test_msal_auth.MSALAppMock.get_accounts"]}, "requirement": {"Functionality": "This function is a method of the MSALDelegatedAuth class. It is used to get an authentication token. It first tries to get the chosen account using the app's get_accounts method. If a chosen account is found, it acquires a token with the specified scopes and chosen account. If the result is empty, it then authenticates with the specified authentication type. Finally, it refreshs the token.", "Arguments": ":param self: MSALDelegatedAuth. An instance of the MSALDelegatedAuth class.\n:return: No return values."}, "tests": ["tests/auth/test_msal_auth.py::test_msal_auth_unkown_user", "tests/auth/test_msal_auth.py::test_msal_auth", "tests/auth/test_msal_auth.py::test_msal_auth_device"], "indent": 8}
{"namespace": "mackup.utils.delete", "type": "function", "project_path": "Utilities/mackup", "completion_path": "Utilities/mackup/mackup/utils.py", "signature_position": [49, 49], "body_position": [59, 68], "dependency": {"intra_class": [], "intra_file": ["mackup.utils.remove_acl", "mackup.utils.remove_immutable_attribute"], "cross_file": []}, "requirement": {"Functionality": "This function deletes the given file, directory, or link. It first removes any ACLs (Access Control Lists) associated with the file, then removes any immutable attributes. Finally, it deletes the file or directory using the appropriate method based on its type.", "Arguments": ":param filepath: str. The absolute full path to the file, directory, or link to be deleted.\n:return: No return values."}, "tests": ["tests/utils_test.py::TestMackup::test_delete_folder_recursively", "tests/utils_test.py::TestMackup::test_delete_file"], "indent": 4}
{"namespace": "pyramid.registry.Introspector.relate", "type": "method", "project_path": "Internet/pyramid", "completion_path": "Internet/pyramid/src/pyramid/registry.py", "signature_position": [185, 185], "body_position": [186, 191], "dependency": {"intra_class": ["pyramid.registry.Introspector._get_intrs_by_pairs", "pyramid.registry.Introspector._refs"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function establishes relationships among introspectables based on the given category name and discriminator pairs. It creates relationships between each pair of introspectables by adding a reference from one introspectable to another.", "Arguments": ":param self: Introspector. An instance of the Introspector class.\n:param pairs: Variable number of arguments. Each argument is a pair of category name and discriminator to identify one introspectable.\n:return: No return values."}, "tests": ["tests/test_registry.py::TestIntrospector::test_relate_fail", "tests/test_registry.py::TestIntrospector::test_relate", "tests/test_registry.py::TestIntrospector::test_remove", "tests/test_registry.py::TestIntrospector::test_unrelate", "tests/test_registry.py::TestIntrospector::test_related"], "indent": 8}
{"namespace": "imapclient.imapclient.IMAPClient._consume_until_tagged_response", "type": "method", "project_path": "Communications/IMAPClient", "completion_path": "Communications/IMAPClient/imapclient/imapclient.py", "signature_position": [1642, 1642], "body_position": [1643, 1652], "dependency": {"intra_class": ["imapclient.imapclient.IMAPClient._checkok", "imapclient.imapclient.IMAPClient._imap"], "intra_file": ["imapclient.imapclient._parse_untagged_response"], "cross_file": []}, "requirement": {"Functionality": "This function consumes responses from the IMAP server until a tagged response with the specified tag is received. It collects all untagged responses received before the tagged response and returns the tagged response and the collected untagged responses.", "Arguments": ":param self: IMAPClient. An instance of the IMAPClient class.\n:param tag: String. The tag of the tagged response to wait for.\n:param command: String. The command associated with the tagged response.\n:return: Tuple. The first element is the data of the tagged response, and the second element is a list of untagged responses received before the tagged response."}, "tests": ["tests/test_imapclient.py::TestIdleAndNoop::test_consume_until_tagged_response", "tests/test_imapclient.py::TestProtocolError::test_tagged_response_with_parse_error"], "indent": 8}
{"namespace": "bplustree.memory.WAL.commit", "type": "method", "project_path": "Database/bplustree", "completion_path": "Database/bplustree/bplustree/memory.py", "signature_position": [418, 419], "body_position": [420, 421], "dependency": {"intra_class": ["bplustree.memory.WAL._add_frame", "bplustree.memory.WAL._not_committed_pages"], "intra_file": ["bplustree.memory.FrameType", "bplustree.memory.FrameType.COMMIT"], "cross_file": []}, "requirement": {"Functionality": "If there are uncommitted pages in the WAL, a commit frame is added.", "Arguments": ":param self: WAL. An instance of the WAL class.\n:return: No return values."}, "tests": ["tests/test_memory.py::test_wal_rollback", "tests/test_memory.py::test_wal_create_reopen_uncommitted", "tests/test_memory.py::test_wal_checkpoint"], "indent": 8}
{"namespace": "playhouse.dataset.DataSet.update_cache", "type": "method", "project_path": "Software-Development/peewee", "completion_path": "Software-Development/peewee/playhouse/dataset.py", "signature_position": [103, 103], "body_position": [104, 121], "dependency": {"intra_class": ["playhouse.dataset.DataSet._include_views", "playhouse.dataset.DataSet._introspector", "playhouse.dataset.DataSet._models", "playhouse.dataset.DataSet.get_table_dependencies"], "intra_file": [], "cross_file": ["playhouse.reflection.Introspector.generate_models"]}, "requirement": {"Functionality": "Update the cache of the DataSet instance based on the given table. If a table is specified, it updates the cache for that table and its related tables. If no table is specified, it updates the cache for all tables. It generates and updates the models in the cache based on the updated cache.", "Arguments": ":param self: DataSet. An instance of the DataSet class.\n:param table: String. The name of the table to update the cache for. Defaults to None.\n:return: No return values."}, "tests": ["tests/dataset.py::TestDataSet::test_update_cache"], "indent": 8}
{"namespace": "twtxt.parser.parse_tweets", "type": "function", "project_path": "Communications/twtxt", "completion_path": "Communications/twtxt/twtxt/parser.py", "signature_position": [32, 32], "body_position": [44, 56], "dependency": {"intra_class": [], "intra_file": ["twtxt.parser.logger", "twtxt.parser.parse_tweet"], "cross_file": []}, "requirement": {"Functionality": "This function takes a list of raw tweet lines from a twtxt file and parses them into a list of Tweet objects. It also handles any exceptions that occur during the parsing process.", "Arguments": ":param raw_tweets: list. A list of raw tweet lines.\n:param source: Source. The source of the given tweets.\n:param now: Datetime. The current datetime. Defaults to None.\n:return: list. A list of parsed tweets as Tweet objects."}, "tests": ["tests/test_parser.py::test_parse_tweets"], "indent": 4}
{"namespace": "mrjob.hadoop.HadoopJobRunner._find_hadoop_streaming_jar", "type": "method", "project_path": "System/mrjob", "completion_path": "System/mrjob/mrjob/hadoop.py", "signature_position": [237, 237], "body_position": [240, 259], "dependency": {"intra_class": ["mrjob.hadoop.HadoopJobRunner._hadoop_streaming_jar_dirs", "mrjob.hadoop.HadoopJobRunner.fs"], "intra_file": ["mrjob.hadoop._HADOOP_STREAMING_JAR_RE", "mrjob.hadoop.log"], "cross_file": ["mrjob.fs.composite.CompositeFilesystem.ls", "mrjob.util.unique"]}, "requirement": {"Functionality": "This function searches for the Hadoop streaming jar file in the specified directories. It iterates through each directory and checks for the presence of the jar file. If found, it returns the path of the first jar file that matches the criteria. It logs an info message for each directory that is searched: \"Looking for Hadoop streaming jar in {directory}...\".", "Arguments": ":param self: HadoopJobRunner. An instance of the HadoopJobRunner class.\n:return: String or None. The path of the Hadoop streaming jar file if found, otherwise None."}, "tests": ["tests/test_hadoop.py::HadoopStreamingJarTestCase::test_directory_order_overrides_path_sort_order", "tests/test_hadoop.py::HadoopStreamingJarTestCase::test_hard_coded_emr_paths", "tests/test_hadoop.py::HadoopStreamingJarTestCase::test_hadoop_prefix", "tests/test_hadoop.py::HadoopStreamingJarTestCase::test_infer_from_hadoop_bin_realpath", "tests/test_hadoop.py::HadoopStreamingJarTestCase::test_hadoop_install"], "indent": 8}
{"namespace": "falcon.request.Request.bounded_stream", "type": "method", "project_path": "Internet/falcon", "completion_path": "Internet/falcon/falcon/request.py", "signature_position": [628, 628], "body_position": [629, 632], "dependency": {"intra_class": ["falcon.request.Request._bounded_stream", "falcon.request.Request._get_wrapped_wsgi_input"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function returns the bounded stream of a Request instance. If the bounded stream is not yet initialized, it initializes it.", "Arguments": ":param self: Request. An instance of the Request class.\n:return: The bounded stream of the Request instance."}, "tests": ["tests/test_request_body.py::TestRequestBody::test_bounded_stream_property_empty_body"], "indent": 8}
{"namespace": "mrjob.fs.hadoop.HadoopFilesystem.rm", "type": "method", "project_path": "System/mrjob", "completion_path": "System/mrjob/mrjob/fs/hadoop.py", "signature_position": [323, 323], "body_position": [324, 338], "dependency": {"intra_class": ["mrjob.fs.hadoop.HadoopFilesystem.get_hadoop_version", "mrjob.fs.hadoop.HadoopFilesystem.invoke_hadoop"], "intra_file": ["mrjob.fs.hadoop._HADOOP_RM_NO_SUCH_FILE"], "cross_file": ["mrjob.compat.uses_yarn", "mrjob.fs.base.Filesystem", "mrjob.fs.base.Filesystem.rm", "mrjob.parse.is_uri"]}, "requirement": {"Functionality": "Remove a file or directory from the Hadoop filesystem. It first checks if the path is a URI, and if not, it requires the superclass to remove that path. Then, it determines the version of Hadoop being used and constructs the appropriate command arguments (Depends on whether to use Yarn). Finally, it invokes Hadoop with the arguments and handles any exceptions that occur.", "Arguments": ":param self: HadoopFilesystem. An instance of the HadoopFilesystem class.\n:param path_glob: String. The path or glob pattern of the file or directory to be removed.\n:return: No return values."}, "tests": ["tests/fs/test_hadoop.py::HadoopFSTestCase::test_rm", "tests/fs/test_hadoop.py::HadoopFSTestCase::test_rm_recursive"], "indent": 8}
{"namespace": "diffprivlib.models.forest._FittingTree.fit", "type": "method", "project_path": "Security/diffprivlib", "completion_path": "Security/diffprivlib/diffprivlib/models/forest.py", "signature_position": [556, 556], "body_position": [568, 594], "dependency": {"intra_class": ["diffprivlib.models.forest._FittingTree._TREE_LEAF", "diffprivlib.models.forest._FittingTree.apply", "diffprivlib.models.forest._FittingTree.classes", "diffprivlib.models.forest._FittingTree.epsilon", "diffprivlib.models.forest._FittingTree.node_count", "diffprivlib.models.forest._FittingTree.nodes", "diffprivlib.models.forest._FittingTree.random_state", "diffprivlib.models.forest._FittingTree.values_"], "intra_file": [], "cross_file": ["diffprivlib.mechanisms.exponential.PermuteAndFlip.randomise"]}, "requirement": {"Functionality": "This function fits a tree to the given training data. It first checks if the tree has been built, and then applies the tree to the input data to determine the leaves. It calculates the unique leaves and initializes an array to store the values for each leaf. It populates the values for the real leaves based on the target vector. It then populates the values for the empty leaves. Finally, it assigns the calculated values to the tree and returns the fitted tree.", "Arguments": ":param self: _FittingTree. An instance of the _FittingTree class.\n:param X: array-like. The training vector with shape (n_samples, n_features), where n_samples is the number of samples and n_features is the number of features.\n:param y: array-like. The target vector relative to X with shape (n_samples,).\n:return: The fitted tree."}, "tests": ["tests/models/test_FittingTree.py::TestFittingTree::test_fit_before_build"], "indent": 8}
{"namespace": "gunicorn.sock.create_sockets", "type": "function", "project_path": "Utilities/gunicorn", "completion_path": "Utilities/gunicorn/gunicorn/sock.py", "signature_position": [143, 143], "body_position": [151, 205], "dependency": {"intra_class": [], "intra_file": ["gunicorn.sock._sock_type"], "cross_file": ["gunicorn.config.Config.address", "gunicorn.glogging.Logger.debug", "gunicorn.glogging.Logger.error"]}, "requirement": {"Functionality": "This function creates new sockets based on the configured addresses or file descriptors. It checks the type of address and creates either a TCP socket or a Unix socket accordingly. It also performs some error checking on the SSL configuration.", "Arguments": ":param conf: The configuration object.\n:param log: The logging object.\n:param fds: List of file descriptors. Optional. Default is None.\n:return: List of socket objects. The created sockets."}, "tests": ["tests/test_sock.py::test_create_sockets_unix_strings", "tests/test_sock.py::test_create_sockets_unix_bytes"], "indent": 4}
{"namespace": "mingus.core.intervals.minor_second", "type": "function", "project_path": "Multimedia/mingus", "completion_path": "Multimedia/mingus/mingus/core/intervals.py", "signature_position": [168, 168], "body_position": [169, 170], "dependency": {"intra_class": [], "intra_file": ["mingus.core.intervals.augment_or_diminish_until_the_interval_is_right", "mingus.core.intervals.second"], "cross_file": []}, "requirement": {"Functionality": "This function calculates the minor second note above the given note.\n", "Arguments": ":param note: str. The note for which the minor second interval is calculated.\n:return: str. The modified note with the correct minor second interval.\n"}, "tests": ["tests/unit/core/test_intervals.py::test_intervals::test_minor_seconds"], "indent": 4}
{"namespace": "mingus.core.intervals.determine", "type": "function", "project_path": "Multimedia/mingus", "completion_path": "Multimedia/mingus/mingus/core/intervals.py", "signature_position": [325, 325], "body_position": [346, 430], "dependency": {"intra_class": [], "intra_file": ["mingus.core.intervals.measure"], "cross_file": ["mingus.core.notes", "mingus.core.notes.fifths"]}, "requirement": {"Functionality": "This function determines the name of the interval between two musical notes.\n", "Arguments": ":param note1: str. The first note of the interval.\n:param note2: str. The second note of the interval.\n:param shorthand: bool. Whether to use the shorthand notation for the interval name. Defaults to False.\n:return: str. The name of the interval between note1 and note2.\n"}, "tests": ["tests/unit/core/test_intervals.py::test_intervals::test_determine_shorthand", "tests/unit/core/test_intervals.py::test_intervals::test_determine"], "indent": 4}
{"namespace": "dash.development.component_loader.load_components", "type": "function", "project_path": "Software-Development/dash", "completion_path": "Software-Development/dash/dash/development/component_loader.py", "signature_position": [19, 19], "body_position": [34, 56], "dependency": {"intra_class": [], "intra_file": ["dash.development.component_loader._get_metadata"], "cross_file": ["dash.development._py_components_generation.generate_class", "dash.development.base_component.ComponentRegistry", "dash.development.base_component.ComponentRegistry.registry"]}, "requirement": {"Functionality": "This function loads React component metadata from a JSON file and converts it into a format that Dash can parse. It registers the component library for index inclusion and then iterates over each component in the metadata, extracting the component name and generating a class for each component. The generated classes are added to a list and returned.", "Arguments": ":param metadata_path: String. The path to the JSON file created by `react-docgen`.\n:param namespace: String. The namespace to register the component library under. It defaults to \"default_namespace\" if not specified.\n:return: List of component objects. Each component object has keys `type`, `valid_kwargs`, and `setup`."}, "tests": ["tests/unit/development/test_component_loader.py::test_loadcomponents"], "indent": 4}
{"namespace": "boto.s3.bucket.Bucket.delete_key", "type": "method", "project_path": "Internet/boto", "completion_path": "Internet/boto/boto/s3/bucket.py", "signature_position": [733, 734], "body_position": [758, 763], "dependency": {"intra_class": ["boto.s3.bucket.Bucket._delete_key_internal"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function deletes a key from the bucket. If a version ID is provided, only that version of the key will be deleted. It also provides the option to delete versioned objects from a bucket that has the MFADelete option enabled.", "Arguments": ":param self: Bucket. An instance of the Bucket class.\n:param key_name: string. The name of the key to be deleted.\n:param headers: dict. Additional headers to include in the request.\n:param version_id: string. The version ID of the key to be deleted (optional).\n:param mfa_token: tuple or list of strings. A tuple or list consisting of the serial number from the MFA device and the current value of the six-digit token associated with the device. This is required for deleting versioned objects from a bucket with MFADelete option enabled.\n:return: :class:`boto.s3.key.Key` or subclass. A key object holding information on what was deleted. The caller can see if a delete_marker was created or removed and what version_id the delete created or removed."}, "tests": ["tests/unit/s3/test_key.py::TestS3Key::test_delete_key_return_key"], "indent": 8}
{"namespace": "mrjob.conf._fix_clear_tags", "type": "function", "project_path": "System/mrjob", "completion_path": "System/mrjob/mrjob/conf.py", "signature_position": [156, 156], "body_position": [167, 187], "dependency": {"intra_class": [], "intra_file": ["mrjob.conf.ClearedValue", "mrjob.conf.ClearedValue.__init__", "mrjob.conf._fix_clear_tags", "mrjob.conf._strip_clear_tag"], "cross_file": []}, "requirement": {"Functionality": "This function recursively resolves ClearedValue wrappers in a given input. It ensures that ClearedValue(...) can only wrap values in dictionaries. In dictionaries, it treats ClearedValue(k): v or ClearedValue(k): ClearedValue(v) as equivalent to k: ClearedValue(v). ClearedValue(k): v1 overrides k: v2. In lists, any ClearedValue wrappers are simply stripped.\nChecks if the input is a list, dictionary or ClearedValue. If the input is a list, process each element separately. If the input is a dictionary, process each key-value pair separately and handle cleared keys. If the input is a ClearedValue, process and return the value of the ClearedValue.\n", "Arguments": ":param x: any data type. The input value to be processed.\n:return: any data type. The processed value.\n"}, "tests": ["tests/test_conf.py::FixClearTag::test_none", "tests/test_conf.py::FixClearTag::test_list", "tests/test_conf.py::FixClearTag::test_nesting", "tests/test_conf.py::FixClearTag::test_string", "tests/test_conf.py::FixClearTag::test_int"], "indent": 4}
{"namespace": "boto.cognito.identity.connect_to_region", "type": "function", "project_path": "Internet/boto", "completion_path": "Internet/boto/boto/cognito/identity/__init__.py", "signature_position": [39, 39], "body_position": [40, 43], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["boto.cognito.identity.layer1.CognitoIdentityConnection", "boto.regioninfo.connect"]}, "requirement": {"Functionality": "Connect to a specific region using the CognitoIdentityConnection class. It calls the connect function with the specified parameters and returns the connection object.", "Arguments": ":param region_name: String. The name of the region to connect to.\n:param **kw_params: Additional keyword arguments that can be passed to the connect function.\n:return: CognitoIdentityConnection. The connection object to the specified region."}, "tests": ["tests/unit/test_connect_to_region.py::TestCognitoIdentityConnection::test_connect_to_region"], "indent": 4}
{"namespace": "rest_framework.fields.DecimalField.to_internal_value", "type": "method", "project_path": "Internet/djangorestframework", "completion_path": "Internet/djangorestframework/rest_framework/fields.py", "signature_position": [1006, 1006], "body_position": [1012, 1032], "dependency": {"intra_class": ["rest_framework.fields.DecimalField.MAX_STRING_LENGTH", "rest_framework.fields.DecimalField.localize", "rest_framework.fields.DecimalField.quantize", "rest_framework.fields.DecimalField.validate_precision"], "intra_file": ["rest_framework.fields.Field.fail"], "cross_file": []}, "requirement": {"Functionality": "This function takes an input data and validates that it is a decimal number. It then returns a Decimal instance of the validated data.", "Arguments": ":param self: DecimalField. An instance of the DecimalField class.\n:param data: The input data to be validated as a decimal number.\n:return: Decimal. The validated Decimal instance of the input data."}, "tests": ["tests/test_fields.py::TestQuantizedValueForDecimal::test_part_precision_string_quantized_value_for_decimal", "tests/test_fields.py::TestQuantizedValueForDecimal::test_string_quantized_value_for_decimal", "tests/test_fields.py::TestQuantizedValueForDecimal::test_int_quantized_value_for_decimal", "tests/test_fields.py::TestLocalizedDecimalField::test_to_internal_value"], "indent": 8}
{"namespace": "praw.util.token_manager.SQLiteTokenManager.post_refresh_callback", "type": "method", "project_path": "Utilities/praw", "completion_path": "Utilities/praw/praw/util/token_manager.py", "signature_position": [167, 167], "body_position": [169, 174], "dependency": {"intra_class": ["praw.util.token_manager.SQLiteTokenManager._set"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function updates the refresh token in the database. It sets the refresh token in the SQLiteTokenManager instance and ensures that the refresh token is not used elsewhere by setting it to None.", "Arguments": ":param self: SQLiteTokenManager. An instance of the SQLiteTokenManager class.\n:param authorizer: The authorizer object that contains the refresh token.\n:return: No return values."}, "tests": ["tests/unit/util/test_token_manager.py::TestSQLiteTokenManager::test_post_refresh_token_callback__sets_value", "tests/unit/util/test_token_manager.py::TestSQLiteTokenManager::test_post_refresh_token_callback__updates_value"], "indent": 8}
{"namespace": "bentoml._internal.runner.container.PandasDataFrameContainer.batch_to_payloads", "type": "method", "project_path": "Scientific-Engineering/bentoml", "completion_path": "Scientific-Engineering/bentoml/src/bentoml/_internal/runner/container.py", "signature_position": [431, 436], "body_position": [437, 440], "dependency": {"intra_class": ["bentoml._internal.runner.container.PandasDataFrameContainer.batch_to_batches", "bentoml._internal.runner.container.PandasDataFrameContainer.to_payload"], "intra_file": ["bentoml._internal.runner.container.Payload"], "cross_file": ["bentoml._internal.external_typing"]}, "requirement": {"Functionality": "This function converts a batch of data in a Pandas DataFrame format into a list of payloads. It first converts the batch into smaller batches based on the specified indices and batch dimension. Then, it converts each subbatch into a payload.", "Arguments": ":param cls: PandasDataFrameContainer. The class itself.\n:param batch: ext.PdDataFrame. The batch of data in Pandas DataFrame format.\n:param indices: Sequence of integers. The indices used to split the batch into smaller batches.\n:param batch_dim: Integer. The dimension along which the batch is split. Defaults to 0.\n:return: list[Payload]. A list of payloads, where each payload represents a subbatch of data."}, "tests": ["tests/unit/_internal/runner/test_container.py::test_pandas_container"], "indent": 8}
{"namespace": "boltons.setutils.IndexedSet.pop", "type": "method", "project_path": "Utilities/boltons", "completion_path": "Utilities/boltons/boltons/setutils.py", "signature_position": [426, 426], "body_position": [428, 440], "dependency": {"intra_class": ["boltons.setutils.IndexedSet._add_dead", "boltons.setutils.IndexedSet._cull", "boltons.setutils.IndexedSet._get_real_index", "boltons.setutils.IndexedSet.item_index_map", "boltons.setutils.IndexedSet.item_list"], "intra_file": ["boltons.setutils._MISSING"], "cross_file": []}, "requirement": {"Functionality": "This function removes and returns an item from the IndexedSet instance at the given index. If the removed item is the last item, it simply pops it from the list and the map. Otherwise, it is replaced by a placeholder in the list and the map is updated accordingly. The list is then culled to maintain the integrity of the IndexedSet instance.", "Arguments": ":param self: IndexedSet. An instance of the IndexedSet class.\n:param index: int. The index of the item to be removed. Defaults to None, which removes the last item.\n:return: The item removed from the IndexedSet instance."}, "tests": ["tests/test_setutils.py::test_iset_index_method", "tests/test_setutils.py::test_indexed_set_mutate"], "indent": 8}
{"namespace": "mrjob.bin.MRJobBinRunner.get_spark_submit_bin", "type": "method", "project_path": "System/mrjob", "completion_path": "System/mrjob/mrjob/bin.py", "signature_position": [871, 871], "body_position": [874, 876], "dependency": {"intra_class": ["mrjob.bin.MRJobBinRunner._find_spark_submit_bin", "mrjob.bin.MRJobBinRunner._spark_submit_bin"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function returns the location of the \"spark-submit\" binary. If the location is not already stored, it searches for it and stores it for future use.", "Arguments": ":param self: MRJobBinRunner. An instance of the MRJobBinRunner class.\n:return: str. The location of the \"spark-submit\" binary."}, "tests": ["tests/test_bin.py::GetSparkSubmitBinTestCase::test_default", "tests/test_bin.py::GetSparkSubmitBinTestCase::test_only_find_spark_submit_bin_once", "tests/test_bin.py::GetSparkSubmitBinTestCase::test_option_short_circuits_find"], "indent": 8}
{"namespace": "jc.parsers.os_release.parse", "type": "function", "project_path": "Utilities/jc", "completion_path": "Utilities/jc/jc/parsers/os_release.py", "signature_position": [92, 96], "body_position": [110, 113], "dependency": {"intra_class": [], "intra_file": ["jc.parsers.os_release._process", "jc.parsers.os_release.info", "jc.parsers.os_release.info.compatible"], "cross_file": ["jc.jc_types.JSONDictType", "jc.utils.compatibility", "jc.parsers.kv", "jc.parsers.kv.parse", "jc.parsers", "jc.utils"]}, "requirement": {"Functionality": "This function is the main text parsing function. It takes in a string of text data and parses it into structured data. It can return either the raw unprocessed output or the processed output.", "Arguments": ":param data: str. The text data to be parsed.\n:param raw: bool. Whether to return unprocessed output. Defaults to False.\n:param quiet: bool. Whether to suppress warning messages. Defaults to False.\n:return: JSONDictType. The parsed structured data, either raw or processed."}, "tests": ["tests/test_os_release.py::MyTests::test_os_release_ubuntu", "tests/test_os_release.py::MyTests::test_os_release_centos", "tests/test_os_release.py::MyTests::test_os_release_nodata"], "indent": 4}
{"namespace": "alembic.operations.ops.AddColumnOp.reverse", "type": "method", "project_path": "Database/alembic", "completion_path": "Database/alembic/alembic/operations/ops.py", "signature_position": [2012, 2012], "body_position": [2013, 2015], "dependency": {"intra_class": ["alembic.operations.ops.AddColumnOp.column"], "intra_file": ["alembic.operations.ops.AlterTableOp.schema", "alembic.operations.ops.AlterTableOp.table_name", "alembic.operations.ops.DropColumnOp", "alembic.operations.ops.DropColumnOp.from_column_and_tablename"], "cross_file": []}, "requirement": {"Functionality": "This function reverses the operation performed by the AddColumnOp.", "Arguments": ":param self: AddColumnOp. An instance of the AddColumnOp class.\n:return: DropColumnOp."}, "tests": ["tests/test_autogen_diffs.py::OrigObjectTest::test_add_column"], "indent": 8}
{"namespace": "mrjob.conf.combine_jobconfs", "type": "function", "project_path": "System/mrjob", "completion_path": "System/mrjob/mrjob/conf.py", "signature_position": [510, 510], "body_position": [514, 516], "dependency": {"intra_class": [], "intra_file": ["mrjob.conf.combine_dicts", "mrjob.conf._to_java_str"], "cross_file": []}, "requirement": {"Functionality": "This function combines multiple job configuration dictionaries into a single dictionary. Non-string values are converted to Java-readable strings, and keys with a value of None are removed.", "Arguments": ":param jobconfs: Variable number of dictionaries. The job configuration dictionaries to be combined.\n:return: dict. The combined job configuration dictionary."}, "tests": ["tests/test_conf.py::CombineJobconfsTestCase::test_convert_non_string_values", "tests/test_conf.py::CombineJobconfsTestCase::test_cleared_value", "tests/test_conf.py::CombineJobconfsTestCase::test_deleted_value", "tests/test_conf.py::CombineJobconfsTestCase::test_skip_None", "tests/test_conf.py::CombineJobconfsTestCase::test_dont_accept_wrapped_dicts"], "indent": 4}
{"namespace": "pyinfra.connectors.mech.MechInventoryConnector.make_names_data", "type": "method", "project_path": "System/pyinfra", "completion_path": "System/pyinfra/pyinfra/connectors/mech.py", "signature_position": [150, 150], "body_position": [151, 190], "dependency": {"intra_class": [], "intra_file": ["pyinfra.connectors.mech._make_name_data", "pyinfra.connectors.mech.get_mech_config"], "cross_file": ["pyinfra.api.exceptions.InventoryError", "pyinfra.logger"]}, "requirement": {"Functionality": "This function retrieves Mech SSH information and processes it to create a list of host names and their corresponding data. It iterates through the Mech SSH information, extracts the host names and their data, and appends them to a list. Finally, it returns the list of host names and data.", "Arguments": ":param limit: Integer. The maximum number of Mech SSH information to retrieve. Defaults to None.\n:return: List of dictionaries. Each dictionary contains the host name and its corresponding data."}, "tests": ["tests/test_connectors/test_mech.py::TestMechConnector::test_make_names_data_no_matches", "tests/test_connectors/test_mech.py::TestMechConnector::test_make_names_data_with_limit", "tests/test_connectors/test_mech.py::TestMechConnector::test_make_names_data_with_options"], "indent": 8}
{"namespace": "praw.util.token_manager.SQLiteTokenManager.pre_refresh_callback", "type": "method", "project_path": "Utilities/praw", "completion_path": "Utilities/praw/praw/util/token_manager.py", "signature_position": [176, 176], "body_position": [178, 179], "dependency": {"intra_class": ["praw.util.token_manager.SQLiteTokenManager._get"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function is a callback method that is called before refreshing the token. It loads the refresh token from the database.", "Arguments": ":param self: SQLiteTokenManager. An instance of the SQLiteTokenManager class.\n:param authorizer: The authorizer object that contains the refresh token attribute.\n:return: None."}, "tests": ["tests/unit/util/test_token_manager.py::TestSQLiteTokenManager::test_pre_refresh_token_callback__raises_key_error", "tests/unit/util/test_token_manager.py::TestSQLiteTokenManager::test_pre_refresh_token_callback"], "indent": 8}
{"namespace": "exodus_bundler.bundling.run_ldd", "type": "function", "project_path": "System/exodus-bundler", "completion_path": "System/exodus-bundler/src/exodus_bundler/bundling.py", "signature_position": [219, 219], "body_position": [221, 226], "dependency": {"intra_class": [], "intra_file": ["exodus_bundler.bundling.detect_elf_binary", "exodus_bundler.bundling.resolve_binary"], "cross_file": ["exodus_bundler.errors.InvalidElfBinaryError"]}, "requirement": {"Functionality": "This function runs the `ldd` command and retrieves the combined output of stdout and stderr as a list of lines. It first checks if the given binary is a valid ELF file. Then it executes the `ldd` command with the binary as an argument. It captures the stdout and stderr outputs and returns them as a list of lines.", "Arguments": ":param ldd: String. The path to the `ldd` command.\n:param binary: String. The path to the binary file to be analyzed.\n:return: List of strings. The combined stdout and stderr output as a list of lines."}, "tests": ["tests/test_bundling.py::test_run_ldd"], "indent": 4}
{"namespace": "gunicorn.instrument.statsd.Statsd.access", "type": "method", "project_path": "Utilities/gunicorn", "completion_path": "Utilities/gunicorn/gunicorn/instrument/statsd.py", "signature_position": [94, 94], "body_position": [98, 105], "dependency": {"intra_class": ["gunicorn.instrument.statsd.Statsd.histogram", "gunicorn.instrument.statsd.Statsd.increment"], "intra_file": [], "cross_file": ["gunicorn.glogging.Logger", "gunicorn.glogging.Logger.access"]}, "requirement": {"Functionality": "This function measures the duration of a request and logs it using the Statsd logger. It calculates the duration in milliseconds based on the request_time parameter and logs it as a histogram. It also increments the count of total requests and the count of requests with different status codes. The status code of the response is obtained from resp. If the status code is a string, it splits the string at the first occurrence of a non-None character and takes the first part, converting it to an integer. This ensures that the status code is always an integer.", "Arguments": ":param self: Statsd. An instance of the Statsd class.\n:param resp: The response object.\n:param req: The request object.\n:param environ: The environment variables.\n:param request_time: The duration of the request as a datetime.timedelta object.\n:return: No return values."}, "tests": ["tests/test_statsd.py::test_instrument"], "indent": 8}
{"namespace": "alembic.command.stamp", "type": "function", "project_path": "Database/alembic", "completion_path": "Database/alembic/alembic/command.py", "signature_position": [623, 629], "body_position": [651, 685], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["alembic.config.Config", "alembic.runtime.environment.EnvironmentContext", "alembic.script.revision._RevIdType", "alembic.script.ScriptDirectory.from_config", "alembic.script.ScriptDirectory.run_env", "alembic.util", "alembic.util.CommandError", "alembic.util.to_tuple"]}, "requirement": {"Functionality": "This function is used to \"stamp\" the revision table with the given revision(s) without running any migrations. It creates a ScriptDirectory instance based on the provided configuration and then performs the stamping operation.", "Arguments": ":param config: Config. An instance of the Config class.\n:param revision: _RevIdType. The target revision(s) to be stamped. It can be a single revision or a list of revisions.\n:param sql: Bool. Whether to use \"--sql\" mode.\n:param tag: Optional[str]. An arbitrary tag that can be intercepted by custom \"env.py\" scripts.\n:param purge: Bool. Whether to delete all entries in the version table before stamping.\n:return: None."}, "tests": ["tests/test_command.py::StampMultipleHeadsTest::test_sql_stamp_different_multi_start", "tests/test_command.py::StampMultipleHeadsTest::test_online_stamp_multi_rev_from_real_ancestor", "tests/test_command.py::CurrentTest::test_two_heads", "tests/test_command.py::StampMultipleHeadsTest::test_online_stamp_multi_rev_nonsensical", "tests/test_command.py::EditTest::test_edit_current"], "indent": 4}
{"namespace": "boto.dynamodb2.items.Item.prepare_full", "type": "method", "project_path": "Internet/boto", "completion_path": "Internet/boto/boto/dynamodb2/items.py", "signature_position": [314, 314], "body_position": [323, 331], "dependency": {"intra_class": ["boto.dynamodb2.items.Item._data", "boto.dynamodb2.items.Item._dynamizer", "boto.dynamodb2.items.Item._is_storable"], "intra_file": [], "cross_file": ["boto.dynamodb.types.Dynamizer.encode"]}, "requirement": {"Functionality": "This function prepares the data of an Item object to be saved in DynamoDB. It encodes each field of the Item object and returns the encoded data as a dictionary.", "Arguments": ":param self: Item. An instance of the Item class.\n:return: Dict. The encoded data of the Item object as a dictionary."}, "tests": ["tests/unit/dynamodb2/test_table.py::ItemTestCase::test_prepare_full", "tests/unit/dynamodb2/test_table.py::ItemTestCase::test_prepare_full_empty_set"], "indent": 8}
{"namespace": "wal_e.blobstore.file.calling_format.Bucket.delete_keys", "type": "method", "project_path": "System/wal-e", "completion_path": "System/wal-e/wal_e/blobstore/file/calling_format.py", "signature_position": [64, 64], "body_position": [65, 70], "dependency": {"intra_class": [], "intra_file": ["wal_e.blobstore.file.calling_format.common_dir_path", "wal_e.blobstore.file.calling_format.remove_empty_dirs"], "cross_file": []}, "requirement": {"Functionality": "Delete the specified keys in the Bucket instance. It iterates over the keys and removes the corresponding files from the file system. It also trims any empty directories that may be left after deleting the files.", "Arguments": ":param self: Bucket. An instance of the Bucket class.\n:param keys: List of strings. The keys to be deleted.\n:return: No return values."}, "tests": ["tests/test_file_blobstore.py::test_delete_keys"], "indent": 8}
{"namespace": "falcon.inspect.inspect_sinks", "type": "function", "project_path": "Internet/falcon", "completion_path": "Internet/falcon/falcon/inspect.py", "signature_position": [123, 123], "body_position": [133, 138], "dependency": {"intra_class": [], "intra_file": ["falcon.inspect.SinkInfo", "falcon.inspect.SinkInfo.__init__", "falcon.inspect._get_source_info_and_name"], "cross_file": ["falcon.app.App", "falcon.app.App._sinks"]}, "requirement": {"Functionality": "This function inspects the sinks of an application. It iterates through the sinks of the given application and creates a list of SinkInfo objects that contain information about each sink.", "Arguments": ":param app: falcon.App. The application to inspect. It can be either a falcon.App or falcon.asgi.App instance.\n:return: List[SinkInfo]. A list of SinkInfo objects that represent the sinks used by the application."}, "tests": ["tests/test_inspect.py::TestStringVisitor::test_sink", "tests/test_inspect.py::TestInspectApp::test_sink", "tests/test_inspect.py::TestStringVisitor::test_sink_verbose"], "indent": 4}
{"namespace": "falcon.request.Request.prefix", "type": "method", "project_path": "Internet/falcon", "completion_path": "Internet/falcon/falcon/request.py", "signature_position": [815, 815], "body_position": [816, 819], "dependency": {"intra_class": ["falcon.request.Request._cached_prefix", "falcon.request.Request.app", "falcon.request.Request.netloc", "falcon.request.Request.scheme"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function returns the prefix of the request URL. It concatenates the scheme, netloc, and app of a Request instance to form the prefix. The output format is \"{scheme}://{netloc}{app}\".", "Arguments": ":param self: Request. An instance of the Request class.\n:return: String. The prefix of the request URL."}, "tests": ["tests/test_request_attrs.py::TestRequestAttributes::test_reconstruct_url", "tests/test_request_attrs.py::TestRequestAttributes::test_uri"], "indent": 8}
{"namespace": "mrjob.fs.local.LocalFilesystem.rm", "type": "method", "project_path": "System/mrjob", "completion_path": "System/mrjob/mrjob/fs/local.py", "signature_position": [73, 73], "body_position": [74, 81], "dependency": {"intra_class": [], "intra_file": ["mrjob.fs.local._from_file_uri", "mrjob.fs.local.log"], "cross_file": []}, "requirement": {"Functionality": "Remove files or directories from the local filesystem based on the given path pattern. It first converts the path pattern from a file URI format to a local filesystem format. Then, it finds all matching paths. For each path, if it is a directory, it recursively deletes the directory. If it is a file, it deletes the file.", "Arguments": ":param self: LocalFilesystem. An instance of the LocalFilesystem class.\n:param path_glob: String. The path pattern to match files or directories to be removed.\n:return: No return values."}, "tests": ["tests/fs/test_local.py::LocalFSTestCase::test_rm_file_by_uri", "tests/fs/test_local.py::LocalFSTestCase::test_rm_file", "tests/fs/test_local.py::LocalFSTestCase::test_rm_dir"], "indent": 8}
{"namespace": "boltons.dictutils.ManyToMany.update", "type": "method", "project_path": "Utilities/boltons", "completion_path": "Utilities/boltons/boltons/dictutils.py", "signature_position": [945, 945], "body_position": [947, 965], "dependency": {"intra_class": ["boltons.dictutils.ManyToMany.add", "boltons.dictutils.ManyToMany.data", "boltons.dictutils.ManyToMany.inv"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function updates the ManyToMany instance with the given iterable. It adds all the key-value pairs from the iterable to the instance's data. If the iterable is of type ManyToMany, it merges the data and inverse data of the two instances. If the iterable is a dictionary-like object, it adds all the keys and values from the iterable to the instance's data. If the iterable is a list of tuples, it adds each key-value pair to the instance's data.", "Arguments": ":param self: ManyToMany. An instance of the ManyToMany class.\n:param iterable: Iterable. The iterable containing key-value pairs to be added to the instance's data.\n:return: None."}, "tests": ["tests/test_dictutils.py::test_many_to_many"], "indent": 8}
{"namespace": "boltons.tableutils.Table.from_object", "type": "method", "project_path": "Utilities/boltons", "completion_path": "Utilities/boltons/boltons/tableutils.py", "signature_position": [343, 343], "body_position": [349, 351], "dependency": {"intra_class": ["boltons.tableutils.Table.from_data"], "intra_file": ["boltons.tableutils.InputType.__init__", "boltons.tableutils.ObjectInputType", "boltons.tableutils._MISSING"], "cross_file": []}, "requirement": {"Functionality": "Create a Table instance from an object.", "Arguments": ":param cls: type. The class of the Table instance.\n:param data: object. The data to create the Table from.\n:param headers: Iterable[str]. The headers of the Table. Defaults to _MISSING.\n:param max_depth: Integer. The level to which nested Tables should be created. Defaults to 1.\n:param metadata: Optional. Additional metadata for the Table. Defaults to None.\n:return: Table. The created Table instance."}, "tests": ["tests/test_tableutils.py::test_table_obj"], "indent": 8}
{"namespace": "mrjob.logs.mixin.LogInterpretationMixin._pick_error", "type": "method", "project_path": "System/mrjob", "completion_path": "System/mrjob/mrjob/logs/mixin.py", "signature_position": [118, 118], "body_position": [120, 140], "dependency": {"intra_class": ["mrjob.logs.mixin.LogInterpretationMixin._interpret_history_log", "mrjob.logs.mixin.LogInterpretationMixin._interpret_step_logs", "mrjob.logs.mixin.LogInterpretationMixin._interpret_task_logs", "mrjob.logs.mixin.LogInterpretationMixin._logs_needed_to_pick_error", "mrjob.logs.mixin.LogInterpretationMixin._read_logs"], "intra_file": ["mrjob.logs.mixin.log"], "cross_file": ["mrjob.logs.errors._pick_error_attempt_ids", "mrjob.logs.errors._pick_error"]}, "requirement": {"Functionality": "This function is used to pick the probable cause of failure in a log interpretation. It checks if the necessary logs are available and then proceeds to interpret the logs to determine the cause of failure. It should log an info message before interpreting the logs: 'Scanning logs for probable cause of failure...'.", "Arguments": ":param self: LogInterpretationMixin. An instance of the LogInterpretationMixin class.\n:param log_interpretation: dict. The log interpretation containing different types of logs.\n:param step_type: str. The type of step being executed.\n:return: None."}, "tests": ["tests/test_hadoop.py::PickErrorTestCase::test_yarn_python_exception"], "indent": 8}
{"namespace": "msticpy.analysis.anomalous_sequence.utils.cmds_params_only.laplace_smooth_counts", "type": "function", "project_path": "Security/msticpy", "completion_path": "Security/msticpy/msticpy/analysis/anomalous_sequence/utils/cmds_params_only.py", "signature_position": [92, 100], "body_position": [136, 162], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["msticpy.analysis.anomalous_sequence.utils.data_structures.StateMatrix", "msticpy.analysis.anomalous_sequence.utils.laplace_smooth.laplace_smooth_cmd_counts", "msticpy.analysis.anomalous_sequence.utils.laplace_smooth.laplace_smooth_param_counts"]}, "requirement": {"Functionality": "This function applies Laplace smoothing to the counts of commands and parameters. It adds 1 to each count to shift some probability mass from very probable commands/parameters to unseen and unlikely commands/parameters. It also handles unseen commands, sequences of commands, and parameters using the `unk_token`.", "Arguments": ":param seq1_counts: DefaultDict[str, int]. The counts of individual commands.\n:param seq2_counts: DefaultDict[str, DefaultDict[str, int]]. The counts of sequence commands (length 2).\n:param param_counts: DefaultDict[str, int]. The counts of individual parameters.\n:param cmd_param_counts: DefaultDict[str, DefaultDict[str, int]]. The counts of parameters conditional on commands.\n:param start_token: str. The dummy command to signify the start of a session.\n:param end_token: str. The dummy command to signify the end of a session.\n:param unk_token: str. The dummy command to signify an unseen command.\n:return: tuple of StateMatrix counts:\n- seq1_counts_sm: StateMatrix. The smoothed counts of individual commands.\n- seq2_counts_sm: StateMatrix. The smoothed counts of sequence commands (length 2).\n- param_counts_sm: StateMatrix. The smoothed counts of individual parameters.\n- cmd_param_counts_sm: StateMatrix. The smoothed counts of parameters conditional on commands."}, "tests": ["tests/analysis/test_anom_seq_cmds_params_only.py::TestCmdsParamsOnly::test_laplace_smooth_counts"], "indent": 4}
{"namespace": "zxcvbn.matching.l33t_match", "type": "function", "project_path": "Security/zxcvbn-python", "completion_path": "Security/zxcvbn-python/zxcvbn/matching.py", "signature_position": [215, 216], "body_position": [217, 246], "dependency": {"intra_class": [], "intra_file": ["zxcvbn.matching.L33T_TABLE", "zxcvbn.matching.RANKED_DICTIONARIES", "zxcvbn.matching.dictionary_match", "zxcvbn.matching.enumerate_l33t_subs", "zxcvbn.matching.relevant_l33t_subtable", "zxcvbn.matching.translate"], "cross_file": []}, "requirement": {"Functionality": "This function performs a l33t match on a given password. It checks for possible substitutions in the password and matches it against a ranked dictionary. It returns a list of matches sorted by their positions in the password.", "Arguments": ":param password: String. The password to perform the l33t match on.\n:param _ranked_dictionaries: List of dictionaries. A list of ranked dictionaries to match against. Defaults to RANKED_DICTIONARIES.\n:param _l33t_table: Dictionary. A dictionary containing l33t character substitutions. Defaults to L33T_TABLE.\n:return: List of matches. A list of dictionaries representing the matches found in the password. Each dictionary contains information about the matched word, its position, l33t substitutions, and the original token. The list is sorted by the positions of the matches."}, "tests": ["tests/matching_test.py::test_l33t_matching"], "indent": 4}
{"namespace": "boltons.ioutils.SpooledBytesIO.write", "type": "method", "project_path": "Utilities/boltons", "completion_path": "Utilities/boltons/boltons/ioutils.py", "signature_position": [317, 317], "body_position": [318, 327], "dependency": {"intra_class": ["boltons.ioutils.SpooledBytesIO.buffer", "boltons.ioutils.SpooledBytesIO.len", "boltons.ioutils.SpooledBytesIO.rollover", "boltons.ioutils.SpooledBytesIO.tell"], "intra_file": ["boltons.ioutils.SpooledIOBase._checkClosed", "boltons.ioutils.SpooledIOBase._max_size", "boltons.ioutils.binary_type"], "cross_file": []}, "requirement": {"Functionality": "Write the input bytes to the SpooledBytesIO instance. It first checks if the instance is closed. Then, it checks if the input string is of binary type. If not, it raises a TypeError: 'bytes expected, got {type of s}'. If writing the input string exceeds the maximum size of the instance, it will roll the instance over to a temp file. Finally, it writes the input string to the buffer.", "Arguments": ":param self: SpooledBytesIO. An instance of the SpooledBytesIO class.\n:param s: bytes. The string to be written to the instance.\n:return: No return values."}, "tests": ["tests/test_ioutils.py::TestSpooledBytesIO::test_invalid_type", "tests/test_ioutils.py::TestSpooledBytesIO::test_len_rollover", "tests/test_ioutils.py::TestSpooledBytesIO::test_iter", "tests/test_ioutils.py::TestSpooledBytesIO::test_use_as_context_mgr", "tests/test_ioutils.py::TestSpooledBytesIO::test_len_no_rollover"], "indent": 8}
{"namespace": "pythonforandroid.graph.obvious_conflict_checker", "type": "function", "project_path": "Utilities/python-for-android", "completion_path": "Utilities/python-for-android/pythonforandroid/graph.py", "signature_position": [146, 146], "body_position": [152, 240], "dependency": {"intra_class": [], "intra_file": ["pythonforandroid.graph.get_dependency_tuple_list_for_recipe", "pythonforandroid.graph.RecipeOrder.conflicts"], "cross_file": ["pythonforandroid.recipe.Recipe", "pythonforandroid.recipe.Recipe.get_recipe", "pythonforandroid.util.BuildInterruptingException"]}, "requirement": {"Functionality": "This function performs a pre-flight check to identify obvious conflicts in a set of multiple choice tuples/dependencies. It adds dependencies for all recipes, throws no obvious commitment into deps for later comparing against.\nThen, it gets recipe to add and who's ultimately adding it and collects the conflicts by seeing if the new deps conflict with things added before and See if what was added before conflicts with the new deps. It throws error on conflict by getting first conflict and see who added that one and prompting errors. Finally, it adds tuple to list and schedule dependencies to be added. If there were no obvious conflicts, it returns None.", "Arguments": ":param ctx: The context in which the check is performed.\n:param name_tuples: A list of multiple choice tuples/dependencies to check for conflicts.\n:param blacklist: A set of items to be excluded from the check. Defaults to None.\n:return: No return values."}, "tests": ["tests/test_graph.py::test_misc_obvious_conflict_checker", "tests/test_graph.py::test_multichoice_obvious_conflict_checker", "tests/test_graph.py::test_invalid_obvious_conflict_checker", "tests/test_graph.py::test_indirectconflict_obvious_conflict_checker"], "indent": 4}
{"namespace": "boto.cloudtrail.connect_to_region", "type": "function", "project_path": "Internet/boto", "completion_path": "Internet/boto/boto/cloudtrail/__init__.py", "signature_position": [38, 38], "body_position": [39, 42], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["boto.cloudtrail.layer1.CloudTrailConnection", "boto.regioninfo.connect"]}, "requirement": {"Functionality": "Connect to a specific region using the CloudTrail service. It creates a connection to the CloudTrail service in the specified region using the provided parameters.", "Arguments": ":param region_name: String. The name of the region to connect to.\n:param **kw_params: Additional keyword arguments that can be passed to the connection.\n:return: CloudTrailConnection. The connection object to the CloudTrail service in the specified region."}, "tests": ["tests/unit/test_connect_to_region.py::TestCloudTrailConnection::test_connect_to_region"], "indent": 4}
{"namespace": "imapclient.imapclient.IMAPClient.shutdown", "type": "method", "project_path": "Communications/IMAPClient", "completion_path": "Communications/IMAPClient/imapclient/imapclient.py", "signature_position": [527, 527], "body_position": [533, 534], "dependency": {"intra_class": ["imapclient.imapclient.IMAPClient._imap"], "intra_file": ["imapclient.imapclient.logger"], "cross_file": ["imapclient.tls.IMAP4_TLS.shutdown"]}, "requirement": {"Functionality": "Close the connection to the IMAP server without logging out. It shuts down the connection to the IMAP server and logs a message indicating that the connection has been closed.", "Arguments": ":param self: IMAPClient. An instance of the IMAPClient class.\n:return: None."}, "tests": ["tests/test_imapclient.py::TestShutdown::test_shutdown"], "indent": 8}
{"namespace": "oletools.oleid.OleID.check", "type": "method", "project_path": "Security/oletools", "completion_path": "Security/oletools/oletools/oleid.py", "signature_position": [259, 259], "body_position": [265, 305], "dependency": {"intra_class": ["oletools.oleid.OleID.check_encrypted", "oletools.oleid.OleID.check_external_relationships", "oletools.oleid.OleID.check_flash", "oletools.oleid.OleID.check_macros", "oletools.oleid.OleID.check_object_pool", "oletools.oleid.OleID.check_properties", "oletools.oleid.OleID.data", "oletools.oleid.OleID.filename", "oletools.oleid.OleID.ftg", "oletools.oleid.OleID.indicators", "oletools.oleid.OleID.ole"], "intra_file": ["oletools.ftguess.CONTAINER.OLE", "oletools.ftguess.FTYPE.GENERIC_OLE", "oletools.ftguess.FileTypeGuesser.container", "oletools.ftguess.FileTypeGuesser.filetype", "oletools.ftguess.FileTypeGuesser.ftype", "oletools.ftguess.FileTypeGuesser.olefile", "oletools.ftguess.FileTypeGuesser.root_clsid", "oletools.ftguess.FileTypeGuesser.root_clsid_name", "oletools.oleid.Indicator", "oletools.oleid.Indicator.__init__", "oletools.oleid.RISK", "oletools.oleid.RISK.INFO"], "cross_file": ["oletools.ftguess", "oletools.ftguess.CONTAINER", "oletools.ftguess.FTYPE", "oletools.ftguess.FType_EXE_PE.container", "oletools.ftguess.FType_EXE_PE.longname", "oletools.ftguess.FileTypeGuesser"]}, "requirement": {"Functionality": "This function opens a file and runs various checks on it to determine its properties and characteristics. It creates a list of Indicator objects based on the results of the checks.", "Arguments": ":param self: OleID. An instance of the OleID class.\n:return: List of Indicator objects. The list contains all the Indicator objects created during the checks."}, "tests": ["tests/oleid/test_issue_166.py::TestEncryptedDocumentDetection::test_encrypted_document_detection"], "indent": 8}
{"namespace": "mingus.core.intervals.from_shorthand", "type": "function", "project_path": "Multimedia/mingus", "completion_path": "Multimedia/mingus/mingus/core/intervals.py", "signature_position": [433, 433], "body_position": [445, 486], "dependency": {"intra_class": [], "intra_file": ["mingus.core.intervals.major_fifth", "mingus.core.intervals.major_fourth", "mingus.core.intervals.major_second", "mingus.core.intervals.major_seventh", "mingus.core.intervals.major_sixth", "mingus.core.intervals.major_third", "mingus.core.intervals.major_unison", "mingus.core.intervals.minor_second", "mingus.core.intervals.minor_seventh", "mingus.core.intervals.minor_sixth", "mingus.core.intervals.minor_third"], "cross_file": ["mingus.core.notes", "mingus.core.notes.augment", "mingus.core.notes.diminish", "mingus.core.notes.is_valid_note"]}, "requirement": {"Functionality": "This function returns the note that is a certain interval up or down from the given note.\n", "Arguments": ":param note: str. The starting note.\n:param interval: str. The interval to move up or down. It should be a number between 1 to 7, along with optional \"#\" (sharp) or \"b\" (flat) symbols.\n:param up: bool. Whether to move up or down from the starting note. It defaults to True.\n:return: str. The resulting note after moving up or down by the specified interval. If the input is not valid, it returns False.\n"}, "tests": ["tests/unit/core/test_intervals.py::test_intervals::test_from_shorthand"], "indent": 4}
{"namespace": "bentoml._internal.runner.container.NdarrayContainer.from_payload", "type": "method", "project_path": "Scientific-Engineering/bentoml", "completion_path": "Scientific-Engineering/bentoml/src/bentoml/_internal/runner/container.py", "signature_position": [309, 312], "body_position": [313, 320], "dependency": {"intra_class": [], "intra_file": ["bentoml._internal.runner.container.Payload"], "cross_file": ["bentoml._internal.external_typing.NpNDArray", "bentoml._internal.runner.container.Payload.data", "bentoml._internal.runner.container.Payload.meta", "bentoml._internal.utils.pickle.pep574_loads", "bentoml._internal.external_typing"]}, "requirement": {"Functionality": "This function creates an NdarrayContainer instance from the given payload. It checks the format of the payload and if it is \"pickle5\", it decodes the pickle bytes and returns the deserialized ndarray. Otherwise, it uses the pickle module to load and return the deserialized ndarray.", "Arguments": ":param cls: Class. The class itself.\n:param payload: Payload. The payload containing the data and metadata of the ndarray.\n:return: ext.NpNDArray. The deserialized ndarray."}, "tests": ["tests/unit/_internal/runner/test_container.py::test_ndarray_container"], "indent": 8}
{"namespace": "mingus.containers.note.Note.transpose", "type": "method", "project_path": "Multimedia/mingus", "completion_path": "Multimedia/mingus/mingus/containers/note.py", "signature_position": [180, 180], "body_position": [192, 200], "dependency": {"intra_class": ["mingus.containers.note.Note.__init__", "mingus.containers.note.Note.name", "mingus.containers.note.Note.octave"], "intra_file": [], "cross_file": ["mingus.core.intervals", "mingus.core.intervals.from_shorthand"]}, "requirement": {"Functionality": "Transpose a note up or down by a given interval.\n", "Arguments": ":param self: Note. An instance of the Note class.\n:param interval: str. The interval to transpose the note by.\n:param up: bool. Whether to transpose the note up or down. It defaults to True if not specified.\n:return: no return values.\n"}, "tests": ["tests/unit/containers/test_note.py::test_Note::test_transpose"], "indent": 8}
{"namespace": "oletools.ooxml.ZipSubFile.seek", "type": "method", "project_path": "Security/oletools", "completion_path": "Security/oletools/oletools/ooxml.py", "signature_position": [328, 328], "body_position": [331, 360], "dependency": {"intra_class": ["oletools.ooxml.ZipSubFile._seek_skip", "oletools.ooxml.ZipSubFile.pos", "oletools.ooxml.ZipSubFile.reset", "oletools.ooxml.ZipSubFile.size"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function is used to reposition the read pointer in a ZipSubFile instance. It calculates the new position based on the current position, the given position, and the offset. Then, it adjusts the read pointer accordingly.", "Arguments": ":param self: ZipSubFile. An instance of the ZipSubFile class.\n:param pos: Integer. The new position to set the read pointer to.\n:param offset: Integer. The offset to determine the new position. It defaults to io.SEEK_SET if not specified.\n:return: No return values."}, "tests": ["tests/ooxml/test_zip_sub_file.py::TestZipSubFile::test_check_size", "tests/ooxml/test_zip_sub_file.py::TestZipSubFile::test_seek_forward", "tests/ooxml/test_zip_sub_file.py::TestZipSubFile::test_error_read"], "indent": 8}
{"namespace": "mackup.utils.get_copy_folder_location", "type": "function", "project_path": "Utilities/mackup", "completion_path": "Utilities/mackup/mackup/utils.py", "signature_position": [256, 256], "body_position": [263, 281], "dependency": {"intra_class": [], "intra_file": ["mackup.utils.error"], "cross_file": ["mackup.constants.ERROR_UNABLE_TO_FIND_STORAGE", "mackup.constants"]}, "requirement": {"Functionality": "This function tries to locate the Copy folder by searching for the Copy settings file. It then connects to the settings database, executes a query to retrieve the value with the option that is csmRootPath from Copy folder path, and returns it.", "Arguments": ":param: No input parameters.\n:return: str. The full path to the current Copy folder."}, "tests": ["tests/utils_test.py::TestMackup::test_failed_backup_location"], "indent": 4}
{"namespace": "falcon.request.Request.forwarded", "type": "method", "project_path": "Internet/falcon", "completion_path": "Internet/falcon/falcon/request.py", "signature_position": [559, 565], "body_position": [566, 574], "dependency": {"intra_class": ["falcon.request.Request._cached_forwarded", "falcon.request.Request.get_header"], "intra_file": [], "cross_file": ["falcon.forwarded._parse_forwarded_header"]}, "requirement": {"Functionality": "This function returns the value of the \"Forwarded\" header in a Request instance. It first checks if the value is already cached, and if not, it retrieves the header value, parses the value, and returns it.", "Arguments": ":param self: Request. An instance of the Request class.\n:return: The value of the \"Forwarded\" header, or None if it is not present."}, "tests": ["tests/test_request_forwarded.py::test_forwarded_missing_first_hop_host", "tests/test_request_forwarded.py::test_forwarded_host", "tests/test_request_forwarded.py::test_forwarded_quote_escaping", "tests/test_request_forwarded.py::test_forwarded_multiple_params", "tests/test_request_forwarded.py::test_forwarded_invalid"], "indent": 8}
{"namespace": "bentoml._internal.runner.container.PandasDataFrameContainer.from_batch_payloads", "type": "method", "project_path": "Scientific-Engineering/bentoml", "completion_path": "Scientific-Engineering/bentoml/src/bentoml/_internal/runner/container.py", "signature_position": [443, 447], "body_position": [448, 449], "dependency": {"intra_class": ["bentoml._internal.runner.container.PandasDataFrameContainer.batches_to_batch", "bentoml._internal.runner.container.PandasDataFrameContainer.from_payload"], "intra_file": ["bentoml._internal.runner.container.Payload"], "cross_file": ["bentoml._internal.external_typing"]}, "requirement": {"Functionality": "This function creates a PandasDataFrameContainer instance from a sequence of payloads. It iterates over the payloads and creates batches. Then, it converts the batches into a single batch based on the specified batch dimension.", "Arguments": ":param cls: PandasDataFrameContainer. The class itself.\n:param payloads: Sequence of Payload. A sequence of payloads to create the PandasDataFrameContainer instance.\n:param batch_dim: int. The dimension along which the batches will be combined. It defaults to 0 if not specified.\n:return: tuple[ext.PdDataFrame, list[int]]. A tuple containing the PandasDataFrameContainer instance and a list of integers representing the batch dimensions."}, "tests": ["tests/unit/_internal/runner/test_container.py::test_pandas_container"], "indent": 8}
{"namespace": "boto.dynamodb2.table.Table.get_item", "type": "method", "project_path": "Internet/boto", "completion_path": "Internet/boto/boto/dynamodb2/table.py", "signature_position": [654, 654], "body_position": [700, 711], "dependency": {"intra_class": ["boto.dynamodb2.table.Table._encode_keys", "boto.dynamodb2.table.Table.connection", "boto.dynamodb2.table.Table.table_name"], "intra_file": [], "cross_file": ["boto.dynamodb2.exceptions.ItemNotFound", "boto.dynamodb2.items.Item", "boto.dynamodb2.items.Item.load", "boto.dynamodb2.layer1.DynamoDBConnection.get_item", "boto.dynamodb2.exceptions"]}, "requirement": {"Functionality": "This function fetches an item (record) from a table in DynamoDB based on the specified key attributes. It can perform a consistent read if specified and can fetch specific fields if specified. It returns an Item instance containing all the data for that record.", "Arguments": ":param self: Table. An instance of the Table class.\n:param consistent: Bool. Whether to perform a consistent read from DynamoDB. Defaults to False.\n:param attributes: List of strings. The fields to fetch. Defaults to None, which means all fields should be fetched.\n:param kwargs: Key-value pairs representing the key attributes of the item to fetch.\n:return: Item. An Item instance containing the data for the fetched record.\n:raises: ItemNotFound. If the item is not found in the table."}, "tests": ["tests/unit/dynamodb2/test_table.py::TableTestCase::test_get_item"], "indent": 8}
{"namespace": "pyt.vulnerabilities.vulnerabilities.build_sanitiser_node_dict", "type": "function", "project_path": "Security/python-taint", "completion_path": "Security/python-taint/pyt/vulnerabilities/vulnerabilities.py", "signature_position": [170, 173], "body_position": [185, 202], "dependency": {"intra_class": [], "intra_file": ["pyt.vulnerabilities.vulnerabilities.find_sanitiser_nodes"], "cross_file": ["pyt.vulnerabilities.vulnerability_helper.Sanitiser", "pyt.vulnerabilities.vulnerability_helper.TriggerNode.sanitisers"]}, "requirement": {"Functionality": "This function builds a dictionary of string -> TriggerNode pairs, where the string represents a sanitiser and the TriggerNode represents a TriggerNode of the sanitiser. It first extracts the sanitisers from the given list of sinks. Then, it searches for the sanitisers in the given CFG and creates a sanitiser instance for each sanitiser found. Finally, it creates a dictionary where the keys are the sanitisers and the values are lists of TriggerNodes associated with each sanitiser.", "Arguments": ":param cfg: CFG. The CFG to traverse.\n:param sinks_in_file: List of TriggerNode. A list of TriggerNodes containing the sinks in the file.\n:return: Dict. A dictionary mapping sanitiser strings to lists of TriggerNodes."}, "tests": ["tests/vulnerabilities/vulnerabilities_test.py::EngineTest::test_build_sanitiser_node_dict"], "indent": 4}
{"namespace": "boto.ec2.elb.ELBConnection.disable_availability_zones", "type": "method", "project_path": "Internet/boto", "completion_path": "Internet/boto/boto/ec2/elb/__init__.py", "signature_position": [368, 368], "body_position": [386, 391], "dependency": {"intra_class": ["boto.ec2.elb.ELBConnection.build_list_params"], "intra_file": [], "cross_file": ["boto.connection.AWSQueryConnection.get_object", "boto.ec2.elb.loadbalancer.LoadBalancerZones"]}, "requirement": {"Functionality": "This function disables availability zones for an existing Load Balancer. It removes the specified zones from the Load Balancer. If the zones are not registered with the Load Balancer, no changes are made. However, it is not possible to remove all zones from a Load Balancer.", "Arguments": ":param self: ELBConnection. An instance of the ELBConnection class.\n:param load_balancer_name: String. The name of the Load Balancer.\n:param zones_to_remove: List of strings. The names of the zones to remove.\n:return: List of strings. An updated list of zones for the Load Balancer."}, "tests": ["tests/unit/ec2/elb/test_loadbalancer.py::TestInstanceStatusResponseParsing::test_next_token"], "indent": 8}
{"namespace": "bplustree.memory.WAL.rollback", "type": "method", "project_path": "Database/bplustree", "completion_path": "Database/bplustree/bplustree/memory.py", "signature_position": [423, 424], "body_position": [425, 426], "dependency": {"intra_class": ["bplustree.memory.WAL._add_frame", "bplustree.memory.WAL._not_committed_pages"], "intra_file": ["bplustree.memory.FrameType", "bplustree.memory.FrameType.ROLLBACK"], "cross_file": []}, "requirement": {"Functionality": "If there are uncommitted pages in the WAL, a rollback frame is added.", "Arguments": ":param self: WAL. An instance of the WAL class.\n:return: No return values."}, "tests": ["tests/test_memory.py::test_wal_rollback"], "indent": 8}
{"namespace": "kinto.plugins.quotas.scripts.rebuild_quotas", "type": "function", "project_path": "Internet/kinto", "completion_path": "Internet/kinto/kinto/plugins/quotas/scripts.py", "signature_position": [17, 17], "body_position": [18, 50], "dependency": {"intra_class": [], "intra_file": ["kinto.plugins.quotas.scripts.OLDEST_FIRST", "kinto.plugins.quotas.scripts.logger", "kinto.plugins.quotas.scripts.rebuild_quotas_collection"], "cross_file": ["kinto.core.storage.utils.paginated", "kinto.plugins.quotas.listener.BUCKET_QUOTA_OBJECT_ID", "kinto.plugins.quotas.utils.record_size"]}, "requirement": {"Functionality": "This function rebuilds quotas for a given storage. It iterates through each bucket in the storage and calculates the total record count, storage size, and collection count for each bucket. It then updates the quota information for each bucket in the storage. Finally, it logs the final size of each bucket.", "Arguments": ":param storage: The storage object to rebuild quotas for.\n:param dry_run: Bool. Whether to perform a dry run without actually updating the quotas. Defaults to False.\n:return: No return values."}, "tests": ["tests/plugins/test_quotas.py::QuotasScriptsTest::test_rebuild_quotas_doesnt_update_if_dry_run", "tests/plugins/test_quotas.py::QuotasScriptsTest::test_rebuild_quotas_updates_records"], "indent": 4}
{"namespace": "litecli.packages.completion_engine.suggest_type", "type": "function", "project_path": "Database/litecli", "completion_path": "Database/litecli/litecli/packages/completion_engine.py", "signature_position": [10, 10], "body_position": [18, 89], "dependency": {"intra_class": [], "intra_file": ["litecli.packages.completion_engine.suggest_based_on_last_token", "litecli.packages.completion_engine.suggest_special"], "cross_file": ["litecli.encodingutils.text_type", "litecli.packages.parseutils.last_word"]}, "requirement": {"Functionality": "This function suggests the completion type and scope based on the text that has been typed so far and the text before the cursor.", "Arguments": ":param full_text: String. The full text that has been typed so far.\n:param text_before_cursor: String. The text before the cursor.\n:return: List of dictionaries. Each dictionary contains a \"type\" key with the type of entity ('table', 'column', etc) and a \"scope\" key with the corresponding scope."}, "tests": ["tests/test_completion_engine.py::test_specials_not_included_after_initial_token", "tests/test_completion_engine.py::test_cross_join", "tests/test_completion_engine.py::test_outer_table_reference_in_exists_subquery_suggests_columns", "tests/test_dbspecial.py::test_list_or_show_create_tables", "tests/test_completion_engine.py::test_insert_into_lparen_partial_text_suggests_cols"], "indent": 4}
{"namespace": "sacred.observers.file_storage.FileStorageObserver.resource_event", "type": "method", "project_path": "Utilities/sacred", "completion_path": "Utilities/sacred/sacred/observers/file_storage.py", "signature_position": [291, 291], "body_position": [292, 294], "dependency": {"intra_class": ["sacred.observers.file_storage.FileStorageObserver.find_or_save", "sacred.observers.file_storage.FileStorageObserver.resource_dir", "sacred.observers.file_storage.FileStorageObserver.run_entry", "sacred.observers.file_storage.FileStorageObserver.save_json"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function handles a resource event by finding or saving the file, updating the 'resources' field of the running entry, and saving the updated running entry as 'run.json'.", "Arguments": ":param self: FileStorageObserver. An instance of the FileStorageObserver class.\n:param filename: str. The name of the file for the resource event.\n:return: No return values."}, "tests": ["tests/test_observers/test_file_storage_observer.py::test_fs_observer_resource_event_does_not_duplicate", "tests/test_observers/test_file_storage_observer.py::test_no_duplicate"], "indent": 8}
{"namespace": "music_dl.source.MusicSource.search", "type": "method", "project_path": "Utilities/pymusic-dl", "completion_path": "Utilities/pymusic-dl/music_dl/source.py", "signature_position": [32, 32], "body_position": [33, 93], "dependency": {"intra_class": ["music_dl.source.MusicSource.logger", "music_dl.source.MusicSource.search_thread"], "intra_file": [], "cross_file": ["music_dl.config.get", "music_dl.utils.colorize", "music_dl.config", "music_dl.song.BasicSong.singer", "music_dl.song.BasicSong.title"]}, "requirement": {"Functionality": "This function searches for a keyword in a list of music sources. It creates multiple threads to search for the keyword in each source concurrently. It then sorts and removes duplicates from the search results based on song title, singer, and file size.", "Arguments": ":param self: MusicSource. An instance of the MusicSource class.\n:param keyword: String. The keyword to search for in the music sources.\n:param sources_list: List of strings. The list of music sources to search in.\n:return: List of songs. The search results containing songs that match the keyword."}, "tests": ["tests/test_source.py::test_search"], "indent": 8}
{"namespace": "dash._grouping.flatten_grouping", "type": "function", "project_path": "Software-Development/dash", "completion_path": "Software-Development/dash/dash/_grouping.py", "signature_position": [20, 20], "body_position": [32, 47], "dependency": {"intra_class": [], "intra_file": ["dash._grouping.validate_grouping"], "cross_file": []}, "requirement": {"Functionality": "This function takes a grouping value and converts it into a list of scalar values. It recursively flattens the grouping value based on the provided schema.", "Arguments": ":param grouping: The grouping value to flatten.\n:param schema: Optional. A grouping value representing the expected structure of the input grouping value. If not provided, the grouping value is treated as its own schema. A schema is required to treat tuples and dicts in the input grouping as scalar values.\n:return: A list of scalar values in the input grouping."}, "tests": ["tests/unit/library/test_grouping.py::test_map_grouping_mixed", "tests/unit/library/test_grouping.py::test_flatten_dict", "tests/unit/library/test_grouping.py::test_flatten_dict_key_order", "tests/unit/library/test_grouping.py::test_flatten_odd_value", "tests/unit/library/test_grouping.py::test_flatten_mixed"], "indent": 4}
{"namespace": "sqlitedict.SqliteDict.terminate", "type": "method", "project_path": "Database/sqlitedict", "completion_path": "Database/sqlitedict/sqlitedict.py", "signature_position": [399, 399], "body_position": [401, 414], "dependency": {"intra_class": ["sqlitedict.SqliteDict.close", "sqlitedict.SqliteDict.filename", "sqlitedict.SqliteDict.flag"], "intra_file": ["sqlitedict.logger"], "cross_file": []}, "requirement": {"Functionality": "This function deletes the underlying database file associated with the SqliteDict instance. It first checks if the instance is read-only, and if so, raises a RuntimeError. Then, it closes the instance. If the filename is not \":memory:\", it attempts to delete the file from the file system.", "Arguments": ":param self: SqliteDict. An instance of the SqliteDict class.\n:return: No return values."}, "tests": ["tests/test_core.py::SqliteDictTerminateTest::test_terminate_instead_close"], "indent": 8}
{"namespace": "mingus.core.intervals.minor_fourth", "type": "function", "project_path": "Multimedia/mingus", "completion_path": "Multimedia/mingus/mingus/core/intervals.py", "signature_position": [188, 188], "body_position": [189, 190], "dependency": {"intra_class": [], "intra_file": ["mingus.core.intervals.augment_or_diminish_until_the_interval_is_right", "mingus.core.intervals.fourth"], "cross_file": []}, "requirement": {"Functionality": "This function generates a minor fourth note based on the given input note.\n", "Arguments": ":param note: str. The input note for generating the minor fourth.\n:return: str. The generated minor fourth note above the given note.\n"}, "tests": ["tests/unit/core/test_intervals.py::test_intervals::test_minor_fourth"], "indent": 4}
{"namespace": "mrjob.fs.hadoop.HadoopFilesystem.get_hadoop_bin", "type": "method", "project_path": "System/mrjob", "completion_path": "System/mrjob/mrjob/fs/hadoop.py", "signature_position": [78, 78], "body_position": [80, 82], "dependency": {"intra_class": ["mrjob.fs.hadoop.HadoopFilesystem._find_hadoop_bin", "mrjob.fs.hadoop.HadoopFilesystem._hadoop_bin"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function returns the path to the Hadoop binary. If the path is not already set, it searches for the Hadoop binary and sets the path.", "Arguments": ":param self: HadoopFilesystem. An instance of the HadoopFilesystem class.\n:return: str. The path to the Hadoop binary."}, "tests": ["tests/fs/test_hadoop.py::FindHadoopBinTestCase::test_two_part_path", "tests/fs/test_hadoop.py::FindHadoopBinTestCase::test_predefined_hadoop_bin", "tests/fs/test_hadoop.py::FindHadoopBinTestCase::test_other_environment_variable", "tests/fs/test_hadoop.py::FindHadoopBinTestCase::test_fallback"], "indent": 8}
{"namespace": "mrjob.fs.local.LocalFilesystem.mkdir", "type": "method", "project_path": "System/mrjob", "completion_path": "System/mrjob/mrjob/fs/local.py", "signature_position": [63, 63], "body_position": [64, 66], "dependency": {"intra_class": [], "intra_file": ["mrjob.fs.local._from_file_uri"], "cross_file": []}, "requirement": {"Functionality": "Create a new directory in the local filesystem. It first converts the input path from a file URI to a local path, and then checks if the directory already exists. If not, it creates the directory.", "Arguments": ":param self: LocalFilesystem. An instance of the LocalFilesystem class.\n:param path: String. The path of the directory to be created, in file URI format.\n:return: No return values."}, "tests": ["tests/fs/test_local.py::LocalFSTestCase::test_mkdir_file_uri", "tests/fs/test_local.py::LocalFSTestCase::test_mkdir"], "indent": 8}
{"namespace": "chatette.parsing.UnitRefBuilder._build_modifiers_repr", "type": "method", "project_path": "Communications/chatette", "completion_path": "Communications/chatette/chatette/parsing/__init__.py", "signature_position": [104, 104], "body_position": [105, 108], "dependency": {"intra_class": ["chatette.parsing.UnitRefBuilder.arg_value", "chatette.parsing.UnitRefBuilder.variation"], "intra_file": ["chatette.parsing.ItemBuilder", "chatette.parsing.ItemBuilder._build_modifiers_repr"], "cross_file": ["chatette.modifiers.representation.ModifiersRepresentation.argument_value", "chatette.modifiers.representation.ModifiersRepresentation.variation_name"]}, "requirement": {"Functionality": "This function builds the representation of modifiers. It first build the representation of modifiers, then it sets the argument value and variation name for the modifiers, and finally returns the modified modifiers.", "Arguments": ":param self: UnitRefBuilder. An instance of the UnitRefBuilder class.\n:return: The modified modifiers."}, "tests": ["tests/unit-testing/parsing/test_init.py::TestUnitRefBuilder::test_create_concrete"], "indent": 8}
{"namespace": "sslyze.plugins.certificate_info._cli_connector._get_name_as_short_text", "type": "function", "project_path": "System/sslyze", "completion_path": "System/sslyze/sslyze/plugins/certificate_info/_cli_connector.py", "signature_position": [326, 326], "body_position": [329, 336], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["sslyze.plugins.certificate_info._certificate_utils.get_common_names"]}, "requirement": {"Functionality": "This function converts a name field returned by the cryptography module to a string that can be displayed to the user. It checks if there is a common name (CN) in the name field and returns it. If there is no CN, it returns the entire name field as a string.", "Arguments": ":param name_field: x509.Name. The name field returned by the cryptography module.\n:return: str. The converted name field as a string suitable for display."}, "tests": ["tests/plugins_tests/certificate_info/test_certificate_utils.py::TestCertificateUtils::test_get_name_as_short_text"], "indent": 4}
{"namespace": "boltons.cacheutils.LRI.clear", "type": "method", "project_path": "Utilities/boltons", "completion_path": "Utilities/boltons/boltons/cacheutils.py", "signature_position": [287, 287], "body_position": [288, 290], "dependency": {"intra_class": ["boltons.cacheutils.LRI._init_ll", "boltons.cacheutils.LRI._lock"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function clears the data stored in the LRI object.\n", "Arguments": ":param self: LRI, an instance of the LRI class.\n:return: no return values.\n"}, "tests": ["tests/test_cacheutils.py::test_callable_cached_dec", "tests/test_cacheutils.py::test_lru_basic"], "indent": 8}
{"namespace": "pycorrector.en_spell.EnSpell.check_init", "type": "method", "project_path": "Text-Processing/pycorrector", "completion_path": "Text-Processing/pycorrector/pycorrector/en_spell.py", "signature_position": [43, 43], "body_position": [44, 45], "dependency": {"intra_class": ["pycorrector.en_spell.EnSpell._init", "pycorrector.en_spell.EnSpell.word_freq_dict"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Check if the EnSpell instance has been initialized. If not, it initializes the instance.", "Arguments": ":param self: EnSpell. An instance of the EnSpell class.\n:return: No return values."}, "tests": ["tests/en_spell_dict_test.py::TestEnSpell::test_word_frequency", "tests/en_spell_dict_test.py::TestEnSpell::test_word_in"], "indent": 8}
{"namespace": "faker.utils.distribution.choices_distribution_unique", "type": "function", "project_path": "Software-Development/Faker", "completion_path": "Software-Development/Faker/faker/utils/distribution.py", "signature_position": [26, 33], "body_position": [34, 54], "dependency": {"intra_class": [], "intra_file": ["faker.utils.distribution.T", "faker.utils.distribution.cumsum", "faker.utils.distribution.random_sample"], "cross_file": ["faker.generator.random"]}, "requirement": {"Functionality": "This function generates a sequence of unique choices based on the given input sequence and their corresponding probabilities. It ensures that the generated choices are unique and takes into account the weight of each choice.", "Arguments": ":param a: Sequence[T]. The input sequence of elements to choose from.\n:param p: Optional[Sequence[float]]. The probabilities associated with each element in the input sequence.\n:param random: Optional[Random]. The random number generator to be used. If not provided, the default random generator is used.\n:param length: int. The number of unique choices to generate. Defaults to 1.\n:return: Sequence[T]. A sequence of unique choices based on the input sequence and their probabilities."}, "tests": ["tests/utils/test_utils.py::UtilsTestCase::test_choices_distribution_unique"], "indent": 4}
{"namespace": "sumy.summarizers.edmundson.EdmundsonSummarizer.title_method", "type": "method", "project_path": "Internet/sumy", "completion_path": "Internet/sumy/sumy/summarizers/edmundson.py", "signature_position": [110, 110], "body_position": [111, 112], "dependency": {"intra_class": ["sumy.summarizers.edmundson.EdmundsonSummarizer._build_title_method_instance"], "intra_file": [], "cross_file": ["sumy.summarizers.edmundson_title.EdmundsonTitleMethod.__call__"]}, "requirement": {"Functionality": "This function applies the title method of summarization to a given document and returns the summarized text. It first creates an instance of the title method and then uses it to summarize the document.", "Arguments": ":param self: EdmundsonSummarizer. An instance of the EdmundsonSummarizer class.\n:param document: String. The document to be summarized.\n:param sentences_count: Integer. The number of sentences to include in the summary.\n:return: Tuple. The summarized text."}, "tests": ["tests/test_summarizers/test_edmundson.py::test_title_method_1", "tests/test_summarizers/test_edmundson.py::test_title_method_3", "tests/test_summarizers/test_edmundson.py::test_title_method_with_empty_document", "tests/test_summarizers/test_edmundson.py::test_title_method_2", "tests/test_summarizers/test_edmundson.py::test_title_method_without_null_words"], "indent": 8}
{"namespace": "sumy.summarizers.sum_basic.SumBasicSummarizer._get_all_content_words_in_doc", "type": "method", "project_path": "Internet/sumy", "completion_path": "Internet/sumy/sumy/summarizers/sum_basic.py", "signature_position": [55, 55], "body_position": [56, 59], "dependency": {"intra_class": ["sumy.summarizers.sum_basic.SumBasicSummarizer._filter_out_stop_words", "sumy.summarizers.sum_basic.SumBasicSummarizer._get_all_words_in_doc", "sumy.summarizers.sum_basic.SumBasicSummarizer._normalize_words"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function takes a list of sentences as input and returns a list of normalized content words. It first gets all the words in the sentences, then filters out the stop words, and finally normalizes the remaining content words.", "Arguments": ":param self: SumBasicSummarizer. An instance of the SumBasicSummarizer class.\n:param sentences: List of Sentence. The sentences from which to extract the content words.\n:return: List of strings. The normalized content words extracted from the sentences."}, "tests": ["tests/test_summarizers/test_sum_basic.py::test_get_all_content_words_in_doc"], "indent": 8}
{"namespace": "jwt.utils.to_base64url_uint", "type": "function", "project_path": "Utilities/PyJWT", "completion_path": "Utilities/PyJWT/jwt/utils.py", "signature_position": [40, 40], "body_position": [41, 49], "dependency": {"intra_class": [], "intra_file": ["jwt.utils.base64url_encode", "jwt.utils.bytes_from_int"], "cross_file": []}, "requirement": {"Functionality": "This function takes an integer value and converts it to a base64url-encoded byte string. It first checks if the input value is a positive integer, and then converts the integer to bytes. If the resulting byte string is empty, it sets it to a single null byte. Finally, it returns the base64url-encoded byte string.", "Arguments": ":param val: int. The integer value to be converted to base64url-encoded byte string.\n:return: bytes. The base64url-encoded byte string representing the input integer value."}, "tests": ["tests/test_utils.py::test_to_base64url_uint"], "indent": 4}
{"namespace": "msticpy.analysis.anomalous_sequence.utils.cmds_only.compute_likelihood_windows_in_session", "type": "function", "project_path": "Security/msticpy", "completion_path": "Security/msticpy/msticpy/analysis/anomalous_sequence/utils/cmds_only.py", "signature_position": [199, 208], "body_position": [242, 277], "dependency": {"intra_class": [], "intra_file": ["msticpy.analysis.anomalous_sequence.utils.cmds_only.compute_likelihood_window"], "cross_file": ["msticpy.analysis.anomalous_sequence.utils.data_structures.StateMatrix", "msticpy.common.exceptions.MsticpyException"]}, "requirement": {"Functionality": "This function computes the likelihoods of a sliding window of commands in a session. It iterates through the session and calculates the likelihood of each window based on the prior probabilities and transition probabilities.", "Arguments": ":param session: List[str]. A list of commands in a session.\n:param prior_probs: Union[StateMatrix, dict]. Computed probabilities of individual commands.\n:param trans_probs: Union[StateMatrix, dict]. Computed probabilities of sequences of commands.\n:param window_len: int. The length of the sliding window for likelihood calculations.\n:param use_start_end_tokens: bool. If True, start_token and end_token will be added to the session before calculations.\n:param start_token: str. A dummy command to signify the start of the session.\n:param end_token: str. A dummy command to signify the end of the session.\n:param use_geo_mean: bool. If True, each likelihood of the sliding windows will be raised to the power of (1/window_len).\n:return: List[float]. A list of likelihoods for each sliding window."}, "tests": ["tests/analysis/test_anom_seq_cmds_only.py::TestCmdsOnly::test_compute_likelihood_windows_in_session"], "indent": 4}
{"namespace": "mssqlcli.telemetry.conclude", "type": "function", "project_path": "Database/mssql-cli", "completion_path": "Database/mssql-cli/mssqlcli/telemetry.py", "signature_position": [122, 123], "body_position": [124, 128], "dependency": {"intra_class": [], "intra_file": ["mssqlcli.telemetry.TelemetrySession.end_time", "mssqlcli.telemetry.TelemetrySession.generate_payload", "mssqlcli.telemetry._session", "mssqlcli.telemetry.output_payload_to_file", "mssqlcli.telemetry.upload_payload"], "cross_file": []}, "requirement": {"Functionality": "This function concludes the session by setting the end time, generating the payload, outputting the payload to a file, and uploading the payload to a service endpoint.", "Arguments": ":param service_endpoint_uri: String. The URI of the service endpoint to upload the payload to. It defaults to 'https://vortex.data.microsoft.com/collect/v1' if not specified.\n:param separate_process: Bool. Whether to upload the payload in a separate process. It defaults to True if not specified.\n:return: The result of the upload."}, "tests": ["tests/test_telemetry.py::TelemetryTests::test_telemetry_vortex_format"], "indent": 4}
{"namespace": "alembic.operations.ops.DropIndexOp.from_index", "type": "method", "project_path": "Database/alembic", "completion_path": "Database/alembic/alembic/operations/ops.py", "signature_position": [1050, 1050], "body_position": [1051, 1058], "dependency": {"intra_class": ["alembic.operations.ops.DropIndexOp.__init__"], "intra_file": ["alembic.operations.ops.CreateIndexOp", "alembic.operations.ops.CreateIndexOp.from_index"], "cross_file": []}, "requirement": {"Functionality": "This function creates a DropIndexOp instance based on the given index. It extracts the necessary information from the index object and initializes the DropIndexOp instance with those values.", "Arguments": ":param cls: Class. The class of the DropIndexOp instance.\n:param index: Index. The index object from which the DropIndexOp instance is created.\n:return: DropIndexOp. The created DropIndexOp instance."}, "tests": ["tests/test_autogen_render.py::AutogenRenderTest::test_drop_index", "tests/test_op.py::ObjectFromToTest::test_drop_index_add_kw", "tests/test_op.py::ObjectFromToTest::test_drop_index", "tests/test_autogen_render.py::AutogenRenderTest::test_drop_index_func", "tests/test_autogen_render.py::AutogenRenderTest::test_drop_index_schema_batch"], "indent": 8}
{"namespace": "alembic.script.revision.RevisionMap.filter_for_lineage", "type": "method", "project_path": "Database/alembic", "completion_path": "Database/alembic/alembic/script/revision.py", "signature_position": [674, 679], "body_position": [680, 694], "dependency": {"intra_class": ["alembic.script.revision.RevisionMap._resolve_revision_number"], "intra_file": ["alembic.script.revision._TR"], "cross_file": []}, "requirement": {"Functionality": "Filter a list of targets based on their lineage in the RevisionMap instance. It checks if each target shares a lineage with the specified revision number and includes it in the result if it does.", "Arguments": ":param self: RevisionMap. An instance of the RevisionMap class.\n:param targets: Iterable. A list of targets to filter.\n:param check_against: Optional string. The revision number to check against. If not specified, all targets will be included.\n:param include_dependencies: Bool. Whether to include targets that are dependencies of the specified targets. Defaults to False.\n:return: Tuple. A tuple of targets that share a lineage with the specified revision number."}, "tests": ["tests/test_revision.py::LabeledBranchTest::test_filter_for_lineage_labeled_head_across_merge", "tests/test_revision.py::LabeledBranchTest::test_filter_for_lineage_heads"], "indent": 8}
{"namespace": "pyramid.config.views.MultiView.match", "type": "method", "project_path": "Internet/pyramid", "completion_path": "Internet/pyramid/src/pyramid/config/views.py", "signature_position": [124, 124], "body_position": [125, 130], "dependency": {"intra_class": ["pyramid.config.views.MultiView.get_views", "pyramid.config.views.MultiView.name"], "intra_file": [], "cross_file": ["pyramid.exceptions.PredicateMismatch"]}, "requirement": {"Functionality": "This function matches a view based on the given context and request. It iterates through the views obtained by request and checks if each view has the `__predicated__`. If a view does not have the attribute or if the predicated result is `True` for the given context and request, that view is returned. If no matching view is found, a predicate mismatch exception is raised.", "Arguments": ":param self: MultiView. An instance of the MultiView class.\n:param context: The context for matching the view.\n:param request: The request for matching the view.\n:return: The matched view."}, "tests": ["tests/test_config/test_views.py::TestMultiView::test_match_predicate_succeeds", "tests/test_config/test_views.py::TestMultiView::test_match_predicate_fails", "tests/test_config/test_views.py::TestMultiView::test_match_not_found"], "indent": 8}
{"namespace": "mrjob.compat.translate_jobconf", "type": "function", "project_path": "System/mrjob", "completion_path": "System/mrjob/mrjob/compat.py", "signature_position": [657, 657], "body_position": [661, 667], "dependency": {"intra_class": [], "intra_file": ["mrjob.compat._JOBCONF_MAP", "mrjob.compat.map_version"], "cross_file": []}, "requirement": {"Functionality": "Translate a job configuration variable to a specific Hadoop version. If the variable is not recognized, it remains unchanged.\n", "Arguments": ":param variable: String. The job configuration variable to be translated.\n:param version: String. The target Hadoop version to translate the variable to.\n:return: String. The translated variable based on the specified Hadoop version. If the variable is not recognized, it returns the unchanged variable.\n"}, "tests": ["tests/test_compat.py::TranslateJobConfTestCase::test_translate_jobconf", "tests/test_compat.py::TranslateJobConfTestCase::test_version_may_not_be_None"], "indent": 4}
{"namespace": "boltons.cacheutils.ThresholdCounter.update", "type": "method", "project_path": "Utilities/boltons", "completion_path": "Utilities/boltons/boltons/cacheutils.py", "signature_position": [805, 805], "body_position": [812, 821], "dependency": {"intra_class": ["boltons.cacheutils.ThresholdCounter.add", "boltons.cacheutils.ThresholdCounter.update"], "intra_file": ["boltons.cacheutils.xrange"], "cross_file": []}, "requirement": {"Functionality": "This function updates the counts in the ThresholdCounter instance by adding multiple items in one call.\n", "Arguments": ":param iterable: Iterable or Mapping. An iterable of keys to add or a mapping of keys to integer counts.\n:param kwargs: Additional key-value pairs that need to be updated in the ThresholdCounter instance.\n:return: No return values.\n"}, "tests": ["tests/test_cacheutils.py::test_threshold_counter"], "indent": 8}
{"namespace": "mrjob.parse.to_uri", "type": "function", "project_path": "System/mrjob", "completion_path": "System/mrjob/mrjob/parse.py", "signature_position": [69, 69], "body_position": [72, 75], "dependency": {"intra_class": [], "intra_file": ["mrjob.parse.is_uri"], "cross_file": []}, "requirement": {"Functionality": "This function takes a path or URI as input and converts it to a \"file:///\" URI if it is not already a URI.", "Arguments": ":param path_or_uri: str. The path or URI to be converted.\n:return: str. The converted URI."}, "tests": ["tests/test_parse.py::URITestCase::test_relative_path_to_uri", "tests/test_parse.py::URITestCase::test_to_uri"], "indent": 4}
{"namespace": "dominate.dom_tag.dom_tag.render", "type": "method", "project_path": "Text-Processing/dominate", "completion_path": "Text-Processing/dominate/dominate/dom_tag.py", "signature_position": [325, 325], "body_position": [326, 327], "dependency": {"intra_class": ["dominate.dom_tag.dom_tag._render"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Render the DOM tag and return the rendered output as a string. It recursively renders the tag and its children.", "Arguments": ":param self: dom_tag. An instance of the dom_tag class.\n:param indent: String. The string used for indentation. Defaults to two spaces.\n:param pretty: Bool. Whether to add line breaks and indentation for a prettier output. Defaults to True.\n:param xhtml: Bool. Whether to use XHTML syntax. Defaults to False.\n:return: String. The rendered output of the DOM tag."}, "tests": ["tests/test_html.py::test_lazy"], "indent": 4}
{"namespace": "pyt.vulnerabilities.vulnerabilities.find_triggers", "type": "function", "project_path": "Security/python-taint", "completion_path": "Security/python-taint/pyt/vulnerabilities/vulnerabilities.py", "signature_position": [129, 133], "body_position": [144, 148], "dependency": {"intra_class": [], "intra_file": ["pyt.vulnerabilities.vulnerabilities.label_contains"], "cross_file": []}, "requirement": {"Functionality": "This function finds triggers from a list of trigger words in a given list of nodes. It iterates through each node and checks if the line number of the node is not in the set of nosec_lines. If it does, it checks if the label of the node contains any of the trigger words and adds the finded trigger node to the list of trigger_nodes.", "Arguments": ":param nodes: List of Node objects. The nodes to find triggers in.\n:param trigger_words: List of Sink or Source objects. The trigger words to look for.\n:param nosec_lines: Set of integers. Lines with # nosec whitelisting.\n:return: List of TriggerNode objects. The found trigger nodes."}, "tests": ["tests/vulnerabilities/vulnerabilities_test.py::EngineTest::test_find_triggers"], "indent": 4}
{"namespace": "bentoml._internal.runner.container.DefaultContainer.to_payload", "type": "method", "project_path": "Scientific-Engineering/bentoml", "completion_path": "Scientific-Engineering/bentoml/src/bentoml/_internal/runner/container.py", "signature_position": [520, 520], "body_position": [521, 531], "dependency": {"intra_class": [], "intra_file": ["bentoml._internal.runner.container.Payload", "bentoml._internal.runner.container.DataContainer.create_payload"], "cross_file": []}, "requirement": {"Functionality": "This function converts a batch of data into a Payload object. It first checks if the batch is a generator and converts it into a list if necessary. Then, it serializes the batch using pickle. Finally, it determines the batch size and creates a Payload object with the serialized data and batch size.", "Arguments": ":param cls: DefaultContainer. The class itself.\n:param batch: Any. The batch of data to be converted.\n:param batch_dim: int. The dimension of the batch.\n:return: Payload. The created Payload object."}, "tests": ["tests/unit/_internal/runner/test_container.py::test_default_container"], "indent": 8}
{"namespace": "zxcvbn.time_estimates.estimate_attack_times", "type": "function", "project_path": "Security/zxcvbn-python", "completion_path": "Security/zxcvbn-python/zxcvbn/time_estimates.py", "signature_position": [3, 3], "body_position": [4, 19], "dependency": {"intra_class": [], "intra_file": ["zxcvbn.time_estimates.display_time", "zxcvbn.time_estimates.float_to_decimal", "zxcvbn.time_estimates.guesses_to_score"], "cross_file": []}, "requirement": {"Functionality": "Estimate the time it would take to crack a password based on the number of guesses. It calculates the crack times in seconds for different scenarios and converts them into a more readable format. It also calculates a score based on the number of guesses.", "Arguments": ":param guesses: The number of guesses to crack the password.\n:return: Dictionary. A dictionary containing the crack times in seconds for different scenarios, the crack times in a more readable format, and the score based on the number of guesses."}, "tests": ["tests/time_estimates_test.py::test_long_ints_dont_overflow"], "indent": 4}
{"namespace": "datasette.facets.DateFacet.facet_results", "type": "method", "project_path": "Database/datasette", "completion_path": "Database/datasette/datasette/facets.py", "signature_position": [503, 503], "body_position": [504, 568], "dependency": {"intra_class": ["datasette.facets.DateFacet.type"], "intra_file": ["datasette.facets.Facet.database", "datasette.facets.Facet.ds", "datasette.facets.Facet.get_configs", "datasette.facets.Facet.get_facet_size", "datasette.facets.Facet.get_querystring_pairs", "datasette.facets.Facet.params", "datasette.facets.Facet.request", "datasette.facets.Facet.sql"], "cross_file": ["datasette.database.QueryInterrupted", "datasette.utils.escape_sqlite", "datasette.utils.path_with_added_args", "datasette.utils.path_with_removed_args", "datasette.app.Datasette.absolute_url", "datasette.app.Datasette.execute", "datasette.app.Datasette.setting"]}, "requirement": {"Functionality": "This function retrieves facet results for a DateFacet instance. It executes a SQL query to retrieve the facet values and their corresponding counts from the database. It then formats the results and returns them.", "Arguments": ":param self: DateFacet. An instance of the DateFacet class.\n:return: Tuple. A tuple containing two lists - facet_results and facets_timed_out. facet_results contains dictionaries representing each facet value, its count, and other information. facets_timed_out contains the names of facets that timed out during execution."}, "tests": ["tests/test_facets.py::test_date_facet_results"], "indent": 8}
{"namespace": "alembic.config.Config.set_section_option", "type": "method", "project_path": "Database/alembic", "completion_path": "Database/alembic/alembic/config.py", "signature_position": [276, 276], "body_position": [296, 298], "dependency": {"intra_class": ["alembic.config.Config.file_config"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function sets an option programmatically within a specific section of a configuration file. If the section does not exist, it creates the section. The value provided will override any existing value in the configuration file.", "Arguments": ":param self: Config. An instance of the Config class.\n:param section: str. The name of the section in the configuration file.\n:param name: str. The name of the value to be set.\n:param value: str. The value to be set. This value supports variable interpolation using pyformat. A raw percent sign not part of an interpolation symbol must be escaped with another percent sign. The given value may refer to another value already in the file using the interpolation format.\n:return: None."}, "tests": ["tests/test_config.py::ConfigTest::test_config_no_file_section_option", "tests/test_config.py::ConfigTest::test_config_set_section_option_interpolation", "tests/test_config.py::ConfigTest::test_config_set_section_option_percent"], "indent": 8}
{"namespace": "msticpy.analysis.anomalous_sequence.model.Model.compute_scores", "type": "method", "project_path": "Security/msticpy", "completion_path": "Security/msticpy/msticpy/analysis/anomalous_sequence/model.py", "signature_position": [131, 131], "body_position": [156, 167], "dependency": {"intra_class": ["msticpy.analysis.anomalous_sequence.model.Model.compute_geomean_lik_of_sessions", "msticpy.analysis.anomalous_sequence.model.Model.compute_likelihoods_of_sessions", "msticpy.analysis.anomalous_sequence.model.Model.compute_rarest_windows", "msticpy.analysis.anomalous_sequence.model.Model.prior_probs"], "intra_file": [], "cross_file": ["msticpy.common.exceptions.MsticpyException"]}, "requirement": {"Functionality": "This function computes various likelihood-based scores/metrics for each session in the model. It calculates the likelihoods and geometric mean of the likelihoods for each session. It also uses a sliding window approach to compute the rarest window likelihoods for each session, with window lengths of 2 and 3.\nNote that if a session has a length of k and a sliding window of length k+1 is used, the rarest window likelihood metric for that session will be np.nan. However, if the parameter `use_start_end_tokens` is set to True, the session will be treated as a session of length k+1 because the start and end tokens will be appended, resulting in a non np.nan value for that session.", "Arguments": ":param self: Model. An instance of the Model class.\n:param use_start_end_tokens: Bool. If True, the start and end tokens will be prepended and appended to each session respectively before the calculations are done.\n:return: No return values."}, "tests": ["tests/analysis/test_anom_seq_model.py::TestModel::test_compute_scores"], "indent": 8}
{"namespace": "ydata_profiling.model.pandas.discretize_pandas.Discretizer.discretize_dataframe", "type": "method", "project_path": "Software-Development/pandas-profiling", "completion_path": "Software-Development/pandas-profiling/src/ydata_profiling/model/pandas/discretize_pandas.py", "signature_position": [38, 38], "body_position": [48, 61], "dependency": {"intra_class": ["ydata_profiling.model.pandas.discretize_pandas.Discretizer._discretize_column", "ydata_profiling.model.pandas.discretize_pandas.Discretizer._get_numerical_columns", "ydata_profiling.model.pandas.discretize_pandas.Discretizer.reset_index"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function takes a pandas DataFrame as input and discretizes the numerical columns in the DataFrame. It creates a copy of the input DataFrame and applies the discretization process to each numerical column. The discretized DataFrame is then returned.", "Arguments": ":param self: Discretizer. An instance of the Discretizer class.\n:param dataframe: pd.DataFrame. The input pandas DataFrame.\n:return: pd.DataFrame. The discretized DataFrame."}, "tests": ["tests/unit/test_pandas/test_discretize.py::test_mixed_discretization", "tests/unit/test_pandas/test_discretize.py::test_discretize_uniform", "tests/unit/test_pandas/test_discretize.py::test_discretize_quantile"], "indent": 8}
{"namespace": "mopidy.internal.validation.check_uris", "type": "function", "project_path": "Multimedia/Mopidy", "completion_path": "Multimedia/Mopidy/mopidy/internal/validation.py", "signature_position": [129, 129], "body_position": [130, 131], "dependency": {"intra_class": [], "intra_file": ["mopidy.internal.validation._check_iterable"], "cross_file": []}, "requirement": {"Functionality": "This function checks if the input argument is a list of URIs. If it is not, it raises an exception with a custom error message. It then iterates over each URI in the list and calls the check_uri function to validate each URI.", "Arguments": ":param arg: Any. The input argument to be checked.\n:param msg: String. The custom error message to be displayed if the input argument is not a list of URIs. It defaults to \"Expected a list of URIs, not {arg!r}\".\n:return: No return values."}, "tests": ["tests/internal/test_validation.py::test_check_uris_error_message", "tests/internal/test_validation.py::test_check_uris_with_invalid_values"], "indent": 4}
{"namespace": "msticpy.analysis.anomalous_sequence.utils.cmds_params_only.compute_likelihood_windows_in_session", "type": "function", "project_path": "Security/msticpy", "completion_path": "Security/msticpy/msticpy/analysis/anomalous_sequence/utils/cmds_params_only.py", "signature_position": [319, 329], "body_position": [368, 404], "dependency": {"intra_class": [], "intra_file": ["msticpy.analysis.anomalous_sequence.utils.cmds_params_only.compute_likelihood_window"], "cross_file": ["msticpy.analysis.anomalous_sequence.utils.data_structures.Cmd", "msticpy.analysis.anomalous_sequence.utils.data_structures.StateMatrix", "msticpy.common.exceptions.MsticpyException"]}, "requirement": {"Functionality": "This function computes the likelihoods of a sliding window in a session. It takes a session, prior probabilities, transition probabilities, parameter conditional command probabilities, window length, start and end tokens, and a flag to indicate whether to use geometric mean. It iterates through the session and calculates the likelihood for each sliding window. If the use_geo_mean flag is set to True, it raises each likelihood to the power of (1/window_len) before appending it to the list of likelihoods.", "Arguments": ":param session: List[Cmd]. A list of Cmd objects representing a session.\n:param prior_probs: Union[StateMatrix, dict]. Computed probabilities of individual commands.\n:param trans_probs: Union[StateMatrix, dict]. Computed probabilities of sequences of commands (length 2).\n:param param_cond_cmd_probs: Union[StateMatrix, dict]. Computed probabilities of the parameters conditional on the command.\n:param window_len: int. The length of the sliding window for likelihood calculations.\n:param use_start_end_tokens: bool. If True, start and end tokens will be prepended and appended to the session respectively before the calculations are done.\n:param start_token: str. A dummy command to signify the start of the session. Defaults to None.\n:param end_token: str. A dummy command to signify the end of the session. Defaults to None.\n:param use_geo_mean: bool. If True, each likelihood of the sliding windows will be raised to the power of (1/window_len).\n:return: List[float]. A list of likelihoods."}, "tests": ["tests/analysis/test_anom_seq_cmds_params_only.py::TestCmdsParamsOnly::test_compute_likelihood_windows_in_session"], "indent": 4}
{"namespace": "barf.arch.emulator.Emulator.load_binary", "type": "method", "project_path": "Security/barf", "completion_path": "Security/barf/barf/arch/emulator.py", "signature_position": [369, 369], "body_position": [370, 382], "dependency": {"intra_class": ["barf.arch.emulator.Emulator._load_binary_elf", "barf.arch.emulator.Emulator._load_binary_pe"], "intra_file": [], "cross_file": ["barf.core.binary.BinaryFile.filename"]}, "requirement": {"Functionality": "This function reads a binary file and determines its format based on the file signature. If it is b'\\x7fELF', it is an ELF file; if it is b'MZ', it is a PE file. It then calls the corresponding private method to further process the binary file. If there is error during reading, it raises an exception with the message \"Error loading file.\" If the file format is not recognized, it raises an exception with the message \"Unknown file format.\"", "Arguments": ":param self: Emulator. An instance of the Emulator class.\n:param binary: The binary file to load.\n:return: No return values."}, "tests": ["tests/arch/test_emulator.py::EmulatorTests::test_emulate_x86_64", "tests/arch/test_emulator.py::EmulatorTests::test_emulate_x86"], "indent": 8}
{"namespace": "boltons.urlutils.URL.path", "type": "method", "project_path": "Utilities/boltons", "completion_path": "Utilities/boltons/boltons/urlutils.py", "signature_position": [586, 586], "body_position": [587, 589], "dependency": {"intra_class": ["boltons.urlutils.URL.path_parts"], "intra_file": ["boltons.urlutils.to_unicode"], "cross_file": []}, "requirement": {"Functionality": "This function splits the given path into its components and caches the result. It splits the path_text by '/' and unquotes each part if it contains '%'.", "Arguments": ":param self: URL. An instance of the URL class.\n:param path_text: str. The path text to be processed.\n:return: No return values."}, "tests": ["tests/test_urlutils.py::test_netloc_slashes"], "indent": 8}
{"namespace": "exodus_bundler.launchers.construct_bash_launcher", "type": "function", "project_path": "System/exodus-bundler", "completion_path": "System/exodus-bundler/src/exodus_bundler/launchers.py", "signature_position": [93, 93], "body_position": [94, 98], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["exodus_bundler.templating.render_template_file"]}, "requirement": {"Functionality": "Construct a bash launcher script based on the given parameters. It creates a bash launcher script by rendering a template file with the provided parameters.", "Arguments": ":param linker: String. The path to the linker executable.\n:param library_path: String. The path to the library.\n:param executable: String. The path to the executable.\n:param full_linker: Bool. Whether to use the full linker path. Defaults to True.\n:return: String. The constructed bash launcher script."}, "tests": ["tests/test_launchers.py::test_construct_bash_launcher"], "indent": 4}
{"namespace": "benedict.dicts.keylist.keylist_util.set_item", "type": "function", "project_path": "Text-Processing/python-benedict", "completion_path": "Text-Processing/python-benedict/benedict/dicts/keylist/keylist_util.py", "signature_position": [69, 69], "body_position": [70, 80], "dependency": {"intra_class": [], "intra_file": ["benedict.dicts.keylist.keylist_util._get_or_new_item_value", "benedict.dicts.keylist.keylist_util._set_item_value"], "cross_file": []}, "requirement": {"Functionality": "This function sets a value in a nested dictionary based on a list of keys. It iterates through the keys and checks if each key exists in the dictionary. If a key does not exist, it creates a new dictionary and assigns it as the value for that key. Finally, it sets the desired value in the last nested dictionary.", "Arguments": ":param d: Dictionary. The dictionary in which to set the value.\n:param keys: List of keys. The list of keys representing the nested structure in the dictionary.\n:param value: Any. The value to be set in the nested dictionary.\n:return: None."}, "tests": ["tests/dicts/keylist/test_keylist_util.py::keylist_util_test_case::test_set_item_with_indexes"], "indent": 4}
{"namespace": "pythonforandroid.graph.get_recipe_order_and_bootstrap", "type": "function", "project_path": "Utilities/python-for-android", "completion_path": "Utilities/python-for-android/pythonforandroid/graph.py", "signature_position": [243, 244], "body_position": [245, 343], "dependency": {"intra_class": [], "intra_file": ["pythonforandroid.graph.RecipeOrder", "pythonforandroid.graph.RecipeOrder.__init__", "pythonforandroid.graph.find_order", "pythonforandroid.graph.fix_deplist", "pythonforandroid.graph.get_recipe_order_and_bootstrap", "pythonforandroid.graph.obvious_conflict_checker", "pythonforandroid.graph.recursively_collect_orders"], "cross_file": ["pythonforandroid.bootstrap.Bootstrap", "pythonforandroid.bootstrap.Bootstrap.get_bootstrap_from_recipes", "pythonforandroid.logger.info", "pythonforandroid.recipe.Recipe", "pythonforandroid.recipe.Recipe.get_recipe", "pythonforandroid.util.BuildInterruptingException"]}, "requirement": {"Functionality": "This function takes in a context, a list of recipe/dependency names, an optional bootstrap instance, and an optional blacklist. It performs various operations on the input names to clean them up and add bootstrap dependencies. It then checks for conflicts and generates all possible order graphs based on the names. It converts each order graph into a linear list and sorts them based on preference. Finally, it returns the chosen order, along with the corresponding recipes, python modules, and bootstrap instance.", "Arguments": ":param ctx: The context in which the function is being called.\n:param names: List of strings. The recipe/dependency names.\n:param bs: Bootstrap instance. An optional bootstrap instance. Defaults to None.\n:param blacklist: Set of strings. An optional set of names to be blacklisted. Defaults to None.\n:return: Tuple. The chosen order of dependencies, the corresponding recipes, python modules, and bootstrap instance."}, "tests": ["tests/test_graph.py::test_bootstrap_dependency_addition2", "tests/test_graph.py::test_bootstrap_dependency_addition", "tests/test_graph.py::test_invalid_recipe_order_and_bootstrap", "tests/test_graph.py::test_blacklist"], "indent": 4}
{"namespace": "fs.path.splitext", "type": "function", "project_path": "System/fs", "completion_path": "System/fs/fs/path.py", "signature_position": [321, 322], "body_position": [340, 347], "dependency": {"intra_class": [], "intra_file": ["fs.path.join", "fs.path.split"], "cross_file": []}, "requirement": {"Functionality": "This function splits the extension from a given path. It separates the path and the extension and returns them as a tuple.", "Arguments": ":param path: Text. The path to split.\n:return: Tuple[Text, Text]. A tuple containing the path and the extension."}, "tests": ["tests/test_path.py::TestPathFunctions::test_splitext"], "indent": 4}
{"namespace": "mopidy.http.Extension.get_default_config", "type": "method", "project_path": "Multimedia/Mopidy", "completion_path": "Multimedia/Mopidy/mopidy/http/__init__.py", "signature_position": [16, 16], "body_position": [17, 18], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["mopidy.config.read", "mopidy.config"]}, "requirement": {"Functionality": "This function retrieves the default configuration for the Extension class. It reads the configuration file \"ext.conf\" located in the same directory as the script and returns the configuration data.", "Arguments": ":param self: Extension. An instance of the Extension class.\n:return: dict. The default configuration data read from the \"ext.conf\" file."}, "tests": ["tests/http/test_extension.py::test_default_config_is_valid", "tests/http/test_extension.py::test_get_default_config"], "indent": 8}
{"namespace": "zulipterminal.ui_tools.buttons.TopButton.update_count", "type": "method", "project_path": "Communications/zulip-term", "completion_path": "Communications/zulip-term/zulipterminal/ui_tools/buttons.py", "signature_position": [58, 58], "body_position": [59, 67], "dependency": {"intra_class": ["zulipterminal.ui_tools.buttons.TopButton.count", "zulipterminal.ui_tools.buttons.TopButton.count_style", "zulipterminal.ui_tools.buttons.TopButton.original_color", "zulipterminal.ui_tools.buttons.TopButton.update_widget"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Update the count value and text color of a TopButton instance. It first determines the new text color based on the input parameters. Then, it updates the count value and generates the count text based on the count value. Finally, it calls the corresponding method to update the widget with the new count style and count text.", "Arguments": ":param self: TopButton. An instance of the TopButton class.\n:param count: int. The new count value to be updated.\n:param text_color: Optional[str]. The new text color to be updated. Defaults to None.\n:return: No return values."}, "tests": ["tests/ui_tools/test_buttons.py::TestTopButton::test_update_count"], "indent": 8}
{"namespace": "boto.ec2.autoscale.connect_to_region", "type": "function", "project_path": "Internet/boto", "completion_path": "Internet/boto/boto/ec2/autoscale/__init__.py", "signature_position": [64, 64], "body_position": [75, 77], "dependency": {"intra_class": [], "intra_file": ["boto.ec2.autoscale.AutoScaleConnection"], "cross_file": ["boto.regioninfo.connect"]}, "requirement": {"Functionality": "Connect to a specific region and return an instance of the AutoScaleConnection class.", "Arguments": ":param region_name: String. The name of the region to connect to.\n:param kw_params: Additional keyword arguments that can be passed to the connect function.\n:return: AutoScaleConnection or None. A connection to the specified region, or None if an invalid region name is given."}, "tests": ["tests/unit/test_connect_to_region.py::TestAutoscaleConnection::test_connect_to_region"], "indent": 4}
{"namespace": "mrjob.hadoop.HadoopJobRunner._stream_task_log_dirs", "type": "method", "project_path": "System/mrjob", "completion_path": "System/mrjob/mrjob/hadoop.py", "signature_position": [557, 557], "body_position": [562, 573], "dependency": {"intra_class": ["mrjob.hadoop.HadoopJobRunner._hadoop_log_dirs", "mrjob.hadoop.HadoopJobRunner.fs"], "intra_file": ["mrjob.hadoop.log"], "cross_file": ["mrjob.fs.composite.CompositeFilesystem.join", "mrjob.logs.mixin.LogInterpretationMixin._read_logs", "mrjob.logs.wrap._logs_exist", "mrjob.util.unique"]}, "requirement": {"Functionality": "This function yields lists of directories to look for task logs in. It first checks if reading logs is enabled. Then, it iterates over unique log directories obtained from the hadoop log directories. For each log directory, it constructs a path based on the application ID: '{log dir}/userlogs/{application id}' if the application ID is available, otherwise '{log dir}/userlogs'. It then logs an info message: 'Looking for task logs in {directory}...'. It then yields a list containing the directory.", "Arguments": ":param self: HadoopJobRunner. An instance of the HadoopJobRunner class.\n:param application_id: str. The ID of the application for which task logs are to be retrieved. Defaults to None.\n:param output_dir: str. The output directory where logs are stored. Defaults to None.\n:return: List of directories. A list of directories to look for task logs in."}, "tests": ["tests/test_hadoop.py::StreamTaskLogDirsTestCase::test_basic", "tests/test_hadoop.py::StreamTaskLogDirsTestCase::test_io_error_from_fs_exists", "tests/test_hadoop.py::StreamTaskLogDirsTestCase::test_application_id", "tests/test_hadoop.py::StreamTaskLogDirsTestCase::test_no_read_logs", "tests/test_hadoop.py::StreamTaskLogDirsTestCase::test_fs_exists"], "indent": 8}
{"namespace": "boltons.iterutils.get_path", "type": "function", "project_path": "Utilities/boltons", "completion_path": "Utilities/boltons/boltons/iterutils.py", "signature_position": [1221, 1221], "body_position": [1254, 1278], "dependency": {"intra_class": [], "intra_file": ["boltons.iterutils.PathAccessError", "boltons.iterutils.PathAccessError.__init__", "boltons.iterutils._UNSET", "boltons.iterutils.basestring", "boltons.iterutils.is_iterable"], "cross_file": []}, "requirement": {"Functionality": "This function retrieves a value from a nested object using a tuple as the lookup path.  If the lookup fails at any level, a default value can be specified to be returned instead. This function also improves error messaging by providing specific information about the error that occurred during the lookup.\n", "Arguments": ":param root: The target nested object, can be dictionaries, lists, or other objects that support the `__getitem__` method.\n:param path: Tuple. A list of strings and integers representing the lookup path within the nested object.\n:param default: Any data type. The value to be returned if any `PathAccessError` exceptions are raised during the lookup. Defaults to _UNSET.\n:return: The value retrieved from the nested object using the specified lookup path. If the lookup fails and a default value is provided, the default value will be returned, or else the exception will be re-raised.\n"}, "tests": ["tests/test_iterutils.py::TestGetPath::test_depth_one", "tests/test_iterutils.py::TestGetPath::test_depth_two"], "indent": 4}
{"namespace": "mopidy.config.types.Float.deserialize", "type": "method", "project_path": "Multimedia/Mopidy", "completion_path": "Multimedia/Mopidy/mopidy/config/types.py", "signature_position": [175, 175], "body_position": [176, 183], "dependency": {"intra_class": ["mopidy.config.types.Float._maximum", "mopidy.config.types.Float._minimum", "mopidy.config.types.Float._required"], "intra_file": ["mopidy.config.types.decode"], "cross_file": ["mopidy.config.validators.validate_maximum", "mopidy.config.validators.validate_minimum", "mopidy.config.validators.validate_required", "mopidy.config.validators"]}, "requirement": {"Functionality": "Deserialize a value into a float. It decodes the input value, validates if it is required, and converts it into a float. It then validates if the float value meets the minimum and maximum constraints.", "Arguments": ":param self: Float. An instance of the Float class.\n:param value: The value to be deserialized into a float.\n:return: The deserialized float value."}, "tests": ["tests/config/test_types.py::TestFloat::test_deserialize_enforces_maximum", "tests/config/test_types.py::TestFloat::test_deserialize_conversion_failure", "tests/config/test_types.py::TestFloat::test_deserialize_enforces_required", "tests/config/test_types.py::TestFloat::test_deserialize_enforces_minimum", "tests/config/test_types.py::TestFloat::test_deserialize_conversion_success"], "indent": 8}
{"namespace": "boto.s3.website.RoutingRules.to_xml", "type": "method", "project_path": "Internet/boto", "completion_path": "Internet/boto/boto/s3/website.py", "signature_position": [167, 167], "body_position": [168, 171], "dependency": {"intra_class": ["boto.s3.website.RoutingRules.to_xml"], "intra_file": ["boto.s3.website.tag"], "cross_file": []}, "requirement": {"Functionality": "Convert the RoutingRules instance to an XML string representation.", "Arguments": ":param self: RoutingRules. An instance of the RoutingRules class.\n:return: String. The XML representation of the RoutingRules instance."}, "tests": ["tests/unit/s3/test_website.py::TestS3WebsiteConfiguration::test_builders"], "indent": 8}
{"namespace": "bentoml._internal.runner.container.PandasDataFrameContainer.from_payload", "type": "method", "project_path": "Scientific-Engineering/bentoml", "completion_path": "Scientific-Engineering/bentoml/src/bentoml/_internal/runner/container.py", "signature_position": [418, 421], "body_position": [422, 428], "dependency": {"intra_class": [], "intra_file": ["bentoml._internal.runner.container.Payload"], "cross_file": ["bentoml._internal.runner.container.Payload.data", "bentoml._internal.runner.container.Payload.meta", "bentoml._internal.utils.pickle.pep574_loads", "bentoml._internal.external_typing"]}, "requirement": {"Functionality": "This function creates a Pandas DataFrame container from the given payload. If the payload contains a buffer, it decodes the buffer and uses it along with other metadata to create the DataFrame. If the payload does not contain a buffer, it creates the DataFrame directly from the payload data.", "Arguments": ":param cls: Class. The class object.\n:param payload: Payload. The payload containing the data and metadata for creating the DataFrame.\n:return: ext.PdDataFrame. The created Pandas DataFrame."}, "tests": ["tests/unit/_internal/runner/test_container.py::test_pandas_container"], "indent": 8}
{"namespace": "mrjob.setup.UploadDirManager.add", "type": "method", "project_path": "System/mrjob", "completion_path": "System/mrjob/mrjob/setup.py", "signature_position": [314, 314], "body_position": [319, 330], "dependency": {"intra_class": ["mrjob.setup.UploadDirManager._names_taken", "mrjob.setup.UploadDirManager._path_to_name", "mrjob.setup.UploadDirManager.uri"], "intra_file": ["mrjob.setup.name_uniquely"], "cross_file": ["mrjob.parse.is_uri"]}, "requirement": {"Functionality": "This function adds a path to the UploadDirManager instance. If the path has not been added before, it assigns it a name and ensures the file will not be hidden. If the path is a URI, it does not add it and just returns the URI.", "Arguments": ":param self: UploadDirManager. An instance of the UploadDirManager class.\n:param path: The path to be added.\n:return: The URI assigned to the path."}, "tests": ["tests/test_setup.py::UploadDirManagerTestCase::test_underscores_only", "tests/test_setup.py::UploadDirManagerTestCase::test_dot_underscore", "tests/test_setup.py::UploadDirManagerTestCase::test_name_collision", "tests/test_setup.py::UploadDirManagerTestCase::test_uri", "tests/test_setup.py::UploadDirManagerTestCase::test_hidden_file_name_collision"], "indent": 8}
{"namespace": "pyramid.predicates.CustomPredicate.text", "type": "method", "project_path": "Internet/pyramid", "completion_path": "Internet/pyramid/src/pyramid/predicates.py", "signature_position": [210, 210], "body_position": [211, 216], "dependency": {"intra_class": ["pyramid.predicates.CustomPredicate.func", "pyramid.predicates.CustomPredicate.__text__"], "intra_file": [], "cross_file": ["pyramid.util.object_description"]}, "requirement": {"Functionality": "This function returns the text representation of the CustomPredicate instance. If the '__text__' is present in the instance's function, it is returned. Otherwise, a default text is returned which includes the description of the function.", "Arguments": ":param self: CustomPredicate. An instance of the CustomPredicate class.\n:return: String. The text representation of the CustomPredicate instance."}, "tests": ["tests/test_predicates.py::TestCustomPredicate::test_text_func_has___text__", "tests/test_predicates.py::TestCustomPredicate::test_text_func_repr"], "indent": 8}
{"namespace": "fs.info.Info.suffix", "type": "method", "project_path": "System/fs", "completion_path": "System/fs/fs/info.py", "signature_position": [207, 208], "body_position": [222, 226], "dependency": {"intra_class": ["fs.info.Info.get"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function returns the suffix of a file name. It checks if the file name has a suffix and returns it. If there is no suffix, it returns an empty string.", "Arguments": ":param self: Info. An instance of the Info class.\n:return: Text. The suffix of the file name, including the dot."}, "tests": ["tests/test_info.py::TestInfo::test_suffix", "tests/test_info.py::TestInfo::test_basic"], "indent": 8}
{"namespace": "viztracer.report_builder.ReportBuilder.save", "type": "method", "project_path": "System/viztracer", "completion_path": "System/viztracer/src/viztracer/report_builder.py", "signature_position": [172, 172], "body_position": [173, 193], "dependency": {"intra_class": ["viztracer.report_builder.ReportBuilder.final_messages", "viztracer.report_builder.ReportBuilder.generate_report", "viztracer.report_builder.ReportBuilder.print_messages"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function saves the report generated by the ReportBuilder instance to an output file. It supports saving the report in different formats such as HTML, JSON, and GZ. If the output_file parameter is a string, it determines the file format based on the file extension and saves the report accordingly. If the output_file parameter is a file object, it saves the report directly to that file. After saving the report, it appends a message to the message list indicating the command to view the saved report and then prints all the messages. The format of the message is \"('view_command', {'output_file': the absolute path of output file})\"", "Arguments": ":param self: ReportBuilder. An instance of the ReportBuilder class.\n:param output_file: Union[str, TextIO]. The output file where the report will be saved. It can be either a string representing the file path or a file object. Defaults to \"result.html\".\n:param file_info: bool. Whether to include file information in the report. Defaults to True.\n:return: No return values."}, "tests": ["tests/test_report_builder.py::TestReportBuilder::test_combine", "tests/test_report_builder.py::TestReportBuilder::test_invalid"], "indent": 8}
{"namespace": "bplustree.tree.BPlusTree._root_node", "type": "method", "project_path": "Database/bplustree", "completion_path": "Database/bplustree/bplustree/tree.py", "signature_position": [272, 272], "body_position": [273, 275], "dependency": {"intra_class": ["bplustree.tree.BPlusTree.LonelyRootNode", "bplustree.tree.BPlusTree.RootNode", "bplustree.tree.BPlusTree._mem", "bplustree.tree.BPlusTree._root_node_page"], "intra_file": [], "cross_file": ["bplustree.memory.FileMemory.get_node"]}, "requirement": {"Functionality": "This function retrieves the root node from memory.", "Arguments": ":param self: BPlusTree. An instance of the BPlusTree class.\n:return: Union['LonelyRootNode', 'RootNode']. The root node of the BPlusTree instance."}, "tests": ["tests/test_tree.py::test_left_record_node_in_tree"], "indent": 8}
{"namespace": "pyinfra.api.operation.add_op", "type": "function", "project_path": "System/pyinfra", "completion_path": "System/pyinfra/pyinfra/api/operation.py", "signature_position": [85, 85], "body_position": [96, 115], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["pyinfra.api.exceptions.PyinfraError", "pyinfra.api.host.Host", "pyinfra.api.inventory.Inventory.iter_active_hosts", "pyinfra.api.state.State", "pyinfra.api.state.State.inventory", "pyinfra.api.util.get_call_location", "pyinfra.context.ctx_host", "pyinfra.context.ctx_state", "pyinfra.is_cli", "pyinfra.context.ContextManager.use"]}, "requirement": {"Functionality": "This function prepares and adds an operation to the input `pyinfra.State` instance by executing it on all hosts. It takes the operation function and its arguments as input and executes the function on each host.", "Arguments": ":param state: State. An instance of the pyinfra.State class. The deploy state to add the operation to.\n:param op_func: function. The operation function from one of the modules, such as `server.user`.\n:param args/kwargs: Additional arguments passed to the operation function.\n:return: No return values."}, "tests": ["tests/test_api/test_api_operations.py::TestOperationsApi::test_rsync_op", "tests/test_api/test_api_operations.py::TestOperationsApi::test_rsync_op_failure", "tests/test_api/test_api_operations.py::TestOperationsApi::test_op_cannot_change_execution_kwargs", "tests/test_api/test_api_operations.py::TestOperationsApi::test_rsync_op_with_strict_host_key_checking_disabled", "tests/test_api/test_api_operations.py::TestOperationsApi::test_file_upload_op"], "indent": 4}
{"namespace": "pyramid.config.Configurator.begin", "type": "method", "project_path": "Internet/pyramid", "completion_path": "Internet/pyramid/src/pyramid/config/__init__.py", "signature_position": [754, 754], "body_position": [772, 778], "dependency": {"intra_class": ["pyramid.config.Configurator.manager", "pyramid.config.Configurator.registry"], "intra_file": ["pyramid.config._marker"], "cross_file": ["pyramid.threadlocal.ThreadLocalManager.get", "pyramid.threadlocal.ThreadLocalManager.push"]}, "requirement": {"Functionality": "This function is used to indicate that application or test configuration has begun. It pushes a dictionary containing the application registry and the request onto the thread local stack. If request is not specified and the registry owned by the configurator is already pushed as the current threadlocal registry then this method will keep the current threadlocal request unchanged.", "Arguments": ":param self: Configurator. An instance of the Configurator class.\n:param request: The request to be pushed onto the thread local stack. Defaults to _marker.\n:return: No return values."}, "tests": ["tests/test_config/test_init.py::ConfiguratorTests::test_begin_overrides_request", "tests/test_config/test_init.py::ConfiguratorTests::test_begin_with_request", "tests/test_config/test_init.py::ConfiguratorTests::test_begin_does_not_propagate_request_for_diff_registry", "tests/test_config/test_init.py::ConfiguratorTests::test_begin", "tests/test_testing.py::TestDummyRequest::test_del_registry"], "indent": 8}
{"namespace": "discord.utils.resolve_annotation", "type": "function", "project_path": "Software-Development/discord-py", "completion_path": "Software-Development/discord-py/discord/utils.py", "signature_position": [1161, 1166], "body_position": [1167, 1175], "dependency": {"intra_class": [], "intra_file": ["discord.utils.evaluate_annotation"], "cross_file": []}, "requirement": {"Functionality": "This function resolves the given annotation by evaluating it based on the provided global and local namespaces. It first checks if the annotation is None and returns type(None) if it is. Then, it checks if the annotation is a string and converts it to a ForwardRef object. Next, it determines the namespace to use (global or local) and initializes a cache if it is not provided. Finally, it evaluates the annotation and returns the result.", "Arguments": ":param annotation: Any. The annotation to resolve.\n:param globalns: Dict[str, Any]. The global namespace to use for evaluation.\n:param localns: Optional[Dict[str, Any]]. The local namespace to use for evaluation. Defaults to None.\n:param cache: Optional[Dict[str, Any]]. The cache to use for storing evaluated annotations. Defaults to None.\n:return: Any. The resolved annotation."}, "tests": ["tests/test_utils.py::test_resolve_annotation", "tests/test_utils.py::test_resolve_annotation_with_cache", "tests/test_utils.py::test_resolve_annotation_optional_normalisation"], "indent": 4}
{"namespace": "pyramid.registry.Introspectable.__repr__", "type": "method", "project_path": "Internet/pyramid", "completion_path": "Internet/pyramid/src/pyramid/registry.py", "signature_position": [240, 240], "body_position": [241, 246], "dependency": {"intra_class": ["pyramid.registry.Introspectable._assert_resolved", "pyramid.registry.Introspectable.category_name", "pyramid.registry.Introspectable.discriminator"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "It returns a string representation of the instance, including the type name, the category name and discriminator, with the format '<%s category %r, discriminator %r>'.", "Arguments": ":param self: Introspectable. An instance of the Introspectable class.\n:return: str. The string representation of the instance, including the category name and discriminator."}, "tests": ["tests/test_registry.py::TestIntrospectable::test___repr__"], "indent": 8}
{"namespace": "mopidy.models.immutable.ValidatedImmutableObject.replace", "type": "method", "project_path": "Multimedia/Mopidy", "completion_path": "Multimedia/Mopidy/mopidy/models/immutable.py", "signature_position": [195, 195], "body_position": [214, 219], "dependency": {"intra_class": [], "intra_file": ["mopidy.models.immutable.ImmutableObject", "mopidy.models.immutable.ImmutableObject.replace"], "cross_file": []}, "requirement": {"Functionality": "This function replaces the fields in the ValidatedImmutableObject instance with new values and returns a new instance with the updated fields. It also memoizes the instances to optimize memory usage.", "Arguments": ":param self: ValidatedImmutableObject. An instance of the ValidatedImmutableObject class.\n:param kwargs: Keyword arguments to set as fields on the object.\n:return: ValidatedImmutableObject. An instance of the model with replaced fields."}, "tests": ["tests/models/test_models.py::PlaylistTest::test_with_new_last_modified", "tests/models/test_models.py::GenericReplaceTest::test_replace_track_with_missing_values", "tests/models/test_models.py::PlaylistTest::test_with_new_uri", "tests/models/test_models.py::GenericReplaceTest::test_replace_track", "tests/models/test_models.py::GenericReplaceTest::test_replace_playlist"], "indent": 8}
{"namespace": "prometheus_client.exposition.choose_encoder", "type": "function", "project_path": "System/prometheus-client", "completion_path": "System/prometheus-client/prometheus_client/exposition.py", "signature_position": [241, 241], "body_position": [242, 248], "dependency": {"intra_class": [], "intra_file": ["prometheus_client.exposition.CONTENT_TYPE_LATEST", "prometheus_client.exposition.generate_latest"], "cross_file": ["prometheus_client.openmetrics.exposition", "prometheus_client.openmetrics.exposition.CONTENT_TYPE_LATEST", "prometheus_client.openmetrics.exposition.generate_latest", "prometheus_client.registry.CollectorRegistry"]}, "requirement": {"Functionality": "This function chooses an encoder based on the accept header. It checks if the accept header contains \"application/openmetrics-text\" and returns the corresponding encoder and content type. If not found, it returns the default encoder and content type.", "Arguments": ":param accept_header: String. The accept header sent by the client.\n:return: Tuple. A tuple containing the chosen encoder and content type."}, "tests": ["tests/test_exposition.py::test_choose_encoder"], "indent": 4}
{"namespace": "fs.info.Info.created", "type": "method", "project_path": "System/fs", "completion_path": "System/fs/fs/info.py", "signature_position": [328, 329], "body_position": [339, 341], "dependency": {"intra_class": ["fs.info.Info._make_datetime", "fs.info.Info._require_namespace", "fs.info.Info.get"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function returns the creation time of a resource. It checks if the \"details\" namespace is present in the Info instance and raises an exception if it is not. It then retrieves the creation time from the \"details\" namespace and returns it.", "Arguments": ":param self: Info. An instance of the Info class.\n:return: Optional[datetime]. The creation time of the resource, or None if it is not available."}, "tests": ["tests/test_info.py::TestInfo::test_details"], "indent": 8}
{"namespace": "sumy.summarizers.edmundson.EdmundsonSummarizer.key_method", "type": "method", "project_path": "Internet/sumy", "completion_path": "Internet/sumy/sumy/summarizers/edmundson.py", "signature_position": [101, 101], "body_position": [102, 103], "dependency": {"intra_class": ["sumy.summarizers.edmundson.EdmundsonSummarizer._build_key_method_instance"], "intra_file": [], "cross_file": ["sumy.summarizers.edmundson_key.EdmundsonKeyMethod.__call__"]}, "requirement": {"Functionality": "This function applies the key method of summarization to a given document. It first builds an instance of the key method and then uses it to summarize the document by selecting a specified number of sentences based on their importance.", "Arguments": ":param self: EdmundsonSummarizer. An instance of the EdmundsonSummarizer class.\n:param document: Document. The document to be summarized.\n:param sentences_count: Integer. The number of sentences to be selected for the summary.\n:param weight: Float. The weight to be assigned to the key method. Defaults to 0.5.\n:return: Tuple. The summarized text."}, "tests": ["tests/test_summarizers/test_edmundson.py::test_key_3", "tests/test_summarizers/test_edmundson.py::test_key_1", "tests/test_summarizers/test_edmundson.py::test_key_empty", "tests/test_summarizers/test_edmundson.py::test_key_2", "tests/test_summarizers/test_edmundson.py::test_key_without_bonus_words"], "indent": 8}
{"namespace": "ydata_profiling.utils.cache.cache_file", "type": "function", "project_path": "Software-Development/pandas-profiling", "completion_path": "Software-Development/pandas-profiling/src/ydata_profiling/utils/cache.py", "signature_position": [9, 9], "body_position": [20, 30], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["ydata_profiling.utils.paths.get_data_path"]}, "requirement": {"Functionality": "This function checks if a file with the given name already exists in the data path. If it does not exist, it downloads the file from the provided URL and saves it in the data path.", "Arguments": ":param file_name: str. The name of the file.\n:param url: str. The URL of the dataset.\n:return: Path. The relative path to the downloaded file."}, "tests": ["tests/issues/test_issue416.py::test_issue416", "tests/unit/test_dataset_schema.py::test_dataset_schema_empty", "tests/unit/test_dataset_schema.py::test_dataset_schema"], "indent": 4}
{"namespace": "diffprivlib.tools.utils.var", "type": "function", "project_path": "Security/diffprivlib", "completion_path": "Security/diffprivlib/diffprivlib/tools/utils.py", "signature_position": [304, 305], "body_position": [358, 361], "dependency": {"intra_class": [], "intra_file": ["diffprivlib.tools.utils._var"], "cross_file": ["diffprivlib.utils.warn_unused_args"]}, "requirement": {"Functionality": "This function computes the differentially private variance of an array along the specified axis. It adds noise to the variance calculation to satisfy differential privacy. The function closely follows the behavior of the `numpy.var` function.", "Arguments": ":param array: array_like. An array containing numbers whose variance is desired.\n:param epsilon: float, default: 1.0. The privacy parameter epsilon.\n:param bounds: tuple, optional. Bounds of the values of the array, in the form (min, max).\n:param axis: int or tuple of ints, optional. The axis or axes along which the variance is computed. The default is to compute the variance of the flattened array.\n:param dtype: data-type, optional. The type to use in computing the variance.\n:param keepdims: bool, default: False. If True, the axes which are reduced are left in the result as dimensions with size one.\n:param random_state: int or RandomState, optional. Controls the randomness of the algorithm.\n:param accountant: BudgetAccountant, optional. An accountant to keep track of privacy budget.\n:param **unused_args: Should warn the user if any other parameters are passed.\n:return: ndarray. Returns a new array containing the variance."}, "tests": ["tests/tools/test_var.py::TestVar::test_no_bounds", "tests/tools/test_var.py::TestVar::test_no_params", "tests/tools/test_var.py::TestVar::test_clipped_output", "tests/tools/test_var.py::TestVar::test_missing_bounds", "tests/tools/test_var.py::TestVar::test_large_epsilon"], "indent": 4}
{"namespace": "boltons.ioutils.SpooledBytesIO.seek", "type": "method", "project_path": "Utilities/boltons", "completion_path": "Utilities/boltons/boltons/ioutils.py", "signature_position": [329, 329], "body_position": [330, 331], "dependency": {"intra_class": ["boltons.ioutils.SpooledBytesIO.buffer"], "intra_file": ["boltons.ioutils.SpooledIOBase._checkClosed"], "cross_file": []}, "requirement": {"Functionality": "This function seeks to a specified position in the SpooledBytesIO instance. It checks if the instance is closed and then seeks in the buffer.", "Arguments": ":param self: SpooledBytesIO. An instance of the SpooledBytesIO class.\n:param pos: int. The position to seek to.\n:param mode: int. The mode to use for seeking. Defaults to 0.\n:return: The result of the seek operation."}, "tests": ["tests/test_ioutils.py::TestSpooledBytesIO::test_iter"], "indent": 8}
{"namespace": "alembic.script.revision.RevisionMap.heads", "type": "method", "project_path": "Database/alembic", "completion_path": "Database/alembic/alembic/script/revision.py", "signature_position": [134, 134], "body_position": [143, 144], "dependency": {"intra_class": ["alembic.script.revision.RevisionMap._revision_map", "alembic.script.revision.RevisionMap.heads"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function first initializes the revision map and then returns all \"head\" revisions as strings.", "Arguments": ":param self: RevisionMap. An instance of the RevisionMap class.\n:return: A tuple of string revision numbers."}, "tests": ["tests/test_revision.py::APITest::test_add_revision_two_head", "tests/test_revision.py::MultipleBaseCrossDependencyTestTwo::test_what_are_the_heads", "tests/test_revision.py::MultipleBaseCrossDependencyTestOne::test_what_are_the_heads", "tests/test_revision.py::APITest::test_add_revision_one_head"], "indent": 8}
{"namespace": "mingus.core.keys.get_key_signature_accidentals", "type": "function", "project_path": "Multimedia/mingus", "completion_path": "Multimedia/mingus/mingus/core/keys.py", "signature_position": [94, 94], "body_position": [96, 106], "dependency": {"intra_class": [], "intra_file": ["mingus.core.keys.get_key_signature"], "cross_file": ["mingus.core.notes", "mingus.core.notes.fifths"]}, "requirement": {"Functionality": "This function returns a list of accidentals present in the key signature of a given key. It first determines the number of accidentals in the key signature. Then, it creates a list of accidentals based on the number of accidentals and the key.", "Arguments": ":param key: String. The key for which the key signature accidentals are to be determined. It defaults to \"C\" if not specified.\n:return: List of strings. The list of accidentals present in the key signature."}, "tests": ["tests/unit/core/test_keys.py::test_keys::test_get_key_signature_accidentals"], "indent": 4}
{"namespace": "mrjob.hadoop.fully_qualify_hdfs_path", "type": "function", "project_path": "System/mrjob", "completion_path": "System/mrjob/mrjob/hadoop.py", "signature_position": [108, 108], "body_position": [110, 116], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["mrjob.parse.is_uri"]}, "requirement": {"Functionality": "This function takes a path as input and returns a fully qualified HDFS path. If the input path is already an \"hdfs://\" URL, it is returned as is. If the input path starts with a \"/\", it is converted into an \"hdfs://\" URL by appending \"hdfs://\" to the beginning. If the input path does not start with a \"/\", it is converted into an \"hdfs://\" URL by appending \"hdfs:///user/{username}/{path}\" where {username} is the current user's username and {path} is the input path.", "Arguments": ":param path: str. The input path that needs to be converted into a fully qualified HDFS path.\n:return: str. The fully qualified HDFS path."}, "tests": ["tests/test_hadoop.py::TestFullyQualifyHDFSPath::test_s3n_uri", "tests/test_hadoop.py::TestFullyQualifyHDFSPath::test_s3a_uri", "tests/test_hadoop.py::TestFullyQualifyHDFSPath::test_other_uri", "tests/test_hadoop.py::TestFullyQualifyHDFSPath::test_empty", "tests/test_hadoop.py::TestFullyQualifyHDFSPath::test_hdfs_uri"], "indent": 4}
{"namespace": "boltons.tbutils.TracebackInfo.from_traceback", "type": "method", "project_path": "Utilities/boltons", "completion_path": "Utilities/boltons/boltons/tbutils.py", "signature_position": [292, 292], "body_position": [309, 322], "dependency": {"intra_class": ["boltons.tbutils.TracebackInfo.__init__", "boltons.tbutils.TracebackInfo.callpoint_type"], "intra_file": ["boltons.tbutils.Callpoint.from_tb"], "cross_file": []}, "requirement": {"Functionality": "Create a new TracebackInfo instance based on the given traceback. It retrieves the traceback from the currently handled exception or from the input parameter. It then recursively goes up the stack a maximum of *limit* times and creates a list of callpoint items. Finally, it returns the TracebackInfo instance with the list of callpoint items.", "Arguments": ":param cls: type. The class itself.\n:param tb: TracebackType. The traceback object. If not provided, it fins the traceback from the currently handled exception. If no exception is being handled, it raises a ValueError: 'no tb set and no exception being handled'. Defaults to None.\n:param limit: int. The maximum number of parent frames to extract. It defaults to system traceback limit if not provided. If that is not available, it defaults to 1000. Defaults to None.\n:return: TracebackInfo. The created TracebackInfo instance."}, "tests": ["tests/test_tbutils.py::test_exception_info"], "indent": 8}
